var suggestions=document.getElementById("suggestions"),search=document.getElementById("search");search!==null&&document.addEventListener("keydown",inputFocus);function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}document.addEventListener("click",function(e){var t=suggestions.contains(e.target);t||suggestions.classList.add("d-none")}),document.addEventListener("keydown",suggestionFocus);function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}(function(){var e=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/docs/prologue/introduction/",title:"Introduction",description:"Nutek Terminal is the only h@xor tool you will ever need.",content:`Get started # There is a one way you can start right away with Nutek Terminal. Until there will be iso files available Docker is the primary way to use it.
Docker Hub page for the latest, nutek-cent - Nutek Terminal distribution # 👉 If you never used Docker ever before, try to head over to their documentation. Docker documentation
The fresh nutek-cent from hub.docker.com. Here →
Quick Start # 👉 The Quick Start is intended for intermediate to advanced users. One page summary of how to start a new Nutek Terminal container. Quick Start →
Go further # Tools and other things, you will be using during you hacker journey.
Attack # List of tools, that you will be using to exploit vulnerebilitie during you bug bounties and ethical hacking. Attack →
Defend # List of tools to use to defend yourself - if you find it to short, don\u0026rsquo;t hesitate to create a pull request with new ones. Defend →
Knowledge # The only thing that push the world further, and the only thing you need to start is knowledge. Gather your intel and stay ahead of everyone else. Knowledge →
Utilities # I won\u0026rsquo;t let you on any journey without the help of many useful tools. Here they are: Utilities →
Contributing # If you want to contribute to any of the Nutek Terminal projects head on to GitHub and look for your choice in nutek-terminal organization, Contributing →, or if you wish to extend this page, head over to this repository.
Help # Get help on Nutek Terminal. Help →
`}),e.add({id:1,href:"/docs/prologue/",title:"Prologue",description:"Prologue Nutek Terminal.",content:""}),e.add({id:2,href:"/docs/tutorial/",title:"Tutorial",description:"Nutek Terminal tutorial.",content:""}),e.add({id:3,href:"/docs/tools/python-neovim/",title:"Python \u0026 Neovim",description:"Basic Python3 and Neovim usage example.",content:`language \u0026amp; text editor
What do you need to have? # Hej, today we begin learning with Nutek to be able to use it how I see it fit. First be sure you have one of the following:
neosb/nutek-core:0.4.0 from Docker Hub Nutek from crates.io or Github - working on a fix You could follow on with Python3, pip, venv and Neovim What you will learn? # I want to show you few Python use cases and how to write code in Neovim. We will use this in future lessons and hacking activities that will surely come to us as we go.
I\u0026rsquo;m not the only source of truth you should rely on, so try to bing-search (which is the part of Nutek) or use Google to look-up interesting parts and to broaden your knowledge.
Where to look for answers? # I give you some links that might help you in the beginning.
Neovim is compatible version of Vim which is Vi improved, it\u0026rsquo;s one of the basic text editor found on most of the UNIX-like operating systems, thus knowing how to use it is likely to payoff int the future :)
Neovim documentation Vim cheatsheet Vim cheatsheet #2 Vim tutorial open nvim in terminal and type :Tutor to open one of the first interactive tutorials out there that will teach you the basics of Neovim. Vim Plug minimalist plugin manager Awesome Vim plugins Python one of the most used programming languages, also one of the easiest to learn. So without bothering you with developers jargon\u0026hellip;
Documentation Tutorial PyPI - pip installable packages 3.. 2.. 1.. 🚀 # First of all, to start Neovim type nvim in your terminal, or if you are ready to edit a text file, type nvim my_first_python_script.py. .py extension tells nvim that it\u0026rsquo;s a Python file and if you use Nutek or nutek-core, after first start you will be given a chance to install coc-jedi which helps a lot with Python files. Keep pressing \u0026lt;Enter\u0026gt; untill it\u0026rsquo;s done. I have preinstalled there, for you too, Github Copilot, so just.
:Copilot setup inside Neovim, confirm your credentials on Github, and have a helping hand ready to assist you with AI generated snippets of code.
Now. To make the first script a little bit challenging, let\u0026rsquo;s use the my_first_python_script.py nvim window and write as follows.
:tabnew :terminal \u0026lt;i\u0026gt; python3 -c \u0026quot;print('Hej piękna!')\u0026quot;\u0026lt;Enter\u0026gt; In context of Vi, Vim and Neovim \u0026lt;i\u0026gt; means pressing the i keyboard key. There is a lot about text in operating systems, especially UNIX-es, where every part of the operating system is a text file and Windows sometimes even borrows the thinking, e.g. /etc/hosts/ file. To the UNIX system family belongs Linux flavours like Debian, Ubuntu, Mint, Arch, Fedora, openSUSE, Red Hat Enterprise Linux; macOS, BSD based systems, freeBSD, openBSD. For now we won\u0026rsquo;t be learning how to cope with OS, right now we want to write something, then we might know how to do something with operating system in terminal and in scripts.
Back on track. You should see now a response from your terminal saying to you Hello beauty in Polish. We used python3 and a switch -c which tells Python to run the code in between quotes. This is called an inline script. Now please press:
\u0026lt;C-\\\u0026gt; \u0026lt;C-n\u0026gt; It will exit terminal mode and let you operate Neovim normally. It\u0026rsquo;s Ctrl+backslash and Ctrl+n.
Right now I want you to get to previos tab.
:tabprevious You might also autocomplete the statement with a \u0026lt;tab\u0026gt;, or use mouse to switch tabs, if have one, but mouse support depends on your configurations, and we want to stay focused, so using only keyboard might really help you stay as creative as it can be. Now type the comment after # sing and if you use Github Copilot, when you press \u0026lt;Enter\u0026gt; and wait a second or two, you should get a proposition to autocomplete the print statement. Agree with \u0026lt;tab\u0026gt;, dismiss with \u0026lt;ctrl-]\u0026gt;, and search for other suggestion with \u0026lt;alt-]\u0026gt;.
hacking rules!\u0026lt;Enter\u0026gt; print(\u0026quot;Hacking Rules!\u0026quot;) You have your first script in text file. So save it. First get out of insert mode with \u0026lt;Esc\u0026gt; to get to normal mode, then please type.
:write I want to run it in a window, which will be visible in this tab, to do it follow on with this commands which will close all the other tabs, split window horizontally, switch to other window, open terminal, run your script and exit Neovim.
:tabonly \u0026lt;C-w+s\u0026gt; \u0026lt;C-w+j\u0026gt; :terminal \u0026lt;i\u0026gt; python3 my_first_python_script.py \u0026lt;Enter\u0026gt; \u0026lt;C-\\\u0026gt; \u0026lt;C-n\u0026gt; :q :wqa You should know now what is the coolest computer activity 🥷.
What we learned so far? # Neovim # how to open a text file (nvim filename) how to create new tab (:tabnew) how to open the terminal (:terminal), get into insert mode (\u0026lt;i\u0026gt;), execute inline Python script (-c \u0026quot;python code here\u0026quot;) and exit the terminal insert mode (\u0026lt;C-\\\u0026gt;\u0026lt;C-n\u0026gt;) how to write text (\u0026lt;i\u0026gt;), exit from insert mode (\u0026lt;Esc\u0026gt;) and write changes to file (:write) close all the other tabs (:tabonly) split window horizontally (\u0026lt;C-w+s\u0026gt;) or vertically (\u0026lt;C-w+v\u0026gt;) and go to other windows (\u0026lt;C-w+h/j/k/l\u0026gt;) - where h is left, j is down, k is up, and l is left and it works with moving around the text in normal and visual mode close tab, window, or just exit Neovim (:q) Python # how comment looks like (# text that is not a code after pound sign) how to output text to terminal (print(\u0026quot;this will be the output\u0026quot;) Copilot 👩🏻‍💻 # he know what do you mean if you provide enough clues, like a comment imported modules, docstring, class name, variables, method or any other part of meta that is an input for an AI generated \u0026ldquo;guess\u0026rdquo; accept suggestion with \u0026lt;tab\u0026gt; ask for next suggestion with \u0026lt;alt-]\u0026gt; dismiss suggestion with \u0026lt;ctrl-]\u0026gt; Flying higher # Open new file.
nvim learning_to_fly.py And write a comment
that prints number from 16 to 0. number is divisible by 4 display 💣. loop finish print 💥 Press \u0026lt;Enter\u0026gt;, write f, wait for suggestion, press tab to accept, \u0026lt;Enter\u0026gt; once more, \u0026lt;tab\u0026gt; to accept, \u0026lt;Enter\u0026gt; and \u0026lt;tab\u0026gt; again. You should have now fully functional script that does exactly what it\u0026rsquo;s asked to do. You should have to have Copilot setup to be able to do this. Exit insert mode with \u0026lt;Esc\u0026gt; and write the file with :write. If you\u0026rsquo;re using Nutek, open new bash sessions with nutek, or if you\u0026rsquo;re using only Docker, run docker exec -it name-of-your-container bash. I mean, that you need other terminal window where you can access the file we\u0026rsquo;re working on right now.
python3 learning_to_fly.py What you learned from this script? # For loop # In one form of it, for loop runs for the exectly specified times code which is after the colon sign. Next lines are indented, and will be exucuted. You can ask to skip one iteration with continue, exit loop with break wich will resume code flow of unindented lines. It also saves a variable i which is the current value of the loop.
for i in \u0026quot;don't go to school, become ninja!\u0026quot;: if i == \u0026quot;!\u0026quot;: print(\u0026quot;🥷\u0026quot;) As you can see, the value of variable can be in many forms too.
If, elif and else statement # Check if condition is true. Uses boolean logic to check if code after colon can be run. It can be True or False. If the condition doesn\u0026rsquo;t stands, goes to next elif check, or straight to else. Both are optional, but there can be many elif checks, but one else statement.
if True == False: # this will never run pass elif not True == True: # this will never run pass elif False == (not False): # this will never run pass else: # this will run because it does not check for condition \\ # only if it is the last checked statement \\ # if one of the if, or elif will run, after the end of \\ # indentation the program flow will resume after the whole \\ # if check print(\u0026quot;This is my last resort\u0026quot;) There are also other methods to use if statements. With and clause or or clause. Let me show you.
And # if True and False: # this will never run pass elif True and True and False: # this will never run pass elif False and False: # this will never run pass elif True and True: print(\u0026quot;We've got a winner!\u0026quot;) Or # if True or False: # this will run print(\u0026quot;Hmmm... Why we do this?\u0026quot;) if True or True: # this is another check that will run print(\u0026quot;Simply the best\u0026quot;) if False or False: # this will never run pass To say it\u0026rsquo;s kind of magic is not enough. and check is True only if all of the parts of equation are True, but or clause let you pass if check when only one part is True. You can help yourself with parentheses (True and (False or True)).
Range function # Functions are parts of code that can be run many times saving you typing, so you dont write Hello world and Hello Agnes two times but instead you define a function and then substitue arguments in your source code as variables that help you save time. It\u0026rsquo;s like cooking. You could add two spoons of sugar, but one spoon of flour.
def hello(who): \u0026quot;\u0026quot;\u0026quot; friendly greeting arguments: who (str): who to greet returns: greeting (str): friendly greeting \u0026quot;\u0026quot;\u0026quot; greeting = \u0026quot;Hello \u0026quot; + who + \u0026quot;! How are you?\u0026quot; return greeting hello(\u0026quot;Agnes\u0026quot;) hello(\u0026quot;Asia\u0026quot;) You learned that range function takes 3 arguments, with optional step and is invoked using parentheses, range(0, 16). Check that with hovering over the name of method (aka function) and pressing \u0026lt;K\u0026gt;. You can see that when hovering over your hello function and again pressing \u0026lt;K\u0026gt;, you can read what is called dockstring, think about it as helping me understand what do you wanted from me, or how it should run exactly. Then use Copilot.
To invoke hello function, use hello(\u0026quot;world\u0026quot;)
List # range(0, 4) is the same as a list of four items, starting with 0 - [0, 1, 2, 3] to access/select an item in a list you use brackets [x]. So the first element is [0] and last is [-1] or in our case [3].
Variable # We have also asigned a number to variable, and a character to variable. Variable is a placeholder for your values, that let\u0026rsquo;s you use stored value in other parts of your program. Variables can be numbers, strings, results of your calculations, methods, classes, lists, dictionaries aka hashmaps, tuples - simply put, objects and basic data types. Check for type of your data.
data_type = type(\u0026quot;this is str class\u0026quot;) print(data_type) You should know that you will be using this a lot if you want to make programs and scripts.
Get request # First of all, be sure that you have pip and venv installed. Now we will make a virtual environment for the next script to run. Venv is used to package the program so it can be easily portable and decoupled from other Python scripts. You might want to have one package installed, or ten, but you don\u0026rsquo;t need them in all of your scripts, so you make a virtual environment with venv and safely install what you need now and safely remove later.
mkdir my_first_get_request cd my_first_get_request python3 -m venv get_request source get_request/bin/activate python3 -m pip install requests First you created a directory called my_first_get_request, then you moved the current working directory to it, then created virtual environment called get_request and activated it, then installed requests package only for this environment.
Exit from previous Neovim session if you haven\u0026rsquo;t already, and be sure to first activate newly created Python environment and again run nvim my_get_request.py
First of all we start with a bad request, which will give us some intuition how the http protocol works.
import requests import json a bad get request to httpbin.org then show the error message \\ print the headers. response = requests.get(\u0026quot;http://httpbin.org/status/404\u0026quot;) print(response.status_code) print(response.reason) print(response.headers) Then try again with another get request, that will send back some data.
a get request to httpbin.org/get with some parameters. response = requests.get(\u0026quot;http://httpbin.org/get\u0026quot;, params={\u0026quot;name\u0026quot;: \u0026quot;Szymon\u0026quot;, \u0026quot;age\u0026quot;: 34} ) print(response.status_code) print(response.reason) the query string from the url. query_string = response.url print(query_string) the json data from the response. data = response.json() print json data. print(json.dumps(data, indent=4, sort_keys=True)) Here we see a classic example of getting data from an API. We provide parameters, name and age, this would be likely a query to database. In an origin header key, you can see value of your IP address, you should know that it\u0026rsquo;s always known, unless you are connected to proxy like TOR or other kind of VPN that could route your request.
Change request to something else.
response = requests.get(\u0026quot;http://httpbin.org/get\u0026quot;, params={\u0026quot;name\u0026quot;: \u0026quot;John\u0026quot;, \u0026quot;surname\u0026quot;: \u0026quot;Dillinger\u0026quot;}, headers={\u0026quot;Accept\u0026quot;: \u0026quot;application/json\u0026quot;} ) You have encoded your first json request! JSON, stands for JavaScript Object Notation which is very common format of exchanging data between services. Most of the API\u0026rsquo;s made to be available on the web support it.
So far you\u0026rsquo;ve learned how to get data from API, what about making a class that will be an actual object of human cosmic conquer? But first let\u0026rsquo;s get some hands dirty with more Neovim commands. We need fuel for our rocket science 🚀
Working with files # :edit .
`}),e.add({id:4,href:"/docs/prologue/quick-start/",title:"Quick Start",description:"One page summary of how to start a new Doks project.",content:`Requirements # Docker — the one and only original and the pioneer of the contenerization technology or
Podman — viable alternative. Simply put: alias docker=podman. Why containers? Nutek Terminal started as a spin-off of Kali Linux run in Docker nutek-core, after all I want to have my own GNU/Linux distribution, or just a Fedora spin. Start a new Nutek Terminal container # It\u0026rsquo;s really easy if you have Docker already, it\u0026rsquo;s just a matter of few GiB, currently 1.75 GB for nutek-cent. I know you might have a 🐢 slow connection, but it\u0026rsquo;s not that bad, you can download once and have as many containers as you wish. I will show you that in just a moment.
Pull Nutek Terminal image from the registry # First of all, you need to have an image. They are available on the Docker Hub, and the ones you\u0026rsquo;re looking for is:
nutek-cent - CentOS Stream 9 based image introduced recently, as a replacement to previous based on Debian. It has lot less tools and is much more slim than nutek-core. You might try it, if you\u0026rsquo;re just strartig out and want to look how the things work. docker pull neosb/nutek-cent # or podman pull neosb/nutek-cent nutek-core - description docker pull neosb/nutek-core # or podman pull neosb/nutek-core Create a new container # The easiest way to start, but only to look around what\u0026rsquo;s in there\u0026hellip;
docker run -it neosb/nutek-cent This command will simply start a new nutek-cent container, but no ports and no folders will be attached to this container.
To attach ports and add folder which you can access from container write this in your terminal:
# You can repeat -v and -p as many times you want docker run -it -h nutek-terminal -v /Users/maria/nutek:/root/nutek -p 8080:8080 neosb/nutek-cent The -h argument changes the hostname of container to nutek-terminal -v argument attaches the /Users/maria/nutek folder to container - WARNIG! - you have to enable sharing certain folders in Docker app Finnaly -p argument attaches port 8080 from host machine (you - the first part) to the 8080 port in the container. Attach to session # docker exec -it container_name /bin/zsh Start previosly stopped container # docker start -i container_name List all containers # docker ps -a `}),e.add({id:5,href:"/docs/tools/python3/",title:"Python3. Filling the Tank",description:"Orbiting Earth with International Space Station using Python.",content:`⛽️ for our rocket 🚀
Ground-up # In previous post I tried to show you how to write simple program in neovim and run using python3. Today I want to fill in the gaps in your knowledge of my understanding of how developer work. First of all we will touch on some Vim commands that migh be useful and then we\u0026rsquo;ll build a tool that show where International Space Station is and who is currently in space. Maybe we will call an Uber for them later, right now they have to use their scooters.
Let\u0026rsquo;s start with
nvim round_globe.py Nvim # Then please feel free to skip to the next section if you already feel comfortable with nvim. I want to elaborate a little bit on the subject.
So you probably want to know how to copy \u0026amp; paste? My solution:
\u0026lt;v\u0026gt; \u0026quot; use arrow keys or h,j,k,l to highlight and... \u0026lt;y\u0026gt; \u0026quot; place cursor in the place where you want to paste and... \u0026lt;P\u0026gt; Do you want to reorganize your codebase and move lines around?
\u0026lt;V\u0026gt; \u0026quot; highlight \u0026lt;x\u0026gt; \u0026quot; cursor in the place and... \u0026lt;p\u0026gt; To undo last step, use \u0026lt;u\u0026gt; and \u0026lt;C-r\u0026gt; to redo.
You can open more than one file, in separate window or tab. I show you the tab option here.
:tabedit i_swear_i_rockyou.py \u0026quot; switch to previous tab :tabprevious \u0026quot; then to close a tab and all it's windows (you know you can \u0026quot; use \u0026lt;tab\u0026gt; key to autocomplete?) :tabclose I hope it helps.
Helpful Vim links # Once more, I encourage you to explore on theese cheatsheets and experiment in your terminal window, tab or webshell.
devhints.io rtorr.com If you use some flavour of Nutek, you can simply try this out in your terminal.
w3m https://devhints.io/vim w3m https://vim.rtorr.com/ I will teach you more about w3m later on, but to quit it - simply \u0026lt;q\u0026gt;\u0026lt;y\u0026gt;
Enough is enough # If you can\u0026rsquo;t stand the pace, or my attitude, or simply want to explore\u0026hellip; Here\u0026rsquo;s an email from freecCodeCamp where the subject is JavaScript.
Quincy Larson \u0026lt;quincy@freecodecamp.org\u0026gt; 6:11 AM (9 hours ago) to me Here are this week's five links that are worth your time: 1. Learn React for Beginners. This new freeCodeCamp Front-End JavaScript course will teach you all about React Hooks, State, the Context API, and more. You'll code along with three experienced software engineers, building projects step-by-step. (8 hour YouTube course): https://www.freecodecamp.org/news/learn-react-from-three-all-star-instructors/ 2. And if you'd prefer to learn Angular, I'm thrilled to share this course with you as well: Learn Angular and TypeScript for Beginners. This in-depth course will teach you TypeScript Data Types, Angular Directives, Components, RxJS, and Lifecycle Hooks. (18 hour YouTube course): https://www.freecodecamp.org/news/angular-for-beginners-course/ (...) Python class # It\u0026rsquo;s not that you\u0026rsquo;re my student. It\u0026rsquo;s just object oriented programming concept. Most, if not all, python types are object and you can create your own types, classes, too. Create your environment and I show you how to call from Houston to space.
case you forgot how to prepare your environment, here's how python3 -m venv space_station source space_station/bin/activate you see now? (space_station)% python -m pip install requests the (space_station)% part, as it is only for reference Import # It\u0026rsquo;s time for the show to begin. Clear out your round_globe.py file (you might need to put it in the same directory as your environment). Starting simple, import statements. We will use json and requests libraries. Put them in separate lines.
statemnts. What we will use. import requests import json ISS # Now we go big. Whole class. ISS - International Space Station. It is initialized without any arguments, then proceeds with a get request to an external api resource. APIs are services on the Internet that perform actions and/or sends data. You can even create your own and host for other well behaved users! I check for a HTTP status code 200 - that means everything is OK and I parse the response json data to self.lat and self.lon class instance variables. If there is an error, we print out the status code and exit.
Then I make two methods get_lat and get_lon which return the stored latitude and longitude ISS position variables. You can see here that accessing instance variables, as well as functions must be prepended with self., but you are not limited to creating only such objects. In __init__ we can observe use of local variable response and status_code which dies out when out of scope and you can no longer access them from other parts of code.
The last bit of information is __str__(self) method that when used to print object, will returned stated action replacing {} with subsequent values.
The last thing I want to say is about indentation, namely tabs, or spaces, which must match the hierarchical pattern and be consistent. Otherwise you might spend much more time debugging your application than you should.
class definition class ISS(): # Class to represent the International Space Station # initialize the class def __init__(self): # get the ISS location data response = requests.get(\u0026quot;http://api.open-notify.org/iss-now.json\u0026quot;) status_code = response.status_code # if the response was successful, parse the JSON data if status_code == 200: response_json = response.json() self.lat = response_json['iss_position']['latitude'] self.lon = response_json['iss_position']['longitude'] # if the response was not successful, print the status code and exit else: print(\u0026quot;Error: \u0026quot; + str(status_code)) exit(1) # return self.lat, self.lon def get_lat(self): return self.lat def get_lon(self): return self.lon # pretty print the ISS location def __str__(self): return \u0026quot;ISS location: latitude: {}, longitude: {}\u0026quot; \\ .format(self.get_lat(), self.get_lon()) Where we at now # To make the round_globe program much more exciting I introduce another class that retrieves the Earth position of provided at initialization attributes latitude and longitude. The concept stays the same.
class definition class PositionRelativeToEarth(): # Initialize the class def __init__(self, latitude, longitude): # get the position data response = requests.get( \u0026quot;https://api.bigdatacloud.net/data/reverse-geocode-client?latitude={}\u0026amp;longitude={}\u0026quot; \\ .format(latitude, longitude)) status_code = response.status_code # if the response was successful, parse the JSON data if status_code == 200: response_json = response.json() self.country = response_json['countryName'] self.countryCode = response_json['countryCode'] self.city = response_json['locality'] # if the response was not successful, print the status code and exit else: print(\u0026quot;Error: \u0026quot; + str(status_code)) exit(1) # pretty print position def __str__(self): return \u0026quot;Position: country: {}, countryCode: {}, city: {}\u0026quot; \\ .format(self.country, self.countryCode, self.city) Astronauts # I want to show you, that you are not limited to sequential program structure, and you can store methods outside of classes too. This one gets our heroes, astronauts in space and when the method is invoked will print out this data to console.
.get(\u0026quot;http://api.open-notify.org/astros.json\u0026quot;) is in space? def astros(): # make the request response = requests.get(\u0026quot;http://api.open-notify.org/astros.json\u0026quot;) status_code = response.status_code # if the response was successful, parse the JSON data if status_code == 200: data = response.json() # Get number of people in space. number = data[\u0026quot;number\u0026quot;] print(\u0026quot;Number of people in space: {}\u0026quot;.format(number)) people = data[\u0026quot;people\u0026quot;] # Print people in space. print(\u0026quot;People in space: \u0026quot;) for person in people: print(person[\u0026quot;name\u0026quot;]) # if the response was not successful, print the status code and exit else: print(\u0026quot;Error: \u0026quot; + str(status_code)) exit(1) Aggregate classes and methods # In this part of code I group all the bits provided before to contitute a program that will run. I have to call the astros() function, initialize ISS class and using another way of representing text data f\u0026quot;{1+1}\u0026quot; clause I pretty print the Internationa Space Station position relative to our globe, and at last I initilize PositionRelativeToEarth with __init__ attributes using iss variable.
function def main(): astros() iss = ISS() print(f\u0026quot;{iss}\u0026quot;) position = PositionRelativeToEarth(iss.lat, iss.lon) print(position) Run the script # The last part of code tells the Python interpreter to call main function when file is run with python or python3.
main function only if this file is executed if __name__ == '__main__': main() That would be it for Today. Lookup where the International Space Station is now and who is in the space when you please. You have me now finished.
Cleanup # Deactivate # Deactivate command, will free you from Python\u0026rsquo;s virtual environment
deactivate Source code on Github # All the Python code is available on Github
`}),e.add({id:6,href:"/docs/tools/hugo/",title:"Hugo. My First Website",description:"Creating website using static site generatior Hugo.",content:`Create YOUR first website # Hej!
This New Year\u0026rsquo;s Eve you have so many new resolutions that you need to get them into one place, and make them public, so you can be as transparent as your nearest politician is.
So you heard that there is GitHub, Nutek, Szymon, Hugo and whoever I have to mention to make you test this, because it\u0026rsquo;s so awesome to have your own static website build with Hugo Markdown and all crazy stuff.
You should already have: # an account on GitHub and git of course; Docker, because you\u0026rsquo;re a good person and want to stick with what Nutek has to offer; 30 minutes before midnight; Visual Studio Code, or you\u0026rsquo;re already a masters degree in (N)Vim Basic scaffolding # your Nutek and type this into terminal to install Hugo apt update \u0026amp;\u0026amp; apt install hugo for any reason you don't use Nutek yet but you have Docker, Docker and then in your 'other' terminal run this to install - static website generator: docker pull klakegg/hugo you're on Windows (Powershell) copy and paste #1 otherwise #2, you also may run it outside docker, then #3 #1, or docker run --rm -it -v \${PWD}:/src klakegg/hugo new site my-website #2, or docker run --rm -it -v $(pwd):/src klakegg/hugo new site my-website #3 - if you already installed Hugo using any other way hugo new site my-website you have a website, let's get into it's folder cd my-website git repository git init simple theme to start with git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke echo \u0026quot;theme = 'ananke'\u0026quot; \u0026gt;\u0026gt; config.toml Now we\u0026rsquo;re making resolutions, right? # Create post # Create your first post on this brand new website with super-simple terminal command:
hugo new posts/my-2023-resolutions.md
or if you\u0026rsquo;re following with Docker Hugo build:
docker run --rm -it -v \${PWD}:/src klakegg/hugo new posts/my-2023-resolutions.md - Windows
docker run --rm -it -v $(pwd):/src klakegg/hugo new posts/my-2023-resolutions.md - Linux and MacOS
If everything goes well on the machine side, you should have a blank page, where you could tell everyone who\u0026rsquo;s caring enough about you (or simply curious enough), what your resolutions are\u0026hellip; Maybe you have just one, like not giving up on you hobbies, or remember about buying those yoga pants, because pandemic is long gone, but your shape is not in the right tuning\u0026hellip; Whatever the details, put them here using Markdown syntax. I will give you the basics.
Markdown basics # Open file my-2023-resolutions.md in content/posts folder. Leave the top of the file as it is (change draft to false when you\u0026rsquo;re done) and start with a second-order header like so:
## My 2023 Resolutions
My 2023 Resolutions # After that you can place a horizontal rule:
___
Start with you goals list:
1. Be a nice person - because humans are friendly - karma goes both ways 2. Learn just to learn * I don't need a collage degree to play a guitar 3. Redesign my desk, because I look for peace (little bonzai might help) ![Example image](/static/img/image.png) Be a nice person because humans are friendly karma goes both ways Learn just to learn I don\u0026rsquo;t need a collage degree to play guitar Redesign my desk, because I look for peace (little bonzai might help) Then fantasize a little bit with paragraphs, emphasis and a link:
Write an [email](mailto:santa@kremlin.ru) to **Santa**, where I ask to have the best experience human can get - *love* Then maybe divorce on 14th February... Write an email to Santa, where I ask to have the best experience human can get - love
Then maybe divorce on 14th February\u0026hellip;
Buld a table with your party budget:
| Day | Club | DJing | | --- | --- | --- | | Friday | London | $1600 | | Saturday | Paris | $12 | | Sunday | Berlin | $1 | Day Club DJing Friday London $1600 Saturday Paris $12 Sunday Berlin $1 And voilà!
Local development server # Spin-up your local server with drafts rendered:
on Windows docker run --rm -it -v \${PWD}:/src klakegg/hugo server --buildDrafts on Linux and MacOS docker run --rm -it -v $(pwd):/src klakegg/hugo server --buildDrafts Hugo hugo server --buildDrafts Satisfied? # End draft phase # Edit your resolution markdown file and on top of if change draf: true to draft: false
Immidietly make production version # on Windows docker run --rm -it -v \${PWD}:/src klakegg/hugo on Linux, MacOS docker run --rm -it -v $(pwd):/src klakegg/hugo Hugo hugo Create repository on GitHub # Go to GitHub, login, or sign up if you don\u0026rsquo;t have an account already - it\u0026rsquo;s free, and it\u0026rsquo;s home to many of other free or open source projects. Don\u0026rsquo;t be afraid, it\u0026rsquo;s just good idea to have such an account, but you can deploy your website to many other places. Here is how to do so.
If you\u0026rsquo;re following this guide, as you should be ;) look on the GitHub\u0026rsquo;s site about creating a GitHub Page using other tools like Jekyll. In case you\u0026rsquo;re unsure what you should use, try to Google this phrase \u0026lsquo;jekyll vs hugo\u0026rsquo;
\u0026hellip;Thank you, for following my guide, now please create a repository according to GitHub Page address you want to have. If you\u0026rsquo;re opting-in for custom domain, I will show you to get this done too. Nevertheless you need any GitHub address to start with.
create new repository The GitHub Page Way add remote to your local git repository with git remote add origin xxx.git (replace xxx with your repository address). when you\u0026rsquo;re done with your resolutions post, commit all your work: git status git add * git status there are some files left, manually add them with: git add path/to/file1 path/to/file2 path/to/file3 flip the slashes for Windows git add path\\to\\file1 path\\to\\file2 path\\to\\file3 Commit with this command that does the foundation commit (think of it as a update to your portfolio, new verse in your song, or a new chapter in a book) itself along with a required message:
git commit -m \u0026quot;Add my 2023 resolutions\u0026quot;
Double check draf: false # Change draft to false on top of resolutions post file.
Configuration # config.toml # Open config.toml file in root of the project.
Set:
baseURL = 'http://user.github.io/' or baseURL = 'http://user.github.io/repository/' or baseURL = 'http://example.com/' Then set:
languageCode = 'en-us'
and
title = 'John Dillinger'
and
theme = 'ananke'
Deploy to GitHub Pages # Workflow file # Create .github/workflows/gh-pages.yml file with this specific content:
name: github pages on: push: branches: - main # Set a branch that will trigger a deployment pull_request: jobs: deploy: runs-on: ubuntu-22.04 steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: github.ref == 'refs/heads/main' with: github_token: \${{ secrets.GITHUB_TOKEN }} publish_dir: ./public This file, when you push your code to GitHub will run the necessairly steps to create the machine readeble representation of what you\u0026rsquo;ve created and it will create gh-pages branch from which you will serve your website.
Check status of this workflow in Actions tab of your repository. This is super-important. Without this action/workflow finishing properly you can\u0026rsquo;t the desired result.
BTW GitHub actions are capable of many more and cmplex things. They can build your whole application and prepare it to run on clients machines without you needeing to build all the binaries on your hardware.
Check this out
Excerpt from Hugo website # GitHub pages setting # By default, the GitHub action pushes the generated content to the gh-pages branch. This means GitHub has to serve your gh-pages branch as a GitHub Pages branch. You can change this setting by going to Settings \u0026gt; Pages, and change the source branch to gh-pages.
Use a Custom Domain # Create CNAME file (another excerpt from Hugo website) # If you’d like to use a custom domain for your GitHub Pages site, create a file static/CNAME. Your custom domain name should be the only contents inside CNAME. Since it’s inside static, the published site will contain the CNAME file at the root of the published site, which is a requirement of GitHub Pages.
Refer to the official documentation for custom domains for further information.
Subdomain # Go to your domain\u0026rsquo;s DNS provider, and add CNAME record for page.your.doman pointing to your GitHub Pages address, for example phoenix-journey.github.io.. The actual process vary from provider, to provider. In the core it\u0026rsquo;s just it.
Example.com # If you want to host your GitHub Page using your domain.com address, then create
A record with this ip addresses:
185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 Maybe then AAAA record with this ip addresses:
2606:50c0:8000::153 2606:50c0:8001::153 2606:50c0:8002::153 2606:50c0:8003::153 WWW # You might want to create CNAME with www.your-domain.com
Final touch # Open your GitHub Page repository Settings, got to Pages and set your Custom domain. If everything goes well and DNS records spreading around the world\u0026hellip; You might even get an option to make it HTTPS! Just Enforce HTTPS checkbox and you\u0026rsquo;re good to go o7 Inspiration # For inspiration, take a look at Phoenix Journey\u0026rsquo;s repository for this website written using the same tools, that\u0026rsquo;s been thaught here.
`}),e.add({id:7,href:"/docs/tools/attack/",title:"Attack",description:"Nutek Terminal attack tools.",content:""}),e.add({id:8,href:"/docs/tools/code/",title:"Code",description:"Nutek Terminal code tools.",content:""}),e.add({id:9,href:"/docs/tools/defend/",title:"Defend",description:"Nutek Terminal defend tools.",content:""}),e.add({id:10,href:"/docs/tools/know/",title:"Knowledge",description:"Nutek Terminal knowledge tools.",content:""}),e.add({id:11,href:"/docs/tools/",title:"Tools",description:"Nutek Terminal tools.",content:""}),e.add({id:12,href:"/docs/tools/utility/",title:"Utility",description:"Nutek Terminal utility tools.",content:""}),e.add({id:13,href:"/docs/help/",title:"Help",description:"Help Doks.",content:""}),e.add({id:14,href:"/docs/help/how-to-update/",title:"How to Update",description:"Regularly update the installed Docker images to keep your Nutek Termina stable, usable, and secure.",content:`Check your version of nutek image # The current way to use Nutek Terminal is through Docker, or Podman.
To update you version of image you will simply use pull command. Like that:
nutek-core:
docker pull neosb/nutek-core # or with podman podman pull neosb/nutek-core nutek-cent:
docker pull neosb/nutek-cent # or with podman podman pull neosb/nutek-cent If you already have created any nutek container, you would have to stop using them, or simply delete them, because you can\u0026rsquo;t update the underyling image that is used by container. Of course, you can just start a new one.
Update to specific version # The pull command allows also to download a specific image version with addaing :0.1.0 for example, or you can default to always use the latest image version with :latest.
# append to the neosb/nutek-* neosb/nutek-cent:0.1.0 You can also ommit using the pull command with just specifying what image you want to run:
docker run --rm -it neosb/nutek-core:latest `}),e.add({id:15,href:"/docs/help/troubleshooting/",title:"Troubleshooting",description:"Solutions to common problems.",content:`Problems with Docker? # With the worst case scenario, you will have to delete all the configuration, images and containers, but sometimes simple update does the trick.
Sometimes, switching to Podman is the answer.
Problems with Linux? # Please look around the internet, ask ChatGPT, or StackOverflow - Google Search, or Bing.com.
`}),e.add({id:16,href:"/docs/help/faq/",title:"FAQ",description:"Answers to frequently asked questions.",content:`Linux \u0026amp; GNU? # Nutek Terminal is a GNU/Linux build by the best for the best. Enclosed in Docker image, portable, easy to run and available everywhere\u0026hellip;
Keyboard shortcuts for search? # focus: Ctrl + / select: ↓ and ↑ open: Enter close: Esc Other documentation? # Docker Stack Overflow ChatGPT Can I get support? # Reach out to me:
Contact Contact the creator? # Send Neosb a message:
Contact `}),e.add({id:17,href:"/docs/help/nutek-versions/",title:"Nutek Versions",description:"Nutek Terminal versions that are available to run. You can try any of them, they are open-source and battle ready.",content:`Nutek Terminal versions # nutek-cent # CentOS Stream 9 based image, which is ment to be just a starting point in a journey into Red Hat world. Since the tooling and packeges for this system are greatly reduced, I\u0026rsquo;m currently working on creating Fedora 37 based image with all the things you might want. This image is intended to be the base for your additional work in a Dockerfile. This image is aiming more at developers, who whish to check their code on the battlefield, than at you my fellow hacker, but if you add your changes to this system, you might tailor it to your liking. Anyway, stay tuned for the arrival of nutek-fedsec.
Blog article about nutek-cent # I have described most of this version in my recent blog post
Extend the image # Create a Dockerfile with this at the beginning:
FROM neosb/nutek-cent:latest # Your additions goes under this line. Happy coding! # EXAMPLE: RUN dnf install -y clang The source code for nutek-cent is on GitHub
nutek-core # Kali Linux based image. This is how it all started. First I have installed many, many, many packages, and then I sterted to reduce the size of the image. At the end, I realized that it might not be what I want, thus I you might pick up my work and safely extend it how you want, I do not intend to be supporting this version, I only include it here as a reference for any of your future hacking activities.
Source code for nutek-core along with friends, nutek-base and nutek-code is on GitHub as well.
`}),e.add({id:18,href:"/docs/tools/utility/w3m/",title:"W3m",description:`Description # w3m is a text-based web browser.
Installation # brew install w3m Usage # w3m https://www.bing.com Key Action
o,m: Open Options Menu, Open Navigation Menu \u0026lt;tab\u0026gt;, \u0026lt;shift\u0026gt;\u0026lt;tab\u0026gt;: Next link, previous link H: Show Current Keybindings U: Go to URL I: Open Image in External Program Ctrl–H: Show History Page Resources # w3m w3m on Sourceforge help # W3M(1) General Commands Manual W3M(1) NAME w3m - a text based web browser and pager SYNOPSIS w3m [OPTION].`,content:"Description # w3m is a text-based web browser.\nInstallation # brew install w3m Usage # w3m https://www.bing.com Key Action\no,m: Open Options Menu, Open Navigation Menu \u0026lt;tab\u0026gt;, \u0026lt;shift\u0026gt;\u0026lt;tab\u0026gt;: Next link, previous link H: Show Current Keybindings U: Go to URL I: Open Image in External Program Ctrl–H: Show History Page Resources # w3m w3m on Sourceforge help # W3M(1) General Commands Manual W3M(1) NAME w3m - a text based web browser and pager SYNOPSIS w3m [OPTION]... [ file | URL ]... DESCRIPTION w3m is a text based browser which can display local or remote web pages as well as other documents. It is able to process HTML tables and frames but it ignores JavaScript and Cascading Style Sheets. w3m can also serve as a pager for text files named as arguments or passed on standard input, and as a general purpose directory browser. w3m organizes its content in buffers or tabs, allowing easy navigation between them. With the w3m-img extension installed, w3m can display inline graphics in web pages. And whenever w3m's HTML rendering capabilities do not meet your needs, the target URL can be handed over to a graphical browser with a single command. For help with runtime options, press “H” while running w3m. ARGUMENTS When given one or more command line arguments, w3m will handle targets according to content type. For web, w3m gets this information from HTTP headers; for relative or absolute file system paths, it relies on filenames. With no argument, w3m expects data from standard input and assumes “text/plain” unless another MIME type is given by the user. If provided with no target and no fallback target (see for instance option -v below), w3m will exit with usage information. OPTIONS Command line options are introduced with a single “-” character and may take an argument. General options -B with no other target defined, use the bookmark page for startup -H use high-intensity colors -M monochrome display -no-mouse deactivate mouse support -num display each line's number -N distribute multiple command line arguments to tabs. By default, a stack of buffers is used -ppc num width of num pixels per character. Range of 4.0 to 32.0, default 8.0. Larger values will make tables narrower. (Implementation not verified) -ppl num height of num pixels per line. Range of 4.0 to 64.0. (Implementation not verified) -title, -title=TERM use the buffer name as terminal title string. With specified TERM, this sets the title configuration style accordingly -v with no other target defined, welcome users with a built-in page -W toggle wrapping mode in searches -X do not initialize/deinitialize the terminal +num go to line num; only effective for num larger than the number of lines in the terminal Browser options -cols num with stdout as destination; HTML is rendered to lines of num characters -cookie, -no-cookie use stored cookies and accept new ones, or do neither -F render frames -graph, -no-graph use or do not use graphic characters for drawing HTML table and frame borders -header string append string to the HTTP(S) request. Expected to match the header syntax Variable: Value -m Render the body of Usenet messages according to the header “Content-type” -no-proxy do not use proxy -post file use POST method to upload data defined in file. The syntax to be used is var1=value1[\u0026amp;var2=value2]... -4 IPv4 only. Corresponds to dns_order=4 in configuration files -6 IPv6 only. Corresponds to dns_order=6 in configuration files -insecure use insecure SSL config options, alias for -o ssl_cipher=ALL:eNULL:@SECLEVEL=0 -o ssl_min_version=all -o ssl_forbid_method= -o ssl_verify_server=0 Text pager options -l num number of lines preserved internally when receiving plain text from stdin (default 10,000) -r use caret notation to display special escape characters (such as ANSI escapes or nroff-style backspaces for bold and underlined characters) instead of processing them -s squeeze multiple blank lines into one -t num set tab width to num columns. No effect on stdout Data type/encoding options -I charset user defined character encoding of input data -O charset user defined character encoding of output data -T type explicit characterization of input data by MIME type Options for data output, followed by immediate exit -dump dump rendered page into stdout. Set implicitly when output is directed to a file or pipe -dump_source dump the page's source code into stdout -dump_head dump response of a HEAD request for a URL into stdout -dump_both dump HEAD, and source code for a URL into stdout -dump_extra dump HEAD, source code, and extra information for a URL into stdout -help show a summary of compiled-in features and command line options -show-option show all available configuration options -version show the version of w3m Options for overriding default settings and resources -bookmark file use file instead of the default bookmark.html file -config file use file instead of the default configuration file -o option=value modify one configuration item with an explicitly given value; without option=value, equivalent to -show-option -debug use debug mode (only for debugging) -reqlog log headers of HTTP communication in file ~/.w3m/request.log EXAMPLES Pager-like usage Combine snippets of HTML code and preview the page $ cat header.html footer.html | w3m -T text/html Compare two files using tabs $ w3m -N config.old config Browser-like usage Display web content in monochrome terminal $ w3m -M http://w3m.sourceforge.net Display embedded graphics $ w3m -o auto_image=TRUE http://w3m.sourceforge.net Display content from Usenet $ w3m -m nntp://news.aioe.org/comp.os.linux.networking Upload data for a URL using the POST method $ w3m -post - http://example.com/form.php \u0026lt;\u0026lt;\u0026lt;'a=0\u0026amp;b=1' Filter-like usage Convert an HTML file to plain text with a defined line length $ w3m -cols 40 foo.html \u0026gt; foo.txt Output the bookmarks page as text with an appended list of links $ w3m -B -o display_link_number=1 \u0026gt; out.txt Conversion of file format and character encoding $ w3m -T text/html -I EUC-JP -O UTF-8 \u0026lt; foo.html \u0026gt; foo.txt Start with no input Welcome users with a built-in page $ w3m -v ENVIRONMENT w3m recognises the environment variable WWW_HOME as defining a fallback target for use if it is invoked without one. If the W3M_DIR environment variable is set to a directory name, w3m will store its user files there instead of under the ~/.w3m directory. FILES The default locations of some files are listed below. These locations can be altered via the W3M_DIR environment variable. ~/.w3m/bookmark.html default bookmark file ~/.w3m/config user defined configuration file; overrides /etc/w3m/config ~/.w3m/cookie cookie jar; written on exit, read on launch ~/.w3m/history browser history - visited files and URLs ~/.w3m/keymap user defined key bindings; overrides default key bindings ~/.w3m/mailcap external viewer configuration file ~/.w3m/menu user defined menu; overrides default menu ~/.w3m/mime.types MIME types file ~/.w3m/mouse user defined mouse settings ~/.w3m/passwd password and username file ~/.w3m/pre_form contains predefined values to fill recurrent HTML forms SEE ALSO README and example files are to be found in the doc directory of your w3m installation. Recent information about w3m may be found on the project's web pages at ⟨http://w3m.sourceforge.net⟩ ACKNOWLEDGMENTS w3m has incorporated code from several sources. Users have contributed patches and suggestions over time. AUTHOR Akinori ITO ⟨aito@fw.ipsj.or.jp⟩ w3m 0.5.3 2016-08-06 W3M(1) ```bash "}),e.add({id:19,href:"/docs/tools/utility/whatmask/",title:"Whatmask",description:`Description # whatmask is a tool to calculate the netmask from a given IP address and netmask.
Installation # brew install whatmask Usage # whatmask 192.168.0.1/24 whatmask 255.255.255.0 Resources # whatmask help # Whatmask(1) Network Whatmask(1) NAME whatmask - Subnet mask notation conversion tool. SYNTAX whatmask \u0026lt;netmask or ip/netmask\u0026gt; see the Examples section below DESCRIPTION Whatmask is a small C program that will help you with network settings. Whatmask can work in two modes.`,content:"Description # whatmask is a tool to calculate the netmask from a given IP address and netmask.\nInstallation # brew install whatmask Usage # whatmask 192.168.0.1/24 whatmask 255.255.255.0 Resources # whatmask help # Whatmask(1) Network Whatmask(1) NAME whatmask - Subnet mask notation conversion tool. SYNTAX whatmask \u0026lt;netmask or ip/netmask\u0026gt; see the Examples section below DESCRIPTION Whatmask is a small C program that will help you with network settings. Whatmask can work in two modes. The first mode is to invoke Whatmask with only a subnet mask as the argument. In this mode Whatmask will echo back the subnet mask in four formats, plus the number of useable addresses in the range. Netmask Notations supported: Name Example CIDR /24 Netmask 255.255.255.0 Netmask (hex) 0xffffff00 Wilcard Bits 0.0.0.255 The above notations are all identical. CIDR notation commonly has a \u0026quot;/\u0026quot; in front of the number (representing the number of bits). Whatmask can accept these notations with or without a slash. This notation is used more and more recently. A lot of popular routers and software support this notation. Netmask notation is pretty much the standard old-school way of doing it. It is supported by most systems (Un*x, Win, Mac, etc.). Netmask (Hex) is the hexadecimal representation of the netmask. Many implementations of ifconfig use this notation Wilcard Bits are similar to the netmask, but they are the logical not of the netmask. This notation is used by a number of popular routers (and nobody knows why...). To use Whatmask in the first mode simply type \u0026quot;whatmask \u0026lt;notation\u0026gt;\u0026quot; The notation can be in any of the four formats and Whatmask will automagically figure out what it is and display all four notations. To use Whatmask in its second mode execute Whatmask with any ip address within the subnet, followed by a slash ('/'), followed by the subnet mask in any format. (e.g. 192.168.0.23/255.255.255.224, or 192.168.0.23/27) Put no spaces in the argument. Whatmask will echo back the following: - The netmask in the following formats: CIDR, Netmask, Netmask (Hex), Wildcard Bits - The Network Address - The Broadcast Address - The number of Usable IP Addresses - The First Usable IP Address - The Last Usable IP Address (Whatmask assumes that the Broadcast address is the highest address in the subnet. This is the most common configuration.) OPTIONS \u0026lt;no options\u0026gt; see above and below for usage. EXAMPLES Examples of how Whatmask works: myhost\u0026gt; whatmask /26 --------------------------------------------- TCP/IP SUBNET MASK EQUIVALENTS --------------------------------------------- CIDR = .....................: /26 Netmask = ..................: 255.255.255.192 Netmask (hex) = ............: 0xffffffc0 Wildcard Bits = ............: 0.0.0.63 Usable IP Addresses = ......: 62 myhost\u0026gt; whatmask 255.255.192.0 --------------------------------------------- TCP/IP SUBNET MASK EQUIVALENTS --------------------------------------------- CIDR = .....................: /18 Netmask = ..................: 255.255.192.0 Netmask (hex) = ............: 0xffffc000 Wildcard Bits = ............: 0.0.63.255 Usable IP Addresses = ......: 16,382 myhost\u0026gt; whatmask 0xffffffe0 --------------------------------------------- TCP/IP SUBNET MASK EQUIVALENTS --------------------------------------------- CIDR = .....................: /27 Netmask = ..................: 255.255.255.224 Netmask (hex) = ............: 0xffffffe0 Wildcard Bits = ............: 0.0.0.31 Usable IP Addresses = ......: 30 myhost\u0026gt; whatmask 0.0.0.31 --------------------------------------------- TCP/IP SUBNET MASK EQUIVALENTS --------------------------------------------- CIDR = .....................: /27 Netmask = ..................: 255.255.255.224 Netmask (hex) = ............: 0xffffffe0 Wildcard Bits = ............: 0.0.0.31 Usable IP Addresses = ......: 30 myhost\u0026gt; whatmask 192.168.165.23/19 ------------------------------------------------ TCP/IP NETWORK INFORMATION ------------------------------------------------ IP Entered = ..................: 192.168.165.23 CIDR = ........................: /19 Netmask = .....................: 255.255.224.0 Netmask (hex) = ...............: 0xffffe000 Wildcard Bits = ...............: 0.0.31.255 ------------------------------------------------ Network Address = .............: 192.168.160.0 Broadcast Address = ...........: 192.168.191.255 Usable IP Addresses = .........: 8,190 First Usable IP Address = .....: 192.168.160.1 Last Usable IP Address = ......: 192.168.191.254 myhost\u0026gt; whatmask 192.168.0.13/255.255.255.0 ------------------------------------------------ TCP/IP NETWORK INFORMATION ------------------------------------------------ IP Entered = ..................: 192.168.0.13 CIDR = ........................: /24 Netmask = .....................: 255.255.255.0 Netmask (hex) = ...............: 0xffffff00 Wildcard Bits = ...............: 0.0.0.255 ------------------------------------------------ Network Address = .............: 192.168.0.0 Broadcast Address = ...........: 192.168.0.255 Usable IP Addresses = .........: 254 First Usable IP Address = .....: 192.168.0.1 Last Usable IP Address = ......: 192.168.0.254 myhost\u0026gt; whatmask 192.168.0.113/0xffffffe0 ------------------------------------------------ TCP/IP NETWORK INFORMATION ------------------------------------------------ IP Entered = ..................: 192.168.0.113 CIDR = ........................: /27 Netmask = .....................: 255.255.255.224 Netmask (hex) = ...............: 0xffffffe0 Wildcard Bits = ...............: 0.0.0.31 ------------------------------------------------ Network Address = .............: 192.168.0.96 Broadcast Address = ...........: 192.168.0.127 Usable IP Addresses = .........: 30 First Usable IP Address = .....: 192.168.0.97 Last Usable IP Address = ......: 192.168.0.126 myhost\u0026gt; whatmask 192.168.0.169/0.0.0.127 ------------------------------------------------ TCP/IP NETWORK INFORMATION ------------------------------------------------ IP Entered = ..................: 192.168.0.169 CIDR = ........................: /25 Netmask = .....................: 255.255.255.128 Netmask (hex) = ...............: 0xffffff80 Wildcard Bits = ...............: 0.0.0.127 ------------------------------------------------ Network Address = .............: 192.168.0.128 Broadcast Address = ...........: 192.168.0.255 Usable IP Addresses = .........: 126 First Usable IP Address = .....: 192.168.0.129 Last Usable IP Address = ......: 192.168.0.254 BUGS Report bugs to \u0026lt;software@laffeycomputer.com\u0026gt; CONTRIBUTORS Original code: Joe Laffey \u0026lt;software@laffeycomputer.com\u0026gt; Assistance with Manpage and Packaging: David Wirch \u0026lt;kuma@linuxboxen.org\u0026gt; Many thanks to the beta testers and users who sent in valuable feedback! UPDATES Official Whatmask website: http://www.laffeycomputer.com/whatmask.html LAFFEY Computer Imaging Nov 14, 2003 Whatmask(1) ```bash "}),e.add({id:20,href:"/docs/tools/utility/viu/",title:"Viu",description:`Description # viu is a command-line image viewer for the terminal.
Installation # brew install viu Usage # viu image.png Resources # viu Similar # imgcat img2txt catimg tiv jp2a caca-utils w3m ueberzug kitty iterm2 help # viu 1.4.0 Atanas Yankov \u0026lt;atanas.yankov98@gmail.com\u0026gt; View images right from the terminal. USAGE: viu [FLAGS] [OPTIONS] [FILE]... When FILE is -, read standard input. FLAGS: -b, --blocks Force block output --help Prints help information -m, --mirror Display a mirror of the original image -n, --name Output the name of the file before displaying -1, --once Only loop once through the animation -r, --recursive Recurse down directories if passed one -s, --static Show only first frame of gif -t, --transparent Display transparent image with transparent background -V, --version Prints version information OPTIONS: -f, --frame-rate \u0026lt;frames-per-second\u0026gt; Play gif at the given frame rate -h, --height \u0026lt;height\u0026gt; Resize the image to a provided height -w, --width \u0026lt;width\u0026gt; Resize the image to a provided width ARGS: \u0026lt;FILE\u0026gt;.`,content:`Description # viu is a command-line image viewer for the terminal.
Installation # brew install viu Usage # viu image.png Resources # viu Similar # imgcat img2txt catimg tiv jp2a caca-utils w3m ueberzug kitty iterm2 help # viu 1.4.0 Atanas Yankov \u0026lt;atanas.yankov98@gmail.com\u0026gt; View images right from the terminal. USAGE: viu [FLAGS] [OPTIONS] [FILE]... When FILE is -, read standard input. FLAGS: -b, --blocks Force block output --help Prints help information -m, --mirror Display a mirror of the original image -n, --name Output the name of the file before displaying -1, --once Only loop once through the animation -r, --recursive Recurse down directories if passed one -s, --static Show only first frame of gif -t, --transparent Display transparent image with transparent background -V, --version Prints version information OPTIONS: -f, --frame-rate \u0026lt;frames-per-second\u0026gt; Play gif at the given frame rate -h, --height \u0026lt;height\u0026gt; Resize the image to a provided height -w, --width \u0026lt;width\u0026gt; Resize the image to a provided width ARGS: \u0026lt;FILE\u0026gt;... The image to be displayed `}),e.add({id:21,href:"/docs/tools/utility/tmux/",title:"Tmux",description:`Description # tmux is a terminal multiplexer.
Installation # brew install tmux Usage # tmux Scrollback # Ctrl + b then [ to enter copy mode Space to start selecting Enter to copy selection q to quit copy mode Splitting # Ctrl + b then % to split vertically Ctrl + b then \u0026quot; to split horizontally Resizing # Ctrl + b then Arrow Key to resize Sessions # Ctrl + b then d to detach tmux attach to reattach Windows # Ctrl + b then c to create a new window Ctrl + b then n to go to the next window Ctrl + b then p to go to the previous window Ctrl + b then 0-9 to go to a specific window Ctrl + b then \u0026amp; to kill the current window Panes # Ctrl + b then o to cycle through panes Ctrl + b then q to show pane numbers Ctrl + b then x to kill the current pane Ctrl + b then z to toggle zoom on the current pane Ctrl + b then Arrow Key to move the current pane The default command key bindings are: [ Enter copy mode to copy text or view the history.`,content:"Description # tmux is a terminal multiplexer.\nInstallation # brew install tmux Usage # tmux Scrollback # Ctrl + b then [ to enter copy mode Space to start selecting Enter to copy selection q to quit copy mode Splitting # Ctrl + b then % to split vertically Ctrl + b then \u0026quot; to split horizontally Resizing # Ctrl + b then Arrow Key to resize Sessions # Ctrl + b then d to detach tmux attach to reattach Windows # Ctrl + b then c to create a new window Ctrl + b then n to go to the next window Ctrl + b then p to go to the previous window Ctrl + b then 0-9 to go to a specific window Ctrl + b then \u0026amp; to kill the current window Panes # Ctrl + b then o to cycle through panes Ctrl + b then q to show pane numbers Ctrl + b then x to kill the current pane Ctrl + b then z to toggle zoom on the current pane Ctrl + b then Arrow Key to move the current pane The default command key bindings are: [ Enter copy mode to copy text or view the history. Function vi emacs -------- -- ----- Half page down C-d M-Down Half page up C-u M-Up Next page C-f Page down Previous page C-b Page up Scroll down C-Down or C-e C-Down Scroll up C-Up or C-y C-Up Search again n n Search again in reverse N N Search backward ? C-r Search forward / C-s You can set the key binding mode using Ctrl-b, then\n:set-window-option mode-keys emacs or vi.\nResources # tmux tmux on GitHub Getting Starte help # TMUX(1) BSD General Commands Manual TMUX(1) NAME tmux -- terminal multiplexer SYNOPSIS tmux [-2CDluvV] [-c shell-command] [-f file] [-L socket-name] [-S socket-path] [-T features] [command [flags]] DESCRIPTION tmux is a terminal multiplexer: it enables a number of terminals to be created, accessed, and controlled from a single screen. tmux may be detached from a screen and continue running in the background, then later reattached. When tmux is started, it creates a new session with a single window and displays it on screen. A status line at the bottom of the screen shows information on the current session and is used to enter interactive com- mands. A session is a single collection of pseudo terminals under the management of tmux. Each session has one or more windows linked to it. A window occupies the entire screen and may be split into rectangular panes, each of which is a separate pseudo terminal (the pty(4) manual page documents the technical details of pseudo terminals). Any number of tmux instances may connect to the same session, and any number of windows may be present in the same session. Once all sessions are killed, tmux exits. Each session is persistent and will survive accidental disconnection (such as ssh(1) connection timeout) or intentional detaching (with the `C-b d' key strokes). tmux may be reattached using: $ tmux attach In tmux, a session is displayed on screen by a client and all sessions are managed by a single server. The server and each client are separate processes which communicate through a socket in /tmp. The options are as follows: -2 Force tmux to assume the terminal supports 256 colours. This is equivalent to -T 256. -C Start in control mode (see the CONTROL MODE section). Given twice (-CC) disables echo. -c shell-command Execute shell-command using the default shell. If neces- sary, the tmux server will be started to retrieve the default-shell option. This option is for compatibility with sh(1) when tmux is used as a login shell. -D Do not start the tmux server as a daemon. This also turns the exit-empty option off. With -D, command may not be specified. -f file Specify an alternative configuration file. By default, tmux loads the system configuration file from /usr/local/etc/tmux.conf, if present, then looks for a user configuration file at ~/.tmux.conf, $XDG_CONFIG_HOME/tmux/tmux.conf or ~/.config/tmux/tmux.conf. The configuration file is a set of tmux commands which are executed in sequence when the server is first started. tmux loads configuration files once when the server process has started. The source-file command may be used to load a file later. tmux shows any error messages from commands in configura- tion files in the first session created, and continues to process the rest of the configuration file. -L socket-name tmux stores the server socket in a directory under TMUX_TMPDIR or /tmp if it is unset. The default socket is named default. This option allows a different socket name to be specified, allowing several independent tmux servers to be run. Unlike -S a full path is not necessary: the sockets are all created in a directory tmux-UID under the directory given by TMUX_TMPDIR or in /tmp. The tmux-UID directory is created by tmux and must not be world read- able, writable or executable. If the socket is accidentally removed, the SIGUSR1 signal may be sent to the tmux server process to recreate it (note that this will fail if any parent directories are missing). -l Behave as a login shell. This flag currently has no effect and is for compatibility with other shells when using tmux as a login shell. -N Do not start the server even if the command would normally do so (for example new-session or start-server). -S socket-path Specify a full alternative path to the server socket. If -S is specified, the default socket directory is not used and any -L flag is ignored. -u Write UTF-8 output to the terminal even if the first envi- ronment variable of LC_ALL, LC_CTYPE, or LANG that is set does not contain \u0026quot;UTF-8\u0026quot; or \u0026quot;UTF8\u0026quot;. This is equivalent to -T UTF-8. -T features Set terminal features for the client. This is a comma-sep- arated list of features. See the terminal-features option. -v Request verbose logging. Log messages will be saved into tmux-client-PID.log and tmux-server-PID.log files in the current directory, where PID is the PID of the server or client process. If -v is specified twice, an additional tmux-out-PID.log file is generated with a copy of every- thing tmux writes to the terminal. The SIGUSR2 signal may be sent to the tmux server process to toggle logging between on (as if -v was given) and off. -V Report the tmux version. command [flags] This specifies one of a set of commands used to control tmux, as described in the following sections. If no com- mands are specified, the new-session command is assumed. DEFAULT KEY BINDINGS tmux may be controlled from an attached client by using a key combination of a prefix key, `C-b' (Ctrl-b) by default, followed by a command key. The default command key bindings are: C-b Send the prefix key (C-b) through to the application. C-o Rotate the panes in the current window forwards. C-z Suspend the tmux client. ! Break the current pane out of the window. \u0026quot; Split the current pane into two, top and bottom. # List all paste buffers. $ Rename the current session. % Split the current pane into two, left and right. \u0026amp; Kill the current window. ' Prompt for a window index to select. ( Switch the attached client to the previous session. ) Switch the attached client to the next session. , Rename the current window. - Delete the most recently copied buffer of text. . Prompt for an index to move the current window. 0 to 9 Select windows 0 to 9. : Enter the tmux command prompt. ; Move to the previously active pane. = Choose which buffer to paste interactively from a list. ? List all key bindings. D Choose a client to detach. L Switch the attached client back to the last session. [ Enter copy mode to copy text or view the history. ] Paste the most recently copied buffer of text. c Create a new window. d Detach the current client. f Prompt to search for text in open windows. i Display some information about the current window. l Move to the previously selected window. m Mark the current pane (see select-pane -m). M Clear the marked pane. n Change to the next window. o Select the next pane in the current window. p Change to the previous window. q Briefly display pane indexes. r Force redraw of the attached client. s Select a new session for the attached client interac- tively. t Show the time. w Choose the current window interactively. x Kill the current pane. z Toggle zoom state of the current pane. { Swap the current pane with the previous pane. } Swap the current pane with the next pane. ~ Show previous messages from tmux, if any. Page Up Enter copy mode and scroll one page up. Up, Down Left, Right Change to the pane above, below, to the left, or to the right of the current pane. M-1 to M-5 Arrange panes in one of the five preset layouts: even- horizontal, even-vertical, main-horizontal, main-verti- cal, or tiled. Space Arrange the current window in the next preset layout. M-n Move to the next window with a bell or activity marker. M-o Rotate the panes in the current window backwards. M-p Move to the previous window with a bell or activity marker. C-Up, C-Down C-Left, C-Right Resize the current pane in steps of one cell. M-Up, M-Down M-Left, M-Right Resize the current pane in steps of five cells. Key bindings may be changed with the bind-key and unbind-key commands. COMMAND PARSING AND EXECUTION tmux supports a large number of commands which can be used to control its behaviour. Each command is named and can accept zero or more flags and arguments. They may be bound to a key with the bind-key command or run from the shell prompt, a shell script, a configuration file or the com- mand prompt. For example, the same set-option command run from the shell prompt, from ~/.tmux.conf and bound to a key may look like: $ tmux set-option -g status-style bg=cyan set-option -g status-style bg=cyan bind-key C set-option -g status-style bg=cyan Here, the command name is `set-option', `-g' is a flag and `status-style' and `bg=cyan' are arguments. tmux distinguishes between command parsing and execution. In order to execute a command, tmux needs it to be split up into its name and argu- ments. This is command parsing. If a command is run from the shell, the shell parses it; from inside tmux or from a configuration file, tmux does. Examples of when tmux parses commands are: - in a configuration file; - typed at the command prompt (see command-prompt); - given to bind-key; - passed as arguments to if-shell or confirm-before. To execute commands, each client has a `command queue'. A global command queue not attached to any client is used on startup for configuration files like ~/.tmux.conf. Parsed commands added to the queue are executed in order. Some commands, like if-shell and confirm-before, parse their argument to create a new command which is inserted immediately after themselves. This means that arguments can be parsed twice or more - once when the parent command (such as if-shell) is parsed and again when it parses and executes its command. Commands like if-shell, run-shell and display-panes stop execution of subsequent commands on the queue until something happens - if-shell and run-shell until a shell command finishes and display-panes until a key is pressed. For example, the following commands: new-session; new-window if-shell \u0026quot;true\u0026quot; \u0026quot;split-window\u0026quot; kill-session Will execute new-session, new-window, if-shell, the shell command true(1), split-window and kill-session in that order. The COMMANDS section lists the tmux commands and their arguments. PARSING SYNTAX This section describes the syntax of commands parsed by tmux, for example in a configuration file or at the command prompt. Note that when com- mands are entered into the shell, they are parsed by the shell - see for example ksh(1) or csh(1). Each command is terminated by a newline or a semicolon (;). Commands separated by semicolons together form a `command sequence' - if a command in the sequence encounters an error, no subsequent commands are executed. It is recommended that a semicolon used as a command separator should be written as an individual token, for example from sh(1): $ tmux neww \\; splitw Or: $ tmux neww ';' splitw Or from the tmux command prompt: neww ; splitw However, a trailing semicolon is also interpreted as a command separator, for example in these sh(1) commands: $ tmux neww\\\\; splitw Or: $ tmux 'neww;' splitw As in these examples, when running tmux from the shell extra care must be taken to properly quote semicolons: 1. Semicolons that should be interpreted as a command separator should be escaped according to the shell conventions. For sh(1) this typically means quoted (such as `neww ';' splitw') or escaped (such as `neww \\\\\\\\; splitw'). 2. Individual semicolons or trailing semicolons that should be interpreted as arguments should be escaped twice: once accord- ing to the shell conventions and a second time for tmux; for example: $ tmux neww 'foo\\\\;' bar $ tmux neww foo\\\\\\\\; bar 3. Semicolons that are not individual tokens or trailing another token should only be escaped once according to shell conven- tions; for example: $ tmux neww 'foo-;-bar' $ tmux neww foo-\\\\;-bar Comments are marked by the unquoted # character - any remaining text after a comment is ignored until the end of the line. If the last character of a line is \\, the line is joined with the follow- ing line (the \\ and the newline are completely removed). This is called line continuation and applies both inside and outside quoted strings and in comments, but not inside braces. Command arguments may be specified as strings surrounded by single (') quotes, double quotes (\u0026quot;) or braces ({}). This is required when the argument contains any special character. Single and double quoted strings cannot span multiple lines except with line continuation. Braces can span multiple lines. Outside of quotes and inside double quotes, these replacements are per- formed: - Environment variables preceded by $ are replaced with their value from the global environment (see the GLOBAL AND SESSION ENVIRONMENT section). - A leading ~ or ~user is expanded to the home directory of the current or specified user. - \\uXXXX or \\uXXXXXXXX is replaced by the Unicode codepoint cor- responding to the given four or eight digit hexadecimal number. - When preceded (escaped) by a \\, the following characters are replaced: \\e by the escape character; \\r by a carriage return; \\n by a newline; and \\t by a tab. - \\ooo is replaced by a character of the octal value ooo. Three octal digits are required, for example \\001. The largest valid character is \\377. - Any other characters preceded by \\ are replaced by themselves (that is, the \\ is removed) and are not treated as having any special meaning - so for example \\; will not mark a command sequence and \\$ will not expand an environment variable. Braces are parsed as a configuration file (so conditions such as `%if' are processed) and then converted into a string. They are designed to avoid the need for additional escaping when passing a group of tmux com- mands as an argument (for example to if-shell). These two examples pro- duce an identical command - note that no escaping is needed when using {}: if-shell true { display -p 'brace-dollar-foo: }$foo' } if-shell true \u0026quot;display -p 'brace-dollar-foo: }\\$foo'\u0026quot; Braces may be enclosed inside braces, for example: bind x if-shell \u0026quot;true\u0026quot; { if-shell \u0026quot;true\u0026quot; { display \u0026quot;true!\u0026quot; } } Environment variables may be set by using the syntax `name=value', for example `HOME=/home/user'. Variables set during parsing are added to the global environment. A hidden variable may be set with `%hidden', for example: %hidden MYVAR=42 Hidden variables are not passed to the environment of processes created by tmux. See the GLOBAL AND SESSION ENVIRONMENT section. Commands may be parsed conditionally by surrounding them with `%if', `%elif', `%else' and `%endif'. The argument to `%if' and `%elif' is expanded as a format (see FORMATS) and if it evaluates to false (zero or empty), subsequent text is ignored until the closing `%elif', `%else' or `%endif'. For example: %if \u0026quot;#{==:#{host},myhost}\u0026quot; set -g status-style bg=red %elif \u0026quot;#{==:#{host},myotherhost}\u0026quot; set -g status-style bg=green %else set -g status-style bg=blue %endif Will change the status line to red if running on `myhost', green if run- ning on `myotherhost', or blue if running on another host. Conditionals may be given on one line, for example: %if #{==:#{host},myhost} set -g status-style bg=red %endif COMMANDS This section describes the commands supported by tmux. Most commands accept the optional -t (and sometimes -s) argument with one of target-client, target-session, target-window, or target-pane. These specify the client, session, window or pane which a command should affect. target-client should be the name of the client, typically the pty(4) file to which the client is connected, for example either of /dev/ttyp1 or ttyp1 for the client attached to /dev/ttyp1. If no client is specified, tmux attempts to work out the client currently in use; if that fails, an error is reported. Clients may be listed with the list-clients command. target-session is tried as, in order: 1. A session ID prefixed with a $. 2. An exact name of a session (as listed by the list-sessions command). 3. The start of a session name, for example `mysess' would match a session named `mysession'. 4. An fnmatch(3) pattern which is matched against the session name. If the session name is prefixed with an `=', only an exact match is accepted (so `=mysess' will only match exactly `mysess', not `mysession'). If a single session is found, it is used as the target session; multiple matches produce an error. If a session is omitted, the current session is used if available; if no current session is available, the most recently used is chosen. target-window (or src-window or dst-window) specifies a window in the form session:window. session follows the same rules as for target-session, and window is looked for in order as: 1. A special token, listed below. 2. A window index, for example `mysession:1' is window 1 in ses- sion `mysession'. 3. A window ID, such as @1. 4. An exact window name, such as `mysession:mywindow'. 5. The start of a window name, such as `mysession:mywin'. 6. As an fnmatch(3) pattern matched against the window name. Like sessions, a `=' prefix will do an exact match only. An empty window name specifies the next unused index if appropriate (for example the new-window and link-window commands) otherwise the current window in session is chosen. The following special tokens are available to indicate particular win- dows. Each has a single-character alternative form. Token Meaning {start} ^ The lowest-numbered window {end} $ The highest-numbered window {last} ! The last (previously current) window {next} + The next window by number {previous} - The previous window by number target-pane (or src-pane or dst-pane) may be a pane ID or takes a similar form to target-window but with the optional addition of a period followed by a pane index or pane ID, for example: `mysession:mywindow.1'. If the pane index is omitted, the currently active pane in the specified window is used. The following special tokens are available for the pane index: Token Meaning {last} ! The last (previously active) pane {next} + The next pane by number {previous} - The previous pane by number {top} The top pane {bottom} The bottom pane {left} The leftmost pane {right} The rightmost pane {top-left} The top-left pane {top-right} The top-right pane {bottom-left} The bottom-left pane {bottom-right} The bottom-right pane {up-of} The pane above the active pane {down-of} The pane below the active pane {left-of} The pane to the left of the active pane {right-of} The pane to the right of the active pane The tokens `+' and `-' may be followed by an offset, for example: select-window -t:+2 In addition, target-session, target-window or target-pane may consist entirely of the token `{mouse}' (alternative form `=') to specify the session, window or pane where the most recent mouse event occurred (see the MOUSE SUPPORT section) or `{marked}' (alternative form `~') to spec- ify the marked pane (see select-pane -m). Sessions, window and panes are each numbered with a unique ID; session IDs are prefixed with a `$', windows with a `@', and panes with a `%'. These are unique and are unchanged for the life of the session, window or pane in the tmux server. The pane ID is passed to the child process of the pane in the TMUX_PANE environment variable. IDs may be displayed using the `session_id', `window_id', or `pane_id' formats (see the FORMATS section) and the display-message, list-sessions, list-windows or list-panes commands. shell-command arguments are sh(1) commands. This may be a single argu- ment passed to the shell, for example: new-window 'vi ~/.tmux.conf' Will run: /bin/sh -c 'vi ~/.tmux.conf' Additionally, the new-window, new-session, split-window, respawn-window and respawn-pane commands allow shell-command to be given as multiple arguments and executed directly (without `sh -c'). This can avoid issues with shell quoting. For example: $ tmux new-window vi ~/.tmux.conf Will run vi(1) directly without invoking the shell. command [arguments] refers to a tmux command, either passed with the com- mand and arguments separately, for example: bind-key F1 set-option status off Or passed as a single string argument in .tmux.conf, for example: bind-key F1 { set-option status off } Example tmux commands include: refresh-client -t/dev/ttyp2 rename-session -tfirst newname set-option -wt:0 monitor-activity on new-window ; split-window -d bind-key R source-file ~/.tmux.conf \\; \\ display-message \u0026quot;source-file done\u0026quot; Or from sh(1): $ tmux kill-window -t :1 $ tmux new-window \\; split-window -d $ tmux new-session -d 'vi ~/.tmux.conf' \\; split-window -d \\; attach CLIENTS AND SESSIONS The tmux server manages clients, sessions, windows and panes. Clients are attached to sessions to interact with them, either when they are cre- ated with the new-session command, or later with the attach-session com- mand. Each session has one or more windows linked into it. Windows may be linked to multiple sessions and are made up of one or more panes, each of which contains a pseudo terminal. Commands for creating, linking and otherwise manipulating windows are covered in the WINDOWS AND PANES sec- tion. The following commands are available to manage clients and sessions: attach-session [-dErx] [-c working-directory] [-f flags] [-t target-session] (alias: attach) If run from outside tmux, create a new client in the current ter- minal and attach it to target-session. If used from inside, switch the current client. If -d is specified, any other clients attached to the session are detached. If -x is given, send SIGHUP to the parent process of the client as well as detaching the client, typically causing it to exit. -f sets a comma-sepa- rated list of client flags. The flags are: active-pane the client has an independent active pane ignore-size the client does not affect the size of other clients no-output the client does not receive pane output in control mode pause-after=seconds output is paused once the pane is seconds behind in con- trol mode read-only the client is read-only wait-exit wait for an empty line input before exiting in control mode A leading `!' turns a flag off if the client is already attached. -r is an alias for -f read-only,ignore-size. When a client is read-only, only keys bound to the detach-client or switch-client commands have any effect. A client with the active-pane flag allows the active pane to be selected independently of the win- dow's active pane used by clients without the flag. This only affects the cursor position and commands issued from the client; other features such as hooks and styles continue to use the win- dow's active pane. If no server is started, attach-session will attempt to start it; this will fail unless sessions are created in the configuration file. The target-session rules for attach-session are slightly adjusted: if tmux needs to select the most recently used session, it will prefer the most recently used unattached session. -c will set the session working directory (used for new windows) to working-directory. If -E is used, the update-environment option will not be applied. detach-client [-aP] [-E shell-command] [-s target-session] [-t target-client] (alias: detach) Detach the current client if bound to a key, the client specified with -t, or all clients currently attached to the session speci- fied by -s. The -a option kills all but the client given with -t. If -P is given, send SIGHUP to the parent process of the client, typically causing it to exit. With -E, run shell-command to replace the client. has-session [-t target-session] (alias: has) Report an error and exit with 1 if the specified session does not exist. If it does exist, exit with 0. kill-server Kill the tmux server and clients and destroy all sessions. kill-session [-aC] [-t target-session] Destroy the given session, closing any windows linked to it and no other sessions, and detaching all clients attached to it. If -a is given, all sessions but the specified one is killed. The -C flag clears alerts (bell, activity, or silence) in all windows linked to the session. list-clients [-F format] [-t target-session] (alias: lsc) List all clients attached to the server. For the meaning of the -F flag, see the FORMATS section. If target-session is speci- fied, list only clients connected to that session. list-commands [-F format] [command] (alias: lscm) List the syntax of command or - if omitted - of all commands sup- ported by tmux. list-sessions [-F format] [-f filter] (alias: ls) List all sessions managed by the server. -F specifies the format of each line and -f a filter. Only sessions for which the filter is true are shown. See the FORMATS section. lock-client [-t target-client] (alias: lockc) Lock target-client, see the lock-server command. lock-session [-t target-session] (alias: locks) Lock all clients attached to target-session. new-session [-AdDEPX] [-c start-directory] [-e environment] [-f flags] [-F format] [-n window-name] [-s session-name] [-t group-name] [-x width] [-y height] [shell-command] (alias: new) Create a new session with name session-name. The new session is attached to the current terminal unless -d is given. window-name and shell-command are the name of and shell command to execute in the initial window. With -d, the initial size comes from the global default-size option; -x and -y can be used to specify a different size. `-' uses the size of the cur- rent client if any. If -x or -y is given, the default-size option is set for the session. -f sets a comma-separated list of client flags (see attach-session). If run from a terminal, any termios(4) special characters are saved and used for new windows in the new session. The -A flag makes new-session behave like attach-session if session-name already exists; in this case, -D behaves like -d to attach-session, and -X behaves like -x to attach-session. If -t is given, it specifies a session group. Sessions in the same group share the same set of windows - new windows are linked to all sessions in the group and any windows closed removed from all sessions. The current and previous window and any session options remain independent and any session in a group may be killed without affecting the others. The group-name argument may be: 1. the name of an existing group, in which case the new ses- sion is added to that group; 2. the name of an existing session - the new session is added to the same group as that session, creating a new group if necessary; 3. the name for a new group containing only the new session. -n and shell-command are invalid if -t is used. The -P option prints information about the new session after it has been created. By default, it uses the format `#{session_name}:' but a different format may be specified with -F. If -E is used, the update-environment option will not be applied. -e takes the form `VARIABLE=value' and sets an environment vari- able for the newly created session; it may be specified multiple times. refresh-client [-cDLRSU] [-A pane:state] [-B name:what:format] [-C size] [-f flags] [-l [target-pane]] [-t target-client] [adjustment] (alias: refresh) Refresh the current client if bound to a key, or a single client if one is given with -t. If -S is specified, only update the client's status line. The -U, -D, -L -R, and -c flags allow the visible portion of a window which is larger than the client to be changed. -U moves the visible part up by adjustment rows and -D down, -L left by adjustment columns and -R right. -c returns to tracking the cur- sor automatically. If adjustment is omitted, 1 is used. Note that the visible position is a property of the client not of the window, changing the current window in the attached session will reset it. -C sets the width and height of a control mode client or of a window for a control mode client, size must be one of `widthxheight' or `window ID:widthxheight', for example `80x24' or `@0:80x24'. -A allows a control mode client to trigger actions on a pane. The argument is a pane ID (with leading `%'), a colon, then one of `on', `off', `continue' or `pause'. If `off', tmux will not send output from the pane to the client and if all clients have turned the pane off, will stop reading from the pane. If `continue', tmux will return to sending output to the pane if it was paused (manually or with the pause-after flag). If `pause', tmux will pause the pane. -A may be given multiple times for different panes. -B sets a subscription to a format for a control mode client. The argument is split into three items by colons: name is a name for the subscription; what is a type of item to subscribe to; format is the format. After a subscription is added, changes to the format are reported with the %subscription-changed notifica- tion, at most once a second. If only the name is given, the sub- scription is removed. what may be empty to check the format only for the attached session, or one of: a pane ID such as `%0'; `%*' for all panes in the attached session; a window ID such as `@0'; or `@*' for all windows in the attached session. -f sets a comma-separated list of client flags, see attach-session. -l requests the clipboard from the client using the xterm(1) escape sequence. If Ar target-pane is given, the clipboard is sent (in encoded form), otherwise it is stored in a new paste buffer. -L, -R, -U and -D move the visible portion of the window left, right, up or down by adjustment, if the window is larger than the client. -c resets so that the position follows the cursor. See the window-size option. rename-session [-t target-session] new-name (alias: rename) Rename the session to new-name. server-access [-adlrw] [user] Change the access or read/write permission of user. The user running the tmux server (its owner) and the root user cannot be changed and are always permitted access. -a and -d are used to give or revoke access for the specified user. If the user is already attached, the -d flag causes their clients to be detached. -r and -w change the permissions for user: -r makes their clients read-only and -w writable. -l lists current access permissions. By default, the access list is empty and tmux creates sockets with file system permissions preventing access by any user other than the owner (and root). These permissions must be changed manually. Great care should be taken not to allow access to untrusted users even read-only. show-messages [-JT] [-t target-client] (alias: showmsgs) Show server messages or information. Messages are stored, up to a maximum of the limit set by the message-limit server option. -J and -T show debugging information about jobs and terminals. source-file [-Fnqv] path ... (alias: source) Execute commands from one or more files specified by path (which may be glob(7) patterns). If -F is present, then path is expanded as a format. If -q is given, no error will be returned if path does not exist. With -n, the file is parsed but no com- mands are executed. -v shows the parsed commands and line num- bers if possible. start-server (alias: start) Start the tmux server, if not already running, without creating any sessions. Note that as by default the tmux server will exit with no ses- sions, this is only useful if a session is created in ~/.tmux.conf, exit-empty is turned off, or another command is run as part of the same command sequence. For example: $ tmux start \\; show -g suspend-client [-t target-client] (alias: suspendc) Suspend a client by sending SIGTSTP (tty stop). switch-client [-ElnprZ] [-c target-client] [-t target-session] [-T key-table] (alias: switchc) Switch the current session for client target-client to target-session. As a special case, -t may refer to a pane (a target that contains `:', `.' or `%'), to change session, window and pane. In that case, -Z keeps the window zoomed if it was zoomed. If -l, -n or -p is used, the client is moved to the last, next or previous session respectively. -r toggles the client read-only and ignore-size flags (see the attach-session command). If -E is used, update-environment option will not be applied. -T sets the client's key table; the next key from the client will be interpreted from key-table. This may be used to configure multiple prefix keys, or to bind commands to sequences of keys. For example, to make typing `abc' run the list-keys command: bind-key -Ttable2 c list-keys bind-key -Ttable1 b switch-client -Ttable2 bind-key -Troot a switch-client -Ttable1 WINDOWS AND PANES Each window displayed by tmux may be split into one or more panes; each pane takes up a certain area of the display and is a separate terminal. A window may be split into panes using the split-window command. Windows may be split horizontally (with the -h flag) or vertically. Panes may be resized with the resize-pane command (bound to `C-Up', `C-Down' `C-Left' and `C-Right' by default), the current pane may be changed with the select-pane command and the rotate-window and swap-pane commands may be used to swap panes without changing their position. Panes are numbered beginning from zero in the order they are created. By default, a tmux pane permits direct access to the terminal contained in the pane. A pane may also be put into one of several modes: - Copy mode, which permits a section of a window or its history to be copied to a paste buffer for later insertion into another window. This mode is entered with the copy-mode command, bound to `[' by default. Copied text can be pasted with the paste-buffer command, bound to `]'. - View mode, which is like copy mode but is entered when a com- mand that produces output, such as list-keys, is executed from a key binding. - Choose mode, which allows an item to be chosen from a list. This may be a client, a session or window or pane, or a buffer. This mode is entered with the choose-buffer, choose-client and choose-tree commands. In copy mode an indicator is displayed in the top-right corner of the pane with the current position and the number of lines in the history. Commands are sent to copy mode using the -X flag to the send-keys com- mand. When a key is pressed, copy mode automatically uses one of two key tables, depending on the mode-keys option: copy-mode for emacs, or copy-mode-vi for vi. Key tables may be viewed with the list-keys com- mand. The following commands are supported in copy mode: Command vi emacs append-selection append-selection-and-cancel A back-to-indentation ^ M-m begin-selection Space C-Space bottom-line L cancel q Escape clear-selection Escape C-g copy-end-of-line [\u0026lt;prefix\u0026gt;] copy-end-of-line-and-cancel [\u0026lt;prefix\u0026gt;] copy-pipe-end-of-line [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] copy-pipe-end-of-line-and-cancel [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] D C-k copy-line [\u0026lt;prefix\u0026gt;] copy-line-and-cancel [\u0026lt;prefix\u0026gt;] copy-pipe-line [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] copy-pipe-line-and-cancel [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] copy-pipe [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] copy-pipe-no-clear [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] copy-pipe-and-cancel [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] copy-selection [\u0026lt;prefix\u0026gt;] copy-selection-no-clear [\u0026lt;prefix\u0026gt;] copy-selection-and-cancel [\u0026lt;prefix\u0026gt;] Enter M-w cursor-down j Down cursor-down-and-cancel cursor-left h Left cursor-right l Right cursor-up k Up end-of-line $ C-e goto-line \u0026lt;line\u0026gt; : g halfpage-down C-d M-Down halfpage-down-and-cancel halfpage-up C-u M-Up history-bottom G M-\u0026gt; history-top g M-\u0026lt; jump-again ; ; jump-backward \u0026lt;to\u0026gt; F F jump-forward \u0026lt;to\u0026gt; f f jump-reverse , , jump-to-backward \u0026lt;to\u0026gt; T jump-to-forward \u0026lt;to\u0026gt; t jump-to-mark M-x M-x middle-line M M-r next-matching-bracket % M-C-f next-paragraph } M-} next-space W next-space-end E next-word w next-word-end e M-f other-end o page-down C-f PageDown page-down-and-cancel page-up C-b PageUp pipe [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] pipe-no-clear [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] pipe-and-cancel [\u0026lt;command\u0026gt;] [\u0026lt;prefix\u0026gt;] previous-matching-bracket M-C-b previous-paragraph { M-{ previous-space B previous-word b M-b rectangle-on rectangle-off rectangle-toggle v R refresh-from-pane r r scroll-down C-e C-Down scroll-down-and-cancel scroll-up C-y C-Up search-again n n search-backward \u0026lt;for\u0026gt; ? search-backward-incremental \u0026lt;for\u0026gt; C-r search-backward-text \u0026lt;for\u0026gt; search-forward \u0026lt;for\u0026gt; / search-forward-incremental \u0026lt;for\u0026gt; C-s search-forward-text \u0026lt;for\u0026gt; search-reverse N N select-line V select-word set-mark X X start-of-line 0 C-a stop-selection toggle-position P P top-line H M-R The search commands come in several varieties: `search-forward' and `search-backward' search for a regular expression; the `-text' variants search for a plain text string rather than a regular expression; `-incremental' perform an incremental search and expect to be used with the -i flag to the command-prompt command. `search-again' repeats the last search and `search-reverse' does the same but reverses the direction (forward becomes backward and backward becomes forward). Copy commands may take an optional buffer prefix argument which is used to generate the buffer name (the default is `buffer' so buffers are named `buffer0', `buffer1' and so on). Pipe commands take a command argument which is the command to which the selected text is piped. `copy-pipe' variants also copy the selection. The `-and-cancel' variants of some commands exit copy mode after they have completed (for copy commands) or when the cursor reaches the bottom (for scrolling commands). `-no-clear' variants do not clear the selection. The next and previous word keys skip over whitespace and treat consecu- tive runs of either word separators or other letters as words. Word sep- arators can be customized with the word-separators session option. Next word moves to the start of the next word, next word end to the end of the next word and previous word to the start of the previous word. The three next and previous space keys work similarly but use a space alone as the word separator. Setting word-separators to the empty string makes next/previous word equivalent to next/previous space. The jump commands enable quick movement within a line. For instance, typing `f' followed by `/' will move the cursor to the next `/' character on the current line. A `;' will then jump to the next occurrence. Commands in copy mode may be prefaced by an optional repeat count. With vi key bindings, a prefix is entered using the number keys; with emacs, the Alt (meta) key and a number begins prefix entry. The synopsis for the copy-mode command is: copy-mode [-eHMqu] [-s src-pane] [-t target-pane] Enter copy mode. The -u option scrolls one page up. -M begins a mouse drag (only valid if bound to a mouse key binding, see MOUSE SUPPORT). -H hides the position indicator in the top right. -q cancels copy mode and any other modes. -s copies from src-pane instead of target-pane. -e specifies that scrolling to the bottom of the history (to the visible screen) should exit copy mode. While in copy mode, pressing a key other than those used for scrolling will disable this behaviour. This is intended to allow fast scrolling through a pane's history, for example with: bind PageUp copy-mode -eu A number of preset arrangements of panes are available, these are called layouts. These may be selected with the select-layout command or cycled with next-layout (bound to `Space' by default); once a layout is chosen, panes within it may be moved and resized as normal. The following layouts are supported: even-horizontal Panes are spread out evenly from left to right across the window. even-vertical Panes are spread evenly from top to bottom. main-horizontal A large (main) pane is shown at the top of the window and the remaining panes are spread from left to right in the leftover space at the bottom. Use the main-pane-height window option to specify the height of the top pane. main-vertical Similar to main-horizontal but the large pane is placed on the left and the others spread from top to bottom along the right. See the main-pane-width window option. tiled Panes are spread out as evenly as possible over the window in both rows and columns. In addition, select-layout may be used to apply a previously used layout - the list-windows command displays the layout of each window in a form suitable for use with select-layout. For example: $ tmux list-windows 0: ksh [159x48] layout: bb62,159x48,0,0{79x48,0,0,79x48,80,0} $ tmux select-layout bb62,159x48,0,0{79x48,0,0,79x48,80,0} tmux automatically adjusts the size of the layout for the current window size. Note that a layout cannot be applied to a window with more panes than that from which the layout was originally defined. Commands related to windows and panes are as follows: break-pane [-abdP] [-F format] [-n window-name] [-s src-pane] [-t dst-window] (alias: breakp) Break src-pane off from its containing window to make it the only pane in dst-window. With -a or -b, the window is moved to the next index after or before (existing windows are moved if neces- sary). If -d is given, the new window does not become the cur- rent window. The -P option prints information about the new win- dow after it has been created. By default, it uses the format `#{session_name}:#{window_index}.#{pane_index}' but a different format may be specified with -F. capture-pane [-aepPqCJN] [-b buffer-name] [-E end-line] [-S start-line] [-t target-pane] (alias: capturep) Capture the contents of a pane. If -p is given, the output goes to stdout, otherwise to the buffer specified with -b or a new buffer if omitted. If -a is given, the alternate screen is used, and the history is not accessible. If no alternate screen exists, an error will be returned unless -q is given. If -e is given, the output includes escape sequences for text and back- ground attributes. -C also escapes non-printable characters as octal \\xxx. -N preserves trailing spaces at each line's end and -J preserves trailing spaces and joins any wrapped lines. -P captures only any output that the pane has received that is the beginning of an as-yet incomplete escape sequence. -S and -E specify the starting and ending line numbers, zero is the first line of the visible pane and negative numbers are lines in the history. `-' to -S is the start of the history and to -E the end of the visible pane. The default is to capture only the visible contents of the pane. choose-client [-NrZ] [-F format] [-f filter] [-K key-format] [-O sort-order] [-t target-pane] [template] Put a pane into client mode, allowing a client to be selected interactively from a list. Each client is shown on one line. A shortcut key is shown on the left in brackets allowing for imme- diate choice, or the list may be navigated and an item chosen or otherwise manipulated using the keys below. -Z zooms the pane. The following keys may be used in client mode: Key Function Enter Choose selected client Up Select previous client Down Select next client C-s Search by name n Repeat last search t Toggle if client is tagged T Tag no clients C-t Tag all clients d Detach selected client D Detach tagged clients x Detach and HUP selected client X Detach and HUP tagged clients z Suspend selected client Z Suspend tagged clients f Enter a format to filter items O Change sort field r Reverse sort order v Toggle preview q Exit mode After a client is chosen, `%%' is replaced by the client name in template and the result executed as a command. If template is not given, \u0026quot;detach-client -t '%%'\u0026quot; is used. -O specifies the initial sort field: one of `name', `size', `creation', or `activity'. -r reverses the sort order. -f spec- ifies an initial filter: the filter is a format - if it evaluates to zero, the item in the list is not shown, otherwise it is shown. If a filter would lead to an empty list, it is ignored. -F specifies the format for each item in the list and -K a format for each shortcut key; both are evaluated once for each line. -N starts without the preview. This command works only if at least one client is attached. choose-tree [-GNrswZ] [-F format] [-f filter] [-K key-format] [-O sort-order] [-t target-pane] [template] Put a pane into tree mode, where a session, window or pane may be chosen interactively from a tree. Each session, window or pane is shown on one line. A shortcut key is shown on the left in brackets allowing for immediate choice, or the tree may be navi- gated and an item chosen or otherwise manipulated using the keys below. -s starts with sessions collapsed and -w with windows collapsed. -Z zooms the pane. The following keys may be used in tree mode: Key Function Enter Choose selected item Up Select previous item Down Select next item + Expand selected item - Collapse selected item M-+ Expand all items M-- Collapse all items x Kill selected item X Kill tagged items \u0026lt; Scroll list of previews left \u0026gt; Scroll list of previews right C-s Search by name m Set the marked pane M Clear the marked pane n Repeat last search t Toggle if item is tagged T Tag no items C-t Tag all items : Run a command for each tagged item f Enter a format to filter items H Jump to the starting pane O Change sort field r Reverse sort order v Toggle preview q Exit mode After a session, window or pane is chosen, the first instance of `%%' and all instances of `%1' are replaced by the target in template and the result executed as a command. If template is not given, \u0026quot;switch-client -t '%%'\u0026quot; is used. -O specifies the initial sort field: one of `index', `name', or `time'. -r reverses the sort order. -f specifies an initial filter: the filter is a format - if it evaluates to zero, the item in the list is not shown, otherwise it is shown. If a fil- ter would lead to an empty list, it is ignored. -F specifies the format for each item in the tree and -K a format for each short- cut key; both are evaluated once for each line. -N starts with- out the preview. -G includes all sessions in any session groups in the tree rather than only the first. This command works only if at least one client is attached. customize-mode [-NZ] [-F format] [-f filter] [-t target-pane] [template] Put a pane into customize mode, where options and key bindings may be browsed and modified from a list. Option values in the list are shown for the active pane in the current window. -Z zooms the pane. The following keys may be used in customize mode: Key Function Enter Set pane, window, session or global option value Up Select previous item Down Select next item + Expand selected item - Collapse selected item M-+ Expand all items M-- Collapse all items s Set option value or key attribute S Set global option value w Set window option value, if option is for pane and window d Set an option or key to the default D Set tagged options and tagged keys to the default u Unset an option (set to default value if global) or unbind a key U Unset tagged options and unbind tagged keys C-s Search by name n Repeat last search t Toggle if item is tagged T Tag no items C-t Tag all items f Enter a format to filter items v Toggle option information q Exit mode -f specifies an initial filter: the filter is a format - if it evaluates to zero, the item in the list is not shown, otherwise it is shown. If a filter would lead to an empty list, it is ignored. -F specifies the format for each item in the tree. -N starts without the option information. This command works only if at least one client is attached. display-panes [-bN] [-d duration] [-t target-client] [template] (alias: displayp) Display a visible indicator of each pane shown by target-client. See the display-panes-colour and display-panes-active-colour ses- sion options. The indicator is closed when a key is pressed (unless -N is given) or duration milliseconds have passed. If -d is not given, display-panes-time is used. A duration of zero means the indicator stays until a key is pressed. While the indicator is on screen, a pane may be chosen with the `0' to `9' keys, which will cause template to be executed as a command with `%%' substituted by the pane ID. The default template is \u0026quot;select-pane -t '%%'\u0026quot;. With -b, other commands are not blocked from running until the indicator is closed. find-window [-iCNrTZ] [-t target-pane] match-string (alias: findw) Search for a fnmatch(3) pattern or, with -r, regular expression match-string in window names, titles, and visible content (but not history). The flags control matching behavior: -C matches only visible window contents, -N matches only the window name and -T matches only the window title. -i makes the search ignore case. The default is -CNT. -Z zooms the pane. This command works only if at least one client is attached. join-pane [-bdfhv] [-l size] [-s src-pane] [-t dst-pane] (alias: joinp) Like split-window, but instead of splitting dst-pane and creating a new pane, split it and move src-pane into the space. This can be used to reverse break-pane. The -b option causes src-pane to be joined to left of or above dst-pane. If -s is omitted and a marked pane is present (see select-pane -m), the marked pane is used rather than the current pane. kill-pane [-a] [-t target-pane] (alias: killp) Destroy the given pane. If no panes remain in the containing window, it is also destroyed. The -a option kills all but the pane given with -t. kill-window [-a] [-t target-window] (alias: killw) Kill the current window or the window at target-window, removing it from any sessions to which it is linked. The -a option kills all but the window given with -t. last-pane [-deZ] [-t target-window] (alias: lastp) Select the last (previously selected) pane. -Z keeps the window zoomed if it was zoomed. -e enables or -d disables input to the pane. last-window [-t target-session] (alias: last) Select the last (previously selected) window. If no target-session is specified, select the last window of the cur- rent session. link-window [-abdk] [-s src-window] [-t dst-window] (alias: linkw) Link the window at src-window to the specified dst-window. If dst-window is specified and no such window exists, the src-window is linked there. With -a or -b the window is moved to the next index after or before dst-window (existing windows are moved if necessary). If -k is given and dst-window exists, it is killed, otherwise an error is generated. If -d is given, the newly linked window is not selected. list-panes [-as] [-F format] [-f filter] [-t target] (alias: lsp) If -a is given, target is ignored and all panes on the server are listed. If -s is given, target is a session (or the current ses- sion). If neither is given, target is a window (or the current window). -F specifies the format of each line and -f a filter. Only panes for which the filter is true are shown. See the FORMATS section. list-windows [-a] [-F format] [-f filter] [-t target-session] (alias: lsw) If -a is given, list all windows on the server. Otherwise, list windows in the current session or in target-session. -F speci- fies the format of each line and -f a filter. Only windows for which the filter is true are shown. See the FORMATS section. move-pane [-bdfhv] [-l size] [-s src-pane] [-t dst-pane] (alias: movep) Does the same as join-pane. move-window [-abrdk] [-s src-window] [-t dst-window] (alias: movew) This is similar to link-window, except the window at src-window is moved to dst-window. With -r, all windows in the session are renumbered in sequential order, respecting the base-index option. new-window [-abdkPS] [-c start-directory] [-e environment] [-F format] [-n window-name] [-t target-window] [shell-command] (alias: neww) Create a new window. With -a or -b, the new window is inserted at the next index after or before the specified target-window, moving windows up if necessary; otherwise target-window is the new window location. If -d is given, the session does not make the new window the cur- rent window. target-window represents the window to be created; if the target already exists an error is shown, unless the -k flag is used, in which case it is destroyed. If -S is given and a window named window-name already exists, it is selected (unless -d is also given in which case the command does nothing). shell-command is the command to execute. If shell-command is not specified, the value of the default-command option is used. -c specifies the working directory in which the new window is cre- ated. When the shell command completes, the window closes. See the remain-on-exit option to change this behaviour. -e takes the form `VARIABLE=value' and sets an environment vari- able for the newly created window; it may be specified multiple times. The TERM environment variable must be set to `screen' or `tmux' for all programs running inside tmux. New windows will automati- cally have `TERM=screen' added to their environment, but care must be taken not to reset this in shell start-up files or by the -e option. The -P option prints information about the new window after it has been created. By default, it uses the format `#{session_name}:#{window_index}' but a different format may be specified with -F. next-layout [-t target-window] (alias: nextl) Move a window to the next layout and rearrange the panes to fit. next-window [-a] [-t target-session] (alias: next) Move to the next window in the session. If -a is used, move to the next window with an alert. pipe-pane [-IOo] [-t target-pane] [shell-command] (alias: pipep) Pipe output sent by the program in target-pane to a shell command or vice versa. A pane may only be connected to one command at a time, any existing pipe is closed before shell-command is exe- cuted. The shell-command string may contain the special charac- ter sequences supported by the status-left option. If no shell-command is given, the current pipe (if any) is closed. -I and -O specify which of the shell-command output streams are connected to the pane: with -I stdout is connected (so anything shell-command prints is written to the pane as if it were typed); with -O stdin is connected (so any output in the pane is piped to shell-command). Both may be used together and if neither are specified, -O is used. The -o option only opens a new pipe if no previous pipe exists, allowing a pipe to be toggled with a single key, for example: bind-key C-p pipe-pane -o 'cat \u0026gt;\u0026gt;~/output.#I-#P' previous-layout [-t target-window] (alias: prevl) Move to the previous layout in the session. previous-window [-a] [-t target-session] (alias: prev) Move to the previous window in the session. With -a, move to the previous window with an alert. rename-window [-t target-window] new-name (alias: renamew) Rename the current window, or the window at target-window if specified, to new-name. resize-pane [-DLMRTUZ] [-t target-pane] [-x width] [-y height] [adjustment] (alias: resizep) Resize a pane, up, down, left or right by adjustment with -U, -D, -L or -R, or to an absolute size with -x or -y. The adjustment is given in lines or columns (the default is 1); -x and -y may be a given as a number of lines or columns or followed by `%' for a percentage of the window size (for example `-x 10%'). With -Z, the active pane is toggled between zoomed (occupying the whole of the window) and unzoomed (its normal position in the layout). -M begins mouse resizing (only valid if bound to a mouse key binding, see MOUSE SUPPORT). -T trims all lines below the current cursor position and moves lines out of the history to replace them. resize-window [-aADLRU] [-t target-window] [-x width] [-y height] [adjustment] (alias: resizew) Resize a window, up, down, left or right by adjustment with -U, -D, -L or -R, or to an absolute size with -x or -y. The adjustment is given in lines or cells (the default is 1). -A sets the size of the largest session containing the window; -a the size of the smallest. This command will automatically set window-size to manual in the window options. respawn-pane [-k] [-c start-directory] [-e environment] [-t target-pane] [shell-command] (alias: respawnp) Reactivate a pane in which the command has exited (see the remain-on-exit window option). If shell-command is not given, the command used when the pane was created or last respawned is executed. The pane must be already inactive, unless -k is given, in which case any existing command is killed. -c specifies a new working directory for the pane. The -e option has the same mean- ing as for the new-window command. respawn-window [-k] [-c start-directory] [-e environment] [-t target-window] [shell-command] (alias: respawnw) Reactivate a window in which the command has exited (see the remain-on-exit window option). If shell-command is not given, the command used when the window was created or last respawned is executed. The window must be already inactive, unless -k is given, in which case any existing command is killed. -c speci- fies a new working directory for the window. The -e option has the same meaning as for the new-window command. rotate-window [-DUZ] [-t target-window] (alias: rotatew) Rotate the positions of the panes within a window, either upward (numerically lower) with -U or downward (numerically higher). -Z keeps the window zoomed if it was zoomed. select-layout [-Enop] [-t target-pane] [layout-name] (alias: selectl) Choose a specific layout for a window. If layout-name is not given, the last preset layout used (if any) is reapplied. -n and -p are equivalent to the next-layout and previous-layout com- mands. -o applies the last set layout if possible (undoes the most recent layout change). -E spreads the current pane and any panes next to it out evenly. select-pane [-DdeLlMmRUZ] [-T title] [-t target-pane] (alias: selectp) Make pane target-pane the active pane in its window. If one of -D, -L, -R, or -U is used, respectively the pane below, to the left, to the right, or above the target pane is used. -Z keeps the window zoomed if it was zoomed. -l is the same as using the last-pane command. -e enables or -d disables input to the pane. -T sets the pane title. -m and -M are used to set and clear the marked pane. There is one marked pane at a time, setting a new marked pane clears the last. The marked pane is the default target for -s to join-pane, move-pane, swap-pane and swap-window. select-window [-lnpT] [-t target-window] (alias: selectw) Select the window at target-window. -l, -n and -p are equivalent to the last-window, next-window and previous-window commands. If -T is given and the selected window is already the current win- dow, the command behaves like last-window. split-window [-bdfhIvPZ] [-c start-directory] [-e environment] [-l size] [-t target-pane] [shell-command] [-F format] (alias: splitw) Create a new pane by splitting target-pane: -h does a horizontal split and -v a vertical split; if neither is specified, -v is assumed. The -l option specifies the size of the new pane in lines (for vertical split) or in columns (for horizontal split); size may be followed by `%' to specify a percentage of the avail- able space. The -b option causes the new pane to be created to the left of or above target-pane. The -f option creates a new pane spanning the full window height (with -h) or full window width (with -v), instead of splitting the active pane. -Z zooms if the window is not zoomed, or keeps it zoomed if already zoomed. An empty shell-command ('') will create a pane with no command running in it. Output can be sent to such a pane with the display-message command. The -I flag (if shell-command is not specified or empty) will create an empty pane and forward any output from stdin to it. For example: $ make 2\u0026gt;\u0026amp;1|tmux splitw -dI \u0026amp; All other options have the same meaning as for the new-window command. swap-pane [-dDUZ] [-s src-pane] [-t dst-pane] (alias: swapp) Swap two panes. If -U is used and no source pane is specified with -s, dst-pane is swapped with the previous pane (before it numerically); -D swaps with the next pane (after it numerically). -d instructs tmux not to change the active pane and -Z keeps the window zoomed if it was zoomed. If -s is omitted and a marked pane is present (see select-pane -m), the marked pane is used rather than the current pane. swap-window [-d] [-s src-window] [-t dst-window] (alias: swapw) This is similar to link-window, except the source and destination windows are swapped. It is an error if no window exists at src-window. If -d is given, the new window does not become the current window. If -s is omitted and a marked pane is present (see select-pane -m), the window containing the marked pane is used rather than the current window. unlink-window [-k] [-t target-window] (alias: unlinkw) Unlink target-window. Unless -k is given, a window may be unlinked only if it is linked to multiple sessions - windows may not be linked to no sessions; if -k is specified and the window is linked to only one session, it is unlinked and destroyed. KEY BINDINGS tmux allows a command to be bound to most keys, with or without a prefix key. When specifying keys, most represent themselves (for example `A' to `Z'). Ctrl keys may be prefixed with `C-' or `^', Shift keys with `S-' and Alt (meta) with `M-'. In addition, the following special key names are accepted: Up, Down, Left, Right, BSpace, BTab, DC (Delete), End, Enter, Escape, F1 to F12, Home, IC (Insert), NPage/PageDown/PgDn, PPage/PageUp/PgUp, Space, and Tab. Note that to bind the `\u0026quot;' or `'' keys, quotation marks are necessary, for example: bind-key '\u0026quot;' split-window bind-key \u0026quot;'\u0026quot; new-window A command bound to the Any key will execute for all keys which do not have a more specific binding. Commands related to key bindings are as follows: bind-key [-nr] [-N note] [-T key-table] key command [arguments] (alias: bind) Bind key key to command. Keys are bound in a key table. By default (without -T), the key is bound in the prefix key table. This table is used for keys pressed after the prefix key (for example, by default `c' is bound to new-window in the prefix ta- ble, so `C-b c' creates a new window). The root table is used for keys pressed without the prefix key: binding `c' to new-window in the root table (not recommended) means a plain `c' will create a new window. -n is an alias for -T root. Keys may also be bound in custom key tables and the switch-client -T com- mand used to switch to them from a key binding. The -r flag indicates this key may repeat, see the repeat-time option. -N attaches a note to the key (shown with list-keys -N). To view the default bindings and possible commands, see the list-keys command. list-keys [-1aN] [-P prefix-string -T key-table] [key] (alias: lsk) List key bindings. There are two forms: the default lists keys as bind-key commands; -N lists only keys with attached notes and shows only the key and note for each key. With the default form, all key tables are listed by default. -T lists only keys in key-table. With the -N form, only keys in the root and prefix key tables are listed by default; -T also lists only keys in key-table. -P specifies a prefix to print before each key and -1 lists only the first matching key. -a lists the command for keys that do not have a note rather than skipping them. send-keys [-FHlMRX] [-N repeat-count] [-t target-pane] key ... (alias: send) Send a key or keys to a window. Each argument key is the name of the key (such as `C-a' or `NPage') to send; if the string is not recognised as a key, it is sent as a series of characters. All arguments are sent sequentially from first to last. If no keys are given and the command is bound to a key, then that key is used. The -l flag disables key name lookup and processes the keys as literal UTF-8 characters. The -H flag expects each key to be a hexadecimal number for an ASCII character. The -R flag causes the terminal state to be reset. -M passes through a mouse event (only valid if bound to a mouse key binding, see MOUSE SUPPORT). -X is used to send a command into copy mode - see the WINDOWS AND PANES section. -N specifies a repeat count and -F expands for- mats in arguments where appropriate. send-prefix [-2] [-t target-pane] Send the prefix key, or with -2 the secondary prefix key, to a window as if it was pressed. unbind-key [-anq] [-T key-table] key (alias: unbind) Unbind the command bound to key. -n and -T are the same as for bind-key. If -a is present, all key bindings are removed. The -q option prevents errors being returned. OPTIONS The appearance and behaviour of tmux may be modified by changing the value of various options. There are four types of option: server options, session options, window options, and pane options. The tmux server has a set of global server options which do not apply to any particular window or session or pane. These are altered with the set-option -s command, or displayed with the show-options -s command. In addition, each individual session may have a set of session options, and there is a separate set of global session options. Sessions which do not have a particular option configured inherit the value from the global session options. Session options are set or unset with the set-option command and may be listed with the show-options command. The available server and session options are listed under the set-option command. Similarly, a set of window options is attached to each window and a set of pane options to each pane. Pane options inherit from window options. This means any pane option may be set as a window option to apply the option to all panes in the window without the option set, for example these commands will set the background colour to red for all panes except pane 0: set -w window-style bg=red set -pt:.0 window-style bg=blue There is also a set of global window options from which any unset window or pane options are inherited. Window and pane options are altered with set-option -w and -p commands and displayed with show-option -w and -p. tmux also supports user options which are prefixed with a `@'. User options may have any name, so long as they are prefixed with `@', and be set to any string. For example: $ tmux set -wq @foo \u0026quot;abc123\u0026quot; $ tmux show -wv @foo abc123 Commands which set options are as follows: set-option [-aFgopqsuUw] [-t target-pane] option value (alias: set) Set a pane option with -p, a window option with -w, a server option with -s, otherwise a session option. If the option is not a user option, -w or -s may be unnecessary - tmux will infer the type from the option name, assuming -w for pane options. If -g is given, the global session or window option is set. -F expands formats in the option value. The -u flag unsets an option, so a session inherits the option from the global options (or with -g, restores a global option to the default). -U unsets an option (like -u) but if the option is a pane option also unsets the option on any panes in the window. value depends on the option and may be a number, a string, or a flag (on, off, or omitted to toggle). The -o flag prevents setting an option that is already set and the -q flag suppresses errors about unknown or ambiguous options. With -a, and if the option expects a string or a style, value is appended to the existing setting. For example: set -g status-left \u0026quot;foo\u0026quot; set -ag status-left \u0026quot;bar\u0026quot; Will result in `foobar'. And: set -g status-style \u0026quot;bg=red\u0026quot; set -ag status-style \u0026quot;fg=blue\u0026quot; Will result in a red background and blue foreground. Without -a, the result would be the default background and a blue foreground. show-options [-AgHpqsvw] [-t target-pane] [option] (alias: show) Show the pane options (or a single option if option is provided) with -p, the window options with -w, the server options with -s, otherwise the session options. If the option is not a user option, -w or -s may be unnecessary - tmux will infer the type from the option name, assuming -w for pane options. Global ses- sion or window options are listed if -g is used. -v shows only the option value, not the name. If -q is set, no error will be returned if option is unset. -H includes hooks (omitted by default). -A includes options inherited from a parent set of options, such options are marked with an asterisk. Available server options are: backspace key Set the key sent by tmux for backspace. buffer-limit number Set the number of buffers; as new buffers are added to the top of the stack, old ones are removed from the bottom if necessary to maintain this maximum length. command-alias[] name=value This is an array of custom aliases for commands. If an unknown command matches name, it is replaced with value. For example, after: set -s command-alias[100] zoom='resize-pane -Z' Using: zoom -t:.1 Is equivalent to: resize-pane -Z -t:.1 Note that aliases are expanded when a command is parsed rather than when it is executed, so binding an alias with bind-key will bind the expanded form. default-terminal terminal Set the default terminal for new windows created in this session - the default value of the TERM environment variable. For tmux to work correctly, this must be set to `screen', `tmux' or a de- rivative of them. copy-command shell-command Give the command to pipe to if the copy-pipe copy mode command is used without arguments. escape-time time Set the time in milliseconds for which tmux waits after an escape is input to determine if it is part of a function or meta key sequences. The default is 500 milliseconds. editor shell-command Set the command used when tmux runs an editor. exit-empty [on | off] If enabled (the default), the server will exit when there are no active sessions. exit-unattached [on | off] If enabled, the server will exit when there are no attached clients. extended-keys [on | off | always] When on or always, the escape sequence to enable extended keys is sent to the terminal, if tmux knows that it is supported. tmux always recognises extended keys itself. If this option is on, tmux will only forward extended keys to applications when they request them; if always, tmux will always forward the keys. focus-events [on | off] When enabled, focus events are requested from the terminal if supported and passed through to applications running in tmux. Attached clients should be detached and attached again after changing this option. history-file path If not empty, a file to which tmux will write command prompt his- tory on exit and load it from on start. message-limit number Set the number of error or information messages to save in the message log for each client. prompt-history-limit number Set the number of history items to save in the history file for each type of command prompt. set-clipboard [on | external | off] Attempt to set the terminal clipboard content using the xterm(1) escape sequence, if there is an Ms entry in the terminfo(5) description (see the TERMINFO EXTENSIONS section). If set to on, tmux will both accept the escape sequence to create a buffer and attempt to set the terminal clipboard. If set to external, tmux will attempt to set the terminal clipboard but ignore attempts by applications to set tmux buffers. If off, tmux will neither accept the clipboard escape sequence nor attempt to set the clipboard. Note that this feature needs to be enabled in xterm(1) by setting the resource: disallowedWindowOps: 20,21,SetXprop Or changing this property from the xterm(1) interactive menu when required. terminal-features[] string Set terminal features for terminal types read from terminfo(5). tmux has a set of named terminal features. Each will apply appropriate changes to the terminfo(5) entry in use. tmux can detect features for a few common terminals; this option can be used to easily tell tmux about features supported by ter- minals it cannot detect. The terminal-overrides option allows individual terminfo(5) capabilities to be set instead, terminal-features is intended for classes of functionality sup- ported in a standard way but not reported by terminfo(5). Care must be taken to configure this only with features the terminal actually supports. This is an array option where each entry is a colon-separated string made up of a terminal type pattern (matched using fnmatch(3)) followed by a list of terminal features. The avail- able features are: 256 Supports 256 colours with the SGR escape sequences. clipboard Allows setting the system clipboard. ccolour Allows setting the cursor colour. cstyle Allows setting the cursor style. extkeys Supports extended keys. focus Supports focus reporting. margins Supports DECSLRM margins. mouse Supports xterm(1) mouse sequences. osc7 Supports the OSC 7 working directory extension. overline Supports the overline SGR attribute. rectfill Supports the DECFRA rectangle fill escape sequence. RGB Supports RGB colour with the SGR escape sequences. strikethrough Supports the strikethrough SGR escape sequence. sync Supports synchronized updates. title Supports xterm(1) title setting. usstyle Allows underscore style and colour to be set. terminal-overrides[] string Allow terminal descriptions read using terminfo(5) to be overrid- den. Each entry is a colon-separated string made up of a termi- nal type pattern (matched using fnmatch(3)) and a set of name=value entries. For example, to set the `clear' terminfo(5) entry to `\\e[H\\e[2J' for all terminal types matching `rxvt*': rxvt*:clear=\\e[H\\e[2J The terminal entry value is passed through strunvis(3) before interpretation. user-keys[] key Set list of user-defined key escape sequences. Each item is associated with a key named `User0', `User1', and so on. For example: set -s user-keys[0] \u0026quot;\\e[5;30012~\u0026quot; bind User0 resize-pane -L 3 Available session options are: activity-action [any | none | current | other] Set action on window activity when monitor-activity is on. any means activity in any window linked to a session causes a bell or message (depending on visual-activity) in the current window of that session, none means all activity is ignored (equivalent to monitor-activity being off), current means only activity in win- dows other than the current window are ignored and other means activity in the current window is ignored but not those in other windows. assume-paste-time milliseconds If keys are entered faster than one in milliseconds, they are assumed to have been pasted rather than typed and tmux key bind- ings are not processed. The default is one millisecond and zero disables. base-index index Set the base index from which an unused index should be searched when a new window is created. The default is zero. bell-action [any | none | current | other] Set action on a bell in a window when monitor-bell is on. The values are the same as those for activity-action. default-command shell-command Set the command used for new windows (if not specified when the window is created) to shell-command, which may be any sh(1) com- mand. The default is an empty string, which instructs tmux to create a login shell using the value of the default-shell option. default-shell path Specify the default shell. This is used as the login shell for new windows when the default-command option is set to empty, and must be the full path of the executable. When started tmux tries to set a default value from the first suitable of the SHELL envi- ronment variable, the shell returned by getpwuid(3), or /bin/sh. This option should be configured when tmux is used as a login shell. default-size XxY Set the default size of new windows when the window-size option is set to manual or when a session is created with new-session -d. The value is the width and height separated by an `x' char- acter. The default is 80x24. destroy-unattached [on | off] If enabled and the session is no longer attached to any clients, it is destroyed. detach-on-destroy [off | on | no-detached] If on (the default), the client is detached when the session it is attached to is destroyed. If off, the client is switched to the most recently active of the remaining sessions. If no-detached, the client is detached only if there are no detached sessions; if detached sessions exist, the client is switched to the most recently active. display-panes-active-colour colour Set the colour used by the display-panes command to show the indicator for the active pane. display-panes-colour colour Set the colour used by the display-panes command to show the indicators for inactive panes. display-panes-time time Set the time in milliseconds for which the indicators shown by the display-panes command appear. display-time time Set the amount of time for which status line messages and other on-screen indicators are displayed. If set to 0, messages and indicators are displayed until a key is pressed. time is in mil- liseconds. history-limit lines Set the maximum number of lines held in window history. This setting applies only to new windows - existing window histories are not resized and retain the limit at the point they were cre- ated. key-table key-table Set the default key table to key-table instead of root. lock-after-time number Lock the session (like the lock-session command) after number seconds of inactivity. The default is not to lock (set to 0). lock-command shell-command Command to run when locking each client. The default is to run lock(1) with -np. message-command-style style Set status line message command style. This is used for the com- mand prompt with vi(1) keys when in command mode. For how to specify style, see the STYLES section. message-style style Set status line message style. This is used for messages and for the command prompt. For how to specify style, see the STYLES section. mouse [on | off] If on, tmux captures the mouse and allows mouse events to be bound as key bindings. See the MOUSE SUPPORT section for details. prefix key Set the key accepted as a prefix key. In addition to the stan- dard keys described under KEY BINDINGS, prefix can be set to the special key `None' to set no prefix. prefix2 key Set a secondary key accepted as a prefix key. Like prefix, prefix2 can be set to `None'. renumber-windows [on | off] If on, when a window is closed in a session, automatically renum- ber the other windows in numerical order. This respects the base-index option if it has been set. If off, do not renumber the windows. repeat-time time Allow multiple commands to be entered without pressing the pre- fix-key again in the specified time milliseconds (the default is 500). Whether a key repeats may be set when it is bound using the -r flag to bind-key. Repeat is enabled for the default keys bound to the resize-pane command. set-titles [on | off] Attempt to set the client terminal title using the tsl and fsl terminfo(5) entries if they exist. tmux automatically sets these to the \\e]0;...\\007 sequence if the terminal appears to be xterm(1). This option is off by default. set-titles-string string String used to set the client terminal title if set-titles is on. Formats are expanded, see the FORMATS section. silence-action [any | none | current | other] Set action on window silence when monitor-silence is on. The values are the same as those for activity-action. status [off | on | 2 | 3 | 4 | 5] Show or hide the status line or specify its size. Using on gives a status line one row in height; 2, 3, 4 or 5 more rows. status-format[] format Specify the format to be used for each line of the status line. The default builds the top status line from the various individ- ual status options below. status-interval interval Update the status line every interval seconds. By default, updates will occur every 15 seconds. A setting of zero disables redrawing at interval. status-justify [left | centre | right | absolute-centre] Set the position of the window list in the status line: left, centre or right. centre puts the window list in the relative centre of the available free space; absolute-centre uses the cen- tre of the entire horizontal space. status-keys [vi | emacs] Use vi or emacs-style key bindings in the status line, for exam- ple at the command prompt. The default is emacs, unless the VISUAL or EDITOR environment variables are set and contain the string `vi'. status-left string Display string (by default the session name) to the left of the status line. string will be passed through strftime(3). Also see the FORMATS and STYLES sections. For details on how the names and titles can be set see the NAMES AND TITLES section. Examples are: #(sysctl vm.loadavg) #[fg=yellow,bold]#(apm -l)%%#[default] [#S] The default is `[#S] '. status-left-length length Set the maximum length of the left component of the status line. The default is 10. status-left-style style Set the style of the left part of the status line. For how to specify style, see the STYLES section. status-position [top | bottom] Set the position of the status line. status-right string Display string to the right of the status line. By default, the current pane title in double quotes, the date and the time are shown. As with status-left, string will be passed to strftime(3) and character pairs are replaced. status-right-length length Set the maximum length of the right component of the status line. The default is 40. status-right-style style Set the style of the right part of the status line. For how to specify style, see the STYLES section. status-style style Set status line style. For how to specify style, see the STYLES section. update-environment[] variable Set list of environment variables to be copied into the session environment when a new session is created or an existing session is attached. Any variables that do not exist in the source envi- ronment are set to be removed from the session environment (as if -r was given to the set-environment command). visual-activity [on | off | both] If on, display a message instead of sending a bell when activity occurs in a window for which the monitor-activity window option is enabled. If set to both, a bell and a message are produced. visual-bell [on | off | both] If on, a message is shown on a bell in a window for which the monitor-bell window option is enabled instead of it being passed through to the terminal (which normally makes a sound). If set to both, a bell and a message are produced. Also see the bell-action option. visual-silence [on | off | both] If monitor-silence is enabled, prints a message after the inter- val has expired on a given window instead of sending a bell. If set to both, a bell and a message are produced. word-separators string Sets the session's conception of what characters are considered word separators, for the purposes of the next and previous word commands in copy mode. Available window options are: aggressive-resize [on | off] Aggressively resize the chosen window. This means that tmux will resize the window to the size of the smallest or largest session (see the window-size option) for which it is the current window, rather than the session to which it is attached. The window may resize when the current window is changed on another session; this option is good for full-screen programs which support SIGWINCH and poor for interactive programs such as shells. automatic-rename [on | off] Control automatic window renaming. When this setting is enabled, tmux will rename the window automatically using the format speci- fied by automatic-rename-format. This flag is automatically dis- abled for an individual window when a name is specified at cre- ation with new-window or new-session, or later with rename-window, or with a terminal escape sequence. It may be switched off globally with: set-option -wg automatic-rename off automatic-rename-format format The format (see FORMATS) used when the automatic-rename option is enabled. clock-mode-colour colour Set clock colour. clock-mode-style [12 | 24] Set clock hour format. fill-character character Set the character used to fill areas of the terminal unused by a window. main-pane-height height main-pane-width width Set the width or height of the main (left or top) pane in the main-horizontal or main-vertical layouts. If suffixed by `%', this is a percentage of the window size. copy-mode-match-style style Set the style of search matches in copy mode. For how to specify style, see the STYLES section. copy-mode-mark-style style Set the style of the line containing the mark in copy mode. For how to specify style, see the STYLES section. copy-mode-current-match-style style Set the style of the current search match in copy mode. For how to specify style, see the STYLES section. mode-keys [vi | emacs] Use vi or emacs-style key bindings in copy mode. The default is emacs, unless VISUAL or EDITOR contains `vi'. mode-style style Set window modes style. For how to specify style, see the STYLES section. monitor-activity [on | off] Monitor for activity in the window. Windows with activity are highlighted in the status line. monitor-bell [on | off] Monitor for a bell in the window. Windows with a bell are high- lighted in the status line. monitor-silence [interval] Monitor for silence (no activity) in the window within interval seconds. Windows that have been silent for the interval are highlighted in the status line. An interval of zero disables the monitoring. other-pane-height height Set the height of the other panes (not the main pane) in the main-horizontal layout. If this option is set to 0 (the default), it will have no effect. If both the main-pane-height and other-pane-height options are set, the main pane will grow taller to make the other panes the specified height, but will never shrink to do so. If suffixed by `%', this is a percentage of the window size. other-pane-width width Like other-pane-height, but set the width of other panes in the main-vertical layout. pane-active-border-style style Set the pane border style for the currently active pane. For how to specify style, see the STYLES section. Attributes are ignored. pane-base-index index Like base-index, but set the starting index for pane numbers. pane-border-format format Set the text shown in pane border status lines. pane-border-indicators [off | colour | arrows | both] Indicate active pane by colouring only half of the border in win- dows with exactly two panes, by displaying arrow markers, by drawing both or neither. pane-border-lines type Set the type of characters used for drawing pane borders. type may be one of: single single lines using ACS or UTF-8 characters double double lines using UTF-8 characters heavy heavy lines using UTF-8 characters simple simple ASCII characters number the pane number `double' and `heavy' will fall back to standard ACS line drawing when UTF-8 is not supported. pane-border-status [off | top | bottom] Turn pane border status lines off or set their position. pane-border-style style Set the pane border style for panes aside from the active pane. For how to specify style, see the STYLES section. Attributes are ignored. popup-style style Set the popup style. For how to specify style, see the STYLES section. Attributes are ignored. popup-border-style style Set the popup border style. For how to specify style, see the STYLES section. Attributes are ignored. popup-border-lines type Set the type of characters used for drawing popup borders. type may be one of: single single lines using ACS or UTF-8 characters (default) rounded variation of single with rounded corners using UTF-8 characters double double lines using UTF-8 characters heavy heavy lines using UTF-8 characters simple simple ASCII characters padded simple ASCII space character none no border `double' and `heavy' will fall back to standard ACS line drawing when UTF-8 is not supported. window-status-activity-style style Set status line style for windows with an activity alert. For how to specify style, see the STYLES section. window-status-bell-style style Set status line style for windows with a bell alert. For how to specify style, see the STYLES section. window-status-current-format string Like window-status-format, but is the format used when the window is the current window. window-status-current-style style Set status line style for the currently active window. For how to specify style, see the STYLES section. window-status-format string Set the format in which the window is displayed in the status line window list. See the FORMATS and STYLES sections. window-status-last-style style Set status line style for the last active window. For how to specify style, see the STYLES section. window-status-separator string Sets the separator drawn between windows in the status line. The default is a single space character. window-status-style style Set status line style for a single window. For how to specify style, see the STYLES section. window-size largest | smallest | manual | latest Configure how tmux determines the window size. If set to largest, the size of the largest attached session is used; if smallest, the size of the smallest. If manual, the size of a new window is set from the default-size option and windows are resized automatically. With latest, tmux uses the size of the client that had the most recent activity. See also the resize-window command and the aggressive-resize option. wrap-search [on | off] If this option is set, searches will wrap around the end of the pane contents. The default is on. Available pane options are: allow-passthrough [on | off] Allow programs in the pane to bypass tmux using a terminal escape sequence (\\ePtmux;...\\e\\\\). allow-rename [on | off] Allow programs in the pane to change the window name using a ter- minal escape sequence (\\ek...\\e\\\\). alternate-screen [on | off] This option configures whether programs running inside the pane may use the terminal alternate screen feature, which allows the smcup and rmcup terminfo(5) capabilities. The alternate screen feature preserves the contents of the window when an interactive application starts and restores it on exit, so that any output visible before the application starts reappears unchanged after it exits. cursor-colour colour Set the colour of the cursor. pane-colours[] colour The default colour palette. Each entry in the array defines the colour tmux uses when the colour with that index is requested. The index may be from zero to 255. cursor-style style Set the style of the cursor. Available styles are: default, blinking-block, block, blinking-underline, underline, blinking-bar, bar. remain-on-exit [on | off | failed] A pane with this flag set is not destroyed when the program run- ning in it exits. If set to failed, then only when the program exit status is not zero. The pane may be reactivated with the respawn-pane command. remain-on-exit-format string Set the text shown at the bottom of exited panes when remain-on-exit is enabled. scroll-on-clear [on | off] When the entire screen is cleared and this option is on, scroll the contents of the screen into history before clearing it. synchronize-panes [on | off] Duplicate input to all other panes in the same window where this option is also on (only for panes that are not in any mode). window-active-style style Set the pane style when it is the active pane. For how to spec- ify style, see the STYLES section. window-style style Set the pane style. For how to specify style, see the STYLES section. HOOKS tmux allows commands to run on various triggers, called hooks. Most tmux commands have an after hook and there are a number of hooks not associ- ated with commands. Hooks are stored as array options, members of the array are executed in order when the hook is triggered. Like options different hooks may be global or belong to a session, window or pane. Hooks may be configured with the set-hook or set-option commands and displayed with show-hooks or show-options -H. The following two commands are equivalent: set-hook -g pane-mode-changed[42] 'set -g status-left-style bg=red' set-option -g pane-mode-changed[42] 'set -g status-left-style bg=red' Setting a hook without specifying an array index clears the hook and sets the first member of the array. A command's after hook is run after it completes, except when the command is run as part of a hook itself. They are named with an `after-' prefix. For example, the following command adds a hook to select the even-verti- cal layout after every split-window: set-hook -g after-split-window \u0026quot;selectl even-vertical\u0026quot; All the notifications listed in the CONTROL MODE section are hooks (with- out any arguments), except %exit. The following additional hooks are available: alert-activity Run when a window has activity. See monitor-activity. alert-bell Run when a window has received a bell. See monitor-bell. alert-silence Run when a window has been silent. See monitor-silence. client-active Run when a client becomes the latest active client of its session. client-attached Run when a client is attached. client-detached Run when a client is detached client-focus-in Run when focus enters a client client-focus-out Run when focus exits a client client-resized Run when a client is resized. client-session-changed Run when a client's attached session is changed. pane-died Run when the program running in a pane exits, but remain-on-exit is on so the pane has not closed. pane-exited Run when the program running in a pane exits. pane-focus-in Run when the focus enters a pane, if the focus-events option is on. pane-focus-out Run when the focus exits a pane, if the focus-events option is on. pane-set-clipboard Run when the terminal clipboard is set using the xterm(1) escape sequence. session-created Run when a new session created. session-closed Run when a session closed. session-renamed Run when a session is renamed. window-linked Run when a window is linked into a session. window-renamed Run when a window is renamed. window-resized Run when a window is resized. This may be after the client-resized hook is run. window-unlinked Run when a window is unlinked from a session. Hooks are managed with these commands: set-hook [-agpRuw] [-t target-pane] hook-name command Without -R, sets (or with -u unsets) hook hook-name to command. The flags are the same as for set-option. With -R, run hook-name immediately. show-hooks [-gpw] [-t target-pane] Shows hooks. The flags are the same as for show-options. MOUSE SUPPORT If the mouse option is on (the default is off), tmux allows mouse events to be bound as keys. The name of each key is made up of a mouse event (such as `MouseUp1') and a location suffix, one of the following: Pane the contents of a pane Border a pane border Status the status line window list StatusLeft the left part of the status line StatusRight the right part of the status line StatusDefault any other part of the status line The following mouse events are available: WheelUp WheelDown MouseDown1 MouseUp1 MouseDrag1 MouseDragEnd1 MouseDown2 MouseUp2 MouseDrag2 MouseDragEnd2 MouseDown3 MouseUp3 MouseDrag3 MouseDragEnd3 SecondClick1 SecondClick2 SecondClick3 DoubleClick1 DoubleClick2 DoubleClick3 TripleClick1 TripleClick2 TripleClick3 The `SecondClick' events are fired for the second click of a double click, even if there may be a third click which will fire `TripleClick' instead of `DoubleClick'. Each should be suffixed with a location, for example `MouseDown1Status'. The special token `{mouse}' or `=' may be used as target-window or target-pane in commands bound to mouse key bindings. It resolves to the window or pane over which the mouse event took place (for example, the window in the status line over which button 1 was released for a `MouseUp1Status' binding, or the pane over which the wheel was scrolled for a `WheelDownPane' binding). The send-keys -M flag may be used to forward a mouse event to a pane. The default key bindings allow the mouse to be used to select and resize panes, to copy text and to change window using the status line. These take effect if the mouse option is turned on. FORMATS Certain commands accept the -F flag with a format argument. This is a string which controls the output format of the command. Format variables are enclosed in `#{' and `}', for example `#{session_name}'. The possi- ble variables are listed in the table below, or the name of a tmux option may be used for an option's value. Some variables have a shorter alias such as `#S'; `##' is replaced by a single `#', `#,' by a `,' and `#}' by a `}'. Conditionals are available by prefixing with `?' and separating two alternatives with a comma; if the specified variable exists and is not zero, the first alternative is chosen, otherwise the second is used. For example `#{?session_attached,attached,not attached}' will include the string `attached' if the session is attached and the string `not attached' if it is unattached, or `#{?automatic-rename,yes,no}' will include `yes' if automatic-rename is enabled, or `no' if not. Condition- als can be nested arbitrarily. Inside a conditional, `,' and `}' must be escaped as `#,' and `#}', unless they are part of a `#{...}' replacement. For example: #{?pane_in_mode,#[fg=white#,bg=red],#[fg=red#,bg=white]}#W . String comparisons may be expressed by prefixing two comma-separated alternatives by `==', `!=', `\u0026lt;', `\u0026gt;', `\u0026lt;=' or `\u0026gt;=' and a colon. For example `#{==:#{host},myhost}' will be replaced by `1' if running on `myhost', otherwise by `0'. `||' and `\u0026amp;\u0026amp;' evaluate to true if either or both of two comma-separated alternatives are true, for example `#{||:#{pane_in_mode},#{alternate_on}}'. An `m' specifies an fnmatch(3) or regular expression comparison. The first argument is the pattern and the second the string to compare. An optional argument specifies flags: `r' means the pattern is a regular expression instead of the default fnmatch(3) pattern, and `i' means to ignore case. For example: `#{m:*foo*,#{host}}' or `#{m/ri:^A,MYVAR}'. A `C' performs a search for an fnmatch(3) pattern or regular expression in the pane content and evaluates to zero if not found, or a line number if found. Like `m', an `r' flag means search for a regular expression and `i' ignores case. For example: `#{C/r:^Start}' Numeric operators may be performed by prefixing two comma-separated alternatives with an `e' and an operator. An optional `f' flag may be given after the operator to use floating point numbers, otherwise inte- gers are used. This may be followed by a number giving the number of decimal places to use for the result. The available operators are: addi- tion `+', subtraction `-', multiplication `*', division `/', modulus `m' or `%' (note that `%' must be escaped as `%%' in formats which are also expanded by strftime(3)) and numeric comparison operators `==', `!=', `\u0026lt;', `\u0026lt;=', `\u0026gt;' and `\u0026gt;='. For example, `#{e|*|f|4:5.5,3}' multiplies 5.5 by 3 for a result with four decimal places and `#{e|%%:7,3}' returns the modulus of 7 and 3. `a' replaces a numeric argument by its ASCII equiva- lent, so `#{a:98}' results in `b'. `c' replaces a tmux colour by its six-digit hexadecimal RGB value. A limit may be placed on the length of the resultant string by prefixing it by an `=', a number and a colon. Positive numbers count from the start of the string and negative from the end, so `#{=5:pane_title}' will include at most the first five characters of the pane title, or `#{=-5:pane_title}' the last five characters. A suffix or prefix may be given as a second argument - if provided then it is appended or prepended to the string if the length has been trimmed, for example `#{=/5/...:pane_title}' will append `...' if the pane title is more than five characters. Similarly, `p' pads the string to a given width, for example `#{p10:pane_title}' will result in a width of at least 10 charac- ters. A positive width pads on the left, a negative on the right. `n' expands to the length of the variable and `w' to its width when dis- played, for example `#{n:window_name}'. Prefixing a time variable with `t:' will convert it to a string, so if `#{window_activity}' gives `1445765102', `#{t:window_activity}' gives `Sun Oct 25 09:25:02 2015'. Adding `p (' ``t/p`') will use shorter but less accurate time format for times in the past. A custom format may be given using an `f' suffix (note that `%' must be escaped as `%%' if the format is separately being passed through strftime(3), for example in the status-left option): `#{t/f/%%H#:%%M:window_activity}', see strftime(3). The `b:' and `d:' prefixes are basename(3) and dirname(3) of the variable respectively. `q:' will escape sh(1) special characters or with a `h' suffix, escape hash characters (so `#' becomes `##'). `E:' will expand the format twice, for example `#{E:status-left}' is the result of expand- ing the content of the status-left option rather than the option itself. `T:' is like `E:' but also expands strftime(3) specifiers. `S:', `W:' or `P:' will loop over each session, window or pane and insert the format once for each. For windows and panes, two comma-separated formats may be given: the second is used for the current window or active pane. For example, to get a list of windows formatted like the status line: #{W:#{E:window-status-format} ,#{E:window-status-current-format} } `N:' checks if a window (without any suffix or with the `w' suffix) or a session (with the `s' suffix) name exists, for example ``N/w:foo`' is replaced with 1 if a window named `foo' exists. A prefix of the form `s/foo/bar/:' will substitute `foo' with `bar' throughout. The first argument may be an extended regular expression and a final argument may be `i' to ignore case, for example `s/a(.)/\\1x/i:' would change `abABab' into `bxBxbx'. In addition, the last line of a shell command's output may be inserted using `#()'. For example, `#(uptime)' will insert the system's uptime. When constructing formats, tmux does not wait for `#()' commands to fin- ish; instead, the previous result from running the same command is used, or a placeholder if the command has not been run before. If the command hasn't exited, the most recent line of output will be used, but the sta- tus line will not be updated more than once a second. Commands are exe- cuted using /bin/sh and with the tmux global environment set (see the GLOBAL AND SESSION ENVIRONMENT section). An `l' specifies that a string should be interpreted literally and not expanded. For example `#{l:#{?pane_in_mode,yes,no}}' will be replaced by `#{?pane_in_mode,yes,no}'. The following variables are available, where appropriate: Variable name Alias Replaced with active_window_index Index of active window in session alternate_on 1 if pane is in alternate screen alternate_saved_x Saved cursor X in alternate screen alternate_saved_y Saved cursor Y in alternate screen buffer_created Time buffer created buffer_name Name of buffer buffer_sample Sample of start of buffer buffer_size Size of the specified buffer in bytes client_activity Time client last had activity client_cell_height Height of each client cell in pixels client_cell_width Width of each client cell in pixels client_control_mode 1 if client is in control mode client_created Time client created client_discarded Bytes discarded when client behind client_flags List of client flags client_height Height of client client_key_table Current key table client_last_session Name of the client's last session client_name Name of client client_pid PID of client process client_prefix 1 if prefix key has been pressed client_readonly 1 if client is read-only client_session Name of the client's session client_termfeatures Terminal features of client, if any client_termname Terminal name of client client_termtype Terminal type of client, if available client_tty Pseudo terminal of client client_uid UID of client process client_user User of client process client_utf8 1 if client supports UTF-8 client_width Width of client client_written Bytes written to client command Name of command in use, if any command_list_alias Command alias if listing commands command_list_name Command name if listing commands command_list_usage Command usage if listing commands config_files List of configuration files loaded copy_cursor_line Line the cursor is on in copy mode copy_cursor_word Word under cursor in copy mode copy_cursor_x Cursor X position in copy mode copy_cursor_y Cursor Y position in copy mode current_file Current configuration file cursor_character Character at cursor in pane cursor_flag Pane cursor flag cursor_x Cursor X position in pane cursor_y Cursor Y position in pane history_bytes Number of bytes in window history history_limit Maximum window history lines history_size Size of history in lines hook Name of running hook, if any hook_client Name of client where hook was run, if any hook_pane ID of pane where hook was run, if any hook_session ID of session where hook was run, if any hook_session_name Name of session where hook was run, if any hook_window ID of window where hook was run, if any hook_window_name Name of window where hook was run, if any host #H Hostname of local host host_short #h Hostname of local host (no domain name) insert_flag Pane insert flag keypad_cursor_flag Pane keypad cursor flag keypad_flag Pane keypad flag last_window_index Index of last window in session line Line number in the list mouse_all_flag Pane mouse all flag mouse_any_flag Pane mouse any flag mouse_button_flag Pane mouse button flag mouse_line Line under mouse, if any mouse_sgr_flag Pane mouse SGR flag mouse_standard_flag Pane mouse standard flag mouse_utf8_flag Pane mouse UTF-8 flag mouse_word Word under mouse, if any mouse_x Mouse X position, if any mouse_y Mouse Y position, if any next_session_id Unique session ID for next new session origin_flag Pane origin flag pane_active 1 if active pane pane_at_bottom 1 if pane is at the bottom of window pane_at_left 1 if pane is at the left of window pane_at_right 1 if pane is at the right of window pane_at_top 1 if pane is at the top of window pane_bg Pane background colour pane_bottom Bottom of pane pane_current_command Current command if available pane_current_path Current path if available pane_dead 1 if pane is dead pane_dead_signal Exit signal of process in dead pane pane_dead_status Exit status of process in dead pane pane_dead_time Exit time of process in dead pane pane_fg Pane foreground colour pane_format 1 if format is for a pane pane_height Height of pane pane_id #D Unique pane ID pane_in_mode 1 if pane is in a mode pane_index #P Index of pane pane_input_off 1 if input to pane is disabled pane_last 1 if last pane pane_left Left of pane pane_marked 1 if this is the marked pane pane_marked_set 1 if a marked pane is set pane_mode Name of pane mode, if any pane_path Path of pane (can be set by application) pane_pid PID of first process in pane pane_pipe 1 if pane is being piped pane_right Right of pane pane_search_string Last search string in copy mode pane_start_command Command pane started with pane_start_path Path pane started with pane_synchronized 1 if pane is synchronized pane_tabs Pane tab positions pane_title #T Title of pane (can be set by application) pane_top Top of pane pane_tty Pseudo terminal of pane pane_width Width of pane pid Server PID rectangle_toggle 1 if rectangle selection is activated scroll_position Scroll position in copy mode scroll_region_lower Bottom of scroll region in pane scroll_region_upper Top of scroll region in pane search_match Search match if any search_present 1 if search started in copy mode selection_active 1 if selection started and changes with the cursor in copy mode selection_end_x X position of the end of the selection selection_end_y Y position of the end of the selection selection_present 1 if selection started in copy mode selection_start_x X position of the start of the selection selection_start_y Y position of the start of the selection session_activity Time of session last activity session_alerts List of window indexes with alerts session_attached Number of clients session is attached to session_attached_list List of clients session is attached to session_created Time session created session_format 1 if format is for a session session_group Name of session group session_group_attached Number of clients sessions in group are attached to session_group_attached_list List of clients sessions in group are attached to session_group_list List of sessions in group session_group_many_attached 1 if multiple clients attached to sessions in group session_group_size Size of session group session_grouped 1 if session in a group session_id Unique session ID session_last_attached Time session last attached session_many_attached 1 if multiple clients attached session_marked 1 if this session contains the marked pane session_name #S Name of session session_path Working directory of session session_stack Window indexes in most recent order session_windows Number of windows in session socket_path Server socket path start_time Server start time uid Server UID user Server user version Server version window_active 1 if window active window_active_clients Number of clients viewing this window window_active_clients_list List of clients viewing this window window_active_sessions Number of sessions on which this window is active window_active_sessions_list List of sessions on which this window is active window_activity Time of window last activity window_activity_flag 1 if window has activity window_bell_flag 1 if window has bell window_bigger 1 if window is larger than client window_cell_height Height of each cell in pixels window_cell_width Width of each cell in pixels window_end_flag 1 if window has the highest index window_flags #F Window flags with # escaped as ## window_format 1 if format is for a window window_height Height of window window_id Unique window ID window_index #I Index of window window_last_flag 1 if window is the last used window_layout Window layout description, ignoring zoomed window panes window_linked 1 if window is linked across sessions window_linked_sessions Number of sessions this window is linked to window_linked_sessions_list List of sessions this window is linked to window_marked_flag 1 if window contains the marked pane window_name #W Name of window window_offset_x X offset into window if larger than client window_offset_y Y offset into window if larger than client window_panes Number of panes in window window_raw_flags Window flags with nothing escaped window_silence_flag 1 if window has silence alert window_stack_index Index in session most recent stack window_start_flag 1 if window has the lowest index window_visible_layout Window layout description, respecting zoomed window panes window_width Width of window window_zoomed_flag 1 if window is zoomed wrap_flag Pane wrap flag STYLES tmux offers various options to specify the colour and attributes of aspects of the interface, for example status-style for the status line. In addition, embedded styles may be specified in format options, such as status-left, by enclosing them in `#[' and `]'. A style may be the single term `default' to specify the default style (which may come from an option, for example status-style in the status line) or a space or comma separated list of the following: fg=colour Set the foreground colour. The colour is one of: black, red, green, yellow, blue, magenta, cyan, white; if supported the bright variants brightred, brightgreen, brightyellow; colour0 to colour255 from the 256-colour set; default for the default colour; terminal for the terminal default colour; or a hexadeci- mal RGB string such as `#ffffff'. bg=colour Set the background colour. none Set no attributes (turn off any active attributes). acs, bright (or bold), dim, underscore, blink, reverse, hidden, italics, overline, strikethrough, double-underscore, curly-underscore, dotted-underscore, dashed-underscore Set an attribute. Any of the attributes may be prefixed with `no' to unset. acs is the terminal alternate character set. align=left (or noalign), align=centre, align=right Align text to the left, centre or right of the available space if appropriate. fill=colour Fill the available space with a background colour if appropriate. list=on, list=focus, list=left-marker, list=right-marker, nolist Mark the position of the various window list components in the status-format option: list=on marks the start of the list; list=focus is the part of the list that should be kept in focus if the entire list won't fit in the available space (typically the current window); list=left-marker and list=right-marker mark the text to be used to mark that text has been trimmed from the left or right of the list if there is not enough space. push-default, pop-default Store the current colours and attributes as the default or reset to the previous default. A push-default affects any subsequent use of the default term until a pop-default. Only one default may be pushed (each push-default replaces the previous saved default). range=left, range=right, range=window|X, norange Mark a range in the status-format option. range=left and range=right are the text used for the `StatusLeft' and `StatusRight' mouse keys. range=window|X is the range for a win- dow passed to the `Status' mouse key, where `X' is a window index. Examples are: fg=yellow bold underscore blink bg=black,fg=default,noreverse NAMES AND TITLES tmux distinguishes between names and titles. Windows and sessions have names, which may be used to specify them in targets and are displayed in the status line and various lists: the name is the tmux identifier for a window or session. Only panes have titles. A pane's title is typically set by the program running inside the pane using an escape sequence (like it would set the xterm(1) window title in X(7)). Windows themselves do not have titles - a window's title is the title of its active pane. tmux itself may set the title of the terminal in which the client is running, see the set-titles option. A session's name is set with the new-session and rename-session commands. A window's name is set with one of: 1. A command argument (such as -n for new-window or new-session). 2. An escape sequence (if the allow-rename option is turned on): $ printf '\\033kWINDOW_NAME\\033\\\\' 3. Automatic renaming, which sets the name to the active command in the window's active pane. See the automatic-rename option. When a pane is first created, its title is the hostname. A pane's title can be set via the title setting escape sequence, for example: $ printf '\\033]2;My Title\\033\\\\' It can also be modified with the select-pane -T command. GLOBAL AND SESSION ENVIRONMENT When the server is started, tmux copies the environment into the global environment; in addition, each session has a session environment. When a window is created, the session and global environments are merged. If a variable exists in both, the value from the session environment is used. The result is the initial environment passed to the new process. The update-environment session option may be used to update the session environment from the client when a new session is created or an old reat- tached. tmux also initialises the TMUX variable with some internal information to allow commands to be executed from inside, and the TERM variable with the correct terminal setting of `screen'. Variables in both session and global environments may be marked as hid- den. Hidden variables are not passed into the environment of new pro- cesses and instead can only be used by tmux itself (for example in for- mats, see the FORMATS section). Commands to alter and view the environment are: set-environment [-Fhgru] [-t target-session] name [value] (alias: setenv) Set or unset an environment variable. If -g is used, the change is made in the global environment; otherwise, it is applied to the session environment for target-session. If -F is present, then value is expanded as a format. The -u flag unsets a vari- able. -r indicates the variable is to be removed from the envi- ronment before starting a new process. -h marks the variable as hidden. show-environment [-hgs] [-t target-session] [variable] (alias: showenv) Display the environment for target-session or the global environ- ment with -g. If variable is omitted, all variables are shown. Variables removed from the environment are prefixed with `-'. If -s is used, the output is formatted as a set of Bourne shell com- mands. -h shows hidden variables (omitted by default). STATUS LINE tmux includes an optional status line which is displayed in the bottom line of each terminal. By default, the status line is enabled and one line in height (it may be disabled or made multiple lines with the status session option) and con- tains, from left-to-right: the name of the current session in square brackets; the window list; the title of the active pane in double quotes; and the time and date. Each line of the status line is configured with the status-format option. The default is made of three parts: configurable left and right sections (which may contain dynamic content such as the time or output from a shell command, see the status-left, status-left-length, status-right, and status-right-length options below), and a central window list. By default, the window list shows the index, name and (if any) flag of the windows present in the current session in ascending numerical order. It may be customised with the window-status-format and window-status-current-format options. The flag is one of the following symbols appended to the window name: Symbol Meaning * Denotes the current window. - Marks the last window (previously selected). # Window activity is monitored and activity has been detected. ! Window bells are monitored and a bell has occurred in the window. ~ The window has been silent for the monitor-silence interval. M The window contains the marked pane. Z The window's active pane is zoomed. The # symbol relates to the monitor-activity window option. The window name is printed in inverted colours if an alert (bell, activity or silence) is present. The colour and attributes of the status line may be configured, the entire status line using the status-style session option and individual windows using the window-status-style window option. The status line is automatically refreshed at interval if it has changed, the interval may be controlled with the status-interval session option. Commands related to the status line are as follows: clear-prompt-history [-T prompt-type] (alias: clearphist) Clear status prompt history for prompt type prompt-type. If -T is omitted, then clear history for all types. See command-prompt for possible values for prompt-type. command-prompt [-1bFikN] [-I inputs] [-p prompts] [-t target-client] [-T prompt-type] [template] Open the command prompt in a client. This may be used from inside tmux to execute commands interactively. If template is specified, it is used as the command. With -F, template is expanded as a format. If present, -I is a comma-separated list of the initial text for each prompt. If -p is given, prompts is a comma-separated list of prompts which are displayed in order; otherwise a single prompt is displayed, constructed from template if it is present, or `:' if not. Before the command is executed, the first occurrence of the string `%%' and all occurrences of `%1' are replaced by the response to the first prompt, all `%2' are replaced with the response to the second prompt, and so on for further prompts. Up to nine prompt responses may be replaced (`%1' to `%9'). `%%%' is like `%%' but any quotation marks are escaped. -1 makes the prompt only accept one key press, in this case the resulting input is a single character. -k is like -1 but the key press is translated to a key name. -N makes the prompt only accept numeric key presses. -i executes the command every time the prompt input changes instead of when the user exits the com- mand prompt. -T tells tmux the prompt type. This affects what completions are offered when Tab is pressed. Available types are: `command', `search', `target' and `window-target'. The following keys have a special meaning in the command prompt, depending on the value of the status-keys option: Function vi emacs Cancel command prompt q Escape Delete from cursor to start of word C-w Delete entire command d C-u Delete from cursor to end D C-k Execute command Enter Enter Get next command from history Down Get previous command from history Up Insert top paste buffer p C-y Look for completions Tab Tab Move cursor left h Left Move cursor right l Right Move cursor to end $ C-e Move cursor to next word w M-f Move cursor to previous word b M-b Move cursor to start 0 C-a Transpose characters C-t With -b, the prompt is shown in the background and the invoking client does not exit until it is dismissed. confirm-before [-b] [-p prompt] [-t target-client] command (alias: confirm) Ask for confirmation before executing command. If -p is given, prompt is the prompt to display; otherwise a prompt is con- structed from command. It may contain the special character sequences supported by the status-left option. With -b, the prompt is shown in the background and the invoking client does not exit until it is dismissed. display-menu [-O] [-c target-client] [-t target-pane] [-T title] [-x position] [-y position] name key command ... (alias: menu) Display a menu on target-client. target-pane gives the target for any commands run from the menu. A menu is passed as a series of arguments: first the menu item name, second the key shortcut (or empty for none) and third the command to run when the menu item is chosen. The name and com- mand are formats, see the FORMATS and STYLES sections. If the name begins with a hyphen (-), then the item is disabled (shown dim) and may not be chosen. The name may be empty for a separa- tor line, in which case both the key and command should be omit- ted. -T is a format for the menu title (see FORMATS). -x and -y give the position of the menu. Both may be a row or column number, or one of the following special values: Value Flag Meaning C Both The centre of the terminal R -x The right side of the terminal P Both The bottom left of the pane M Both The mouse position W Both The window position on the status line S -y The line above or below the status line Or a format, which is expanded including the following additional variables: Variable name Replaced with popup_centre_x Centered in the client popup_centre_y Centered in the client popup_height Height of menu or popup popup_mouse_bottom Bottom of at the mouse popup_mouse_centre_x Horizontal centre at the mouse popup_mouse_centre_y Vertical centre at the mouse popup_mouse_top Top at the mouse popup_mouse_x Mouse X position popup_mouse_y Mouse Y position popup_pane_bottom Bottom of the pane popup_pane_left Left of the pane popup_pane_right Right of the pane popup_pane_top Top of the pane popup_status_line_y Above or below the status line popup_width Width of menu or popup popup_window_status_line_x At the window position in status line popup_window_status_line_y At the status line showing the window Each menu consists of items followed by a key shortcut shown in brackets. If the menu is too large to fit on the terminal, it is not displayed. Pressing the key shortcut chooses the correspond- ing item. If the mouse is enabled and the menu is opened from a mouse key binding, releasing the mouse button with an item selected chooses that item and releasing the mouse button without an item selected closes the menu. -O changes this behaviour so that the menu does not close when the mouse button is released without an item selected the menu is not closed and a mouse but- ton must be clicked to choose an item. The following keys are also available: Key Function Enter Choose selected item Up Select previous item Down Select next item q Exit menu display-message [-aINpv] [-c target-client] [-d delay] [-t target-pane] [message] (alias: display) Display a message. If -p is given, the output is printed to std- out, otherwise it is displayed in the target-client status line for up to delay milliseconds. If delay is not given, the display-time option is used; a delay of zero waits for a key press. `N' ignores key presses and closes only after the delay expires. The format of message is described in the FORMATS sec- tion; information is taken from target-pane if -t is given, oth- erwise the active pane. -v prints verbose logging as the format is parsed and -a lists the format variables and their values. -I forwards any input read from stdin to the empty pane given by target-pane. display-popup [-BCE] [-b border-lines] [-c target-client] [-d start-directory] [-e environment] [-h height] [-s style] [-S border-style] [-t target-pane] [-T title] [-w width] [-x position] [-y position] [shell-command] (alias: popup) Display a popup running shell-command on target-client. A popup is a rectangular box drawn over the top of any panes. Panes are not updated while a popup is present. -E closes the popup automatically when shell-command exits. Two -E closes the popup only if shell-command exited with success. -x and -y give the position of the popup, they have the same meaning as for the display-menu command. -w and -h give the width and height - both may be a percentage (followed by `%'). If omitted, half of the terminal size is used. -B does not surround the popup by a border. -b sets the type of border line for the popup. When -B is speci- fied, the -b option is ignored. See popup-border-lines for pos- sible values for border-lines. -s sets the style for the popup and -S sets the style for the popup border. For how to specify style, see the STYLES section. -e takes the form `VARIABLE=value' and sets an environment vari- able for the popup; it may be specified multiple times. -T is a format for the popup title (see FORMATS). The -C flag closes any popup on the client. show-prompt-history [-T prompt-type] (alias: showphist) Display status prompt history for prompt type prompt-type. If -T is omitted, then show history for all types. See command-prompt for possible values for prompt-type. BUFFERS tmux maintains a set of named paste buffers. Each buffer may be either explicitly or automatically named. Explicitly named buffers are named when created with the set-buffer or load-buffer commands, or by renaming an automatically named buffer with set-buffer -n. Automatically named buffers are given a name such as `buffer0001', `buffer0002' and so on. When the buffer-limit option is reached, the oldest automatically named buffer is deleted. Explicitly named buffers are not subject to buffer-limit and may be deleted with the delete-buffer command. Buffers may be added using copy-mode or the set-buffer and load-buffer commands, and pasted into a window using the paste-buffer command. If a buffer command is used and no buffer is specified, the most recently added automatically named buffer is assumed. A configurable history buffer is also maintained for each window. By default, up to 2000 lines are kept; this can be altered with the history-limit option (see the set-option command above). The buffer commands are as follows: choose-buffer [-NZr] [-F format] [-f filter] [-K key-format] [-O sort-order] [-t target-pane] [template] Put a pane into buffer mode, where a buffer may be chosen inter- actively from a list. Each buffer is shown on one line. A shortcut key is shown on the left in brackets allowing for imme- diate choice, or the list may be navigated and an item chosen or otherwise manipulated using the keys below. -Z zooms the pane. The following keys may be used in buffer mode: Key Function Enter Paste selected buffer Up Select previous buffer Down Select next buffer C-s Search by name or content n Repeat last search t Toggle if buffer is tagged T Tag no buffers C-t Tag all buffers p Paste selected buffer P Paste tagged buffers d Delete selected buffer D Delete tagged buffers e Open the buffer in an editor f Enter a format to filter items O Change sort field r Reverse sort order v Toggle preview q Exit mode After a buffer is chosen, `%%' is replaced by the buffer name in template and the result executed as a command. If template is not given, \u0026quot;paste-buffer -b '%%'\u0026quot; is used. -O specifies the initial sort field: one of `time', `name' or `size'. -r reverses the sort order. -f specifies an initial filter: the filter is a format - if it evaluates to zero, the item in the list is not shown, otherwise it is shown. If a fil- ter would lead to an empty list, it is ignored. -F specifies the format for each item in the list and -K a format for each short- cut key; both are evaluated once for each line. -N starts with- out the preview. This command works only if at least one client is attached. clear-history [-t target-pane] (alias: clearhist) Remove and free the history for the specified pane. delete-buffer [-b buffer-name] (alias: deleteb) Delete the buffer named buffer-name, or the most recently added automatically named buffer if not specified. list-buffers [-F format] [-f filter] (alias: lsb) List the global buffers. -F specifies the format of each line and -f a filter. Only buffers for which the filter is true are shown. See the FORMATS section. load-buffer [-w] [-b buffer-name] [-t target-client] path (alias: loadb) Load the contents of the specified paste buffer from path. If -w is given, the buffer is also sent to the clipboard for target-client using the xterm(1) escape sequence, if possible. paste-buffer [-dpr] [-b buffer-name] [-s separator] [-t target-pane] (alias: pasteb) Insert the contents of a paste buffer into the specified pane. If not specified, paste into the current one. With -d, also delete the paste buffer. When output, any linefeed (LF) charac- ters in the paste buffer are replaced with a separator, by default carriage return (CR). A custom separator may be speci- fied using the -s flag. The -r flag means to do no replacement (equivalent to a separator of LF). If -p is specified, paste bracket control codes are inserted around the buffer if the application has requested bracketed paste mode. save-buffer [-a] [-b buffer-name] path (alias: saveb) Save the contents of the specified paste buffer to path. The -a option appends to rather than overwriting the file. set-buffer [-aw] [-b buffer-name] [-t target-client] [-n new-buffer-name] data (alias: setb) Set the contents of the specified buffer to data. If -w is given, the buffer is also sent to the clipboard for target-client using the xterm(1) escape sequence, if possible. The -a option appends to rather than overwriting the buffer. The -n option renames the buffer to new-buffer-name. show-buffer [-b buffer-name] (alias: showb) Display the contents of the specified buffer. MISCELLANEOUS Miscellaneous commands are as follows: clock-mode [-t target-pane] Display a large clock. if-shell [-bF] [-t target-pane] shell-command command [command] (alias: if) Execute the first command if shell-command (run with /bin/sh) returns success or the second command otherwise. Before being executed, shell-command is expanded using the rules specified in the FORMATS section, including those relevant to target-pane. With -b, shell-command is run in the background. If -F is given, shell-command is not executed but considered suc- cess if neither empty nor zero (after formats are expanded). lock-server (alias: lock) Lock each client individually by running the command specified by the lock-command option. run-shell [-bC] [-d delay] [-t target-pane] [shell-command] (alias: run) Execute shell-command using /bin/sh or (with -C) a tmux command in the background without creating a window. Before being exe- cuted, shell-command is expanded using the rules specified in the FORMATS section. With -b, the command is run in the background. -d waits for delay seconds before starting the command. If -C is not given, any output to stdout is displayed in view mode (in the pane specified by -t or the current pane if omitted) after the command finishes. If the command fails, the exit status is also displayed. wait-for [-L | -S | -U] channel (alias: wait) When used without options, prevents the client from exiting until woken using wait-for -S with the same channel. When -L is used, the channel is locked and any clients that try to lock the same channel are made to wait until the channel is unlocked with wait-for -U. EXIT MESSAGES When a tmux client detaches, it prints a message. This may be one of: detached (from session ...) The client was detached normally. detached and SIGHUP The client was detached and its parent sent the SIGHUP signal (for example with detach-client -P). lost tty The client's tty(4) or pty(4) was unexpectedly destroyed. terminated The client was killed with SIGTERM. too far behind The client is in control mode and became unable to keep up with the data from tmux. exited The server exited when it had no sessions. server exited The server exited when it received SIGTERM. server exited unexpectedly The server crashed or otherwise exited without telling the client the reason. TERMINFO EXTENSIONS tmux understands some unofficial extensions to terminfo(5). It is not normally necessary to set these manually, instead the terminal-features option should be used. AX An existing extension that tells tmux the terminal supports default colours. Bidi Tell tmux that the terminal supports the VTE bidirectional text extensions. Cs, Cr Set the cursor colour. The first takes a single string argument and is used to set the colour; the second takes no arguments and restores the default cursor colour. If set, a sequence such as this may be used to change the cursor colour from inside tmux: $ printf '\\033]12;red\\033\\\\' The colour is an X(7) colour, see XParseColor(3). Cmg, Clmg, Dsmg, Enmg Set, clear, disable or enable DECSLRM margins. These are set automatically if the terminal reports it is VT420 compatible. Dsbp, Enbp Disable and enable bracketed paste. These are set automatically if the XT capability is present. Dseks, Eneks Disable and enable extended keys. Dsfcs, Enfcs Disable and enable focus reporting. These are set automatically if the XT capability is present. Rect Tell tmux that the terminal supports rectangle operations. Smol Enable the overline attribute. Smulx Set a styled underscore. The single parameter is one of: 0 for no underscore, 1 for normal underscore, 2 for double underscore, 3 for curly underscore, 4 for dotted underscore and 5 for dashed underscore. Setulc, ol Set the underscore colour or reset to the default. The argument is (red * 65536) + (green * 256) + blue where each is between 0 and 255. Ss, Se Set or reset the cursor style. If set, a sequence such as this may be used to change the cursor to an underline: $ printf '\\033[4 q' If Se is not set, Ss with argument 0 will be used to reset the cursor style instead. Swd Set the opening sequence for the working directory notification. The sequence is terminated using the standard fsl capability. Sync Start (parameter is 1) or end (parameter is 2) a synchronized update. Tc Indicate that the terminal supports the `direct colour' RGB escape sequence (for example, \\e[38;2;255;255;255m). If supported, this is used for the initialize colour escape sequence (which may be enabled by adding the `initc' and `ccc' capabilities to the tmux terminfo(5) entry). This is equivalent to the RGB terminfo(5) capability. Ms Store the current buffer in the host terminal's selection (clip- board). See the set-clipboard option above and the xterm(1) man page. XT This is an existing extension capability that tmux uses to mean that the terminal supports the xterm(1) title set sequences and to automatically set some of the capabilities above. CONTROL MODE tmux offers a textual interface called control mode. This allows appli- cations to communicate with tmux using a simple text-only protocol. In control mode, a client sends tmux commands or command sequences termi- nated by newlines on standard input. Each command will produce one block of output on standard output. An output block consists of a %begin line followed by the output (which may be empty). The output block ends with a %end or %error. %begin and matching %end or %error have three argu- ments: an integer time (as seconds from epoch), command number and flags (currently not used). For example: %begin 1363006971 2 1 0: ksh* (1 panes) [80x24] [layout b25f,80x24,0,0,2] @2 (active) %end 1363006971 2 1 The refresh-client -C command may be used to set the size of a client in control mode. In control mode, tmux outputs notifications. A notification will never occur inside an output block. The following notifications are defined: %client-detached client The client has detached. %client-session-changed client session-id name The client is now attached to the session with ID session-id, which is named name. %continue pane-id The pane has been continued after being paused (if the pause-after flag is set, see refresh-client -A). %exit [reason] The tmux client is exiting immediately, either because it is not attached to any session or an error occurred. If present, reason describes why the client exited. %extended-output pane-id age ... : value New form of %output sent when the pause-after flag is set. age is the time in milliseconds for which tmux had buffered the out- put before it was sent. Any subsequent arguments up until a sin- gle `:' are for future use and should be ignored. %layout-change window-id window-layout window-visible-layout window-flags The layout of a window with ID window-id changed. The new layout is window-layout. The window's visible layout is window-visible-layout and the window flags are window-flags. %output pane-id value A window pane produced output. value escapes non-printable char- acters and backslash as octal \\xxx. %pane-mode-changed pane-id The pane with ID pane-id has changed mode. %pause pane-id The pane has been paused (if the pause-after flag is set). %session-changed session-id name The client is now attached to the session with ID session-id, which is named name. %session-renamed name The current session was renamed to name. %session-window-changed session-id window-id The session with ID session-id changed its active window to the window with ID window-id. %sessions-changed A session was created or destroyed. %subscription-changed name session-id window-id window-index pane-id ... : value The value of the format associated with subscription name has changed to value. See refresh-client -B. Any arguments after pane-id up until a single `:' are for future use and should be ignored. %unlinked-window-add window-id The window with ID window-id was created but is not linked to the current session. %unlinked-window-close window-id The window with ID window-id, which is not linked to the current session, was closed. %unlinked-window-renamed window-id The window with ID window-id, which is not linked to the current session, was renamed. %window-add window-id The window with ID window-id was linked to the current session. %window-close window-id The window with ID window-id closed. %window-pane-changed window-id pane-id The active pane in the window with ID window-id changed to the pane with ID pane-id. %window-renamed window-id name The window with ID window-id was renamed to name. ENVIRONMENT When tmux is started, it inspects the following environment variables: EDITOR If the command specified in this variable contains the string `vi' and VISUAL is unset, use vi-style key bindings. Overrid- den by the mode-keys and status-keys options. HOME The user's login directory. If unset, the passwd(5) database is consulted. LC_CTYPE The character encoding locale(1). It is used for two separate purposes. For output to the terminal, UTF-8 is used if the -u option is given or if LC_CTYPE contains \u0026quot;UTF-8\u0026quot; or \u0026quot;UTF8\u0026quot;. Otherwise, only ASCII characters are written and non-ASCII characters are replaced with underscores (`_'). For input, tmux always runs with a UTF-8 locale. If en_US.UTF-8 is pro- vided by the operating system, it is used and LC_CTYPE is ignored for input. Otherwise, LC_CTYPE tells tmux what the UTF-8 locale is called on the current system. If the locale specified by LC_CTYPE is not available or is not a UTF-8 locale, tmux exits with an error message. LC_TIME The date and time format locale(1). It is used for locale- dependent strftime(3) format specifiers. PWD The current working directory to be set in the global environ- ment. This may be useful if it contains symbolic links. If the value of the variable does not match the current working directory, the variable is ignored and the result of getcwd(3) is used instead. SHELL The absolute path to the default shell for new windows. See the default-shell option for details. TMUX_TMPDIR The parent directory of the directory containing the server sockets. See the -L option for details. VISUAL If the command specified in this variable contains the string `vi', use vi-style key bindings. Overridden by the mode-keys and status-keys options. FILES ~/.tmux.conf $XDG_CONFIG_HOME/tmux/tmux.conf ~/.config/tmux/tmux.conf Default tmux configuration file. /usr/local/etc/tmux.conf System-wide configuration file. EXAMPLES To create a new tmux session running vi(1): $ tmux new-session vi Most commands have a shorter form, known as an alias. For new-session, this is new: $ tmux new vi Alternatively, the shortest unambiguous form of a command is accepted. If there are several options, they are listed: $ tmux n ambiguous command: n, could be: new-session, new-window, next-window Within an active session, a new window may be created by typing `C-b c' (Ctrl followed by the `b' key followed by the `c' key). Windows may be navigated with: `C-b 0' (to select window 0), `C-b 1' (to select window 1), and so on; `C-b n' to select the next window; and `C-b p' to select the previous window. A session may be detached using `C-b d' (or by an external event such as ssh(1) disconnection) and reattached with: $ tmux attach-session Typing `C-b ?' lists the current key bindings in the current window; up and down may be used to navigate the list or `q' to exit from it. Commands to be run when the tmux server is started may be placed in the ~/.tmux.conf configuration file. Common examples include: Changing the default prefix key: set-option -g prefix C-a unbind-key C-b bind-key C-a send-prefix Turning the status line off, or changing its colour: set-option -g status off set-option -g status-style bg=blue Setting other options, such as the default command, or locking after 30 minutes of inactivity: set-option -g default-command \u0026quot;exec /bin/ksh\u0026quot; set-option -g lock-after-time 1800 Creating new key bindings: bind-key b set-option status bind-key / command-prompt \u0026quot;split-window 'exec man %%'\u0026quot; bind-key S command-prompt \u0026quot;new-window -n %1 'ssh %1'\u0026quot; SEE ALSO pty(4) AUTHORS Nicholas Marriott \u0026lt;nicholas.marriott@gmail.com\u0026gt; BSD February 16, 2023 BSD "}),e.add({id:22,href:"/docs/tools/utility/ripgrep/",title:"Ripgrep",description:`Description # ripgrep recursively searches directories for a regex pattern while respecting your gitignore rules.
Installation # brew install ripgrep Usage # file | rg pattern Resources # ripgrep help # ripgrep 13.0.0 Andrew Gallant jamslam@gmail.com
ripgrep (rg) recursively searches the current directory for a regex pattern. By default, ripgrep will respect gitignore rules and automatically skip hidden files/directories and binary files.
Use -h for short descriptions and \u0026ndash;help for more details.`,content:`Description # ripgrep recursively searches directories for a regex pattern while respecting your gitignore rules.
Installation # brew install ripgrep Usage # file | rg pattern Resources # ripgrep help # ripgrep 13.0.0 Andrew Gallant jamslam@gmail.com
ripgrep (rg) recursively searches the current directory for a regex pattern. By default, ripgrep will respect gitignore rules and automatically skip hidden files/directories and binary files.
Use -h for short descriptions and \u0026ndash;help for more details.
Project home page: https://github.com/BurntSushi/ripgrep
User Guide # This guide is intended to give an elementary description of ripgrep and an overview of its capabilities. This guide assumes that ripgrep is installed and that readers have passing familiarity with using command line tools. This also assumes a Unix-like system, although most commands are probably easily translatable to any command line shell environment.
Table of Contents # Basics Recursive search Automatic filtering Manual filtering: globs Manual filtering: file types Replacements Configuration file File encoding Binary data Preprocessor Common options Basics # ripgrep is a command line tool that searches your files for patterns that you give it. ripgrep behaves as if reading each file line by line. If a line matches the pattern provided to ripgrep, then that line will be printed. If a line does not match the pattern, then the line is not printed.
The best way to see how this works is with an example. To show an example, we need something to search. Let\u0026rsquo;s try searching ripgrep\u0026rsquo;s source code. First grab a ripgrep source archive from https://github.com/BurntSushi/ripgrep/archive/0.7.1.zip and extract it:
curl -LO https://github.com/BurntSushi/ripgrep/archive/0.7.1.zip unzip 0.7.1.zip cd ripgrep-0.7.1 ls benchsuite grep tests Cargo.toml LICENSE-MIT ci ignore wincolor CHANGELOG.md README.md complete pkg appveyor.yml compile snapcraft.yaml doc src build.rs COPYING UNLICENSE globset termcolor Cargo.lock HomebrewFormula Let\u0026rsquo;s try our first search by looking for all occurrences of the word fast in README.md:
rg fast README.md 75: faster than both. (N.B. It is not, strictly speaking, a \u0026quot;drop-in\u0026quot; replacement 88: color and full Unicode support. Unlike GNU grep, \`ripgrep\` stays fast while 119:### Is it really faster than everything else? 124:Summarizing, \`ripgrep\` is fast because: 129: optimizations to make searching very fast. (Note: If you see an error message from ripgrep saying that it didn\u0026rsquo;t search any files, then re-run ripgrep with the --debug flag. One likely cause of this is that you have a * rule in a $HOME/.gitignore file.)
So what happened here? ripgrep read the contents of README.md, and for each line that contained fast, ripgrep printed it to your terminal. ripgrep also included the line number for each line by default. If your terminal supports colors, then your output might actually look something like this screenshot:
In this example, we searched for something called a \u0026ldquo;literal\u0026rdquo; string. This means that our pattern was just some normal text that we asked ripgrep to find. But ripgrep supports the ability to specify patterns via regular expressions. As an example, what if we wanted to find all lines have a word that contains fast followed by some number of other letters?
rg 'fast\\w+' README.md 75: faster than both. (N.B. It is not, strictly speaking, a \u0026quot;drop-in\u0026quot; replacement 119:### Is it really faster than everything else? In this example, we used the pattern fast\\w+. This pattern tells ripgrep to look for any lines containing the letters fast followed by one or more word-like characters. Namely, \\w matches characters that compose words (like a and L but unlike . and \u0026quot; \u0026quot; [remove the quotes]). The + after the \\w means, \u0026ldquo;match the previous pattern one or more times.\u0026rdquo; This means that the word fast won\u0026rsquo;t match because there are no word characters following the final t. But a word like faster will. faste would also match!
Here\u0026rsquo;s a different variation on this same theme:
rg 'fast\\w*' README.md 75: faster than both. (N.B. It is not, strictly speaking, a \u0026quot;drop-in\u0026quot; replacement 88: color and full Unicode support. Unlike GNU grep, \`ripgrep\` stays fast while 119:### Is it really faster than everything else? 124:Summarizing, \`ripgrep\` is fast because: 129: optimizations to make searching very fast. In this case, we used fast\\w* for our pattern instead of fast\\w+. The * means that it should match zero or more times. In this case, ripgrep will print the same lines as the pattern fast, but if your terminal supports colors, you\u0026rsquo;ll notice that faster will be highlighted instead of just the fast prefix.
It is beyond the scope of this guide to provide a full tutorial on regular expressions, but ripgrep\u0026rsquo;s specific syntax is documented here: https://docs.rs/regex/1.7.1/regex/#syntax
Recursive search # In the previous section, we showed how to use ripgrep to search a single file. In this section, we\u0026rsquo;ll show how to use ripgrep to search an entire directory of files. In fact, recursively searching your current working directory is the default mode of operation for ripgrep, which means doing this is very simple.
Using our unzipped archive of ripgrep source code, here\u0026rsquo;s how to find all function definitions whose name is write:
rg 'fn write\\(' src/printer.rs 469: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) { termcolor/src/lib.rs 227: fn write(\u0026amp;mut self, b: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 250: fn write(\u0026amp;mut self, b: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 428: fn write(\u0026amp;mut self, b: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { self.wtr.write(b) } 441: fn write(\u0026amp;mut self, b: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { self.wtr.write(b) } 454: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 511: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 848: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 915: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 949: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 1114: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 1348: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { 1353: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { (Note: We escape the ( here because ( has special significance inside regular expressions. You could also use rg -F 'fn write(' to achieve the same thing, where -F interprets your pattern as a literal string instead of a regular expression.)
In this example, we didn\u0026rsquo;t specify a file at all. Instead, ripgrep defaulted to searching your current directory in the absence of a path. In general, rg foo is equivalent to rg foo ./.
This particular search showed us results in both the src and termcolor directories. The src directory is the core ripgrep code where as termcolor is a dependency of ripgrep (and is used by other tools). What if we only wanted to search core ripgrep code? Well, that\u0026rsquo;s easy, just specify the directory you want:
rg 'fn write\\(' src src/printer.rs 469: fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) { Here, ripgrep limited its search to the src directory. Another way of doing this search would be to cd into the src directory and simply use rg 'fn write\\(' again.
Automatic filtering # After recursive search, ripgrep\u0026rsquo;s most important feature is what it doesn\u0026rsquo;t search. By default, when you search a directory, ripgrep will ignore all of the following:
Files and directories that match glob patterns in these three categories: gitignore globs (including global and repo-specific globs). .ignore globs, which take precedence over all gitignore globs when there\u0026rsquo;s a conflict. .rgignore globs, which take precedence over all .ignore globs when there\u0026rsquo;s a conflict. Hidden files and directories. Binary files. (ripgrep considers any file with a NUL byte to be binary.) Symbolic links aren\u0026rsquo;t followed. All of these things can be toggled using various flags provided by ripgrep:
You can disable all ignore-related filtering with the --no-ignore flag. Hidden files and directories can be searched with the --hidden (-. for short) flag. Binary files can be searched via the --text (-a for short) flag. Be careful with this flag! Binary files may emit control characters to your terminal, which might cause strange behavior. ripgrep can follow symlinks with the --follow (-L for short) flag. As a special convenience, ripgrep also provides a flag called --unrestricted (-u for short). Repeated uses of this flag will cause ripgrep to disable more and more of its filtering. That is, -u will disable .gitignore handling, -uu will search hidden files and directories and -uuu will search binary files. This is useful when you\u0026rsquo;re using ripgrep and you aren\u0026rsquo;t sure whether its filtering is hiding results from you. Tacking on a couple -u flags is a quick way to find out. (Use the --debug flag if you\u0026rsquo;re still perplexed, and if that doesn\u0026rsquo;t help, file an issue.)
ripgrep\u0026rsquo;s .gitignore handling actually goes a bit beyond just .gitignore files. ripgrep will also respect repository specific rules found in $GIT_DIR/info/exclude, as well as any global ignore rules in your core.excludesFile (which is usually $XDG_CONFIG_HOME/git/ignore on Unix-like systems).
Sometimes you want to search files that are in your .gitignore, so it is possible to specify additional ignore rules or overrides in a .ignore (application agnostic) or .rgignore (ripgrep specific) file.
For example, let\u0026rsquo;s say you have a .gitignore file that looks like this:
log/ This generally means that any log directory won\u0026rsquo;t be tracked by git. However, perhaps it contains useful output that you\u0026rsquo;d like to include in your searches, but you still don\u0026rsquo;t want to track it in git. You can achieve this by creating a .ignore file in the same directory as the .gitignore file with the following contents:
!log/ ripgrep treats .ignore files with higher precedence than .gitignore files (and treats .rgignore files with higher precedence than .ignore files). This means ripgrep will see the !log/ whitelist rule first and search that directory.
Like .gitignore, a .ignore file can be placed in any directory. Its rules will be processed with respect to the directory it resides in, just like .gitignore.
To process .gitignore and .ignore files case insensitively, use the flag --ignore-file-case-insensitive. This is especially useful on case insensitive file systems like those on Windows and macOS. Note though that this can come with a significant performance penalty, and is therefore disabled by default.
For a more in depth description of how glob patterns in a .gitignore file are interpreted, please see man gitignore.
Manual filtering: globs # In the previous section, we talked about ripgrep\u0026rsquo;s filtering that it does by default. It is \u0026ldquo;automatic\u0026rdquo; because it reacts to your environment. That is, it uses already existing .gitignore files to produce more relevant search results.
In addition to automatic filtering, ripgrep also provides more manual or ad hoc filtering. This comes in two varieties: additional glob patterns specified in your ripgrep commands and file type filtering. This section covers glob patterns while the next section covers file type filtering.
In our ripgrep source code (see Basics for instructions on how to get a source archive to search), let\u0026rsquo;s say we wanted to see which things depend on clap, our argument parser.
We could do this:
rg clap [lots of results] But this shows us many things, and we\u0026rsquo;re only interested in where we wrote clap as a dependency. Instead, we could limit ourselves to TOML files, which is how dependencies are communicated to Rust\u0026rsquo;s build tool, Cargo:
rg clap -g '*.toml' Cargo.toml 35:clap = \u0026quot;2.26\u0026quot; 51:clap = \u0026quot;2.26\u0026quot; The -g '*.toml' syntax says, \u0026ldquo;make sure every file searched matches this glob pattern.\u0026rdquo; Note that we put '*.toml' in single quotes to prevent our shell from expanding the *.
If we wanted, we could tell ripgrep to search anything but *.toml files:
rg clap -g '!*.toml' [lots of results] This will give you a lot of results again as above, but they won\u0026rsquo;t include files ending with .toml. Note that the use of a ! here to mean \u0026ldquo;negation\u0026rdquo; is a bit non-standard, but it was chosen to be consistent with how globs in .gitignore files are written. (Although, the meaning is reversed. In .gitignore files, a ! prefix means whitelist, and on the command line, a ! means blacklist.)
Globs are interpreted in exactly the same way as .gitignore patterns. That is, later globs will override earlier globs. For example, the following command will search only *.toml files:
rg clap -g '!*.toml' -g '*.toml' Interestingly, reversing the order of the globs in this case will match nothing, since the presence of at least one non-blacklist glob will institute a requirement that every file searched must match at least one glob. In this case, the blacklist glob takes precedence over the previous glob and prevents any file from being searched at all!
Manual filtering: file types # Over time, you might notice that you use the same glob patterns over and over. For example, you might find yourself doing a lot of searches where you only want to see results for Rust files:
rg 'fn run' -g '*.rs' Instead of writing out the glob every time, you can use ripgrep\u0026rsquo;s support for file types:
rg 'fn run' --type rust or, more succinctly,
rg 'fn run' -trust The way the --type flag functions is simple. It acts as a name that is assigned to one or more globs that match the relevant files. This lets you write a single type that might encompass a broad range of file extensions. For example, if you wanted to search C files, you\u0026rsquo;d have to check both C source files and C header files:
rg 'int main' -g '*.{c,h}' or you could just use the C file type:
rg 'int main' -tc Just as you can write blacklist globs, you can blacklist file types too:
rg clap --type-not rust or, more succinctly,
rg clap -Trust That is, -t means \u0026ldquo;include files of this type\u0026rdquo; where as -T means \u0026ldquo;exclude files of this type.\u0026rdquo;
To see the globs that make up a type, run rg --type-list:
rg --type-list | rg '^make:' make: *.mak, *.mk, GNUmakefile, Gnumakefile, Makefile, gnumakefile, makefile By default, ripgrep comes with a bunch of pre-defined types. Generally, these types correspond to well known public formats. But you can define your own types as well. For example, perhaps you frequently search \u0026ldquo;web\u0026rdquo; files, which consist of JavaScript, HTML and CSS:
rg --type-add 'web:*.html' --type-add 'web:*.css' --type-add 'web:*.js' -tweb title or, more succinctly,
rg --type-add 'web:*.{html,css,js}' -tweb title The above command defines a new type, web, corresponding to the glob *.{html,css,js}. It then applies the new filter with -tweb and searches for the pattern title. If you ran
rg --type-add 'web:*.{html,css,js}' --type-list Then you would see your web type show up in the list, even though it is not part of ripgrep\u0026rsquo;s built-in types.
It is important to stress here that the --type-add flag only applies to the current command. It does not add a new file type and save it somewhere in a persistent form. If you want a type to be available in every ripgrep command, then you should either create a shell alias:
alias rg=\u0026quot;rg --type-add 'web:*.{html,css,js}'\u0026quot; or add --type-add=web:*.{html,css,js} to your ripgrep configuration file. (Configuration files are covered in more detail later.)
The special all file type # A special option supported by the --type flag is all. --type all looks for a match in any of the supported file types listed by --type-list, including those added on the command line using --type-add. It\u0026rsquo;s equivalent to the command rg --type agda --type asciidoc --type asm ..., where ... stands for a list of --type flags for the rest of the types in --type-list.
As an example, let\u0026rsquo;s suppose you have a shell script in your current directory, my-shell-script, which includes a shell library, my-shell-library.bash. Both rg --type sh and rg --type all would only search for matches in my-shell-library.bash, not my-shell-script, because the globs matched by the sh file type don\u0026rsquo;t include files without an extension. On the other hand, rg --type-not all would search my-shell-script but not my-shell-library.bash.
Replacements # ripgrep provides a limited ability to modify its output by replacing matched text with some other text. This is easiest to explain with an example. Remember when we searched for the word fast in ripgrep\u0026rsquo;s README?
rg fast README.md 75: faster than both. (N.B. It is not, strictly speaking, a \u0026quot;drop-in\u0026quot; replacement 88: color and full Unicode support. Unlike GNU grep, \`ripgrep\` stays fast while 119:### Is it really faster than everything else? 124:Summarizing, \`ripgrep\` is fast because: 129: optimizations to make searching very fast. What if we wanted to replace all occurrences of fast with FAST? That\u0026rsquo;s easy with ripgrep\u0026rsquo;s --replace flag:
rg fast README.md --replace FAST 75: FASTer than both. (N.B. It is not, strictly speaking, a \u0026quot;drop-in\u0026quot; replacement 88: color and full Unicode support. Unlike GNU grep, \`ripgrep\` stays FAST while 119:### Is it really FASTer than everything else? 124:Summarizing, \`ripgrep\` is FAST because: 129: optimizations to make searching very FAST. or, more succinctly,
rg fast README.md -r FAST [snip] In essence, the --replace flag applies only to the matching portion of text in the output. If you instead wanted to replace an entire line of text, then you need to include the entire line in your match. For example:
rg '^.*fast.*$' README.md -r FAST 75:FAST 88:FAST 119:FAST 124:FAST 129:FAST Alternatively, you can combine the --only-matching (or -o for short) with the --replace flag to achieve the same result:
rg fast README.md --only-matching --replace FAST 75:FAST 88:FAST 119:FAST 124:FAST 129:FAST or, more succinctly,
rg fast README.md -or FAST [snip] Finally, replacements can include capturing groups. For example, let\u0026rsquo;s say we wanted to find all occurrences of fast followed by another word and join them together with a dash. The pattern we might use for that is fast\\s+(\\w+), which matches fast, followed by any amount of whitespace, followed by any number of \u0026ldquo;word\u0026rdquo; characters. We put the \\w+ in a \u0026ldquo;capturing group\u0026rdquo; (indicated by parentheses) so that we can reference it later in our replacement string. For example:
rg 'fast\\s+(\\w+)' README.md -r 'fast-$1' 88: color and full Unicode support. Unlike GNU grep, \`ripgrep\` stays fast-while 124:Summarizing, \`ripgrep\` is fast-because: Our replacement string here, fast-$1, consists of fast- followed by the contents of the capturing group at index 1. (Capturing groups actually start at index 0, but the 0th capturing group always corresponds to the entire match. The capturing group at index 1 always corresponds to the first explicit capturing group found in the regex pattern.)
Capturing groups can also be named, which is sometimes more convenient than using the indices. For example, the following command is equivalent to the above command:
rg 'fast\\s+(?P\u0026lt;word\u0026gt;\\w+)' README.md -r 'fast-$word' 88: color and full Unicode support. Unlike GNU grep, \`ripgrep\` stays fast-while 124:Summarizing, \`ripgrep\` is fast-because: It is important to note that ripgrep will never modify your files. The --replace flag only controls ripgrep\u0026rsquo;s output. (And there is no flag to let you do a replacement in a file.)
Configuration file # It is possible that ripgrep\u0026rsquo;s default options aren\u0026rsquo;t suitable in every case. For that reason, and because shell aliases aren\u0026rsquo;t always convenient, ripgrep supports configuration files.
Setting up a configuration file is simple. ripgrep will not look in any predetermined directory for a config file automatically. Instead, you need to set the RIPGREP_CONFIG_PATH environment variable to the file path of your config file. Once the environment variable is set, open the file and just type in the flags you want set automatically. There are only two rules for describing the format of the config file:
Every line is a shell argument, after trimming whitespace. Lines starting with # (optionally preceded by any amount of whitespace) are ignored. In particular, there is no escaping. Each line is given to ripgrep as a single command line argument verbatim.
Here\u0026rsquo;s an example of a configuration file, which demonstrates some of the formatting peculiarities:
cat $HOME/.ripgreprc # Don't let ripgrep vomit really long lines to my terminal, and show a preview. --max-columns=150 --max-columns-preview # Add my 'web' type. --type-add web:*.{html,css,js}* # Using glob patterns to include/exclude files or folders --glob=!git/* # or --glob !git/* # Set the colors. --colors=line:none --colors=line:style:bold # Because who cares about case!? --smart-case When we use a flag that has a value, we either put the flag and the value on the same line but delimited by an = sign (e.g., --max-columns=150), or we put the flag and the value on two different lines. This is because ripgrep\u0026rsquo;s argument parser knows to treat the single argument --max-columns=150 as a flag with a value, but if we had written --max-columns 150 in our configuration file, then ripgrep\u0026rsquo;s argument parser wouldn\u0026rsquo;t know what to do with it.
Putting the flag and value on different lines is exactly equivalent and is a matter of style.
Comments are encouraged so that you remember what the config is doing. Empty lines are OK too.
So let\u0026rsquo;s say you\u0026rsquo;re using the above configuration file, but while you\u0026rsquo;re at a terminal, you really want to be able to see lines longer than 150 columns. What do you do? Thankfully, all you need to do is pass --max-columns 0 (or -M0 for short) on the command line, which will override your configuration file\u0026rsquo;s setting. This works because ripgrep\u0026rsquo;s configuration file is prepended to the explicit arguments you give it on the command line. Since flags given later override flags given earlier, everything works as expected. This works for most other flags as well, and each flag\u0026rsquo;s documentation states which other flags override it.
If you\u0026rsquo;re confused about what configuration file ripgrep is reading arguments from, then running ripgrep with the --debug flag should help clarify things. The debug output should note what config file is being loaded and the arguments that have been read from the configuration.
Finally, if you want to make absolutely sure that ripgrep isn\u0026rsquo;t reading a configuration file, then you can pass the --no-config flag, which will always prevent ripgrep from reading extraneous configuration from the environment, regardless of what other methods of configuration are added to ripgrep in the future.
File encoding # Text encoding is a complex topic, but we can try to summarize its relevancy to ripgrep:
Files are generally just a bundle of bytes. There is no reliable way to know their encoding. Either the encoding of the pattern must match the encoding of the files being searched, or a form of transcoding must be performed that converts either the pattern or the file to the same encoding as the other. ripgrep tends to work best on plain text files, and among plain text files, the most popular encodings likely consist of ASCII, latin1 or UTF-8. As a special exception, UTF-16 is prevalent in Windows environments In light of the above, here is how ripgrep behaves when --encoding auto is given, which is the default:
All input is assumed to be ASCII compatible (which means every byte that corresponds to an ASCII codepoint actually is an ASCII codepoint). This includes ASCII itself, latin1 and UTF-8. ripgrep works best with UTF-8. For example, ripgrep\u0026rsquo;s regular expression engine supports Unicode features. Namely, character classes like \\w will match all word characters by Unicode\u0026rsquo;s definition and . will match any Unicode codepoint instead of any byte. These constructions assume UTF-8, so they simply won\u0026rsquo;t match when they come across bytes in a file that aren\u0026rsquo;t UTF-8. To handle the UTF-16 case, ripgrep will do something called \u0026ldquo;BOM sniffing\u0026rdquo; by default. That is, the first three bytes of a file will be read, and if they correspond to a UTF-16 BOM, then ripgrep will transcode the contents of the file from UTF-16 to UTF-8, and then execute the search on the transcoded version of the file. (This incurs a performance penalty since transcoding is needed in addition to regex searching.) If the file contains invalid UTF-16, then the Unicode replacement codepoint is substituted in place of invalid code units. To handle other cases, ripgrep provides a -E/--encoding flag, which permits you to specify an encoding from the Encoding Standard. ripgrep will assume all files searched are the encoding specified (unless the file has a BOM) and will perform a transcoding step just like in the UTF-16 case described above. By default, ripgrep will not require its input be valid UTF-8. That is, ripgrep can and will search arbitrary bytes. The key here is that if you\u0026rsquo;re searching content that isn\u0026rsquo;t UTF-8, then the usefulness of your pattern will degrade. If you\u0026rsquo;re searching bytes that aren\u0026rsquo;t ASCII compatible, then it\u0026rsquo;s likely the pattern won\u0026rsquo;t find anything. With all that said, this mode of operation is important, because it lets you find ASCII or UTF-8 within files that are otherwise arbitrary bytes.
As a special case, the -E/--encoding flag supports the value none, which will completely disable all encoding related logic, including BOM sniffing. When -E/--encoding is set to none, ripgrep will search the raw bytes of the underlying file with no transcoding step. For example, here\u0026rsquo;s how you might search the raw UTF-16 encoding of the string Шерлок:
rg '(?-u)\\(\\x045\\x04@\\x04;\\x04\u0026gt;\\x04:\\x04' -E none -a some-utf16-file Of course, that\u0026rsquo;s just an example meant to show how one can drop down into raw bytes. Namely, the simpler command works as you might expect automatically:
rg 'Шерлок' some-utf16-file Finally, it is possible to disable ripgrep\u0026rsquo;s Unicode support from within the regular expression. For example, let\u0026rsquo;s say you wanted . to match any byte rather than any Unicode codepoint. (You might want this while searching a binary file, since . by default will not match invalid UTF-8.) You could do this by disabling Unicode via a regular expression flag:
rg '(?-u:.)' This works for any part of the pattern. For example, the following will find any Unicode word character followed by any ASCII word character followed by another Unicode word character:
rg '\\w(?-u:\\w)\\w' Binary data # In addition to skipping hidden files and files in your .gitignore by default, ripgrep also attempts to skip binary files. ripgrep does this by default because binary files (like PDFs or images) are typically not things you want to search when searching for regex matches. Moreover, if content in a binary file did match, then it\u0026rsquo;s possible for undesirable binary data to be printed to your terminal and wreak havoc.
Unfortunately, unlike skipping hidden files and respecting your .gitignore rules, a file cannot as easily be classified as binary. In order to figure out whether a file is binary, the most effective heuristic that balances correctness with performance is to simply look for NUL bytes. At that point, the determination is simple: a file is considered \u0026ldquo;binary\u0026rdquo; if and only if it contains a NUL byte somewhere in its contents.
The issue is that while most binary files will have a NUL byte toward the beginning of its contents, this is not necessarily true. The NUL byte might be the very last byte in a large file, but that file is still considered binary. While this leads to a fair amount of complexity inside ripgrep\u0026rsquo;s implementation, it also results in some unintuitive user experiences.
At a high level, ripgrep operates in three different modes with respect to binary files:
The default mode is to attempt to remove binary files from a search completely. This is meant to mirror how ripgrep removes hidden files and files in your .gitignore automatically. That is, as soon as a file is detected as binary, searching stops. If a match was already printed (because it was detected long before a NUL byte), then ripgrep will print a warning message indicating that the search stopped prematurely. This default mode only applies to files searched by ripgrep as a result of recursive directory traversal, which is consistent with ripgrep\u0026rsquo;s other automatic filtering. For example, rg foo .file will search .file even though it is hidden. Similarly, rg foo binary-file will search binary-file in \u0026ldquo;binary\u0026rdquo; mode automatically. Binary mode is similar to the default mode, except it will not always stop searching after it sees a NUL byte. Namely, in this mode, ripgrep will continue searching a file that is known to be binary until the first of two conditions is met: 1) the end of the file has been reached or 2) a match is or has been seen. This means that in binary mode, if ripgrep reports no matches, then there are no matches in the file. When a match does occur, ripgrep prints a message similar to one it prints when in its default mode indicating that the search has stopped prematurely. This mode can be forcefully enabled for all files with the --binary flag. The purpose of binary mode is to provide a way to discover matches in all files, but to avoid having binary data dumped into your terminal. Text mode completely disables all binary detection and searches all files as if they were text. This is useful when searching a file that is predominantly text but contains a NUL byte, or if you are specifically trying to search binary data. This mode can be enabled with the -a/--text flag. Note that when using this mode on very large binary files, it is possible for ripgrep to use a lot of memory. Unfortunately, there is one additional complexity in ripgrep that can make it difficult to reason about binary files. That is, the way binary detection works depends on the way that ripgrep searches your files. Specifically:
When ripgrep uses memory maps, then binary detection is only performed on the first few kilobytes of the file in addition to every matching line. When ripgrep doesn\u0026rsquo;t use memory maps, then binary detection is performed on all bytes searched. This means that whether a file is detected as binary or not can change based on the internal search strategy used by ripgrep. If you prefer to keep ripgrep\u0026rsquo;s binary file detection consistent, then you can disable memory maps via the --no-mmap flag. (The cost will be a small performance regression when searching very large files on some platforms.)
Preprocessor # In ripgrep, a preprocessor is any type of command that can be run to transform the input of every file before ripgrep searches it. This makes it possible to search virtually any kind of content that can be automatically converted to text without having to teach ripgrep how to read said content.
One common example is searching PDFs. PDFs are first and foremost meant to be displayed to users. But PDFs often have text streams in them that can be useful to search. In our case, we want to search Bruce Watson\u0026rsquo;s excellent dissertation, Taxonomies and Toolkits of Regular Language Algorithms. After downloading it, let\u0026rsquo;s try searching it:
rg 'The Commentz-Walter algorithm' 1995-watson.pdf $ Surely, a dissertation on regular language algorithms would mention Commentz-Walter. Indeed it does, but our search isn\u0026rsquo;t picking it up because PDFs are a binary format, and the text shown in the PDF may not be encoded as simple contiguous UTF-8. Namely, even passing the -a/--text flag to ripgrep will not make our search work.
One way to fix this is to convert the PDF to plain text first. This won\u0026rsquo;t work well for all PDFs, but does great in a lot of cases. (Note that the tool we use, pdftotext, is part of the poppler PDF rendering library.)
pdftotext 1995-watson.pdf \u0026gt; 1995-watson.txt rg 'The Commentz-Walter algorithm' 1995-watson.txt 316:The Commentz-Walter algorithms : : : : : : : : : : : : : : : 7165:4.4 The Commentz-Walter algorithms 10062:in input string S , we obtain the Boyer-Moore algorithm. The Commentz-Walter algorithm 17218:The Commentz-Walter algorithm (and its variants) displayed more interesting behaviour, 17249:Aho-Corasick algorithms are used extensively. The Commentz-Walter algorithms are used 17297: The Commentz-Walter algorithms (CW). In all versions of the CW algorithms, a common program skeleton is used with di erent shift functions. The CW algorithms are But having to explicitly convert every file can be a pain, especially when you have a directory full of PDF files. Instead, we can use ripgrep\u0026rsquo;s preprocessor feature to search the PDF. ripgrep\u0026rsquo;s --pre flag works by taking a single command name and then executing that command for every file that it searches. ripgrep passes the file path as the first and only argument to the command and also sends the contents of the file to stdin. So let\u0026rsquo;s write a simple shell script that wraps pdftotext in a way that conforms to this interface:
cat preprocess #!/bin/sh exec pdftotext - - With preprocess in the same directory as 1995-watson.pdf, we can now use it to search the PDF:
rg --pre ./preprocess 'The Commentz-Walter algorithm' 1995-watson.pdf 316:The Commentz-Walter algorithms : : : : : : : : : : : : : : : 7165:4.4 The Commentz-Walter algorithms 10062:in input string S , we obtain the Boyer-Moore algorithm. The Commentz-Walter algorithm 17218:The Commentz-Walter algorithm (and its variants) displayed more interesting behaviour, 17249:Aho-Corasick algorithms are used extensively. The Commentz-Walter algorithms are used 17297: The Commentz-Walter algorithms (CW). In all versions of the CW algorithms, a common program skeleton is used with di erent shift functions. The CW algorithms are Note that preprocess must be resolvable to a command that ripgrep can read. The simplest way to do this is to put your preprocessor command in a directory that is in your PATH (or equivalent), or otherwise use an absolute path.
As a bonus, this turns out to be quite a bit faster than other specialized PDF grepping tools:
time rg --pre ./preprocess 'The Commentz-Walter algorithm' 1995-watson.pdf -c 6 real 0.697 user 0.684 sys 0.007 maxmem 16 MB faults 0 time pdfgrep 'The Commentz-Walter algorithm' 1995-watson.pdf -c 6 real 1.336 user 1.310 sys 0.023 maxmem 16 MB faults 0 If you wind up needing to search a lot of PDFs, then ripgrep\u0026rsquo;s parallelism can make the speed difference even greater.
A more robust preprocessor # One of the problems with the aforementioned preprocessor is that it will fail if you try to search a file that isn\u0026rsquo;t a PDF:
echo foo \u0026gt; not-a-pdf rg --pre ./preprocess 'The Commentz-Walter algorithm' not-a-pdf not-a-pdf: preprocessor command failed: '\u0026quot;./preprocess\u0026quot; \u0026quot;not-a-pdf\u0026quot;': ------------------------------------------------------------------------------- Syntax Warning: May not be a PDF file (continuing anyway) Syntax Error: Couldn't find trailer dictionary Syntax Error: Couldn't find trailer dictionary Syntax Error: Couldn't read xref table To fix this, we can make our preprocessor script a bit more robust by only running pdftotext when we think the input is a non-empty PDF:
cat preprocessor #!/bin/sh case \u0026quot;$1\u0026quot; in *.pdf) # The -s flag ensures that the file is non-empty. if [ -s \u0026quot;$1\u0026quot; ]; then exec pdftotext - - else exec cat fi ;; *) exec cat ;; esac We can even extend our preprocessor to search other kinds of files. Sometimes we don\u0026rsquo;t always know the file type from the file name, so we can use the file utility to \u0026ldquo;sniff\u0026rdquo; the type of the file based on its contents:
cat processor #!/bin/sh case \u0026quot;$1\u0026quot; in *.pdf) # The -s flag ensures that the file is non-empty. if [ -s \u0026quot;$1\u0026quot; ]; then exec pdftotext - - else exec cat fi ;; *) case $(file \u0026quot;$1\u0026quot;) in *Zstandard*) exec pzstd -cdq ;; *) exec cat ;; esac ;; esac Reducing preprocessor overhead # There is one more problem with the above approach: it requires running a preprocessor for every single file that ripgrep searches. If every file needs a preprocessor, then this is OK. But if most don\u0026rsquo;t, then this can substantially slow down searches because of the overhead of launching new processors. You can avoid this by telling ripgrep to only invoke the preprocessor when the file path matches a glob. For example, consider the performance difference even when searching a repository as small as ripgrep\u0026rsquo;s:
time rg --pre pre-rg 'fn is_empty' -c crates/globset/src/lib.rs:1 crates/matcher/src/lib.rs:2 crates/ignore/src/overrides.rs:1 crates/ignore/src/gitignore.rs:1 crates/ignore/src/types.rs:1 real 0.138 user 0.485 sys 0.209 maxmem 7 MB faults 0 time rg --pre pre-rg --pre-glob '*.pdf' 'fn is_empty' -c crates/globset/src/lib.rs:1 crates/ignore/src/types.rs:1 crates/ignore/src/gitignore.rs:1 crates/ignore/src/overrides.rs:1 crates/matcher/src/lib.rs:2 real 0.008 user 0.010 sys 0.002 maxmem 7 MB faults 0 Common options # ripgrep has a lot of flags. Too many to keep in your head at once. This section is intended to give you a sampling of some of the most important and frequently used options that will likely impact how you use ripgrep on a regular basis.
-h: Show ripgrep\u0026rsquo;s condensed help output. --help: Show ripgrep\u0026rsquo;s longer form help output. (Nearly what you\u0026rsquo;d find in ripgrep\u0026rsquo;s help, so pipe it into a pager!) -i/--ignore-case: When searching for a pattern, ignore case differences. That is rg -i fast matches fast, fASt, FAST, etc. -S/--smart-case: This is similar to --ignore-case, but disables itself if the pattern contains any uppercase letters. Usually this flag is put into alias or a config file. -F/--fixed-strings: Disable regular expression matching and treat the pattern as a literal string. -w/--word-regexp: Require that all matches of the pattern be surrounded by word boundaries. That is, given pattern, the --word-regexp flag will cause ripgrep to behave as if pattern were actually \\b(?:pattern)\\b. -c/--count: Report a count of total matched lines. --files: Print the files that ripgrep would search, but don\u0026rsquo;t actually search them. -a/--text: Search binary files as if they were plain text. -U/--multiline: Permit matches to span multiple lines. -z/--search-zip: Search compressed files (gzip, bzip2, lzma, xz, lz4, brotli, zstd). This is disabled by default. -C/--context: Show the lines surrounding a match. --sort path: Force ripgrep to sort its output by file name. (This disables parallelism, so it might be slower.) -L/--follow: Follow symbolic links while recursively searching. -M/--max-columns: Limit the length of lines printed by ripgrep. --debug: Shows ripgrep\u0026rsquo;s debug output. This is useful for understanding why a particular file might be ignored from search, or what kinds of configuration ripgrep is loading from the environment. this user guide is taken from here
`}),e.add({id:23,href:"/docs/tools/utility/sd/",title:"Sd",description:"Description # sd is a find and replace CLI tool that aims to be simpler and faster than other tools like sed and awk.\nInstallation # brew install sd Usage # sd 'foo' 'bar' input.txt Resources # sd Similar # sed awk help # sd 0.7.6 USAGE: sd [OPTIONS] \u0026lt;find\u0026gt; \u0026lt;replace-with\u0026gt; [files]... OPTIONS: -f, --flags \u0026lt;flags\u0026gt; Regex flags. May be combined (like `-f mc`). c - case-sensitive e - disable multi-line matching i - case-insensitive m - multi-line matching s - make `.",content:"Description # sd is a find and replace CLI tool that aims to be simpler and faster than other tools like sed and awk.\nInstallation # brew install sd Usage # sd 'foo' 'bar' input.txt Resources # sd Similar # sed awk help # sd 0.7.6 USAGE: sd [OPTIONS] \u0026lt;find\u0026gt; \u0026lt;replace-with\u0026gt; [files]... OPTIONS: -f, --flags \u0026lt;flags\u0026gt; Regex flags. May be combined (like `-f mc`). c - case-sensitive e - disable multi-line matching i - case-insensitive m - multi-line matching s - make `.` match newlines w - match full words only -h, --help Prints help information -s, --string-mode Treat expressions as non-regex strings -p, --preview Output result into stdout and do not modify files -V, --version Prints version information ARGS: \u0026lt;find\u0026gt; The regexp or string (if -s) to search for \u0026lt;replace-with\u0026gt; What to replace each match with. Unless in string mode, you may use captured values like $1, $2, etc \u0026lt;files\u0026gt;... The path to file(s). This is optional - sd can also read from STDIN "}),e.add({id:24,href:"/docs/tools/utility/podman/",title:"Podman",description:"Description # podman is a daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers on your Linux System, simply put it is a tool to manage containers.\nInstallation # brew install podman ```bash ## Usage ```bash podman machine podman machine init --cpus=2 --disk-size=36 --memory=4096 --rootful=true podman machine start container podman run -it alpine sh ```bash ## Resources - [podman](https://podman.io/) ## help ```bash podman(1) podman(1) NAME podman - A Simple management tool for pods, containers and images.",content:"Description # podman is a daemonless container engine for developing, managing, and running Open Container Initiative (OCI) containers on your Linux System, simply put it is a tool to manage containers.\nInstallation # brew install podman ```bash ## Usage ```bash podman machine podman machine init --cpus=2 --disk-size=36 --memory=4096 --rootful=true podman machine start container podman run -it alpine sh ```bash ## Resources - [podman](https://podman.io/) ## help ```bash podman(1) podman(1) NAME podman - A Simple management tool for pods, containers and images. SYNOPSIS podman [options] command DESCRIPTION Podman (Pod Manager) is a fully featured container engine that is a simple daemonless tool. Podman provides a Docker-CLI comparable com- mand line that eases the transition from other container engines and allows the management of pods, containers and images. Simply put: alias docker=podman. Most Podman commands can be run as a regular user, without requiring additional privileges. Podman uses Buildah(1) internally to create container images. Both tools share image (not container) storage, hence each can use or manip- ulate images (but not containers) created by the other. Podman for Mac provides a local client interacting with a Podman back- end node through a RESTful API tunneled through a ssh connection. In this context, a Podman node is a Linux system with Podman installed on it and the API service activated. Credentials for this session can be passed in using flags, environment variables, or in containers.conf. The containers.conf file should be placed under $HOME/.config/contain- ers/containers.conf on Linux and Mac and %APPDATA%\\containers\\contain- ers.conf on Windows. podman [GLOBAL OPTIONS] GLOBAL OPTIONS --connection=name, -c Remote connection name Overrides environment variable CONTAINER_CONNECTION if set. --help, -h Print usage statement --identity=path Path to ssh identity file. If the identity file has been encrypted, Podman prompts the user for the passphrase. If no identity file is provided and no user is given, Podman defaults to the user running the podman command. Podman prompts for the login password on the remote server. Identity value resolution precedence: - command line value - environment variable CONTAINER_SSHKEY, if CONTAINER_HOST is found - containers.conf --log-level=level Log messages above specified level: debug, info, warn, error (default), fatal or panic --url=value URL to access Podman service (default from containers.conf, rootless \u0026quot;unix://run/user/$UID/podman/podman.sock\u0026quot; or as root \u0026quot;unix://run/pod- man/podman.sock). o CONTAINER_HOST is of the format \u0026lt;schema\u0026gt;://[\u0026lt;user[:\u0026lt;pass- word\u0026gt;]@]\u0026lt;host\u0026gt;[:\u0026lt;port\u0026gt;][\u0026lt;path\u0026gt;] o CONTAINER_PROXY is of the format \u0026lt;socks5|socks5h\u0026gt;://[\u0026lt;user[:\u0026lt;password\u0026gt;]@]\u0026lt;host\u0026gt;[:\u0026lt;port\u0026gt;] Details: - schema is one of: * ssh (default): a local unix(7) socket on the named host and port, reachable via SSH * tcp: an unencrypted, unauthenticated TCP connection to the named host and port, can work with proxy if CONTAINER_PROXY is set * unix: a local unix(7) socket at the specified path, or the default for the user - user will default to either root or the current running user (ssh only) - password has no default (ssh only) - host must be provided and is either the IP or name of the machine hosting the Podman service (ssh and tcp) - port defaults to 22 (ssh and tcp) - path defaults to either /run/podman/podman.sock, or /run/user/$UID/podman/podman.sock if running rootless (unix), or must be explicitly specified (ssh) - CONTAINER_PROXY: use proxy (socks5 or socks5h) to access Podman ser- vice (tcp only) URL value resolution precedence: - command line value - environment variable CONTAINER_HOST - containers.conf service_destinations table - unix://run/podman/podman.sock Remote connections use local containers.conf for default. Some example URL values in valid formats: - unix://run/podman/podman.sock - unix://run/user/$UID/podman/podman.sock - ssh://notroot@localhost:22/run/user/$UID/podman/podman.sock - ssh://root@localhost:22/run/podman/podman.sock - tcp://localhost:34451 - tcp://127.0.0.1:34451 --version Print the version Environment Variables Podman can set up environment variables from env of [engine] table in containers.conf. These variables can be overridden by passing environ- ment variables before the podman commands. CONTAINERS_CONF Set default locations of containers.conf file CONTAINER_CONNECTION Set default --connection value to access Podman service. CONTAINER_HOST Set default --url value to access Podman service. CONTAINER_SSHKEY Set default --identity path to ssh key file value used to access Podman service. Exit Status The exit code from podman gives information about why the container failed to run or why it exited. When podman commands exit with a non- zero code, the exit codes follow the chroot standard, see below: 125 The error is with podman itself $ podman run --foo busybox; echo $? Error: unknown flag: --foo 125 126 Executing a contained command and the command cannot be invoked $ podman run busybox /etc; echo $? Error: container_linux.go:346: starting container process caused \u0026quot;exec: \\\u0026quot;/etc\\\u0026quot;: permission denied\u0026quot;: OCI runtime error 126 127 Executing a contained command and the command cannot be found $ podman run busybox foo; echo $? Error: container_linux.go:346: starting container process caused \u0026quot;exec: \\\u0026quot;foo\\\u0026quot;: executable file not found in $PATH\u0026quot;: OCI runtime error 127 Exit code contained command exit code $ podman run busybox /bin/sh -c 'exit 3'; echo $? 3 COMMANDS +-------------------------------+--------------------------------+ |Command | Description | +-------------------------------+--------------------------------+ |podman-attach(1)(podman- | | |attach.1.md) | | +-------------------------------+--------------------------------+ | | Attach to a running container. | +-------------------------------+--------------------------------+ |podman-build(1)(podman- | | |build.1.md) | | +-------------------------------+--------------------------------+ | | Build a container image using | | | a Dockerfile. | +-------------------------------+--------------------------------+ |podman-commit(1)(podman-com- | | |mit.1.md) | | +-------------------------------+--------------------------------+ | | Create new image based on the | | | changed container. | +-------------------------------+--------------------------------+ |podman-container(1)(podman- | | |container.1.md) | | +-------------------------------+--------------------------------+ | | Manage containers. | +-------------------------------+--------------------------------+ |podman-cp(1)(podman-cp.1.md) | Copy files/folders between a | | | container and the local | | | filesystem. | +-------------------------------+--------------------------------+ |podman-create(1)(podman-cre- | | |ate.1.md) | | +-------------------------------+--------------------------------+ | | Create a new container. | +-------------------------------+--------------------------------+ |podman-diff(1)(podman- | | |diff.1.md) | | +-------------------------------+--------------------------------+ | | Inspect changes on a container | | | or image's filesystem. | +-------------------------------+--------------------------------+ |podman-events(1)(podman- | | |events.1.md) | | +-------------------------------+--------------------------------+ | | Monitor Podman events | +-------------------------------+--------------------------------+ |podman-export(1)(podman- | | |export.1.md) | | +-------------------------------+--------------------------------+ | | Export a container's filesys- | | | tem contents as a tar archive. | +-------------------------------+--------------------------------+ |podman-generate(1)(podman-gen- | | |erate.1.md) | | +-------------------------------+--------------------------------+ | | Generate structured data based | | | for a containers and pods. | +-------------------------------+--------------------------------+ |podman-healthcheck(1)(podman- | | |healthcheck.1.md) | | +-------------------------------+--------------------------------+ | | Manage healthchecks for con- | | | tainers | +-------------------------------+--------------------------------+ |podman-history(1)(podman-his- | | |tory.1.md) | | +-------------------------------+--------------------------------+ | | Show the history of an image. | +-------------------------------+--------------------------------+ |podman-image(1)(podman- | | |image.1.md) | | +-------------------------------+--------------------------------+ | | Manage images. | +-------------------------------+--------------------------------+ |podman-images(1)(podman- | | |images.1.md) | | +-------------------------------+--------------------------------+ | | List images in local storage. | +-------------------------------+--------------------------------+ |podman-import(1)(podman- | | |import.1.md) | | +-------------------------------+--------------------------------+ | | Import a tarball and save it | | | as a filesystem image. | +-------------------------------+--------------------------------+ |podman-info(1)(podman- | | |info.1.md) | | +-------------------------------+--------------------------------+ | | Displays Podman related system | | | information. | +-------------------------------+--------------------------------+ |podman-init(1)(podman- | | |init.1.md) | | +-------------------------------+--------------------------------+ | | Initialize a container | +-------------------------------+--------------------------------+ |podman-inspect(1)(podman- | | |inspect.1.md) | | +-------------------------------+--------------------------------+ | | Display a container or image's | | | configuration. | +-------------------------------+--------------------------------+ |podman-kill(1)(podman- | | |kill.1.md) | | +-------------------------------+--------------------------------+ | | Kill the main process in one | | | or more containers. | +-------------------------------+--------------------------------+ |podman-load(1)(podman- | | |load.1.md) | | +-------------------------------+--------------------------------+ | | Load an image from a container | | | image archive into container | | | storage. | +-------------------------------+--------------------------------+ |podman-logs(1)(podman- | | |logs.1.md) | | +-------------------------------+--------------------------------+ | | Display the logs of a con- | | | tainer. | +-------------------------------+--------------------------------+ |podman-pause(1)(podman- | | |pause.1.md) | | +-------------------------------+--------------------------------+ | | Pause one or more containers. | +-------------------------------+--------------------------------+ |podman-pod(1)(podman-pod.1.md) | Management tool for groups of | | | containers, called pods. | +-------------------------------+--------------------------------+ |podman-port(1)(podman- | | |port.1.md) | | +-------------------------------+--------------------------------+ | | List port mappings for a con- | | | tainer. | +-------------------------------+--------------------------------+ |podman-ps(1)(podman-ps.1.md) | Prints out information about | | | containers. | +-------------------------------+--------------------------------+ |podman-pull(1)(podman- | | |pull.1.md) | | +-------------------------------+--------------------------------+ | | Pull an image from a registry. | +-------------------------------+--------------------------------+ |podman-push(1)(podman- | | |push.1.md) | | +-------------------------------+--------------------------------+ | | Push an image from local stor- | | | age to elsewhere. | +-------------------------------+--------------------------------+ |podman-restart(1)(podman- | | |restart.1.md) | | +-------------------------------+--------------------------------+ | | Restart one or more contain- | | | ers. | +-------------------------------+--------------------------------+ |podman-rm(1)(podman-rm.1.md) | Remove one or more containers. | +-------------------------------+--------------------------------+ |podman-rmi(1)(podman-rmi.1.md) | Removes one or more locally | | | stored images. | +-------------------------------+--------------------------------+ |podman-run(1)(podman-run.1.md) | Run a command in a new con- | | | tainer. | +-------------------------------+--------------------------------+ |podman-save(1)(podman- | | |save.1.md) | | +-------------------------------+--------------------------------+ | | Save an image to a container | | | archive. | +-------------------------------+--------------------------------+ |podman-start(1)(podman- | | |start.1.md) | | +-------------------------------+--------------------------------+ | | Start one or more containers. | +-------------------------------+--------------------------------+ |podman-stop(1)(podman- | | |stop.1.md) | | +-------------------------------+--------------------------------+ | | Stop one or more running con- | | | tainers. | +-------------------------------+--------------------------------+ |podman-system(1)(podman-sys- | | |tem.1.md) | | +-------------------------------+--------------------------------+ | | Manage podman. | +-------------------------------+--------------------------------+ |podman-tag(1)(podman-tag.1.md) | Add an additional name to a | | | local image. | +-------------------------------+--------------------------------+ |podman-top(1)(podman-top.1.md) | Display the running processes | | | of a container. | +-------------------------------+--------------------------------+ |podman-unpause(1)(podman- | | |unpause.1.md) | | +-------------------------------+--------------------------------+ | | Unpause one or more contain- | | | ers. | +-------------------------------+--------------------------------+ |podman-version(1)(podman-ver- | | |sion.1.md) | | +-------------------------------+--------------------------------+ | | Display the Podman version | | | information. | +-------------------------------+--------------------------------+ |podman-volume(1)(podman-vol- | | |ume.1.md) | | +-------------------------------+--------------------------------+ | | Manage Volumes. | +-------------------------------+--------------------------------+ FILES containers.conf ($HOME/.config/containers/containers.conf) Podman has builtin defaults for command line options. These defaults can be overridden using the containers.conf configuration files. Users can modify defaults by creating the $HOME/.config/containers/con- tainers.conf file. Podman merges its builtin defaults with the speci- fied fields from this file, if it exists. Fields specified in the users file override the built-in defaults. Podman uses builtin defaults if no containers.conf file is found. SEE ALSO podman(1)(podman.1.md), podman-system-service(1)(podman-system-ser- vice.1.md), containers.conf(5) \u0026lt;https://github.com/containers/com- mon/blob/main/docs/containers.conf.5.md\u0026gt; podman(1) "}),e.add({id:25,href:"/docs/tools/utility/pandoc/",title:"Pandoc",description:`Description # pandoc is a universal document converter.
Installation # brew install pandoc Usage # pandoc -f markdown -t html README.md -o README.html Resources # pandoc help # pandoc [OPTIONS] [FILES] -f FORMAT, -r FORMAT --from=FORMAT, --read=FORMAT -t FORMAT, -w FORMAT --to=FORMAT, --write=FORMAT -o FILE --output=FILE --data-dir=DIRECTORY -M KEY[:VALUE] --metadata=KEY[:VALUE] --metadata-file=FILE -d FILE --defaults=FILE --file-scope --sandbox -s --standalone --template=FILE -V KEY[:VALUE] --variable=KEY[:VALUE] --wrap=auto|none|preserve --ascii --toc, --table-of-contents --toc-depth=NUMBER -N --number-sections --number-offset=NUMBERS --top-level-division=section|chapter|part --extract-media=PATH --resource-path=SEARCHPATH -H FILE --include-in-header=FILE -B FILE --include-before-body=FILE -A FILE --include-after-body=FILE --no-highlight --highlight-style=STYLE|FILE --syntax-definition=FILE --dpi=NUMBER --eol=crlf|lf|native --columns=NUMBER -p --preserve-tabs --tab-stop=NUMBER --pdf-engine=PROGRAM --pdf-engine-opt=STRING --reference-doc=FILE --self-contained --embed-resources --request-header=NAME:VALUE --no-check-certificate --abbreviations=FILE --indented-code-classes=STRING --default-image-extension=extension -F PROGRAM --filter=PROGRAM -L SCRIPTPATH --lua-filter=SCRIPTPATH --shift-heading-level-by=NUMBER --base-header-level=NUMBER --track-changes=accept|reject|all --strip-comments --reference-links --reference-location=block|section|document --markdown-headings=setext|atx --list-tables --listings -i --incremental --slide-level=NUMBER --section-divs --html-q-tags --email-obfuscation=none|javascript|references --id-prefix=STRING -T STRING --title-prefix=STRING -c URL --css=URL --epub-subdirectory=DIRNAME --epub-cover-image=FILE --epub-title-page=true|false --epub-metadata=FILE --epub-embed-font=FILE --split-level=NUMBER --chunk-template=PATHTEMPLATE --epub-chapter-level=NUMBER --ipynb-output=all|none|best -C --citeproc --bibliography=FILE --csl=FILE --citation-abbreviations=FILE --natbib --biblatex --mathml --webtex[=URL] --mathjax[=URL] --katex[=URL] --gladtex --trace --dump-args --ignore-args --verbose --quiet --fail-if-warnings --log=FILE --bash-completion --list-input-formats --list-output-formats --list-extensions[=FORMAT] --list-highlight-languages --list-highlight-styles -D FORMAT --print-default-template=FORMAT --print-default-data-file=FILE --print-highlight-style=STYLE|FILE -v --version -h --help `,content:`Description # pandoc is a universal document converter.
Installation # brew install pandoc Usage # pandoc -f markdown -t html README.md -o README.html Resources # pandoc help # pandoc [OPTIONS] [FILES] -f FORMAT, -r FORMAT --from=FORMAT, --read=FORMAT -t FORMAT, -w FORMAT --to=FORMAT, --write=FORMAT -o FILE --output=FILE --data-dir=DIRECTORY -M KEY[:VALUE] --metadata=KEY[:VALUE] --metadata-file=FILE -d FILE --defaults=FILE --file-scope --sandbox -s --standalone --template=FILE -V KEY[:VALUE] --variable=KEY[:VALUE] --wrap=auto|none|preserve --ascii --toc, --table-of-contents --toc-depth=NUMBER -N --number-sections --number-offset=NUMBERS --top-level-division=section|chapter|part --extract-media=PATH --resource-path=SEARCHPATH -H FILE --include-in-header=FILE -B FILE --include-before-body=FILE -A FILE --include-after-body=FILE --no-highlight --highlight-style=STYLE|FILE --syntax-definition=FILE --dpi=NUMBER --eol=crlf|lf|native --columns=NUMBER -p --preserve-tabs --tab-stop=NUMBER --pdf-engine=PROGRAM --pdf-engine-opt=STRING --reference-doc=FILE --self-contained --embed-resources --request-header=NAME:VALUE --no-check-certificate --abbreviations=FILE --indented-code-classes=STRING --default-image-extension=extension -F PROGRAM --filter=PROGRAM -L SCRIPTPATH --lua-filter=SCRIPTPATH --shift-heading-level-by=NUMBER --base-header-level=NUMBER --track-changes=accept|reject|all --strip-comments --reference-links --reference-location=block|section|document --markdown-headings=setext|atx --list-tables --listings -i --incremental --slide-level=NUMBER --section-divs --html-q-tags --email-obfuscation=none|javascript|references --id-prefix=STRING -T STRING --title-prefix=STRING -c URL --css=URL --epub-subdirectory=DIRNAME --epub-cover-image=FILE --epub-title-page=true|false --epub-metadata=FILE --epub-embed-font=FILE --split-level=NUMBER --chunk-template=PATHTEMPLATE --epub-chapter-level=NUMBER --ipynb-output=all|none|best -C --citeproc --bibliography=FILE --csl=FILE --citation-abbreviations=FILE --natbib --biblatex --mathml --webtex[=URL] --mathjax[=URL] --katex[=URL] --gladtex --trace --dump-args --ignore-args --verbose --quiet --fail-if-warnings --log=FILE --bash-completion --list-input-formats --list-output-formats --list-extensions[=FORMAT] --list-highlight-languages --list-highlight-styles -D FORMAT --print-default-template=FORMAT --print-default-data-file=FILE --print-highlight-style=STYLE|FILE -v --version -h --help `}),e.add({id:26,href:"/docs/tools/utility/openvpn/",title:"Openvpn",description:`Description # openvpn is a full-featured SSL VPN which implements OSI layer 2 or 3 secure network extension using the industry standard SSL/TLS protocol, as well as secure tunneling protocols like SSH.
Installation # brew install openvpn Usage # Resources # openvpn help # OPENVPN(8) System Manager's Manual OPENVPN(8) NAME openvpn - Secure IP tunnel daemon SYNOPSIS openvpn [ options ... ] openvpn --help INTRODUCTION OpenVPN is an open source VPN daemon by James Yonan.`,content:"Description # openvpn is a full-featured SSL VPN which implements OSI layer 2 or 3 secure network extension using the industry standard SSL/TLS protocol, as well as secure tunneling protocols like SSH.\nInstallation # brew install openvpn Usage # Resources # openvpn help # OPENVPN(8) System Manager's Manual OPENVPN(8) NAME openvpn - Secure IP tunnel daemon SYNOPSIS openvpn [ options ... ] openvpn --help INTRODUCTION OpenVPN is an open source VPN daemon by James Yonan. Because OpenVPN tries to be a universal VPN tool offering a great deal of flexibility, there are a lot of options on this manual page. If you're new to OpenVPN, you might want to skip ahead to the examples section where you will see how to construct simple VPNs on the command line without even needing a configuration file. Also note that there's more documentation and examples on the OpenVPN web site: https://openvpn.net/ And if you would like to see a shorter version of this manual, see the openvpn usage message which can be obtained by running openvpn without any parameters. DESCRIPTION OpenVPN is a robust and highly flexible VPN daemon. OpenVPN supports SSL/TLS security, ethernet bridging, TCP or UDP tunnel transport through proxies or NAT, support for dynamic IP addresses and DHCP, scalability to hundreds or thousands of users, and portability to most major OS platforms. OpenVPN is tightly bound to the OpenSSL library, and derives much of its crypto capabilities from it. OpenVPN supports conventional encryption using a pre-shared secret key (Static Key mode) or public key security (SSL/TLS mode) using client \u0026amp; server certificates. OpenVPN also supports non-en‐ crypted TCP/UDP tunnels. OpenVPN is designed to work with the TUN/TAP virtual networking interface that exists on most platforms. Overall, OpenVPN aims to offer many of the key features of IPSec but with a relatively lightweight footprint. OPTIONS OpenVPN allows any option to be placed either on the command line or in a configuration file. Though all command line options are preceded by a double-leading-dash (\u0026quot;--\u0026quot;), this prefix can be removed when an option is placed in a configuration file. Generic Options This section covers generic options which are accessible regardless of which mode OpenVPN is configured as. --help Show options. --auth-nocache Don't cache --askpass or --auth-user-pass username/passwords in virtual memory. If specified, this directive will cause OpenVPN to immediately forget username/password inputs after they are used. As a result, when OpenVPN needs a username/password, it will prompt for input from stdin, which may be multiple times during the duration of an OpenVPN session. When using --auth-nocache in combination with a user/password file and --chroot or --daemon, make sure to use an absolute path. This directive does not affect the --http-proxy username/password. It is always cached. --cd dir Change directory to dir prior to reading any files such as configuration files, key files, scripts, etc. dir should be an absolute path, with a leading \u0026quot;/\u0026quot;, and without any references to the current directory such as . or ... This option is useful when you are running OpenVPN in --daemon mode, and you want to consolidate all of your OpenVPN control files in one location. --chroot dir Chroot to dir after initialization. --chroot essentially redefines dir as being the top level directory tree (/). OpenVPN will therefore be unable to access any files outside this tree. This can be desirable from a security standpoint. Since the chroot operation is delayed until after initialization, most OpenVPN options that reference files will operate in a pre-chroot context. In many cases, the dir parameter can point to an empty directory, however complications can result when scripts or restarts are executed after the chroot operation. Note: The SSL library will probably need /dev/urandom to be available inside the chroot directory dir. This is because SSL libraries occasionally need to collect fresh random. Newer linux kernels and some BSDs implement a getrandom() or getentropy() syscall that removes the need for /dev/urandom to be available. --config file Load additional config options from file where each line corresponds to one command line option, but with the leading '--' removed. If --config file is the only option to the openvpn command, the --config can be removed, and the command can be given as openvpn file Note that configuration files can be nested to a reasonable depth. Double quotation or single quotation characters (\u0026quot;\u0026quot;, '') can be used to enclose single parameters containing whitespace, and \u0026quot;#\u0026quot; or \u0026quot;;\u0026quot; characters in the first column can be used to de‐ note comments. Note that OpenVPN 2.0 and higher performs backslash-based shell escaping for characters not in single quotations, so the following mappings should be observed: \\\\ Maps to a single backslash character (\\). \\\u0026quot; Pass a literal doublequote character (\u0026quot;), don't interpret it as enclosing a parameter. \\[SPACE] Pass a literal space or tab character, don't interpret it as a parameter delimiter. For example on Windows, use double backslashes to represent pathnames: secret \u0026quot;c:\\\\OpenVPN\\\\secret.key\u0026quot; For examples of configuration files, see https://openvpn.net/community-resources/how-to/ Here is an example configuration file: # # Sample OpenVPN configuration file for # using a pre-shared static key. # # '#' or ';' may be used to delimit comments. # Use a dynamic tun device. dev tun # Our remote peer remote mypeer.mydomain # 10.1.0.1 is our local VPN endpoint # 10.1.0.2 is our remote VPN endpoint ifconfig 10.1.0.1 10.1.0.2 # Our pre-shared static key secret static.key --daemon progname Become a daemon after all initialization functions are completed. This option will cause all message and error output to be sent to the syslog file (such as /var/log/messages), except for the output of scripts and ifconfig commands, which will go to /dev/null unless otherwise redirected. The syslog redirection occurs immediately at the point that --daemon is parsed on the command line even though the daemonization point occurs later. If one of the --log options is present, it will supersede syslog redirection. The optional progname parameter will cause OpenVPN to report its program name to the system logger as progname. This can be useful in linking OpenVPN messages in the syslog file with specific tunnels. When unspecified, progname defaults to \u0026quot;openvpn\u0026quot;. When OpenVPN is run with the --daemon option, it will try to delay daemonization until the majority of initialization functions which are capable of generating fatal errors are com‐ plete. This means that initialization scripts can test the return status of the openvpn command for a fairly reliable indication of whether the command has correctly initialized and en‐ tered the packet forwarding event loop. In OpenVPN, the vast majority of errors which occur after initialization are non-fatal. Note: as soon as OpenVPN has daemonized, it can not ask for usernames, passwords, or key pass phrases anymore. This has certain consequences, namely that using a password-protected pri‐ vate key will fail unless the --askpass option is used to tell OpenVPN to ask for the pass phrase (this requirement is new in v2.3.7, and is a consequence of calling daemon() before initializing the crypto layer). Further, using --daemon together with --auth-user-pass (entered on console) and --auth-nocache will fail as soon as key renegotiation (and reauthentication) occurs. --disable-occ Don't output a warning message if option inconsistencies are detected between peers. An example of an option inconsistency would be where one peer uses --dev tun while the other peer uses --dev tap. Use of this option is discouraged, but is provided as a temporary fix in situations where a recent version of OpenVPN must connect to an old version. --engine engine-name Enable OpenSSL hardware-based crypto engine functionality. If engine-name is specified, use a specific crypto engine. Use the --show-engines standalone option to list the crypto engines which are supported by OpenSSL. --fast-io (Experimental) Optimize TUN/TAP/UDP I/O writes by avoiding a call to poll/epoll/select prior to the write operation. The purpose of such a call would normally be to block until the de‐ vice or socket is ready to accept the write. Such blocking is unnecessary on some platforms which don't support write blocking on UDP sockets or TUN/TAP devices. In such cases, one can optimize the event loop by avoiding the poll/epoll/select call, improving CPU efficiency by 5% to 10%. This option can only be used on non-Windows systems, when --proto udp is specified, and when --shaper is NOT specified. --group group Similar to the --user option, this option changes the group ID of the OpenVPN process to group after initialization. --ignore-unknown-option args Valid syntax: ignore-unknown-options opt1 opt2 opt3 ... optN When one of options opt1 ... optN is encountered in the configuration file the configuration file parsing does not fail if this OpenVPN version does not support the option. Multiple --ignore-unknown-option options can be given to support a larger number of options to ignore. This option should be used with caution, as there are good security reasons for having OpenVPN fail if it detects problems in a config file. Having said that, there are valid reasons for wanting new software features to gracefully degrade when encountered by older software versions. --ignore-unknown-option is available since OpenVPN 2.3.3. --iproute cmd Set alternate command to execute instead of default iproute2 command. May be used in order to execute OpenVPN in unprivileged environment. --keying-material-exporter args Save Exported Keying Material [RFC5705] of len bytes (must be between 16 and 4095 bytes) using label in environment (exported_keying_material) for use by plugins in OPEN‐ VPN_PLUGIN_TLS_FINAL callback. Valid syntax: keying-material-exporter label len Note that exporter labels have the potential to collide with existing PRF labels. In order to prevent this, labels MUST begin with EXPORTER. --mlock Disable paging by calling the POSIX mlockall function. Requires that OpenVPN be initially run as root (though OpenVPN can subsequently downgrade its UID using the --user option). Using this option ensures that key material and tunnel data are never written to disk due to virtual memory paging operations which occur under most modern operating systems. It ensures that even if an attacker was able to crack the box running OpenVPN, he would not be able to scan the system swap file to recover previously used ephemeral keys, which are used for a pe‐ riod of time governed by the --reneg options (see below), then are discarded. The downside of using --mlock is that it will reduce the amount of physical memory available to other applications. The limit on how much memory can be locked and how that limit is enforced are OS-dependent. On Linux the default limit that an unprivileged process may lock (RLIMIT_MEMLOCK) is low, and if privileges are dropped later, future memory allocations will very likely fail. The limit can be increased using ulimit or systemd directives depending on how OpenVPN is started. --nice n Change process priority after initialization (n greater than 0 is lower priority, n less than zero is higher priority). --persist-key Don't re-read key files across SIGUSR1 or --ping-restart. This option can be combined with --user nobody to allow restarts triggered by the SIGUSR1 signal. Normally if you drop root privileges in OpenVPN, the daemon cannot be restarted since it will now be unable to re-read protected key files. This option solves the problem by persisting keys across SIGUSR1 resets, so they don't need to be re-read. --providers providers Load the list of (OpenSSL) providers. This is mainly useful for using an external provider for key management like tpm2-openssl or to load the legacy provider with --providers legacy default Behaviour of changing this option between SIGHUP might not be well behaving. If you need to change/add/remove this option, fully restart OpenVPN. --remap-usr1 signal Control whether internally or externally generated SIGUSR1 signals are remapped to SIGHUP (restart without persisting state) or SIGTERM (exit). signal can be set to SIGHUP or SIGTERM. By default, no remapping occurs. --script-security level This directive offers policy-level control over OpenVPN's usage of external programs and scripts. Lower level values are more restrictive, higher values are more permissive. Settings for level: 0 Strictly no calling of external programs. 1 (Default) Only call built-in executables such as ifconfig, ip, route, or netsh. 2 Allow calling of built-in executables and user-defined scripts. 3 Allow passwords to be passed to scripts via environmental variables (potentially unsafe). OpenVPN releases before v2.3 also supported a method flag which indicated how OpenVPN should call external commands and scripts. This could be either execve or system. As of OpenVPN 2.3, this flag is no longer accepted. In most *nix environments the execve() approach has been used without any issues. Some directives such as --up allow options to be passed to the external script. In these cases make sure the script name does not contain any spaces or the configuration parser will choke because it can't determine where the script name ends and script options start. To run scripts in Windows in earlier OpenVPN versions you needed to either add a full path to the script interpreter which can parse the script or use the system flag to run these scripts. As of OpenVPN 2.3 it is now a strict requirement to have full path to the script interpreter when running non-executables files. This is not needed for executable files, such as .exe, .com, .bat or .cmd files. For example, if you have a Visual Basic script, you must use this syntax now: --up 'C:\\\\Windows\\\\System32\\\\wscript.exe C:\\\\Program\\ Files\\\\OpenVPN\\\\config\\\\my-up-script.vbs' Please note the single quote marks and the escaping of the backslashes (\\) and the space character. The reason the support for the system flag was removed is due to the security implications with shell expansions when executing scripts via the system() call. --setcon context Apply SELinux context after initialization. This essentially provides the ability to restrict OpenVPN's rights to only network I/O operations, thanks to SELinux. This goes further than --user and --chroot in that those two, while being great security features, unfortunately do not protect against privilege escalation by exploitation of a vulnerable system call. You can of course combine all three, but please note that since setcon requires access to /proc you will have to provide it inside the chroot directory (e.g. with mount --bind). Since the setcon operation is delayed until after initialization, OpenVPN can be restricted to just network-related system calls, whereas by applying the context before startup (such as the OpenVPN one provided in the SELinux Reference Policies) you will have to allow many things required only during initialization. Like with chroot, complications can result when scripts or restarts are executed after the setcon operation, which is why you should really consider using the --persist-key and --per‐ sist-tun options. --status args Write operational status to file every n seconds. Valid syntaxes: status file status file n Status can also be written to the syslog by sending a SIGUSR2 signal. With multi-client capability enabled on a server, the status file includes a list of clients and a routing table. The output format can be controlled by the --status-version option in that case. For clients or instances running in point-to-point mode, it will contain the traffic statistics. --status-version n Set the status file format version number to n. This only affects the status file on servers with multi-client capability enabled. Valid status version values: 1 Traditional format (default). The client list contains the following fields comma-separated: Common Name, Real Address, Bytes Received, Bytes Sent, Connected Since. 2 A more reliable format for external processing. Compared to version 1, the client list contains some additional fields: Virtual Address, Virtual IPv6 Address, Username, Client ID, Peer ID, Data Channel Cipher. Future versions may extend the number of fields. 3 Identical to 2, but fields are tab-separated. --test-crypto Do a self-test of OpenVPN's crypto options by encrypting and decrypting test packets using the data channel encryption options specified above. This option does not require a peer to function, and therefore can be specified without --dev or --remote. The typical usage of --test-crypto would be something like this: openvpn --test-crypto --secret key or openvpn --test-crypto --secret key --verb 9 This option is very useful to test OpenVPN after it has been ported to a new platform, or to isolate problems in the compiler, OpenSSL crypto library, or OpenVPN's crypto code. Since it is a self-test mode, problems with encryption and authentication can be debugged independently of network and tunnel issues. --tmp-dir dir Specify a directory dir for temporary files. This directory will be used by openvpn processes and script to communicate temporary data with openvpn main process. Note that the directory must be writable by the OpenVPN process after it has dropped it's root privileges. This directory will be used by in the following cases: • --client-connect scripts and OPENVPN_PLUGIN_CLIENT_CONNECT plug-in hook to dynamically generate client-specific configuration client_connect_config_file and return success/failure via client_connect_deferred_file when using deferred client connect method • OPENVPN_PLUGIN_AUTH_USER_PASS_VERIFY plug-in hooks returns success/failure via auth_control_file when using deferred auth method • OPENVPN_PLUGIN_ENABLE_PF plugin hook to pass filtering rules via pf_file --use-prediction-resistance Enable prediction resistance on mbed TLS's RNG. Enabling prediction resistance causes the RNG to reseed in each call for random. Reseeding this often can quickly deplete the kernel entropy pool. If you need this option, please consider running a daemon that adds entropy to the kernel pool. --user user Change the user ID of the OpenVPN process to user after initialization, dropping privileges in the process. This option is useful to protect the system in the event that some hostile party was able to gain control of an OpenVPN session. Though OpenVPN's security features make this unlikely, it is provided as a second line of defense. By setting user to nobody or somebody similarly unprivileged, the hostile party would be limited in what damage they could cause. Of course once you take away privileges, you cannot re‐ turn them to an OpenVPN session. This means, for example, that if you want to reset an OpenVPN daemon with a SIGUSR1 signal (for example in response to a DHCP reset), you should make use of one or more of the --persist options to ensure that OpenVPN doesn't need to execute any privileged operations in order to restart (such as re-reading key files or running ifcon‐ fig on the TUN device). --writepid file Write OpenVPN's main process ID to file. Log options --echo parms Echo parms to log output. Designed to be used to send messages to a controlling application which is receiving the OpenVPN log output. --errors-to-stderr Output errors to stderr instead of stdout unless log output is redirected by one of the --log options. --log file Output logging messages to file, including output to stdout/stderr which is generated by called scripts. If file already exists it will be truncated. This option takes effect immedi‐ ately when it is parsed in the command line and will supersede syslog output if --daemon or --inetd is also specified. This option is persistent over the entire course of an OpenVPN in‐ stantiation and will not be reset by SIGHUP, SIGUSR1, or --ping-restart. Note that on Windows, when OpenVPN is started as a service, logging occurs by default without the need to specify this option. --log-append file Append logging messages to file. If file does not exist, it will be created. This option behaves exactly like --log except that it appends to rather than truncating the log file. --machine-readable-output Always write timestamps and message flags to log messages, even when they otherwise would not be prefixed. In particular, this applies to log messages sent to stdout. --mute n Log at most n consecutive messages in the same category. This is useful to limit repetitive logging of similar message types. --mute-replay-warnings Silence the output of replay warnings, which are a common false alarm on WiFi networks. This option preserves the security of the replay protection code without the verbosity associated with warnings about duplicate packets. --suppress-timestamps Avoid writing timestamps to log messages, even when they otherwise would be prepended. In particular, this applies to log messages sent to stdout. --syslog progname Direct log output to system logger, but do not become a daemon. See --daemon directive above for description of progname parameter. --verb n Set output verbosity to n (default 1). Each level shows all info from the previous levels. Level 3 is recommended if you want a good summary of what's happening without being swamped by output. 0 No output except fatal errors. 1 to 4 Normal usage range. 5 Outputs R and W characters to the console for each packet read and write, uppercase is used for TCP/UDP packets and lowercase is used for TUN/TAP packets. 6 to 11 Debug info range (see errlevel.h in the source code for additional information on debug levels). Protocol options Options in this section affect features available in the OpenVPN wire protocol. Many of these options also define the encryption options of the data channel in the OpenVPN wire protocol. These options must be configured in a compatible way between both the local and remote side. --allow-compression mode As described in the --compress option, compression is a potentially dangerous option. This option allows controlling the behaviour of OpenVPN when compression is used and allowed. Valid syntaxes: allow-compression allow-compression mode The mode argument can be one of the following values: asym (default) OpenVPN will only decompress downlink packets but not compress uplink packets. This also allows migrating to disable compression when changing both server and client configura‐ tions to remove compression at the same time is not a feasible option. no OpenVPN will refuse any non-stub compression. yes OpenVPN will send and receive compressed packets. --auth alg Authenticate data channel packets and (if enabled) tls-auth control channel packets with HMAC using message digest algorithm alg. (The default is SHA1 ). HMAC is a commonly used message authentication algorithm (MAC) that uses a data string, a secure hash algorithm and a key to produce a digital signature. The OpenVPN data channel protocol uses encrypt-then-mac (i.e. first encrypt a packet then HMAC the resulting ciphertext), which prevents padding oracle attacks. If an AEAD cipher mode (e.g. GCM) is chosen then the specified --auth algorithm is ignored for the data channel and the authentication method of the AEAD cipher is used instead. Note that alg still specifies the digest used for tls-auth. In static-key encryption mode, the HMAC key is included in the key file generated by --genkey. In TLS mode, the HMAC key is dynamically generated and shared between peers via the TLS control channel. If OpenVPN receives a packet with a bad HMAC it will drop the packet. HMAC usually adds 16 or 20 bytes per packet. Set alg=none to disable authentication. For more information on HMAC see http://www.cs.ucsd.edu/users/mihir/papers/hmac.html --cipher alg This option is deprecated for server-client mode. --data-ciphers or possibly --data-ciphers-fallback` should be used instead. Encrypt data channel packets with cipher algorithm alg. The default is BF-CBC, an abbreviation for Blowfish in Cipher Block Chaining mode. When cipher negotiation (NCP) is allowed, OpenVPN 2.4 and newer on both client and server side will automatically upgrade to AES-256-GCM. See --data-ciphers and --ncp-disable for more details on NCP. Using BF-CBC is no longer recommended, because of its 64-bit block size. This small block size allows attacks based on collisions, as demonstrated by SWEET32. See https://community.openvpn.net/openvpn/wiki/SWEET32 for details. Due to this, support for BF-CBC, DES, CAST5, IDEA and RC2 ciphers will be removed in OpenVPN 2.6. To see other ciphers that are available with OpenVPN, use the --show-ciphers option. Set alg to none to disable encryption. --compress algorithm DEPRECATED Enable a compression algorithm. Compression is generally not recommended. VPN tunnels which use compression are susceptible to the VORALCE attack vector. The algorithm parameter may be lzo, lz4, lz4-v2, stub, stub-v2 or empty. LZO and LZ4 are different compression algorithms, with LZ4 generally offering the best performance with least CPU usage. The lz4-v2 and stub-v2 variants implement a better framing that does not add overhead when packets cannot be compressed. All other variants always add one extra framing byte compared to no compression framing. If the algorithm parameter is stub, stub-v2 or empty, compression will be turned off, but the packet framing for compression will still be enabled, allowing a different setting to be pushed later. Additionally, stub and stub-v2 wil disable announcing lzo and lz4 compression support via IV_ variables to the server. Note: the stub (or empty) option is NOT compatible with the older option --comp-lzo no. *Security Considerations* Compression and encryption is a tricky combination. If an attacker knows or is able to control (parts of) the plain-text of packets that contain secrets, the attacker might be able to extract the secret if compression is enabled. See e.g. the CRIME and BREACH attacks on TLS and VORACLE on VPNs which also leverage to break encryption. If you are not entirely sure that the above does not apply to your traffic, you are advised to not enable compression. --comp-lzo mode DEPRECATED Enable LZO compression algorithm. Compression is generally not recommended. VPN tunnels which uses compression are suspectible to the VORALCE attack vector. Use LZO compression -- may add up to 1 byte per packet for incompressible data. mode may be yes, no, or adaptive (default). In a server mode setup, it is possible to selectively turn compression on or off for individual clients. First, make sure the client-side config file enables selective compression by having at least one --comp-lzo directive, such as --comp-lzo no. This will turn off compression by default, but allow a future directive push from the server to dynamically change the on/off/adaptive setting. Next in a --client-config-dir file, specify the compression setting for the client, for example: comp-lzo yes push \u0026quot;comp-lzo yes\u0026quot; The first line sets the comp-lzo setting for the server side of the link, the second sets the client side. --comp-noadapt DEPRECATED When used in conjunction with --comp-lzo, this option will disable OpenVPN's adaptive compression algorithm. Normally, adaptive compression is enabled with --comp-lzo. Adaptive compression tries to optimize the case where you have compression enabled, but you are sending predominantly incompressible (or pre-compressed) packets over the tunnel, such as an FTP or rsync transfer of a large, compressed file. With adaptive compression, OpenVPN will periodically sample the compression process to measure its efficiency. If the data being sent over the tunnel is already compressed, the compression efficiency will be very low, triggering openvpn to disable compression for a period of time until the next re-sample test. --key-direction Alternative way of specifying the optional direction parameter for the --tls-auth and --secret options. Useful when using inline files (See section on inline files). --keysize n DEPRECATED This option will be removed in OpenVPN 2.6. Size of cipher key in bits (optional). If unspecified, defaults to cipher-specific default. The --show-ciphers option (see below) shows all available OpenSSL ciphers, their default key sizes, and whether the key size can be changed. Use care in changing a cipher's default key size. Many ciphers have not been extensively cryptanalyzed with non-standard key lengths, and a larger key may offer no real guarantee of greater security, or may even reduce security. --data-ciphers cipher-list Restrict the allowed ciphers to be negotiated to the ciphers in cipher-list. cipher-list is a colon-separated list of ciphers, and defaults to AES-256-GCM:AES-128-GCM. For servers, the first cipher from cipher-list that is also supported by the client will be pushed to clients that support cipher negotiation. Cipher negotiation is enabled in client-server mode only. I.e. if --mode is set to 'server' (server-side, implied by setting --server ), or if --pull is specified (client-side, implied by setting --client). If no common cipher is found during cipher negotiation, the connection is terminated. To support old clients/old servers that do not provide any cipher negotiation support see --data-ciphers-fallback. Additionally, to allow for more smooth transition, if NCP is enabled, OpenVPN will inherit the cipher of the peer if that cipher is different from the local --cipher setting, but the peer cipher is one of the ciphers specified in --data-ciphers. E.g. a non-NCP client (\u0026lt;=v2.3, or with --ncp-disabled set) connecting to a NCP server (v2.4+) with --cipher BF-CBC and --data-ciphers AES-256-GCM:AES-256-CBC set can either specify --cipher BF-CBC or --cipher AES-256-CBC and both will work. Note for using NCP with an OpenVPN 2.4 peer: This list must include the AES-256-GCM and AES-128-GCM ciphers. This list is restricted to be 127 chars long after conversion to OpenVPN ciphers. This option was called --ncp-ciphers in OpenVPN 2.4 but has been renamed to --data-ciphers in OpenVPN 2.5 to more accurately reflect its meaning. --data-ciphers-fallback alg Configure a cipher that is used to fall back to if we could not determine which cipher the peer is willing to use. This option should only be needed to connect to peers that are running OpenVPN 2.3 and older version, and have been configured with --enable-small (typically used on routers or other embedded devices). --ncp-disable DEPRECATED Disable \u0026quot;Negotiable Crypto Parameters\u0026quot;. This completely disables cipher negotiation. --secret args Enable Static Key encryption mode (non-TLS). Use pre-shared secret file which was generated with --genkey. Valid syntaxes: secret file secret file direction The optional direction parameter enables the use of 4 distinct keys (HMAC-send, cipher-encrypt, HMAC-receive, cipher-decrypt), so that each data flow direction has a different set of HMAC and cipher keys. This has a number of desirable security properties including eliminating certain kinds of DoS and message replay attacks. When the direction parameter is omitted, 2 keys are used bidirectionally, one for HMAC and the other for encryption/decryption. The direction parameter should always be complementary on either side of the connection, i.e. one side should use 0 and the other should use 1, or both sides should omit it altogether. The direction parameter requires that file contains a 2048 bit key. While pre-1.5 versions of OpenVPN generate 1024 bit key files, any version of OpenVPN which supports the direction parameter, will also support 2048 bit key file generation using the --genkey option. Static key encryption mode has certain advantages, the primary being ease of configuration. There are no certificates or certificate authorities or complicated negotiation handshakes and protocols. The only requirement is that you have a pre-existing secure channel with your peer (such as ssh) to initially copy the key. This requirement, along with the fact that your key never changes unless you manually generate a new one, makes it somewhat less secure than TLS mode (see below). If an attacker manages to steal your key, everything that was ever encrypted with it is compromised. Contrast that to the perfect forward secrecy features of TLS mode (using Diffie Hellman key exchange), where even if an attacker was able to steal your private key, he would gain no information to help him decrypt past sessions. Another advantageous aspect of Static Key encryption mode is that it is a handshake-free protocol without any distinguishing signature or feature (such as a header or protocol handshake sequence) that would mark the ciphertext packets as being generated by OpenVPN. Anyone eavesdropping on the wire would see nothing but random-looking data. --tran-window n Transition window -- our old key can live this many seconds after a new a key renegotiation begins (default 3600 seconds). This feature allows for a graceful transition from old to new key, and removes the key renegotiation sequence from the critical path of tunnel data forwarding. Client Options The client options are used when connecting to an OpenVPN server configured to use --server, --server-bridge, or --mode server in its configuration. --allow-pull-fqdn Allow client to pull DNS names from server (rather than being limited to IP address) for --ifconfig, --route, and --route-gateway. --allow-recursive-routing When this option is set, OpenVPN will not drop incoming tun packets with same destination as host. --auth-token token This is not an option to be used directly in any configuration files, but rather push this option from a --client-connect script or a --plugin which hooks into the OPEN‐ VPN_PLUGIN_CLIENT_CONNECT or OPENVPN_PLUGIN_CLIENT_CONNECT_V2 calls. This option provides a possibility to replace the clients password with an authentication token during the lifetime of the OpenVPN client. Whenever the connection is renegotiated and the --auth-user-pass-verify script or --plugin making use of the OPENVPN_PLUGIN_AUTH_USER_PASS_VERIFY hook is triggered, it will pass over this token as the password instead of the password the user provided. The authentication token can only be reset by a full reconnect where the server can push new options to the client. The password the user entered is never preserved once an authentication token has been set. If the OpenVPN server side rejects the authentication token then the client will receive an AUTH_FAILED and disconnect. The purpose of this is to enable two factor authentication methods, such as HOTP or TOTP, to be used without needing to retrieve a new OTP code each time the connection is renegotiated. Another use case is to cache authentication data on the client without needing to have the users password cached in memory during the life time of the session. To make use of this feature, the --client-connect script or --plugin needs to put push \u0026quot;auth-token UNIQUE_TOKEN_VALUE\u0026quot; into the file/buffer for dynamic configuration data. This will then make the OpenVPN server to push this value to the client, which replaces the local password with the UNIQUE_TO‐ KEN_VALUE. Newer clients (2.4.7+) will fall back to the original password method after a failed auth. Older clients will keep using the token value and react according to --auth-retry --auth-token-user base64username Companion option to --auth-token. This options allows to override the username used by the client when reauthenticating with the auth-token. It also allows to use --auth-token in set‐ ups that normally do not use username and password. The username has to be base64 encoded. --auth-user-pass Authenticate with server using username/password. Valid syntaxes: auth-user-pass auth-user-pass up If up is present, it must be a file containing username/password on 2 lines. If the password line is missing, OpenVPN will prompt for one. If up is omitted, username/password will be prompted from the console. The server configuration must specify an --auth-user-pass-verify script to verify the username/password provided by the client. --auth-retry type Controls how OpenVPN responds to username/password verification errors such as the client-side response to an AUTH_FAILED message from the server or verification failure of the private key password. Normally used to prevent auth errors from being fatal on the client side, and to permit username/password requeries in case of error. An AUTH_FAILED message is generated by the server if the client fails --auth-user-pass authentication, or if the server-side --client-connect script returns an error status when the client tries to connect. type can be one of: none Client will exit with a fatal error (this is the default). nointeract Client will retry the connection without requerying for an --auth-user-pass username/password. Use this option for unattended clients. interact Client will requery for an --auth-user-pass username/password and/or private key password before attempting a reconnection. Note that while this option cannot be pushed, it can be controlled from the management interface. --client A helper directive designed to simplify the configuration of OpenVPN's client mode. This directive is equivalent to: pull tls-client --client-nat args This pushable client option sets up a stateless one-to-one NAT rule on packet addresses (not ports), and is useful in cases where routes or ifconfig settings pushed to the client would create an IP numbering conflict. Examples: client-nat snat 192.168.0.0/255.255.0.0 client-nat dnat 10.64.0.0/255.255.0.0 network/netmask (for example 192.168.0.0/255.255.0.0) defines the local view of a resource from the client perspective, while alias/netmask (for example 10.64.0.0/255.255.0.0) defines the remote view from the server perspective. Use snat (source NAT) for resources owned by the client and dnat (destination NAT) for remote resources. Set --verb 6 for debugging info showing the transformation of src/dest addresses in packets. --connect-retry n Wait n seconds between connection attempts (default 5). Repeated reconnection attempts are slowed down after 5 retries per remote by doubling the wait time after each unsuccessful at‐ tempt. An optional argument max specifies the maximum value of wait time in seconds at which it gets capped (default 300). --connect-retry-max n n specifies the number of times each --remote or \u0026lt;connection\u0026gt; entry is tried. Specifying n as 1 would try each entry exactly once. A successful connection resets the counter. (default unlimited). --connect-timeout n See --server-poll-timeout. --explicit-exit-notify n In UDP client mode or point-to-point mode, send server/peer an exit notification if tunnel is restarted or OpenVPN process is exited. In client mode, on exit/restart, this option will tell the server to immediately close its client instance object rather than waiting for a timeout. The n parameter (default 1 if not present) controls the maximum number of attempts that the client will try to resend the exit notification message. In UDP server mode, send RESTART control channel command to connected clients. The n parameter (default 1 if not present) controls client behavior. With n = 1 client will attempt to re‐ connect to the same server, with n = 2 client will advance to the next server. OpenVPN will not send any exit notifications unless this option is enabled. --inactive args Causes OpenVPN to exit after n seconds of inactivity on the TUN/TAP device. The time length of inactivity is measured since the last incoming or outgoing tunnel packet. The default value is 0 seconds, which disables this feature. Valid syntaxes: inactive n inactive n bytes If the optional bytes parameter is included, exit if less than bytes of combined in/out traffic are produced on the tun/tap device in n seconds. In any case, OpenVPN's internal ping packets (which are just keepalives) and TLS control packets are not considered \u0026quot;activity\u0026quot;, nor are they counted as traffic, as they are used inter‐ nally by OpenVPN and are not an indication of actual user activity. --proto-force p When iterating through connection profiles, only consider profiles using protocol p (tcp | udp). Note that this specifically only filters by the transport layer protocol, i.e. UDP or TCP. This does not affect whether IPv4 or IPv6 is used as IP protocol. For implementation reasons the option accepts the 4 and 6 suffixes when specifying the protocol (i.e. udp4 / udp6 / tcp4 / tcp6). However, these behave the same as without the suffix and should be avoided to prevent confusion. --pull This option must be used on a client which is connecting to a multi-client server. It indicates to OpenVPN that it should accept options pushed by the server, provided they are part of the legal set of pushable options (note that the --pull option is implied by --client ). In particular, --pull allows the server to push routes to the client, so you should not use --pull or --client in situations where you don't trust the server to have control over the client's routing table. --pull-filter args Filter options on the client pushed by the server to the client. Valid syntaxes: pull-filter accept text pull-filter ignore text pull-filter reject text Filter options received from the server if the option starts with text. The action flag accept allows the option, ignore removes it and reject flags an error and triggers a SIGUSR1 restart. The filters may be specified multiple times, and each filter is applied in the order it is specified. The filtering of each option stops as soon as a match is found. Unmatched options are accepted by default. Prefix comparison is used to match text against the received option so that pull-filter ignore \u0026quot;route\u0026quot; would remove all pushed options starting with route which would include, for example, route-gateway. Enclose text in quotes to embed spaces. pull-filter accept \u0026quot;route 192.168.1.\u0026quot; pull-filter ignore \u0026quot;route \u0026quot; would remove all routes that do not start with 192.168.1. Note that reject may result in a repeated cycle of failure and reconnect, unless multiple remotes are specified and connection to the next remote succeeds. To silently ignore an option pushed by the server, use ignore. --push-peer-info Push additional information about the client to server. The following data is always pushed to the server: IV_VER=\u0026lt;version\u0026gt; The client OpenVPN version IV_PLAT=[linux|solaris|openbsd|mac|netbsd|freebsd|win] The client OS platform IV_LZO_STUB=1 If client was built with LZO stub capability IV_LZ4=1 If the client supports LZ4 compressions. IV_PROTO Details about protocol extensions that the peer supports. The variable is a bitfield and the bits are defined as follows (starting a bit 0 for the first (unused) bit: • bit 1: The peer supports peer-id floating mechanism • bit 2: The client expects a push-reply and the server may send this reply without waiting for a push-request first. • bit 3: The client is capable of doing key derivation using RFC5705 key material exporter. • bit 4: The client is capable of accepting additional arguments to the AUTH_PENDING message. IV_NCP=2 Negotiable ciphers, client supports --cipher pushed by the server, a value of 2 or greater indicates client supports AES-GCM-128 and AES-GCM-256. IV_CIPHERS=\u0026lt;ncp-ciphers\u0026gt; The client announces the list of supported ciphers configured with the --data-ciphers option to the server. IV_GUI_VER=\u0026lt;gui_id\u0026gt; \u0026lt;version\u0026gt; The UI version of a UI if one is running, for example de.blinkt.openvpn 0.5.47 for the Android app. IV_SSO=[crtext,][openurl,][proxy_url] Additional authentication methods supported by the client. This may be set by the client UI/GUI using --setenv When --push-peer-info is enabled the additional information consists of the following data: IV_HWADDR=\u0026lt;string\u0026gt; This is intended to be a unique and persistent ID of the client. The string value can be any readable ASCII string up to 64 bytes. OpenVPN 2.x and some other implementations use the MAC address of the client's interface used to reach the default gateway. If this string is generated by the client, it should be consistent and preserved across indepen‐ dent session and preferably re-installations and upgrades. IV_SSL=\u0026lt;version string\u0026gt; The ssl version used by the client, e.g. OpenSSL 1.0.2f 28 Jan 2016. IV_PLAT_VER=x.y The version of the operating system, e.g. 6.1 for Windows 7. UV_\u0026lt;name\u0026gt;=\u0026lt;value\u0026gt; Client environment variables whose names start with UV_ --remote args Remote host name or IP address, port and protocol. Valid syntaxes: remote host remote host port remote host port proto The port and proto arguments are optional. The OpenVPN client will try to connect to a server at host:port. The proto argument indicates the protocol to use when connecting with the remote, and may be tcp or udp. To enforce IPv4 or IPv6 connections add a 4 or 6 suffix; like udp4 / udp6 / tcp4 / tcp6. On the client, multiple --remote options may be specified for redundancy, each referring to a different OpenVPN server, in the order specified by the list of --remote options. Specify‐ ing multiple --remote options for this purpose is a special case of the more general connection-profile feature. See the \u0026lt;connection\u0026gt; documentation below. The client will move on to the next host in the list, in the event of connection failure. Note that at any given time, the OpenVPN client will at most be connected to one server. Examples: remote server1.example.net remote server1.example.net 1194 remote server2.example.net 1194 tcp Note: Since UDP is connectionless, connection failure is defined by the --ping and --ping-restart options. Also, if you use multiple --remote options, AND you are dropping root privileges on the client with --user and/or --group AND the client is running a non-Windows OS, if the client needs to switch to a different server, and that server pushes back different TUN/TAP or route settings, the client may lack the necessary privileges to close and reopen the TUN/TAP interface. This could cause the client to exit with a fatal error. If --remote is unspecified, OpenVPN will listen for packets from any IP address, but will not act on those packets unless they pass all authentication tests. This requirement for au‐ thentication is binding on all potential peers, even those from known and supposedly trusted IP addresses (it is very easy to forge a source IP address on a UDP packet). When used in TCP mode, --remote will act as a filter, rejecting connections from any host which does not match host. If host is a DNS name which resolves to multiple IP addresses, OpenVPN will try them in the order that the system getaddrinfo() presents them, so priorization and DNS randomization is done by the system library. Unless an IP version is forced by the protocol specification (4/6 suffix), OpenVPN will try both IPv4 and IPv6 addresses, in the order getaddrinfo() returns them. --remote-random When multiple --remote address/ports are specified, or if connection profiles are being used, initially randomize the order of the list as a kind of basic load-balancing measure. --remote-random-hostname Prepend a random string (6 bytes, 12 hex characters) to hostname to prevent DNS caching. For example, \u0026quot;foo.bar.gov\u0026quot; would be modified to \u0026quot;\u0026lt;random-chars\u0026gt;.foo.bar.gov\u0026quot;. --resolv-retry n If hostname resolve fails for --remote, retry resolve for n seconds before failing. Set n to \u0026quot;infinite\u0026quot; to retry indefinitely. By default, --resolv-retry infinite is enabled. You can disable by setting n=0. --single-session After initially connecting to a remote peer, disallow any new connections. Using this option means that a remote peer cannot connect, disconnect, and then reconnect. If the daemon is reset by a signal or --ping-restart, it will allow one new connection. --single-session can be used with --ping-exit or --inactive to create a single dynamic session that will exit when finished. --server-poll-timeout n When connecting to a remote server do not wait for more than n seconds for a response before trying the next server. The default value is 120s. This timeout includes proxy and TCP con‐ nect timeouts. --static-challenge args Enable static challenge/response protocol Valid syntax: static-challenge text echo The text challenge text is presented to the user which describes what information is requested. The echo flag indicates if the user's input should be echoed on the screen. Valid echo values are 0 or 1. See management-notes.txt in the OpenVPN distribution for a description of the OpenVPN challenge/response protocol. --show-proxy-settings Show sensed HTTP or SOCKS proxy settings. Currently, only Windows clients support this option. --http-proxy args Connect to remote host through an HTTP proxy. This requires at least an address server and port argument. If HTTP Proxy-Authenticate is required, a file name to an authfile file con‐ taining a username and password on 2 lines can be given, or stdin to prompt from console. Its content can also be specified in the config file with the --http-proxy-user-pass option. (See section on inline files) The last optional argument is an auth-method which should be one of none, basic, or ntlm. HTTP Digest authentication is supported as well, but only via the auto or auto-nct flags (below). This must replace the authfile argument. The auto flag causes OpenVPN to automatically determine the auth-method and query stdin or the management interface for username/password credentials, if required. This flag exists on OpenVPN 2.1 or higher. The auto-nct flag (no clear-text auth) instructs OpenVPN to automatically determine the authentication method, but to reject weak authentication protocols such as HTTP Basic Authentica‐ tion. Examples: http-proxy proxy.example.net 3128 http-proxy proxy.example.net 3128 authfile.txt http-proxy proxy.example.net 3128 stdin http-proxy proxy.example.net 3128 auto basic http-proxy proxy.example.net 3128 auto-nct ntlm --http-proxy-option args Set extended HTTP proxy options. Requires an option type as argument and an optional parameter to the type. Repeat to set multiple options. VERSION version Set HTTP version number to version (default 1.0). AGENT user-agent Set HTTP \u0026quot;User-Agent\u0026quot; string to user-agent. CUSTOM-HEADER name content Adds the custom Header with name as name and content as the content of the custom HTTP header. Examples: http-proxy-option VERSION 1.1 http-proxy-option AGENT OpenVPN/2.4 http-proxy-option X-Proxy-Flag some-flags --socks-proxy args Connect to remote host through a Socks5 proxy. A required server argument is needed. Optionally a port (default 1080) and authfile can be given. The authfile is a file containing a username and password on 2 lines, or stdin can be used to prompt from console. Server Options Starting with OpenVPN 2.0, a multi-client TCP/UDP server mode is supported, and can be enabled with the --mode server option. In server mode, OpenVPN will listen on a single port for incoming client connections. All client connections will be routed through a single tun or tap interface. This mode is designed for scalability and should be able to support hundreds or even thousands of clients on sufficiently fast hardware. SSL/TLS authentication must be used in this mode. --auth-gen-token args Returns an authentication token to successfully authenticated clients. Valid syntax: auth-gen-token [lifetime] [external-auth] After successful user/password authentication, the OpenVPN server will with this option generate a temporary authentication token and push that to the client. On the following renegoti‐ ations, the OpenVPN client will pass this token instead of the users password. On the server side the server will do the token authentication internally and it will NOT do any addi‐ tional authentications against configured external user/password authentication mechanisms. The tokens implemented by this mechanism include an initial timestamp and a renew timestamp and are secured by HMAC. The lifetime argument defines how long the generated token is valid. The lifetime is defined in seconds. If lifetime is not set or it is set to 0, the token will never expire. The token will expire either after the configured lifetime of the token is reached or after not being renewed for more than 2 * reneg-sec seconds. Clients will be sent renewed tokens on every TLS renogiation to keep the client's token updated. This is done to invalidate a token if a client is disconnected for a sufficently long time, while at the same time permitting much longer token lifetimes for active clients. This feature is useful for environments which are configured to use One Time Passwords (OTP) as part of the user/password authentications and that authentication mechanism does not im‐ plement any auth-token support. When the external-auth keyword is present the normal authentication method will always be called even if auth-token succeeds. Normally other authentications method are skipped if auth-token verification suceeds or fails. This option postpones this decision to the external authentication methods and checks the validity of the account and do other checks. In this mode the environment will have a session_id variable that holds the session id from auth-gen-token. Also an environment variable session_state is present. This variable indi‐ cates whether the auth-token has succeeded or not. It can have the following values: Initial No token from client. Authenticated Token is valid and not expired. Expired Token is valid but has expired. Invalid Token is invalid (failed HMAC or wrong length) AuthenticatedEmptyUser / ExpiredEmptyUser The token is not valid with the username sent from the client but would be valid (or expired) if we assume an empty username was used instead. These two cases are a workaround for behaviour in OpenVPN 3. If this workaround is not needed these two cases should be handled in the same way as Invalid. Warning: Use this feature only if you want your authentication method called on every verification. Since the external authentication is called it needs to also indicate a success or failure of the authentication. It is strongly recommended to return an authentication failure in the case of the Invalid/Expired auth-token with the external-auth option unless the client could authenticate in another acceptable way (e.g. client certificate), otherwise returning success will lead to authentication bypass (as does returning success on a wrong pass‐ word from a script). --auth-gen-token-secret file Specifies a file that holds a secret for the HMAC used in --auth-gen-token If file is not present OpenVPN will generate a random secret on startup. This file should be used if auth-to‐ ken should validate after restarting a server or if client should be able to roam between multiple OpenVPN servers with their auth-token. --auth-user-pass-optional Allow connections by clients that do not specify a username/password. Normally, when --auth-user-pass-verify or --management-client-auth are specified (or an authentication plugin mod‐ ule), the OpenVPN server daemon will require connecting clients to specify a username and password. This option makes the submission of a username/password by clients optional, passing the responsibility to the user-defined authentication module/script to accept or deny the client based on other factors (such as the setting of X509 certificate fields). When this op‐ tion is used, and a connecting client does not submit a username/password, the user-defined authentication module/script will see the username and password as being set to empty strings (\u0026quot;\u0026quot;). The authentication module/script MUST have logic to detect this condition and respond accordingly. --ccd-exclusive Require, as a condition of authentication, that a connecting client has a --client-config-dir file. --client-config-dir dir Specify a directory dir for custom client config files. After a connecting client has been authenticated, OpenVPN will look in this directory for a file having the same name as the client's X509 common name. If a matching file exists, it will be opened and parsed for client-specific configuration options. If no matching file is found, OpenVPN will instead try to open and parse a default file called \u0026quot;DEFAULT\u0026quot;, which may be provided but is not required. Note that the configuration files must be readable by the OpenVPN process after it has dropped it's root privileges. This file can specify a fixed IP address for a given client using --ifconfig-push, as well as fixed subnets owned by the client using --iroute. One of the useful properties of this option is that it allows client configuration files to be conveniently created, edited, or removed while the server is live, without needing to restart the server. The following options are legal in a client-specific context: --push, --push-reset, --push-remove, --iroute, --ifconfig-push, --vlan-pvid and --config. --client-to-client Because the OpenVPN server mode handles multiple clients through a single tun or tap interface, it is effectively a router. The --client-to-client flag tells OpenVPN to internally route client-to-client traffic rather than pushing all client-originating traffic to the TUN/TAP interface. When this option is used, each client will \u0026quot;see\u0026quot; the other clients which are currently connected. Otherwise, each client will only see the server. Don't use this option if you want to firewall tunnel traffic using custom, per-client rules. --disable Disable a particular client (based on the common name) from connecting. Don't use this option to disable a client due to key or password compromise. Use a CRL (certificate revocation list) instead (see the --crl-verify option). This option must be associated with a specific client instance, which means that it must be specified either in a client instance config file using --client-config-dir or dynamically generated using a --client-connect script. --connect-freq args Allow a maximum of n new connections per sec seconds from clients. Valid syntax: connect-freq n sec This is designed to contain DoS attacks which flood the server with connection requests using certificates which will ultimately fail to authenticate. This is an imperfect solution however, because in a real DoS scenario, legitimate connections might also be refused. For the best protection against DoS attacks in server mode, use --proto udp and either --tls-auth or --tls-crypt. --duplicate-cn Allow multiple clients with the same common name to concurrently connect. In the absence of this option, OpenVPN will disconnect a client instance upon connection of a new client having the same common name. --ifconfig-pool args Set aside a pool of subnets to be dynamically allocated to connecting clients, similar to a DHCP server. Valid syntax: ifconfig-pool start-IP end-IP [netmask] For tun-style tunnels, each client will be given a /30 subnet (for interoperability with Windows clients). For tap-style tunnels, individual addresses will be allocated, and the op‐ tional netmask parameter will also be pushed to clients. --ifconfig-ipv6-pool args Specify an IPv6 address pool for dynamic assignment to clients. Valid args: ifconfig-ipv6-pool ipv6addr/bits The pool starts at ipv6addr and matches the offset determined from the start of the IPv4 pool. If the host part of the given IPv6 address is 0, the pool starts at ipv6addr +1. --ifconfig-pool-persist args Persist/unpersist ifconfig-pool data to file, at seconds intervals (default 600), as well as on program startup and shutdown. Valid syntax: ifconfig-pool-persist file [seconds] The goal of this option is to provide a long-term association between clients (denoted by their common name) and the virtual IP address assigned to them from the ifconfig-pool. Main‐ taining a long-term association is good for clients because it allows them to effectively use the --persist-tun option. file is a comma-delimited ASCII file, formatted as \u0026lt;Common-Name\u0026gt;,\u0026lt;IP-address\u0026gt;. If seconds = 0, file will be treated as read-only. This is useful if you would like to treat file as a configuration file. Note that the entries in this file are treated by OpenVPN as suggestions only, based on past associations between a common name and IP address. They do not guarantee that the given common name will always receive the given IP address. If you want guaranteed assignment, use --ifconfig-push --ifconfig-push args Push virtual IP endpoints for client tunnel, overriding the --ifconfig-pool dynamic allocation. Valid syntax: ifconfig-push local remote-netmask [alias] The parameters local and remote-netmask are set according to the --ifconfig directive which you want to execute on the client machine to configure the remote end of the tunnel. Note that the parameters local and remote-netmask are from the perspective of the client, not the server. They may be DNS names rather than IP addresses, in which case they will be resolved on the server at the time of client connection. The optional alias parameter may be used in cases where NAT causes the client view of its local endpoint to differ from the server view. In this case local/remote-netmask will refer to the server view while alias/remote-netmask will refer to the client view. This option must be associated with a specific client instance, which means that it must be specified either in a client instance config file using --client-config-dir or dynamically generated using a --client-connect script. Remember also to include a --route directive in the main OpenVPN config file which encloses local, so that the kernel will know to route it to the server's TUN/TAP interface. OpenVPN's internal client IP address selection algorithm works as follows: 1. Use --client-connect script generated file for static IP (first choice). 2. Use --client-config-dir file for static IP (next choice). 3. Use --ifconfig-pool allocation for dynamic IP (last choice). --ifconfig-ipv6-push args for --client-config-dir per-client static IPv6 interface configuration, see --client-config-dir and --ifconfig-push for more details. Valid syntax: ifconfig-ipv6-push ipv6addr/bits ipv6remote --inetd args Valid syntaxes: inetd inetd wait inetd nowait inetd wait progname Use this option when OpenVPN is being run from the inetd or xinetd(8) server. The wait and nowait option must match what is specified in the inetd/xinetd config file. The nowait mode can only be used with --proto tcp-server The default is wait. The nowait mode can be used to instantiate the OpenVPN daemon as a classic TCP server, where client connection requests are serviced on a single port number. For additional information on this kind of configuration, see the OpenVPN FAQ: https://community.openvpn.net/openvpn/wiki/325-openvpn-as-a--forking-tcp-server-which-can-service-multiple-clients-over-a-single-tcp-port This option precludes the use of --daemon, --local or --remote. Note that this option causes message and error output to be handled in the same way as the --daemon option. The optional progname parameter is also handled exactly as in --daemon. Also note that in wait mode, each OpenVPN tunnel requires a separate TCP/UDP port and a separate inetd or xinetd entry. See the OpenVPN 1.x HOWTO for an example on using OpenVPN with xinetd: https://openvpn.net/community-resources/1xhowto/ --multihome Configure a multi-homed UDP server. This option needs to be used when a server has more than one IP address (e.g. multiple interfaces, or secondary IP addresses), and is not using --lo‐ cal to force binding to one specific address only. This option will add some extra lookups to the packet path to ensure that the UDP reply packets are always sent from the address that the client is talking to. This is not supported on all platforms, and it adds more processing, so it's not enabled by default. Notes: • This option is only relevant for UDP servers. • If you do an IPv6+IPv4 dual-stack bind on a Linux machine with multiple IPv4 address, connections to IPv4 addresses will not work right on kernels before 3.15, due to missing kernel support for the IPv4-mapped case (some distributions have ported this to earlier kernel versions, though). --iroute args Generate an internal route to a specific client. The netmask parameter, if omitted, defaults to 255.255.255.255. Valid syntax: iroute network [netmask] This directive can be used to route a fixed subnet from the server to a particular client, regardless of where the client is connecting from. Remember that you must also add the route to the system routing table as well (such as by using the --route directive). The reason why two routes are needed is that the --route directive routes the packet from the kernel to OpenVPN. Once in OpenVPN, the --iroute directive routes to the specific client. This option must be specified either in a client instance config file using --client-config-dir or dynamically generated using a --client-connect script. The --iroute directive also has an important interaction with --push \u0026quot;route ...\u0026quot;. --iroute essentially defines a subnet which is owned by a particular client (we will call this client A). If you would like other clients to be able to reach A's subnet, you can use --push \u0026quot;route ...\u0026quot; together with --client-to-client to effect this. In order for all clients to see A's subnet, OpenVPN must push this route to all clients EXCEPT for A, since the subnet is already owned by A. OpenVPN accomplishes this by not not pushing a route to a client if it matches one of the client's iroutes. --iroute-ipv6 args for --client-config-dir per-client static IPv6 route configuration, see --iroute for more details how to setup and use this, and how --iroute and --route interact. Valid syntax: iroute-ipv6 ipv6addr/bits --max-clients n Limit server to a maximum of n concurrent clients. --max-routes-per-client n Allow a maximum of n internal routes per client (default 256). This is designed to help contain DoS attacks where an authenticated client floods the server with packets appearing to come from many unique MAC addresses, forcing the server to deplete virtual memory as its internal routing table expands. This directive can be used in a --client-config-dir file or auto-generated by a --client-connect script to override the global value for a particular client. Note that this directive affects OpenVPN's internal routing table, not the kernel routing table. --opt-verify Clients that connect with options that are incompatible with those of the server will be disconnected. Options that will be compared for compatibility include dev-type, link-mtu, tun-mtu, proto, ifconfig, comp-lzo, fragment, keydir, cipher, auth, keysize, secret, no-replay, tls-auth, key-method, tls-server and tls-client. This option requires that --disable-occ NOT be used. --port-share args Share OpenVPN TCP with another service Valid syntax: port-share host port [dir] When run in TCP server mode, share the OpenVPN port with another application, such as an HTTPS server. If OpenVPN senses a connection to its port which is using a non-OpenVPN protocol, it will proxy the connection to the server at host:port. Currently only designed to work with HTTP/HTTPS, though it would be theoretically possible to extend to other protocols such as ssh. dir specifies an optional directory where a temporary file with name N containing content C will be dynamically generated for each proxy connection, where N is the source IP:port of the client connection and C is the source IP:port of the connection to the proxy receiver. This directory can be used as a dictionary by the proxy receiver to determine the origin of the connection. Each generated file will be automatically deleted when the proxied connection is torn down. Not implemented on Windows. --push option Push a config file option back to the client for remote execution. Note that option must be enclosed in double quotes (\u0026quot;\u0026quot;). The client must specify --pull in its config file. The set of options which can be pushed is limited by both feasibility and security. Some options such as those which would execute scripts are banned, since they would effectively allow a compro‐ mised server to execute arbitrary code on the client. Other options such as TLS or MTU parameters cannot be pushed because the client needs to know them before the connection to the server can be initiated. This is a partial list of options which can currently be pushed: --route, --route-gateway, --route-delay, --redirect-gateway, --ip-win32, --dhcp-option, --inactive, --ping, --ping-exit, --ping-restart, --setenv, --auth-token, --persist-key, --persist-tun, --echo, --comp-lzo, --socket-flags, --sndbuf, --rcvbuf --push-remove opt Selectively remove all --push options matching \u0026quot;opt\u0026quot; from the option list for a client. opt is matched as a substring against the whole option string to-be-pushed to the client, so --push-remove route would remove all --push route ... and --push route-ipv6 ... statements, while --push-remove \u0026quot;route-ipv6 2001:\u0026quot; would only remove IPv6 routes for 2001:... networks. --push-remove can only be used in a client-specific context, like in a --client-config-dir file, or --client-connect script or plugin -- similar to --push-reset, just more selective. NOTE: to change an option, --push-remove can be used to first remove the old value, and then add a new --push option with the new value. NOTE 2: due to implementation details, 'ifconfig' and 'ifconfig-ipv6' can only be removed with an exact match on the option ( push-remove ifconfig), no substring matching and no match‐ ing on the IPv4/IPv6 address argument is possible. --push-reset Don't inherit the global push list for a specific client instance. Specify this option in a client-specific context such as with a --client-config-dir configuration file. This option will ignore --push options at the global config file level. NOTE: --push-reset is very thorough: it will remove almost all options from the list of to-be-pushed options. In many cases, some of these options will need to be re-configured after‐ wards - specifically, --topology subnet and --route-gateway will get lost and this will break client configs in many cases. Thus, for most purposes, --push-remove is better suited to selectively remove push options for individual clients. --server args A helper directive designed to simplify the configuration of OpenVPN's server mode. This directive will set up an OpenVPN server which will allocate addresses to clients out of the given network/netmask. The server itself will take the .1 address of the given network for use as the server-side endpoint of the local TUN/TAP interface. If the optional nopool flag is given, no dynamic IP address pool will prepared for VPN clients. Valid syntax: server network netmask [nopool] For example, --server 10.8.0.0 255.255.255.0 expands as follows: mode server tls-server push \u0026quot;topology [topology]\u0026quot; if dev tun AND (topology == net30 OR topology == p2p): ifconfig 10.8.0.1 10.8.0.2 if !nopool: ifconfig-pool 10.8.0.4 10.8.0.251 route 10.8.0.0 255.255.255.0 if client-to-client: push \u0026quot;route 10.8.0.0 255.255.255.0\u0026quot; else if topology == net30: push \u0026quot;route 10.8.0.1\u0026quot; if dev tap OR (dev tun AND topology == subnet): ifconfig 10.8.0.1 255.255.255.0 if !nopool: ifconfig-pool 10.8.0.2 10.8.0.253 255.255.255.0 push \u0026quot;route-gateway 10.8.0.1\u0026quot; if route-gateway unset: route-gateway 10.8.0.2 Don't use --server if you are ethernet bridging. Use --server-bridge instead. --server-bridge args A helper directive similar to --server which is designed to simplify the configuration of OpenVPN's server mode in ethernet bridging configurations. Valid syntaxes: server-bridge gateway netmask pool-start-IP pool-end-IP server-bridge [nogw] If --server-bridge is used without any parameters, it will enable a DHCP-proxy mode, where connecting OpenVPN clients will receive an IP address for their TAP adapter from the DHCP server running on the OpenVPN server-side LAN. Note that only clients that support the binding of a DHCP client with the TAP adapter (such as Windows) can support this mode. The op‐ tional nogw flag (advanced) indicates that gateway information should not be pushed to the client. To configure ethernet bridging, you must first use your OS's bridging capability to bridge the TAP interface with the ethernet NIC interface. For example, on Linux this is done with the brctl tool, and with Windows XP it is done in the Network Connections Panel by selecting the ethernet and TAP adapters and right-clicking on \u0026quot;Bridge Connections\u0026quot;. Next you you must manually set the IP/netmask on the bridge interface. The gateway and netmask parameters to --server-bridge can be set to either the IP/netmask of the bridge inter‐ face, or the IP/netmask of the default gateway/router on the bridged subnet. Finally, set aside a IP range in the bridged subnet, denoted by pool-start-IP and pool-end-IP, for OpenVPN to allocate to connecting clients. For example, server-bridge 10.8.0.4 255.255.255.0 10.8.0.128 10.8.0.254 expands as follows: mode server tls-server ifconfig-pool 10.8.0.128 10.8.0.254 255.255.255.0 push \u0026quot;route-gateway 10.8.0.4\u0026quot; In another example, --server-bridge (without parameters) expands as follows: mode server tls-server push \u0026quot;route-gateway dhcp\u0026quot; Or --server-bridge nogw expands as follows: mode server tls-server --server-ipv6 args Convenience-function to enable a number of IPv6 related options at once, namely --ifconfig-ipv6, --ifconfig-ipv6-pool and --push tun-ipv6. Valid syntax: server-ipv6 ipv6addr/bits Pushing of the --tun-ipv6 directive is done for older clients which require an explicit --tun-ipv6 in their configuration. --stale-routes-check args Remove routes which haven't had activity for n seconds (i.e. the ageing time). This check is run every t seconds (i.e. check interval). Valid syntax: stale-routes-check n [t] If t is not present it defaults to n. This option helps to keep the dynamic routing table small. See also --max-routes-per-client --username-as-common-name Use the authenticated username as the common-name, rather than the common-name from the client certificate. Requires that some form of --auth-user-pass verification is in effect. As the replacement happens after --auth-user-pass verification, the verification script or plugin will still receive the common-name from the certificate. The common_name environment variable passed to scripts and plugins invoked after authentication (e.g, client-connect script) and file names parsed in client-config directory will match the username. --verify-client-cert mode Specify whether the client is required to supply a valid certificate. Possible mode options are: none A client certificate is not required. the client needs to authenticate using username/password only. Be aware that using this directive is less secure than requiring certificates from all clients. If you use this directive, the entire responsibility of authentication will rest on your --auth-user-pass-verify script, so keep in mind that bugs in your script could poten‐ tially compromise the security of your VPN. --verify-client-cert none is functionally equivalent to --client-cert-not-required. optional A client may present a certificate but it is not required to do so. When using this directive, you should also use a --auth-user-pass-verify script to ensure that clients are authenticated using a certificate, a username and password, or possibly even both. Again, the entire responsibility of authentication will rest on your --auth-user-pass-verify script, so keep in mind that bugs in your script could potentially compromise the se‐ curity of your VPN. require This is the default option. A client is required to present a certificate, otherwise VPN access is refused. If you don't use this directive (or use --verify-client-cert require) but you also specify an --auth-user-pass-verify script, then OpenVPN will perform double authentication. The client certificate verification AND the --auth-user-pass-verify script will need to succeed in order for a client to be authenticated and accepted onto the VPN. --vlan-tagging Server-only option. Turns the OpenVPN server instance into a switch that understands VLAN-tagging, based on IEEE 802.1Q. The server TAP device and each of the connecting clients is seen as a port of the switch. All client ports are in untagged mode and the server TAP device is VLAN-tagged, untagged or ac‐ cepts both, depending on the --vlan-accept setting. Ethernet frames with a prepended 802.1Q tag are called \u0026quot;tagged\u0026quot;. If the VLAN Identifier (VID) field in such a tag is non-zero, the frame is called \u0026quot;VLAN-tagged\u0026quot;. If the VID is zero, but the Priority Control Point (PCP) field is non-zero, the frame is called \u0026quot;prio-tagged\u0026quot;. If there is no 802.1Q tag, the frame is \u0026quot;untagged\u0026quot;. Using the --vlan-pvid v option once per client (see --client-config-dir), each port can be associated with a certain VID. Packets can only be forwarded between ports having the same VID. Therefore, clients with differing VIDs are completely separated from one-another, even if --client-to-client is activated. The packet filtering takes place in the OpenVPN server. Clients should not have any VLAN tagging configuration applied. The --vlan-tagging option is off by default. While turned off, OpenVPN accepts any Ethernet frame and does not perform any special processing for VLAN-tagged packets. This option can only be activated in --dev tap mode. --vlan-accept args Configure the VLAN tagging policy for the server TAP device. Valid syntax: vlan-accept all|tagged|untagged The following modes are available: tagged Admit only VLAN-tagged frames. Only VLAN-tagged packets are accepted, while untagged or priority-tagged packets are dropped when entering the server TAP device. untagged Admit only untagged and prio-tagged frames. VLAN-tagged packets are not accepted, while untagged or priority-tagged packets entering the server TAP device are tagged with the value configured for the global --vlan-pvid setting. all (default) Admit all frames. All packets are admitted and then treated like untagged or tagged mode respectively. Note: Some vendors refer to switch ports running in tagged mode as \u0026quot;trunk ports\u0026quot; and switch ports running in untagged mode as \u0026quot;access ports\u0026quot;. Packets forwarded from clients to the server are VLAN-tagged with the originating client's PVID, unless the VID matches the global --vlan-pvid, in which case the tag is removed. If no PVID is configured for a given client (see --vlan-pvid) packets are tagged with 1 by default. --vlan-pvid v Specifies which VLAN identifier a \u0026quot;port\u0026quot; is associated with. Only valid when --vlan-tagging is speficied. In the client context, the setting specifies which VLAN ID a client is associated with. In the global context, the VLAN ID of the server TAP device is set. The latter only makes sense for --vlan-accept untagged and --vlan-accept all modes. Valid values for v go from 1 through to 4094. The global value defaults to 1. If no --vlan-pvid is specified in the client context, the global value is inherited. In some switch implementations, the PVID is also referred to as \u0026quot;Native VLAN\u0026quot;. ENCRYPTION OPTIONS SSL Library information --show-ciphers (Standalone) Show all cipher algorithms to use with the --cipher option. --show-digests (Standalone) Show all message digest algorithms to use with the --auth option. --show-tls (Standalone) Show all TLS ciphers supported by the crypto library. OpenVPN uses TLS to secure the control channel, over which the keys that are used to protect the actual VPN traffic are exchanged. The TLS ciphers will be sorted from highest preference (most secure) to lowest. Be aware that whether a cipher suite in this list can actually work depends on the specific setup of both peers (e.g. both peers must support the cipher, and an ECDSA cipher suite will not work if you are using an RSA certificate, etc.). --show-engines (Standalone) Show currently available hardware-based crypto acceleration engines supported by the OpenSSL library. --show-groups (Standalone) Show all available elliptic curves/groups to use with the --ecdh-curve and tls-groups options. Generating key material --genkey args (Standalone) Generate a key to be used of the type keytype. if keyfile is left out or empty the key will be output on stdout. See the following sections for the different keytypes. Valid syntax: --genkey keytype keyfile Valid keytype arguments are: secret Standard OpenVPN shared secret keys tls-crypt Alias for secret tls-auth Alias for secret auth-token Key used for --auth-gen-token-key tls-crypt-v2-server TLS Crypt v2 server key tls-crypt-v2-client TLS Crypt v2 client key Examples: $ openvpn --genkey secret shared.key $ openvpn --genkey tls-crypt shared.key $ openvpn --genkey tls-auth shared.key $ openvpn --genkey tls-crypt-v2-server v2crypt-server.key $ openvpn --tls-crypt-v2 v2crypt-server.key --genkey tls-crypt-v2-client v2crypt-client-1.key • Generating Shared Secret Keys Generate a shared secret, for use with the --secret, --tls-auth or --tls-crypt options. Syntax: $ openvpn --genkey secret|tls-crypt|tls-auth keyfile The key is saved in keyfile. All three variants (--secret, tls-crypt and tls-auth) generate the same type of key. The aliases are added for convenience. If using this for --secret, this file must be shared with the peer over a pre-existing secure channel such as scp(1). • Generating TLS Crypt v2 Server key Generate a --tls-crypt-v2 key to be used by an OpenVPN server. The key is stored in keyfile. Syntax: --genkey tls-crypt-v2-server keyfile • Generating TLS Crypt v2 Client key Generate a --tls-crypt-v2 key to be used by OpenVPN clients. The key is stored in keyfile. Syntax --genkey tls-crypt-v2-client keyfile [metadata] If supplied, include the supplied metadata in the wrapped client key. This metadata must be supplied in base64-encoded form. The metadata must be at most 735 bytes long (980 bytes in base64). If no metadata is supplied, OpenVPN will use a 64-bit unix timestamp representing the current time in UTC, encoded in network order, as metadata for the generated key. A tls-crypt-v2 client key is wrapped using a server key. To generate a client key, the user must therefore supply the server key using the --tls-crypt-v2 option. Servers can use --tls-crypt-v2-verify to specify a metadata verification command. • Generate Authentication Token key Generate a new secret that can be used with --auth-gen-token-secret Syntax: --genkey auth-token [keyfile] Note: This file should be kept secret to the server as anyone that has access to this file will be able to generate auth tokens that the OpenVPN server will accept as valid. Data Channel Renegotiation When running OpenVPN in client/server mode, the data channel will use a separate ephemeral encryption key which is rotated at regular intervals. --reneg-bytes n Renegotiate data channel key after n bytes sent or received (disabled by default with an exception, see below). OpenVPN allows the lifetime of a key to be expressed as a number of bytes encrypted/decrypted, a number of packets, or a number of seconds. A key renegotiation will be forced if any of these three criteria are met by either peer. If using ciphers with cipher block sizes less than 128-bits, --reneg-bytes is set to 64MB by default, unless it is explicitly disabled by setting the value to 0, but this is HIGHLY DIS‐ COURAGED as this is designed to add some protection against the SWEET32 attack vector. For more information see the --cipher option. --reneg-pkts n Renegotiate data channel key after n packets sent and received (disabled by default). --reneg-sec args Renegotiate data channel key after at most max seconds (default 3600) and at least min seconds (default is 90% of max for servers, and equal to max for clients). reneg-sec max [min] The effective --reneg-sec value used is per session pseudo-uniform-randomized between min and max. With the default value of 3600 this results in an effective per session value in the range of 3240 .. 3600 seconds for servers, or just 3600 for clients. When using dual-factor authentication, note that this default value may cause the end user to be challenged to reauthorize once per hour. Also, keep in mind that this option can be used on both the client and server, and whichever uses the lower value will be the one to trigger the renegotiation. A common mistake is to set --reneg-sec to a higher value on either the client or server, while the other side of the connection is still using the default value of 3600 seconds, meaning that the renegotiation will still occur once per 3600 seconds. The solution is to increase --reneg-sec on both the client and server, or set it to 0 on one side of the connection (to disable), and to your chosen value on the other side. TLS Mode Options TLS mode is the most powerful crypto mode of OpenVPN in both security and flexibility. TLS mode works by establishing control and data channels which are multiplexed over a single TCP/UDP port. OpenVPN initiates a TLS session over the control channel and uses it to exchange cipher and HMAC keys to protect the data channel. TLS mode uses a robust reliability layer over the UDP connection for all control channel communication, while the data channel, over which encrypted tunnel data passes, is forwarded without any mediation. The result is the best of both worlds: a fast data channel that forwards over UDP with only the overhead of encrypt, decrypt, and HMAC functions, and a control channel that provides all of the security features of TLS, including cer‐ tificate-based authentication and Diffie Hellman forward secrecy. To use TLS mode, each peer that runs OpenVPN should have its own local certificate/key pair (--cert and --key), signed by the root certificate which is specified in --ca. When two OpenVPN peers connect, each presents its local certificate to the other. Each peer will then check that its partner peer presented a certificate which was signed by the master root certificate as specified in --ca. If that check on both peers succeeds, then the TLS negotiation will succeed, both OpenVPN peers will exchange temporary session keys, and the tunnel will begin passing data. The OpenVPN project provides a set of scripts for managing RSA certificates and keys: https://github.com/OpenVPN/easy-rsa --askpass file Get certificate password from console or file before we daemonize. Valid syntaxes: askpass askpass file For the extremely security conscious, it is possible to protect your private key with a password. Of course this means that every time the OpenVPN daemon is started you must be there to type the password. The --askpass option allows you to start OpenVPN from the command line. It will query you for a password before it daemonizes. To protect a private key with a pass‐ word you should omit the -nodes option when you use the openssl command line tool to manage certificates and private keys. If file is specified, read the password from the first line of file. Keep in mind that storing your password in a file to a certain extent invalidates the extra security provided by us‐ ing an encrypted key. --ca file Certificate authority (CA) file in .pem format, also referred to as the root certificate. This file can have multiple certificates in .pem format, concatenated together. You can con‐ struct your own certificate authority certificate and private key by using a command such as: openssl req -nodes -new -x509 -keyout ca.key -out ca.crt Then edit your openssl.cnf file and edit the certificate variable to point to your new root certificate ca.crt. For testing purposes only, the OpenVPN distribution includes a sample CA certificate (ca.crt). Of course you should never use the test certificates and test keys distributed with Open‐ VPN in a production environment, since by virtue of the fact that they are distributed with OpenVPN, they are totally insecure. --capath dir Directory containing trusted certificates (CAs and CRLs). Not available with mbed TLS. CAs in the capath directory are expected to be named \u0026lt;hash\u0026gt;.\u0026lt;n\u0026gt;. CRLs are expected to be named \u0026lt;hash\u0026gt;.r\u0026lt;n\u0026gt;. See the -CApath option of openssl verify, and the -hash option of openssl x509, openssl crl and X509_LOOKUP_hash_dir()(3) for more information. Similar to the --crl-verify option, CRLs are not mandatory - OpenVPN will log the usual warning in the logs if the relevant CRL is missing, but the connection will be allowed. --cert file Local peer's signed certificate in .pem format -- must be signed by a certificate authority whose certificate is in --ca file. Each peer in an OpenVPN link running in TLS mode should have its own certificate and private key file. In addition, each certificate should have been signed by the key of a certificate authority whose public key resides in the --ca certifi‐ cate authority file. You can easily make your own certificate authority (see above) or pay money to use a commercial service such as thawte.com (in which case you will be helping to fi‐ nance the world's second space tourist :). To generate a certificate, you can use a command such as: openssl req -nodes -new -keyout mycert.key -out mycert.csr If your certificate authority private key lives on another machine, copy the certificate signing request (mycert.csr) to this other machine (this can be done over an insecure channel such as email). Now sign the certificate with a command such as: openssl ca -out mycert.crt -in mycert.csr Now copy the certificate (mycert.crt) back to the peer which initially generated the .csr file (this can be over a public medium). Note that the openssl ca command reads the location of the certificate authority key from its configuration file such as /usr/share/ssl/openssl.cnf -- note also that for certificate authority functions, you must set up the files index.txt (may be empty) and serial (initialize to 01). --crl-verify args Check peer certificate against a Certificate Revocation List. Valid syntax: crl-verify file/directory flag Examples: crl-verify crl-file.pem crl-verify /etc/openvpn/crls dir A CRL (certificate revocation list) is used when a particular key is compromised but when the overall PKI is still intact. Suppose you had a PKI consisting of a CA, root certificate, and a number of client certificates. Suppose a laptop computer containing a client key and certificate was stolen. By adding the stolen certificate to the CRL file, you could reject any connection which attempts to use it, while preserving the overall integrity of the PKI. The only time when it would be necessary to rebuild the entire PKI from scratch would be if the root certificate key itself was compromised. The option is not mandatory - if the relevant CRL is missing, OpenVPN will log a warning in the logs - e.g. VERIFY WARNING: depth=0, unable to get certificate CRL but the connection will be allowed. If the optional dir flag is specified, enable a different mode where the crl-verify is pointed at a directory containing files named as revoked se‐ rial numbers (the files may be empty, the contents are never read). If a client requests a connection, where the client certificate serial number (decimal string) is the name of a file present in the directory, it will be rejected. Note: As the crl file (or directory) is read every time a peer connects, if you are dropping root privileges with --user, make sure that this user has sufficient privileges to read the file. --dh file File containing Diffie Hellman parameters in .pem format (required for --tls-server only). Set file to none to disable Diffie Hellman key exchange (and use ECDH only). Note that this requires peers to be using an SSL library that supports ECDH TLS cipher suites (e.g. OpenSSL 1.0.1+, or mbed TLS 2.0+). Use openssl dhparam -out dh2048.pem 2048 to generate 2048-bit DH parameters. Diffie Hellman parameters may be considered public. --ecdh-curve name Specify the curve to use for elliptic curve Diffie Hellman. Available curves can be listed with --show-curves. The specified curve will only be used for ECDH TLS-ciphers. This option is not supported in mbed TLS builds of OpenVPN. --extra-certs file Specify a file containing one or more PEM certs (concatenated together) that complete the local certificate chain. This option is useful for \u0026quot;split\u0026quot; CAs, where the CA for server certs is different than the CA for client certs. Putting certs in this file allows them to be used to complete the local certificate chain without trusting them to verify the peer-submitted certificate, as would be the case if the certs were placed in the ca file. --hand-window n Handshake Window -- the TLS-based key exchange must finalize within n seconds of handshake initiation by any peer (default 60 seconds). If the handshake fails we will attempt to reset our connection with our peer and try again. Even in the event of handshake failure we will still use our expiring key for up to --tran-window seconds to maintain continuity of transmis‐ sion of tunnel data. --key file Local peer's private key in .pem format. Use the private key which was generated when you built your peer's certificate (see --cert file above). --pkcs12 file Specify a PKCS #12 file containing local private key, local certificate, and root CA certificate. This option can be used instead of --ca, --cert, and --key. Not available with mbed TLS. --remote-cert-eku oid Require that peer certificate was signed with an explicit extended key usage. This is a useful security option for clients, to ensure that the host they connect to is a designated server. The extended key usage should be encoded in oid notation, or OpenSSL symbolic representation. --remote-cert-ku key-usage Require that peer certificate was signed with an explicit key-usage. If present in the certificate, the keyUsage value is validated by the TLS library during the TLS handshake. Specifying this option without arguments requires this extension to be present (so the TLS library will verify it). If key-usage is a list of usage bits, the keyUsage field must have at least the same bits set as the bits in one of the values supplied in the key-usage list. The key-usage values in the list must be encoded in hex, e.g. remote-cert-ku a0 --remote-cert-tls type Require that peer certificate was signed with an explicit key usage and extended key usage based on RFC3280 TLS rules. Valid syntaxes: remote-cert-tls server remote-cert-tls client This is a useful security option for clients, to ensure that the host they connect to is a designated server. Or the other way around; for a server to verify that only hosts with a client certificate can connect. The --remote-cert-tls client option is equivalent to remote-cert-ku remote-cert-eku \u0026quot;TLS Web Client Authentication\u0026quot; The --remote-cert-tls server option is equivalent to remote-cert-ku remote-cert-eku \u0026quot;TLS Web Server Authentication\u0026quot; This is an important security precaution to protect against a man-in-the-middle attack where an authorized client attempts to connect to another client by impersonating the server. The attack is easily prevented by having clients verify the server certificate using any one of --remote-cert-tls, --verify-x509-name, or --tls-verify. --tls-auth args Add an additional layer of HMAC authentication on top of the TLS control channel to mitigate DoS attacks and attacks on the TLS stack. Valid syntaxes: tls-auth file tls-auth file 0 tls-auth file 1 In a nutshell, --tls-auth enables a kind of \u0026quot;HMAC firewall\u0026quot; on OpenVPN's TCP/UDP port, where TLS control channel packets bearing an incorrect HMAC signature can be dropped immediately without response. file (required) is a file in OpenVPN static key format which can be generated by --genkey. Older versions (up to OpenVPN 2.3) supported a freeform passphrase file. This is no longer supported in newer versions (v2.4+). See the --secret option for more information on the optional direction parameter. --tls-auth is recommended when you are running OpenVPN in a mode where it is listening for packets from any IP address, such as when --remote is not specified, or --remote is specified with --float. The rationale for this feature is as follows. TLS requires a multi-packet exchange before it is able to authenticate a peer. During this time before authentication, OpenVPN is allocat‐ ing resources (memory and CPU) to this potential peer. The potential peer is also exposing many parts of OpenVPN and the OpenSSL library to the packets it is sending. Most successful network attacks today seek to either exploit bugs in programs (such as buffer overflow attacks) or force a program to consume so many resources that it becomes unusable. Of course the first line of defense is always to produce clean, well-audited code. OpenVPN has been written with buffer overflow attack prevention as a top priority. But as history has shown, many of the most widely used network applications have, from time to time, fallen to buffer overflow attacks. So as a second line of defense, OpenVPN offers this special layer of authentication on top of the TLS control channel so that every packet on the control channel is authenticated by an HMAC signature and a unique ID for replay protection. This signature will also help protect against DoS (Denial of Service) attacks. An important rule of thumb in reducing vulnerability to DoS attacks is to minimize the amount of resources a potential, but as yet unauthenticated, client is able to consume. --tls-auth does this by signing every TLS control channel packet with an HMAC signature, including packets which are sent before the TLS level has had a chance to authenticate the peer. The result is that packets without the correct signature can be dropped immediately upon reception, before they have a chance to consume additional system resources such as by initiat‐ ing a TLS handshake. --tls-auth can be strengthened by adding the --replay-persist option which will keep OpenVPN's replay protection state in a file so that it is not lost across restarts. It should be emphasized that this feature is optional and that the key file used with --tls-auth gives a peer nothing more than the power to initiate a TLS handshake. It is not used to encrypt or authenticate any tunnel data. Use --tls-crypt instead if you want to use the key file to not only authenticate, but also encrypt the TLS control channel. --tls-groups list A list of allowable groups/curves in order of preference. Set the allowed elliptic curves/groups for the TLS session. These groups are allowed to be used in signatures and key exchange. mbedTLS currently allows all known curves per default. OpenSSL 1.1+ restricts the list per default to \u0026quot;X25519:secp256r1:X448:secp521r1:secp384r1\u0026quot;. If you use certificates that use non-standard curves, you might need to add them here. If you do not force the ecdh curve by using --ecdh-curve, the groups for ecdh will also be picked from this list. OpenVPN maps the curve name secp256r1 to prime256v1 to allow specifying the same tls-groups option for mbedTLS and OpenSSL. Warning: this option not only affects elliptic curve certificates but also the key exchange in TLS 1.3 and using this option improperly will disable TLS 1.3. --tls-cert-profile profile Set the allowed cryptographic algorithms for certificates according to profile. The following profiles are supported: insecure Identical for mbed TLS to legacy legacy (default) SHA1 and newer, RSA 2048-bit+, any elliptic curve. preferred SHA2 and newer, RSA 2048-bit+, any elliptic curve. suiteb SHA256/SHA384, ECDSA with P-256 or P-384. This option is only fully supported for mbed TLS builds. OpenSSL builds use the following approximation: insecure sets \u0026quot;security level 0\u0026quot; legacy (default) sets \u0026quot;security level 1\u0026quot; preferred sets \u0026quot;security level 2\u0026quot; suiteb sets \u0026quot;security level 3\u0026quot; and --tls-cipher \u0026quot;SUITEB128\u0026quot;. OpenVPN will migrate to 'preferred' as default in the future. Please ensure that your keys already comply. WARNING: --tls-ciphers, --tls-ciphersuites and tls-groups These options are expert features, which - if used correctly - can improve the security of your VPN connection. But it is also easy to unwittingly use them to carefully align a gun with your foot, or just break your connection. Use with care! --tls-cipher l A list l of allowable TLS ciphers delimited by a colon (\u0026quot;:\u0026quot;). These setting can be used to ensure that certain cipher suites are used (or not used) for the TLS connection. OpenVPN uses TLS to secure the control channel, over which the keys that are used to protect the actual VPN traffic are exchanged. The supplied list of ciphers is (after potential OpenSSL/IANA name translation) simply supplied to the crypto library. Please see the OpenSSL and/or mbed TLS documentation for details on the cipher list interpretation. For OpenSSL, the --tls-cipher is used for TLS 1.2 and below. Use --show-tls to see a list of TLS ciphers supported by your crypto library. The default for --tls-cipher is to use mbed TLS's default cipher list when using mbed TLS or DEFAULT:!EXP:!LOW:!MEDIUM:!kDH:!kECDH:!DSS:!PSK:!SRP:!kRSA when using OpenSSL. --tls-ciphersuites l Same as --tls-cipher but for TLS 1.3 and up. mbed TLS has no TLS 1.3 support yet and only the --tls-cipher setting is used. The default for --tls-ciphersuites is to use the crypto library's default. --tls-client Enable TLS and assume client role during TLS handshake. --tls-crypt keyfile Encrypt and authenticate all control channel packets with the key from keyfile. (See --tls-auth for more background.) Encrypting (and authenticating) control channel packets: • provides more privacy by hiding the certificate used for the TLS connection, • makes it harder to identify OpenVPN traffic as such, • provides \u0026quot;poor-man's\u0026quot; post-quantum security, against attackers who will never know the pre-shared key (i.e. no forward secrecy). In contrast to --tls-auth, --tls-crypt does not require the user to set --key-direction. Security Considerations All peers use the same --tls-crypt pre-shared group key to authenticate and encrypt control channel messages. To ensure that IV collisions remain unlikely, this key should not be used to encrypt more than 2^48 client-to-server or 2^48 server-to-client control channel messages. A typical initial negotiation is about 10 packets in each direction. Assuming both initial negotiation and renegotiations are at most 2^16 (65536) packets (to be conservative), and (re)negotiations happen each minute for each user (24/7), this limits the tls-crypt key life‐ time to 8171 years divided by the number of users. So a setup with 1000 users should rotate the key at least once each eight years. (And a setup with 8000 users each year.) If IV collisions were to occur, this could result in the security of --tls-crypt degrading to the same security as using --tls-auth. That is, the control channel still benefits from the extra protection against active man-in-the-middle-attacks and DoS attacks, but may no longer offer extra privacy and post-quantum security on top of what TLS itself offers. For large setups or setups where clients are not trusted, consider using --tls-crypt-v2 instead. That uses per-client unique keys, and thereby improves the bounds to 'rotate a client key at least once per 8000 years'. --tls-crypt-v2 keyfile Use client-specific tls-crypt keys. For clients, keyfile is a client-specific tls-crypt key. Such a key can be generated using the --genkey tls-crypt-v2-client option. For servers, keyfile is used to unwrap client-specific keys supplied by the client during connection setup. This key must be the same as the key used to generate the client-specific key (see --genkey tls-crypt-v2-client). On servers, this option can be used together with the --tls-auth or --tls-crypt option. In that case, the server will detect whether the client is using client-specific keys, and auto‐ matically select the right mode. --tls-crypt-v2-verify cmd Run command cmd to verify the metadata of the client-specific tls-crypt-v2 key of a connecting client. This allows server administrators to reject client connections, before exposing the TLS stack (including the notoriously dangerous X.509 and ASN.1 stacks) to the connecting client. OpenVPN supplies the following environment variables to the command: • script_type is set to tls-crypt-v2-verify • metadata_type is set to 0 if the metadata was user supplied, or 1 if it's a 64-bit unix timestamp representing the key creation time. • metadata_file contains the filename of a temporary file that contains the client metadata. The command can reject the connection by exiting with a non-zero exit code. --tls-exit Exit on TLS negotiation failure. --tls-export-cert directory Store the certificates the clients use upon connection to this directory. This will be done before --tls-verify is called. The certificates will use a temporary name and will be deleted when the tls-verify script returns. The file name used for the certificate is available via the peer_cert environment variable. --tls-server Enable TLS and assume server role during TLS handshake. Note that OpenVPN is designed as a peer-to-peer application. The designation of client or server is only for the purpose of nego‐ tiating the TLS control channel. --tls-timeout n Packet retransmit timeout on TLS control channel if no acknowledgment from remote within n seconds (default 2). When OpenVPN sends a control packet to its peer, it will expect to re‐ ceive an acknowledgement within n seconds or it will retransmit the packet, subject to a TCP-like exponential backoff algorithm. This parameter only applies to control channel packets. Data channel packets (which carry encrypted tunnel data) are never acknowledged, sequenced, or retransmitted by OpenVPN because the higher level network protocols running on top of the tunnel such as TCP expect this role to be left to them. --tls-version-min args Sets the minimum TLS version we will accept from the peer (default is \u0026quot;1.0\u0026quot;). Valid syntax: tls-version-min version ['or-highest'] Examples for version include 1.0, 1.1, or 1.2. If or-highest is specified and version is not recognized, we will only accept the highest TLS version supported by the local SSL implemen‐ tation. --tls-version-max version Set the maximum TLS version we will use (default is the highest version supported). Examples for version include 1.0, 1.1, or 1.2. --verify-hash args Specify SHA1 or SHA256 fingerprint for level-1 cert. Valid syntax: verify-hash hash [algo] The level-1 cert is the CA (or intermediate cert) that signs the leaf certificate, and is one removed from the leaf certificate in the direction of the root. When accepting a connection from a peer, the level-1 cert fingerprint must match hash or certificate verification will fail. Hash is specified as XX:XX:... For example: AD:B0:95:D8:09:C8:36:45:12:A9:89:C8:90:09:CB:13:72:A6:AD:16 The algo flag can be either SHA1 or SHA256. If not provided, it defaults to SHA1. --verify-x509-name args Accept connections only if a host's X.509 name is equal to name. The remote host must also pass all other tests of verification. Valid syntax: verify-x509 name type Which X.509 name is compared to name depends on the setting of type. type can be subject to match the complete subject DN (default), name to match a subject RDN or name-prefix to match a subject RDN prefix. Which RDN is verified as name depends on the --x509-username-field option. But it defaults to the common name (CN), e.g. a certificate with a subject DN C=KG, ST=NA, L=Bishkek, CN=Server-1 would be matched by: verify-x509-name 'C=KG, ST=NA, L=Bishkek, CN=Server-1' verify-x509-name Server-1 name verify-x509-name Server- name-prefix The last example is useful if you want a client to only accept connections to Server-1, Server-2, etc. --verify-x509-name is a useful replacement for the --tls-verify option to verify the remote host, because --verify-x509-name works in a --chroot environment without any dependencies. Using a name prefix is a useful alternative to managing a CRL (Certificate Revocation List) on the client, since it allows the client to refuse all certificates except for those associ‐ ated with designated servers. NOTE: Test against a name prefix only when you are using OpenVPN with a custom CA certificate that is under your control. Never use this option with type name-prefix when your client certificates are signed by a third party, such as a commercial web CA. --x509-track attribute Save peer X509 attribute value in environment for use by plugins and management interface. Prepend a + to attribute to save values from full cert chain. Values will be encoded as X509_\u0026lt;depth\u0026gt;_\u0026lt;attribute\u0026gt;=\u0026lt;value\u0026gt;. Multiple --x509-track options can be defined to track multiple attributes. --x509-username-field args Field in the X.509 certificate subject to be used as the username (default CN). Valid syntax: x509-username-field [ext:]fieldname Typically, this option is specified with fieldname as either of the following: x509-username-field emailAddress x509-username-field ext:subjectAltName The first example uses the value of the emailAddress attribute in the certificate's Subject field as the username. The second example uses the ext: prefix to signify that the X.509 ex‐ tension fieldname subjectAltName be searched for an rfc822Name (email) field to be used as the username. In cases where there are multiple email addresses in ext:fieldname, the last oc‐ currence is chosen. When this option is used, the --verify-x509-name option will match against the chosen fieldname instead of the Common Name. Only the subjectAltName and issuerAltName X.509 extensions are supported. Please note: This option has a feature which will convert an all-lowercase fieldname to uppercase characters, e.g., ou -\u0026gt; OU. A mixed-case fieldname or one having the ext: prefix will be left as-is. This automatic upcasing feature is deprecated and will be removed in a future release. PKCS#11 / SmartCard options --pkcs11-cert-private args Set if access to certificate object should be performed after login. Every provider has its own setting. Valid syntaxes: pkcs11-cert-private 0 pkcs11-cert-private 1 --pkcs11-id name Specify the serialized certificate id to be used. The id can be gotten by the standalone --show-pkcs11-ids option. --pkcs11-id-management Acquire PKCS#11 id from management interface. In this case a NEED-STR 'pkcs11-id-request' real-time message will be triggered, application may use pkcs11-id-count command to retrieve available number of certificates, and pkcs11-id-get command to retrieve certificate id and certificate body. --pkcs11-pin-cache seconds Specify how many seconds the PIN can be cached, the default is until the token is removed. --pkcs11-private-mode mode Specify which method to use in order to perform private key operations. A different mode can be specified for each provider. Mode is encoded as hex number, and can be a mask one of the following: 0 (default) Try to determine automatically. 1 Use sign. 2 Use sign recover. 4 Use decrypt. 8 Use unwrap. --pkcs11-protected-authentication args Use PKCS#11 protected authentication path, useful for biometric and external keypad devices. Every provider has its own setting. Valid syntaxes: pkcs11-protected-authentication 0 pkcs11-protected-authentication 1 --pkcs11-providers provider Specify an RSA Security Inc. PKCS #11 Cryptographic Token Interface (Cryptoki) providers to load. This option can be used instead of --cert, --key and --pkcs12. If p11-kit is present on the system, its p11-kit-proxy.so module will be loaded by default if either the --pkcs11-id or --pkcs11-id-management options are specified without --pkcs11-provider being given. --show-pkcs11-ids args (Standalone) Show PKCS#11 token object list. Valid syntax: show-pkcs11 [provider] [cert_private] Specify cert_private as 1 if certificates are stored as private objects. If p11-kit is present on the system, the provider argument is optional; if omitted the default p11-kit-proxy.so module will be queried. --verb option can be used BEFORE this option to produce debugging information. DATA CHANNEL CIPHER NEGOTIATION OpenVPN 2.4 and higher have the capability to negotiate the data cipher that is used to encrypt data packets. This section describes the mechanism in more detail and the different backwards compatibility mechanism with older server and clients. OpenVPN 2.5 and higher behaviour When both client and server are at least running OpenVPN 2.5, that the order of the ciphers of the server's --data-ciphers is used to pick the the data cipher. That means that the first ci‐ pher in that list that is also in the client's --data-ciphers list is chosen. If no common cipher is found the client is rejected with a AUTH_FAILED message (as seen in client log): AUTH: Received control message: AUTH_FAILED,Data channel cipher negotiation failed (no shared cipher) OpenVPN 2.5 will only allow the ciphers specified in --data-ciphers. To ensure backwards compatibility also if a cipher is specified using the --cipher option it is automatically added to this list. If both options are unset the default is AES-256-GCM:AES-128-GCM. OpenVPN 2.4 clients The negotiation support in OpenVPN 2.4 was the first iteration of the implementation and still had some quirks. Its main goal was \u0026quot;upgrade to AES-256-GCM when possible\u0026quot;. An OpenVPN 2.4 client that is built against a crypto library that supports AES in GCM mode and does not have --ncp-disable will always announce support for AES-256-GCM and AES-128-GCM to a server by sending IV_NCP=2. This only causes a problem if --ncp-ciphers option has been changed from the default of AES-256-GCM:AES-128-GCM to a value that does not include these two ciphers. When a OpenVPN servers try to use AES-256-GCM or AES-128-GCM the connection will then fail. It is therefore recommended to always have the AES-256-GCM and AES-128-GCM ciphers to the --ncp-ciphers options to avoid this behaviour. OpenVPN 3 clients Clients based on the OpenVPN 3.x library (https://github.com/openvpn/openvpn3/) do not have a configurable --ncp-ciphers or --data-ciphers option. Instead these clients will announce support for all their supported AEAD ciphers (AES-256-GCM, AES-128-GCM and in newer versions also Chacha20-Poly1305). To support OpenVPN 3.x based clients at least one of these ciphers needs to be included in the server's --data-ciphers option. OpenVPN 2.3 and older clients (and clients with --ncp-disable) When a client without cipher negotiation support connects to a server the cipher specified with the --cipher option in the client configuration must be included in the --data-ciphers option of the server to allow the client to connect. Otherwise the client will be sent the AUTH_FAILED message that indicates no shared cipher. If the client is 2.3 or older and has been configured with the --enable-small ./configure argument, using data-ciphers-fallback cipher in the server config file with the explicit cipher used by the client is necessary. OpenVPN 2.4 server When a client indicates support for AES-128-GCM and AES-256-GCM (with IV_NCP=2) an OpenVPN 2.4 server will send the first cipher of the --ncp-ciphers to the OpenVPN client regardless of what the cipher is. To emulate the behaviour of an OpenVPN 2.4 client as close as possible and have compatibility to a setup that depends on this quirk, adding AES-128-GCM and AES-256-GCM to the client's --data-ciphers option is required. OpenVPN 2.5+ will only announce the IV_NCP=2 flag if those ciphers are present. OpenVPN 2.3 and older servers (and servers with --ncp-disable) The cipher used by the server must be included in --data-ciphers to allow the client connecting to a server without cipher negotiation support. (For compatibility OpenVPN 2.5 will also accept the cipher set with --cipher) If the server is 2.3 or older and has been configured with the --enable-small ./configure argument, adding data-ciphers-fallback cipher to the client config with the explicit cipher used by the server is necessary. Blowfish in CBC mode (BF-CBC) deprecation The --cipher option defaulted to BF-CBC in OpenVPN 2.4 and older version. The default was never changed to ensure backwards compatibility. In OpenVPN 2.5 this behaviour has now been changed so that if the --cipher is not explicitly set it does not allow the weak BF-CBC cipher any more and needs to explicitly added as --cipher BFC-CBC or added to --data-ciphers. We strongly recommend to switching away from BF-CBC to a more secure cipher as soon as possible instead. NETWORK CONFIGURATION OpenVPN consists of two sides of network configuration. One side is the link between the local and remote side, the other side is the virtual network adapter (tun/tap device). Link Options This link options section covers options related to the connection between the local and the remote host. --bind keywords Bind to local address and port. This is the default unless any of --proto tcp-client , --http-proxy or --socks-proxy are used. If the optional ipv6only keyword is present OpenVPN will bind only to IPv6 (as opposed to IPv6 and IPv4) when a IPv6 socket is opened. --float Allow remote peer to change its IP address and/or port number, such as due to DHCP (this is the default if --remote is not used). --float when specified with --remote allows an OpenVPN session to initially connect to a peer at a known address, however if packets arrive from a new address and pass all authentication tests, the new address will take control of the ses‐ sion. This is useful when you are connecting to a peer which holds a dynamic address such as a dial-in user or DHCP client. Essentially, --float tells OpenVPN to accept authenticated packets from any address, not only the address which was specified in the --remote option. --fragment max Enable internal datagram fragmentation so that no UDP datagrams are sent which are larger than max bytes. The max parameter is interpreted in the same way as the --link-mtu parameter, i.e. the UDP packet size after encapsulation overhead has been added in, but not including the UDP header itself. The --fragment option only makes sense when you are using the UDP protocol (--proto udp). --fragment adds 4 bytes of overhead per datagram. See the --mssfix option below for an important related option to --fragment. It should also be noted that this option is not meant to replace UDP fragmentation at the IP stack level. It is only meant as a last resort when path MTU discovery is broken. Using this option is less efficient than fixing path MTU discovery for your IP link and using native IP fragmentation instead. Having said that, there are circumstances where using OpenVPN's internal fragmentation capability may be your only option, such as tunneling a UDP multicast stream which requires frag‐ mentation. --keepalive args A helper directive designed to simplify the expression of --ping and --ping-restart. Valid syntax: keepalive interval timeout This option can be used on both client and server side, but it is enough to add this on the server side as it will push appropriate --ping and --ping-restart options to the client. If used on both server and client, the values pushed from server will override the client local values. The timeout argument will be twice as long on the server side. This ensures that a timeout is detected on client side before the server side drops the connection. For example, --keepalive 10 60 expands as follows: if mode server: ping 10 # Argument: interval ping-restart 120 # Argument: timeout*2 push \u0026quot;ping 10\u0026quot; # Argument: interval push \u0026quot;ping-restart 60\u0026quot; # Argument: timeout else ping 10 # Argument: interval ping-restart 60 # Argument: timeout --link-mtu n Sets an upper bound on the size of UDP packets which are sent between OpenVPN peers. It's best not to set this parameter unless you know what you're doing. --local host Local host name or IP address for bind. If specified, OpenVPN will bind to this address only. If unspecified, OpenVPN will bind to all interfaces. --lport port Set local TCP/UDP port number or name. Cannot be used together with --nobind option. --mark value Mark encrypted packets being sent with value. The mark value can be matched in policy routing and packetfilter rules. This option is only supported in Linux and does nothing on other operating systems. --mode m Set OpenVPN major mode. By default, OpenVPN runs in point-to-point mode (p2p). OpenVPN 2.0 introduces a new mode (server) which implements a multi-client server capability. --mssfix max Announce to TCP sessions running over the tunnel that they should limit their send packet sizes such that after OpenVPN has encapsulated them, the resulting UDP packet size that OpenVPN sends to its peer will not exceed max bytes. The default value is 1450. The max parameter is interpreted in the same way as the --link-mtu parameter, i.e. the UDP packet size after encapsulation overhead has been added in, but not including the UDP header itself. Resulting packet would be at most 28 bytes larger for IPv4 and 48 bytes for IPv6 (20/40 bytes for IP header and 8 bytes for UDP header). Default value of 1450 allows IPv4 pack‐ ets to be transmitted over a link with MTU 1473 or higher without IP level fragmentation. The --mssfix option only makes sense when you are using the UDP protocol for OpenVPN peer-to-peer communication, i.e. --proto udp. --mssfix and --fragment can be ideally used together, where --mssfix will try to keep TCP from needing packet fragmentation in the first place, and if big packets come through anyhow (from protocols other than TCP), --fragment will internally fragment them. Both --fragment and --mssfix are designed to work around cases where Path MTU discovery is broken on the network path between OpenVPN peers. The usual symptom of such a breakdown is an OpenVPN connection which successfully starts, but then stalls during active usage. If --fragment and --mssfix are used together, --mssfix will take its default max parameter from the --fragment max option. Therefore, one could lower the maximum UDP packet size to 1300 (a good first try for solving MTU-related connection problems) with the following options: --tun-mtu 1500 --fragment 1300 --mssfix --mtu-disc type Should we do Path MTU discovery on TCP/UDP channel? Only supported on OSes such as Linux that supports the necessary system call to set. Valid types: no Never send DF (Don't Fragment) frames maybe Use per-route hints yes Always DF (Don't Fragment) --mtu-test To empirically measure MTU on connection startup, add the --mtu-test option to your configuration. OpenVPN will send ping packets of various sizes to the remote peer and measure the largest packets which were successfully received. The --mtu-test process normally takes about 3 minutes to complete. --nobind Do not bind to local address and port. The IP stack will allocate a dynamic port for returning packets. Since the value of the dynamic port could not be known in advance by a peer, this option is only suitable for peers which will be initiating connections by using the --remote option. --passtos Set the TOS field of the tunnel packet to what the payload's TOS is. --ping n Ping remote over the TCP/UDP control channel if no packets have been sent for at least n seconds (specify --ping on both peers to cause ping packets to be sent in both directions since OpenVPN ping packets are not echoed like IP ping packets). When used in one of OpenVPN's secure modes (where --secret, --tls-server or --tls-client is specified), the ping packet will be cryptographically secure. This option has two intended uses: 1. Compatibility with stateful firewalls. The periodic ping will ensure that a stateful firewall rule which allows OpenVPN UDP packets to pass will not time out. 2. To provide a basis for the remote to test the existence of its peer using the --ping-exit option. --ping-exit n Causes OpenVPN to exit after n seconds pass without reception of a ping or other packet from remote. This option can be combined with --inactive, --ping and --ping-exit to create a two-tiered inactivity disconnect. For example, openvpn [options...] --inactive 3600 --ping 10 --ping-exit 60 when used on both peers will cause OpenVPN to exit within 60 seconds if its peer disconnects, but will exit after one hour if no actual tunnel data is exchanged. --ping-restart n Similar to --ping-exit, but trigger a SIGUSR1 restart after n seconds pass without reception of a ping or other packet from remote. This option is useful in cases where the remote peer has a dynamic IP address and a low-TTL DNS name is used to track the IP address using a service such as https://www.nsupdate.info/ + a dynamic DNS client such as ddclient. If the peer cannot be reached, a restart will be triggered, causing the hostname used with --remote to be re-resolved (if --resolv-retry is also specified). In server mode, --ping-restart, --inactive or any other type of internally generated signal will always be applied to individual client instance objects, never to whole server itself. Note also in server mode that any internally generated signal which would normally cause a restart, will cause the deletion of the client instance object instead. In client mode, the --ping-restart parameter is set to 120 seconds by default. This default will hold until the client pulls a replacement value from the server, based on the --keepalive setting in the server configuration. To disable the 120 second default, set --ping-restart 0 on the client. See the signals section below for more information on SIGUSR1. Note that the behavior of SIGUSR1 can be modified by the --persist-tun, --persist-key, --persist-local-ip and --persist-remote-ip options. Also note that --ping-exit and --ping-restart are mutually exclusive and cannot be used together. --ping-timer-rem Run the --ping-exit / --ping-restart timer only if we have a remote address. Use this option if you are starting the daemon in listen mode (i.e. without an explicit --remote peer), and you don't want to start clocking timeouts until a remote peer connects. --proto p Use protocol p for communicating with remote host. p can be udp, tcp-client, or tcp-server. You can also limit OpenVPN to use only IPv4 or only IPv6 by specifying p as udp4, tcp4-client, tcp4-server or udp6, tcp6-client, tcp6-server, respectively. The default protocol is udp when --proto is not specified. For UDP operation, --proto udp should be specified on both peers. For TCP operation, one peer must use --proto tcp-server and the other must use --proto tcp-client. A peer started with tcp-server will wait indefinitely for an incoming connection. A peer started with tcp-client will attempt to connect, and if that fails, will sleep for 5 seconds (adjustable via the --connect-retry option) and try again infinite or up to N retries (adjustable via the --connect-retry-max option). Both TCP client and server will simulate a SIGUSR1 restart signal if either side resets the connection. OpenVPN is designed to operate optimally over UDP, but TCP capability is provided for situations where UDP cannot be used. In comparison with UDP, TCP will usually be somewhat less ef‐ ficient and less robust when used over unreliable or congested networks. This article outlines some of problems with tunneling IP over TCP: http://sites.inka.de/sites/bigred/devel/tcp-tcp.html There are certain cases, however, where using TCP may be advantageous from a security and robustness perspective, such as tunneling non-IP or application-level UDP protocols, or tunnel‐ ing protocols which don't possess a built-in reliability layer. --port port TCP/UDP port number or port name for both local and remote (sets both --lport and --rport options to given port). The current default of 1194 represents the official IANA port number assignment for OpenVPN and has been used since version 2.0-beta17. Previous versions used port 5000 as the default. --rport port Set TCP/UDP port number or name used by the --remote option. The port can also be set directly using the --remote option. --replay-window args Modify the replay protection sliding-window size and time window. Valid syntax: replay-window n [t] Use a replay protection sliding-window of size n and a time window of t seconds. By default n is 64 (the IPSec default) and t is 15 seconds. This option is only relevant in UDP mode, i.e. when either --proto udp is specified, or no --proto option is specified. When OpenVPN tunnels IP packets over UDP, there is the possibility that packets might be dropped or delivered out of order. Because OpenVPN, like IPSec, is emulating the physical net‐ work layer, it will accept an out-of-order packet sequence, and will deliver such packets in the same order they were received to the TCP/IP protocol stack, provided they satisfy sev‐ eral constraints. a. The packet cannot be a replay (unless --no-replay is specified, which disables replay protection altogether). b. If a packet arrives out of order, it will only be accepted if the difference between its sequence number and the highest sequence number received so far is less than n. c. If a packet arrives out of order, it will only be accepted if it arrives no later than t seconds after any packet containing a higher sequence number. If you are using a network link with a large pipeline (meaning that the product of bandwidth and latency is high), you may want to use a larger value for n. Satellite links in particu‐ lar often require this. If you run OpenVPN at --verb 4, you will see the message \u0026quot;Replay-window backtrack occurred [x]\u0026quot; every time the maximum sequence number backtrack seen thus far increases. This can be used to calibrate n. There is some controversy on the appropriate method of handling packet reordering at the security layer. Namely, to what extent should the security layer protect the encapsulated protocol from attacks which masquerade as the kinds of normal packet loss and reordering that occur over IP networks? The IPSec and OpenVPN approach is to allow packet reordering within a certain fixed sequence number window. OpenVPN adds to the IPSec model by limiting the window size in time as well as sequence space. OpenVPN also adds TCP transport as an option (not offered by IPSec) in which case OpenVPN can adopt a very strict attitude towards message deletion and reordering: Don't allow it. Since TCP guarantees reliability, any packet loss or reordering event can be assumed to be an attack. In this sense, it could be argued that TCP tunnel transport is preferred when tunneling non-IP or UDP application protocols which might be vulnerable to a message deletion or reordering attack which falls within the normal operational parameters of IP networks. So I would make the statement that one should never tunnel a non-IP protocol or UDP application protocol over UDP, if the protocol might be vulnerable to a message deletion or reorder‐ ing attack that falls within the normal operating parameters of what is to be expected from the physical IP layer. The problem is easily fixed by simply using TCP as the VPN transport layer. --replay-persist file Persist replay-protection state across sessions using file to save and reload the state. This option will strengthen protection against replay attacks, especially when you are using OpenVPN in a dynamic context (such as with --inetd) when OpenVPN sessions are frequently started and stopped. This option will keep a disk copy of the current replay protection state (i.e. the most recent packet timestamp and sequence number received from the remote peer), so that if an OpenVPN session is stopped and restarted, it will reject any replays of packets which were already received by the prior session. This option only makes sense when replay protection is enabled (the default) and you are using either --secret (shared-secret key mode) or TLS mode with --tls-auth. --socket-flags flags Apply the given flags to the OpenVPN transport socket. Currently, only TCP_NODELAY is supported. The TCP_NODELAY socket flag is useful in TCP mode, and causes the kernel to send tunnel packets immediately over the TCP connection without trying to group several smaller packets into a larger packet. This can result in a considerably improvement in latency. This option is pushable from server to client, and should be used on both client and server for maximum effect. --tcp-nodelay This macro sets the TCP_NODELAY socket flag on the server as well as pushes it to connecting clients. The TCP_NODELAY flag disables the Nagle algorithm on TCP sockets causing packets to be transmitted immediately with low latency, rather than waiting a short period of time in order to aggregate several packets into a larger containing packet. In VPN applications over TCP, TCP_NODELAY is generally a good latency optimization. The macro expands as follows: if mode server: socket-flags TCP_NODELAY push \u0026quot;socket-flags TCP_NODELAY\u0026quot; Virtual Network Adapter (VPN interface) Options in this section relates to configuration of the virtual tun/tap network interface, including setting the VPN IP address and network routing. --bind-dev device (Linux only) Set device to bind the server socket to a Virtual Routing and Forwarding device --block-ipv6 On the client, instead of sending IPv6 packets over the VPN tunnel, all IPv6 packets are answered with an ICMPv6 no route host message. On the server, all IPv6 packets from clients are answered with an ICMPv6 no route to host message. This options is intended for cases when IPv6 should be blocked and other options are not available. --block-ipv6 will use the remote IPv6 as source address of the ICMPv6 packets if set, otherwise will use fe80::7 as source address. For this option to make sense you actually have to route traffic to the tun interface. The following example config block would send all IPv6 traffic to OpenVPN and answer all requests with no route to host, effectively blocking IPv6 (to avoid IPv6 connections from dual-stacked clients leaking around IPv4-only VPN services). Client config --ifconfig-ipv6 fd15:53b6:dead::2/64 fd15:53b6:dead::1 --redirect-gateway ipv6 --block-ipv6 Server config Push a \u0026quot;valid\u0026quot; ipv6 config to the client and block on the server --push \u0026quot;ifconfig-ipv6 fd15:53b6:dead::2/64 fd15:53b6:dead::1\u0026quot; --push \u0026quot;redirect-gateway ipv6\u0026quot; --block-ipv6 Note: this option does not influence traffic sent from the server towards the client (neither on the server nor on the client side). This is not seen as necessary, as such traffic can be most easily avoided by not configuring IPv6 on the server tun, or setting up a server-side firewall rule. --dev device TUN/TAP virtual network device which can be tunX, tapX, null or an arbitrary name string (X can be omitted for a dynamic device.) See examples section below for an example on setting up a TUN device. You must use either tun devices on both ends of the connection or tap devices on both ends. You cannot mix them, as they represent different underlying network layers: tun devices encapsulate IPv4 or IPv6 (OSI Layer 3) tap devices encapsulate Ethernet 802.3 (OSI Layer 2). Valid syntaxes: dev tun2 dev tap4 dev ovpn When the device name starts with tun or tap, the device type is extracted automatically. Otherwise the --dev-type option needs to be added as well. --dev-node node Explicitly set the device node rather than using /dev/net/tun, /dev/tun, /dev/tap, etc. If OpenVPN cannot figure out whether node is a TUN or TAP device based on the name, you should also specify --dev-type tun or --dev-type tap. Under Mac OS X this option can be used to specify the default tun implementation. Using --dev-node utun forces usage of the native Darwin tun kernel support. Use --dev-node utunN to se‐ lect a specific utun instance. To force using the tun.kext (/dev/tunX) use --dev-node tun. When not specifying a --dev-node option openvpn will first try to open utun, and fall back to tun.kext. On Windows systems, select the TAP-Win32 adapter which is named node in the Network Connections Control Panel or the raw GUID of the adapter enclosed by braces. The --show-adapters op‐ tion under Windows can also be used to enumerate all available TAP-Win32 adapters and will show both the network connections control panel name and the GUID for each TAP-Win32 adapter. --dev-type device-type Which device type are we using? device-type should be tun (OSI Layer 3) or tap (OSI Layer 2). Use this option only if the TUN/TAP device used with --dev does not begin with tun or tap. --dhcp-option args Set additional network parameters on supported platforms. May be specified on the client or pushed from the server. On Windows these options are handled by the tap-windows6 driver by default or directly by OpenVPN if dhcp is disabled or the wintun driver is in use. The OpenVPN for Android client also handles them internally. On all other platforms these options are only saved in the client's environment under the name foreign_option_{n} before the --up script is called. A plugin or an --up script must be used to pick up and interpret these as required. Many Linux distributions include such scripts and some third-party user interfaces such as tunnelblick also come with scripts that process these options. Valid syntax: dhcp-options type [parm] DOMAIN name Set Connection-specific DNS Suffix to name. ADAPTER_DOMAIN_SUFFIX name Alias to DOMAIN. This is a compatibility option, it should not be used in new deployments. DOMAIN-SEARCH name Add name to the domain search list. Repeat this option to add more entries. Up to 10 domains are supported. DNS address Set primary domain name server IPv4 or IPv6 address. Repeat this option to set secondary DNS server addresses. Note: DNS IPv6 servers are currently set using netsh (the existing DHCP code can only do IPv4 DHCP, and that protocol only permits IPv4 addresses anywhere). The option will be put into the environment, so an --up script could act upon it if needed. WINS address Set primary WINS server address (NetBIOS over TCP/IP Name Server). Repeat this option to set secondary WINS server addresses. NBDD address Set primary NBDD server address (NetBIOS over TCP/IP Datagram Distribution Server). Repeat this option to set secondary NBDD server addresses. NTP address Set primary NTP server address (Network Time Protocol). Repeat this option to set secondary NTP server addresses. NBT type Set NetBIOS over TCP/IP Node type. Possible options: 1 b-node (broadcasts) 2 p-node (point-to-point name queries to a WINS server) 4 m-node (broadcast then query name server) 8 h-node (query name server, then broadcast). NBS scope-id Set NetBIOS over TCP/IP Scope. A NetBIOS Scope ID provides an extended naming service for the NetBIOS over TCP/IP (Known as NBT) module. The primary purpose of a NetBIOS scope ID is to isolate NetBIOS traffic on a single network to only those nodes with the same NetBIOS scope ID. The NetBIOS scope ID is a character string that is appended to the NetBIOS name. The NetBIOS scope ID on two hosts must match, or the two hosts will not be able to communicate. The NetBIOS Scope ID also allows computers to use the same computer name, as they have different scope IDs. The Scope ID becomes a part of the NetBIOS name, making the name unique. (This description of NetBIOS scopes courtesy of NeonSurge@abyss.com) DISABLE-NBT Disable Netbios-over-TCP/IP. --ifconfig args Set TUN/TAP adapter parameters. It requires the IP address of the local VPN endpoint. For TUN devices in point-to-point mode, the next argument must be the VPN IP address of the remote VPN endpoint. For TAP devices, or TUN devices used with --topology subnet, the second argument is the subnet mask of the virtual network segment which is being created or connected to. For TUN devices, which facilitate virtual point-to-point IP connections (when used in --topology net30 or p2p mode), the proper usage of --ifconfig is to use two private IP addresses which are not a member of any existing subnet which is in use. The IP addresses may be consecutive and should have their order reversed on the remote peer. After the VPN is estab‐ lished, by pinging rn, you will be pinging across the VPN. For TAP devices, which provide the ability to create virtual ethernet segments, or TUN devices in --topology subnet mode (which create virtual \u0026quot;multipoint networks\u0026quot;), --ifconfig is used to set an IP address and subnet mask just as a physical ethernet adapter would be similarly configured. If you are attempting to connect to a remote ethernet bridge, the IP address and subnet should be set to values which would be valid on the the bridged ethernet segment (note also that DHCP can be used for the same purpose). This option, while primarily a proxy for the ifconfig(8) command, is designed to simplify TUN/TAP tunnel configuration by providing a standard interface to the different ifconfig imple‐ mentations on different platforms. --ifconfig parameters which are IP addresses can also be specified as a DNS or /etc/hosts file resolvable name. For TAP devices, --ifconfig should not be used if the TAP interface will be getting an IP address lease from a DHCP server. Examples: # tun device in net30/p2p mode ifconfig 10.8.0.2 10.8.0.1 # tun/tap device in subnet mode ifconfig 10.8.0.2 255.255.255.0 --ifconfig-ipv6 args Configure an IPv6 address on the tun device. Valid syntax: ifconfig-ipv6 ipv6addr/bits [ipv6remote] The ipv6addr/bits argument is the IPv6 address to use. The second parameter is used as route target for --route-ipv6 if no gateway is specified. The --topology option has no influence with --ifconfig-ipv6 --ifconfig-noexec Don't actually execute ifconfig/netsh commands, instead pass --ifconfig parameters to scripts using environmental variables. --ifconfig-nowarn Don't output an options consistency check warning if the --ifconfig option on this side of the connection doesn't match the remote side. This is useful when you want to retain the overall benefits of the options consistency check (also see --disable-occ option) while only disabling the ifconfig component of the check. For example, if you have a configuration where the local host uses --ifconfig but the remote host does not, use --ifconfig-nowarn on the local host. This option will also silence warnings about potential address conflicts which occasionally annoy more experienced users by triggering \u0026quot;false positive\u0026quot; warnings. --lladdr address Specify the link layer address, more commonly known as the MAC address. Only applied to TAP devices. --persist-tun Don't close and reopen TUN/TAP device or run up/down scripts across SIGUSR1 or --ping-restart restarts. SIGUSR1 is a restart signal similar to SIGHUP, but which offers finer-grained control over reset options. --redirect-gateway flags Automatically execute routing commands to cause all outgoing IP traffic to be redirected over the VPN. This is a client-side option. This option performs three steps: 1. Create a static route for the --remote address which forwards to the pre-existing default gateway. This is done so that (3) will not create a routing loop. 2. Delete the default gateway route. 3. Set the new default gateway to be the VPN endpoint address (derived either from --route-gateway or the second parameter to --ifconfig when --dev tun is specified). When the tunnel is torn down, all of the above steps are reversed so that the original default route is restored. Option flags: local Add the local flag if both OpenVPN peers are directly connected via a common subnet, such as with wireless. The local flag will cause step (1) above to be omitted. autolocal Try to automatically determine whether to enable local flag above. def1 Use this flag to override the default gateway by using 0.0.0.0/1 and 128.0.0.0/1 rather than 0.0.0.0/0. This has the benefit of overriding but not wiping out the original default gateway. bypass-dhcp Add a direct route to the DHCP server (if it is non-local) which bypasses the tunnel (Available on Windows clients, may not be available on non-Windows clients). bypass-dns Add a direct route to the DNS server(s) (if they are non-local) which bypasses the tunnel (Available on Windows clients, may not be available on non-Windows clients). block-local Block access to local LAN when the tunnel is active, except for the LAN gateway itself. This is accomplished by routing the local LAN (except for the LAN gateway address) into the tunnel. ipv6 Redirect IPv6 routing into the tunnel. This works similar to the def1 flag, that is, more specific IPv6 routes are added (2000::/4, 3000::/4), covering the whole IPv6 unicast space. !ipv4 Do not redirect IPv4 traffic - typically used in the flag pair ipv6 !ipv4 to redirect IPv6-only. --redirect-private flags Like --redirect-gateway, but omit actually changing the default gateway. Useful when pushing private subnets. --route args Add route to routing table after connection is established. Multiple routes can be specified. Routes will be automatically torn down in reverse order prior to TUN/TAP device close. Valid syntaxes: route network/IP route network/IP netmask route network/IP netmask gateway route network/IP netmask gateway metric This option is intended as a convenience proxy for the route(8) shell command, while at the same time providing portable semantics across OpenVPN's platform space. netmask defaults to 255.255.255.255 when not given gateway default taken from --route-gateway or the second parameter to --ifconfig when --dev tun is specified. metric default taken from --route-metric if set, otherwise 0. The default can be specified by leaving an option blank or setting it to default. The network and gateway parameters can also be specified as a DNS or /etc/hosts file resolvable name, or as one of three special keywords: vpn_gateway The remote VPN endpoint address (derived either from --route-gateway or the second parameter to --ifconfig when --dev tun is specified). net_gateway The pre-existing IP default gateway, read from the routing table (not supported on all OSes). remote_host The --remote address if OpenVPN is being run in client mode, and is undefined in server mode. --route-delay args Valid syntaxes: route-delay route-delay n route-delay n m Delay n seconds (default 0) after connection establishment, before adding routes. If n is 0, routes will be added immediately upon connection establishment. If --route-delay is omitted, routes will be added immediately after TUN/TAP device open and --up script execution, before any --user or --group privilege downgrade (or --chroot execution.) This option is designed to be useful in scenarios where DHCP is used to set tap adapter addresses. The delay will give the DHCP handshake time to complete before routes are added. On Windows, --route-delay tries to be more intelligent by waiting w seconds (default 30 by default) for the TAP-Win32 adapter to come up before adding routes. --route-ipv6 args Setup IPv6 routing in the system to send the specified IPv6 network into OpenVPN's tun. Valid syntax: route-ipv6 ipv6addr/bits [gateway] [metric] The gateway parameter is only used for IPv6 routes across tap devices, and if missing, the ipv6remote field from --ifconfig-ipv6 or --route-ipv6-gateway is used. --route-gateway arg Specify a default gateway for use with --route. If dhcp is specified as the parameter, the gateway address will be extracted from a DHCP negotiation with the OpenVPN server-side LAN. Valid syntaxes: route-gateway gateway route-gateway dhcp --route-ipv6-gateway gw Specify a default gateway gw for use with --route-ipv6. --route-metric m Specify a default metric m for use with --route. --route-noexec Don't add or remove routes automatically. Instead pass routes to --route-up script using environmental variables. --route-nopull When used with --client or --pull, accept options pushed by server EXCEPT for routes, block-outside-dns and dhcp options like DNS servers. When used on the client, this option effectively bars the server from adding routes to the client's routing table, however note that this option still allows the server to set the TCP/IP properties of the client's TUN/TAP interface. --topology mode Configure virtual addressing topology when running in --dev tun mode. This directive has no meaning in --dev tap mode, which always uses a subnet topology. If you set this directive on the server, the --server and --server-bridge directives will automatically push your chosen topology setting to clients as well. This directive can also be manually pushed to clients. Like the --dev directive, this directive must always be compatible between client and server. mode can be one of: net30 Use a point-to-point topology, by allocating one /30 subnet per client. This is designed to allow point-to-point semantics when some or all of the connecting clients might be Windows systems. This is the default on OpenVPN 2.0. p2p Use a point-to-point topology where the remote endpoint of the client's tun interface always points to the local endpoint of the server's tun interface. This mode allocates a single IP address per connecting client. Only use when none of the connecting clients are Windows systems. subnet Use a subnet rather than a point-to-point topology by configuring the tun interface with a local IP address and subnet mask, similar to the topology used in --dev tap and ether‐ net bridging mode. This mode allocates a single IP address per connecting client and works on Windows as well. Only available when server and clients are OpenVPN 2.1 or higher, or OpenVPN 2.0.x which has been manually patched with the --topology directive code. When used on Windows, requires version 8.2 or higher of the TAP-Win32 driver. When used on *nix, requires that the tun driver supports an ifconfig(8) command which sets a subnet instead of a remote endpoint IP address. Note: Using --topology subnet changes the interpretation of the arguments of --ifconfig to mean \u0026quot;address netmask\u0026quot;, no longer \u0026quot;local remote\u0026quot;. --tun-mtu n Take the TUN device MTU to be n and derive the link MTU from it (default 1500). In most cases, you will probably want to leave this parameter set to its default value. The MTU (Maximum Transmission Units) is the maximum datagram size in bytes that can be sent unfragmented over a particular network path. OpenVPN requires that packets on the control and data channels be sent unfragmented. MTU problems often manifest themselves as connections which hang during periods of active usage. It's best to use the --fragment and/or --mssfix options to deal with MTU sizing issues. --tun-mtu-extra n Assume that the TUN/TAP device might return as many as n bytes more than the --tun-mtu size on read. This parameter defaults to 0, which is sufficient for most TUN devices. TAP devices may introduce additional overhead in excess of the MTU size, and a setting of 32 is the default when TAP devices are used. This parameter only controls internal OpenVPN buffer sizing, so there is no transmission overhead associated with using a larger value. TUN/TAP standalone operations These two standalone operations will require --dev and optionally --user and/or --group. --mktun (Standalone) Create a persistent tunnel on platforms which support them such as Linux. Normally TUN/TAP tunnels exist only for the period of time that an application has them open. This option takes advantage of the TUN/TAP driver's ability to build persistent tunnels that live through multiple instantiations of OpenVPN and die only when they are deleted or the machine is rebooted. One of the advantages of persistent tunnels is that they eliminate the need for separate --up and --down scripts to run the appropriate ifconfig(8) and route(8) commands. These commands can be placed in the the same shell script which starts or terminates an OpenVPN session. Another advantage is that open connections through the TUN/TAP-based tunnel will not be reset if the OpenVPN peer restarts. This can be useful to provide uninterrupted connectivity through the tunnel in the event of a DHCP reset of the peer's public IP address (see the --ipchange option above). One disadvantage of persistent tunnels is that it is harder to automatically configure their MTU value (see --link-mtu and --tun-mtu above). On some platforms such as Windows, TAP-Win32 tunnels are persistent by default. --rmtun (Standalone) Remove a persistent tunnel. Virtual Routing and Forwarding Options in this section relates to configuration of virtual routing and forwarding in combination with the underlying operating system. As of today this is only supported on Linux, a kernel \u0026gt;= 4.9 is recommended. This could come in handy when for example the external network should be only used as a means to connect to some VPN endpoints and all regular traffic should only be routed through any tun‐ nel(s). This could be achieved by setting up a VRF and configuring the interface connected to the external network to be part of the VRF. The examples below will cover this setup. Another option would be to put the tun/tap interface into a VRF. This could be done by an up-script which uses the ip link set command shown below. VRF setup with iproute2 Create VRF vrf_external and map it to routing table 1023 ip link add vrf_external type vrf table 1023 Move eth0 into vrf_external ip link set master vrf_external dev eth0 Any prefixes configured on eth0 will be moved from the :code`main` routing table into routing table 1023 VRF setup with ifupdown For Debian based Distributions ifupdown2 provides an almost drop-in replacement for ifupdown including VRFs and other features. A configuration for an interface eth0 being part of VRF code:vrf_external could look like this: auto eth0 iface eth0 address 192.0.2.42/24 address 2001:db8:08:15::42/64 gateway 192.0.2.1 gateway 2001:db8:08:15::1 vrf vrf_external auto vrf_external iface vrf_external vrf-table 1023 OpenVPN configuration The OpenVPN configuration needs to contain this line: bind-dev vrf_external Further reading Wikipedia has nice page one VRFs: https://en.wikipedia.org/wiki/Virtual_routing_and_forwarding This talk from the Network Track of FrOSCon 2018 provides an overview about advanced layer 2 and layer 3 features of Linux • Slides: https://www.slideshare.net/BarbarossaTM/l2l3-fr-fortgeschrittene-helle-und-dunkle-magie-im-linuxnetzwerkstack • Video (german): https://media.ccc.de/v/froscon2018-2247-l2_l3_fur_fortgeschrittene_-_helle_und_dunkle_magie_im_linux-netzwerkstack SCRIPTING INTEGRATION OpenVPN can execute external scripts in various phases of the lifetime of the OpenVPN process. Script Order of Execution 1. --up Executed after TCP/UDP socket bind and TUN/TAP open. 2. --tls-verify Executed when we have a still untrusted remote peer. 3. --ipchange Executed after connection authentication, or remote IP address change. 4. --client-connect Executed in --mode server mode immediately after client authentication. 5. --route-up Executed after connection authentication, either immediately after, or some number of seconds after as defined by the --route-delay option. 6. --route-pre-down Executed right before the routes are removed. 7. --client-disconnect Executed in --mode server mode on client instance shutdown. 8. --down Executed after TCP/UDP and TUN/TAP close. 9. --learn-address Executed in --mode server mode whenever an IPv4 address/route or MAC address is added to OpenVPN's internal routing table. 10. --auth-user-pass-verify Executed in --mode server mode on new client connections, when the client is still untrusted. SCRIPT HOOKS --auth-user-pass-verify args Require the client to provide a username/password (possibly in addition to a client certificate) for authentication. Valid syntax: auth-user-pass-verify cmd method OpenVPN will run command cmd to validate the username/password provided by the client. cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. If method is set to via-env, OpenVPN will call script with the environmental variables username and password set to the username/password strings provided by the client. Beware that this method is insecure on some platforms which make the environment of a process publicly visible to other unprivileged processes. If method is set to via-file, OpenVPN will write the username and password to the first two lines of a temporary file. The filename will be passed as an argument to script, and the file will be automatically deleted by OpenVPN after the script returns. The location of the temporary file is controlled by the --tmp-dir option, and will default to the current directory if unspecified. For security, consider setting --tmp-dir to a volatile storage medium such as /dev/shm (if available) to prevent the username/password file from touching the hard drive. The script should examine the username and password, returning a success exit code (0) if the client's authentication request is to be accepted, or a failure code (1) to reject the client. This directive is designed to enable a plugin-style interface for extending OpenVPN's authentication capabilities. To protect against a client passing a maliciously formed username or password string, the username string must consist only of these characters: alphanumeric, underbar ('_'), dash ('-'), dot ('.'), or at ('@'). The password string can consist of any printable characters except for CR or LF. Any illegal characters in either the username or password string will be converted to underbar ('_'). Care must be taken by any user-defined scripts to avoid creating a security vulnerability in the way that these strings are handled. Never use these strings in such a way that they might be escaped or evaluated by a shell interpreter. For a sample script that performs PAM authentication, see sample-scripts/auth-pam.pl in the OpenVPN source distribution. --client-connect cmd Run command cmd on client connection. cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. The command is passed the common name and IP address of the just-authenticated client as environmental variables (see environmental variable section below). The command is also passed the pathname of a freshly created temporary file as the last argument (after any arguments specified in cmd ), to be used by the command to pass dynamically generated config file direc‐ tives back to OpenVPN. If the script wants to generate a dynamic config file to be applied on the server when the client connects, it should write it to the file named by the last argument. See the --client-config-dir option below for options which can be legally used in a dynamically generated config file. Note that the return value of script is significant. If script returns a non-zero error status, it will cause the client to be disconnected. If a --client-connect wants to defer the generating of the configuration then the script needs to use the client_connect_deferred_file and client_connect_config_file environment vari‐ ables, and write status accordingly into these files. See the Environmental Variables section for more details. --client-disconnect cmd Like --client-connect but called on client instance shutdown. Will not be called unless the --client-connect script and plugins (if defined) were previously called on this instance with successful (0) status returns. The exception to this rule is if the --client-disconnect command or plugins are cascaded, and at least one client-connect function succeeded, then ALL of the client-disconnect functions for scripts and plugins will be called on client instance object deletion, even in cases where some of the related client-connect functions returned an error status. The --client-disconnect command is not passed any extra arguments (only those arguments specified in cmd, if any). --down cmd Run command cmd after TUN/TAP device close (post --user UID change and/or --chroot ). cmd consists of a path to script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. Called with the same parameters and environmental variables as the --up option above. Note that if you reduce privileges by using --user and/or --group, your --down script will also run at reduced privilege. --down-pre Call --down cmd/script before, rather than after, TUN/TAP close. --ipchange cmd Run command cmd when our remote ip-address is initially authenticated or changes. cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. When cmd is executed two arguments are appended after any arguments specified in cmd , as follows: cmd ip address port number Don't use --ipchange in --mode server mode. Use a --client-connect script instead. See the Environmental Variables section below for additional parameters passed as environmental variables. If you are running in a dynamic IP address environment where the IP addresses of either peer could change without notice, you can use this script, for example, to edit the /etc/hosts file with the current address of the peer. The script will be run every time the remote peer changes its IP address. Similarly if our IP address changes due to DHCP, we should configure our IP address change script (see help for dhcpcd(8)) to deliver a SIGHUP or SIGUSR1 signal to OpenVPN. OpenVPN will then re-establish a connection with its most recently authenticated peer on its new IP address. --learn-address cmd Run command cmd to validate client virtual addresses or routes. cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. Three arguments will be appended to any arguments in cmd as follows: $1 - [operation] \u0026quot;add\u0026quot;, \u0026quot;update\u0026quot;, or \u0026quot;delete\u0026quot; based on whether or not the address is being added to, modified, or deleted from OpenVPN's internal routing table. $2 - [address] The address being learned or unlearned. This can be an IPv4 address such as \u0026quot;198.162.10.14\u0026quot;, an IPv4 subnet such as \u0026quot;198.162.10.0/24\u0026quot;, or an ethernet MAC address (when --dev tap is being used) such as \u0026quot;00:FF:01:02:03:04\u0026quot;. $3 - [common name] The common name on the certificate associated with the client linked to this address. Only present for \u0026quot;add\u0026quot; or \u0026quot;update\u0026quot; operations, not \u0026quot;delete\u0026quot;. On \u0026quot;add\u0026quot; or \u0026quot;update\u0026quot; methods, if the script returns a failure code (non-zero), OpenVPN will reject the address and will not modify its internal routing table. Normally, the cmd script will use the information provided above to set appropriate firewall entries on the VPN TUN/TAP interface. Since OpenVPN provides the association between virtual IP or MAC address and the client's authenticated common name, it allows a user-defined script to configure firewall access policies with regard to the client's high-level common name, rather than the low level client virtual addresses. --route-up cmd Run command cmd after routes are added, subject to --route-delay. cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. See the Environmental Variables section below for additional parameters passed as environmental variables. --route-pre-down cmd Run command cmd before routes are removed upon disconnection. cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. See the Environmental Variables section below for additional parameters passed as environmental variables. --setenv args Set a custom environmental variable name=value to pass to script. Valid syntaxes: setenv name value setenv FORWARD_COMPATIBLE 1 setenv opt config_option By setting FORWARD_COMPATIBLE to 1, the config file syntax checking is relaxed so that unknown directives will trigger a warning but not a fatal error, on the assumption that a given unknown directive might be valid in future OpenVPN versions. This option should be used with caution, as there are good security reasons for having OpenVPN fail if it detects problems in a config file. Having said that, there are valid reasons for wanting new software features to gracefully degrade when encountered by older software versions. It is also possible to tag a single directive so as not to trigger a fatal error if the directive isn't recognized. To do this, prepend the following before the directive: setenv opt Versions prior to OpenVPN 2.3.3 will always ignore options set with the setenv opt directive. See also --ignore-unknown-option --setenv-safe args Set a custom environmental variable OPENVPN_name to value to pass to scripts. Valid syntaxes: setenv-safe name value This directive is designed to be pushed by the server to clients, and the prepending of OPENVPN_ to the environmental variable is a safety precaution to prevent a LD_PRELOAD style at‐ tack from a malicious or compromised server. --tls-verify cmd Run command cmd to verify the X509 name of a pending TLS connection that has otherwise passed all other tests of certification (except for revocation via --crl-verify directive; the re‐ vocation test occurs after the --tls-verify test). cmd should return 0 to allow the TLS handshake to proceed, or 1 to fail. cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. When cmd is executed two arguments are appended after any arguments specified in cmd, as follows: cmd certificate_depth subject These arguments are, respectively, the current certificate depth and the X509 subject distinguished name (dn) of the peer. This feature is useful if the peer you want to trust has a certificate which was signed by a certificate authority who also signed many other certificates, where you don't necessarily want to trust all of them, but rather be selective about which peer certificate you will accept. This feature allows you to write a script which will test the X509 name on a certificate and decide whether or not it should be accepted. For a simple perl script which will test the common name field on the certificate, see the file verify-cn in the OpenVPN distribution. See the Environmental Variables section below for additional parameters passed as environmental variables. --up cmd Run command cmd after successful TUN/TAP device open (pre --user UID change). cmd consists of a path to a script (or executable program), optionally followed by arguments. The path and arguments may be single- or double-quoted and/or escaped using a backslash, and should be separated by one or more spaces. The up command is useful for specifying route commands which route IP traffic destined for private subnets which exist at the other end of the VPN connection into the tunnel. For --dev tun execute as: cmd tun_dev tun_mtu link_mtu ifconfig_local_ip ifconfig_remote_ip [init | restart] For --dev tap execute as: cmd tap_dev tap_mtu link_mtu ifconfig_local_ip ifconfig_netmask [init | restart] See the Environmental Variables section below for additional parameters passed as environmental variables. Note that if cmd includes arguments, all OpenVPN-generated arguments will be appended to them to build an argument list with which the executable will be called. Typically, cmd will run a script to add routes to the tunnel. Normally the up script is called after the TUN/TAP device is opened. In this context, the last command line parameter passed to the script will be init. If the --up-restart option is also used, the up script will be called for restarts as well. A restart is considered to be a partial reinitialization of OpenVPN where the TUN/TAP instance is preserved (the --per‐ sist-tun option will enable such preservation). A restart can be generated by a SIGUSR1 signal, a --ping-restart timeout, or a connection reset when the TCP protocol is enabled with the --proto option. If a restart occurs, and --up-restart has been specified, the up script will be called with restart as the last parameter. NOTE: On restart, OpenVPN will not pass the full set of environment variables to the script. Namely, everything related to routing and gateways will not be passed, as nothing needs to be done anyway - all the routing setup is already in place. Additionally, the up-restart script will run with the downgraded UID/GID settings (if configured). The following standalone example shows how the --up script can be called in both an initialization and restart context. (NOTE: for security reasons, don't run the following example un‐ less UDP port 9999 is blocked by your firewall. Also, the example will run indefinitely, so you should abort with control-c). openvpn --dev tun --port 9999 --verb 4 --ping-restart 10 \\ --up 'echo up' --down 'echo down' --persist-tun \\ --up-restart Note that OpenVPN also provides the --ifconfig option to automatically ifconfig the TUN device, eliminating the need to define an --up script, unless you also want to configure routes in the --up script. If --ifconfig is also specified, OpenVPN will pass the ifconfig local and remote endpoints on the command line to the --up script so that they can be used to configure routes such as: route add -net 10.0.0.0 netmask 255.255.255.0 gw $5 --up-delay Delay TUN/TAP open and possible --up script execution until after TCP/UDP connection establishment with peer. In --proto udp mode, this option normally requires the use of --ping to allow connection initiation to be sensed in the absence of tunnel data, since UDP is a \u0026quot;connectionless\u0026quot; protocol. On Windows, this option will delay the TAP-Win32 media state transitioning to \u0026quot;connected\u0026quot; until connection establishment, i.e. the receipt of the first authenticated packet from the peer. --up-restart Enable the --up and --down scripts to be called for restarts as well as initial program start. This option is described more fully above in the --up option documentation. String Types and Remapping In certain cases, OpenVPN will perform remapping of characters in strings. Essentially, any characters outside the set of permitted characters for each string type will be converted to under‐ bar ('_'). Q: Why is string remapping necessary? It's an important security feature to prevent the malicious coding of strings from untrusted sources to be passed as parameters to scripts, saved in the environment, used as a common name, translated to a filename, etc. Q: Can string remapping be disabled? Yes, by using the --no-name-remapping option, however this should be considered an advanced option. Here is a brief rundown of OpenVPN's current string types and the permitted character class for each string: X509 Names Alphanumeric, underbar ('_'), dash ('-'), dot ('.'), at ('@'), colon (':'), slash ('/'), and equal ('='). Alphanumeric is defined as a character which will cause the C library isalnum() function to return true. Common Names Alphanumeric, underbar ('_'), dash ('-'), dot ('.'), and at ('@'). --auth-user-pass username Same as Common Name, with one exception: starting with OpenVPN 2.0.1, the username is passed to the OPENVPN_PLUGIN_AUTH_USER_PASS_VERIFY plugin in its raw form, without string remap‐ ping. --auth-user-pass password Any \u0026quot;printable\u0026quot; character except CR or LF. Printable is defined to be a character which will cause the C library isprint() function to return true. --client-config-dir filename as derived from common name or`username Alphanumeric, underbar ('_'), dash ('-'), and dot ('.') except for \u0026quot;.\u0026quot; or \u0026quot;..\u0026quot; as standalone strings. As of v2.0.1-rc6, the at ('@') character has been added as well for compatibility with the common name character class. Environmental variable names Alphanumeric or underbar ('_'). Environmental variable values Any printable character. For all cases, characters in a string which are not members of the legal character class for that string type will be remapped to underbar ('_'). Environmental Variables Once set, a variable is persisted indefinitely until it is reset by a new value or a restart, As of OpenVPN 2.0-beta12, in server mode, environmental variables set by OpenVPN are scoped according to the client objects they are associated with, so there should not be any issues with scripts having access to stale, previously set variables which refer to different client instances. bytes_received Total number of bytes received from client during VPN session. Set prior to execution of the --client-disconnect script. bytes_sent Total number of bytes sent to client during VPN session. Set prior to execution of the --client-disconnect script. client_connect_config_file The path to the configuration file that should be written to by the --client-connect script (optional, if per-session configuration is desired). This is the same file name as passed via command line argument on the call to the --client-connect script. client_connect_deferred_file This file can be optionally written to in order to to communicate a status code of the --client-connect script or plgin. Only the first character in the file is relevant. It must be either 1 to indicate normal script execution, 0 indicates an error (in the same way that a non zero exit status does) or 2 to indicate that the script deferred returning the config file. For deferred (background) handling, the script or plugin MUST write 2 to the file to indicate the deferral and then return with exit code 0 to signal deferred handler started OK. A background process or similar must then take care of writing the configuration to the file indicated by the client_connect_config_file environment variable and when finished, write the a 1 to this file (or 0 in case of an error). The absence of any character in the file when the script finishes executing is interpreted the same as 1. This allows scripts that are not written to support the defer mechanism to be used unmodified. common_name The X509 common name of an authenticated client. Set prior to execution of --client-connect, --client-disconnect and --auth-user-pass-verify scripts. config Name of first --config file. Set on program initiation and reset on SIGHUP. daemon Set to \u0026quot;1\u0026quot; if the --daemon directive is specified, or \u0026quot;0\u0026quot; otherwise. Set on program initiation and reset on SIGHUP. daemon_log_redirect Set to \u0026quot;1\u0026quot; if the --log or --log-append directives are specified, or \u0026quot;0\u0026quot; otherwise. Set on program initiation and reset on SIGHUP. dev The actual name of the TUN/TAP device, including a unit number if it exists. Set prior to --up or --down script execution. dev_idx On Windows, the device index of the TUN/TAP adapter (to be used in netsh.exe calls which sometimes just do not work right with interface names). Set prior to --up or --down script exe‐ cution. foreign_option_{n} An option pushed via --push to a client which does not natively support it, such as --dhcp-option on a non-Windows system, will be recorded to this environmental variable sequence prior to --up script execution. ifconfig_broadcast The broadcast address for the virtual ethernet segment which is derived from the --ifconfig option when --dev tap is used. Set prior to OpenVPN calling the ifconfig or netsh (windows version of ifconfig) commands which normally occurs prior to --up script execution. ifconfig_ipv6_local The local VPN endpoint IPv6 address specified in the --ifconfig-ipv6 option (first parameter). Set prior to OpenVPN calling the ifconfig or code:netsh (windows version of ifconfig) com‐ mands which normally occurs prior to --up script execution. ifconfig_ipv6_netbits The prefix length of the IPv6 network on the VPN interface. Derived from the /nnn parameter of the IPv6 address in the --ifconfig-ipv6 option (first parameter). Set prior to OpenVPN calling the ifconfig or netsh (windows version of ifconfig) commands which normally occurs prior to --up script execution. ifconfig_ipv6_remote The remote VPN endpoint IPv6 address specified in the --ifconfig-ipv6 option (second parameter). Set prior to OpenVPN calling the ifconfig or netsh (windows version of ifconfig) com‐ mands which normally occurs prior to --up script execution. ifconfig_local The local VPN endpoint IP address specified in the --ifconfig option (first parameter). Set prior to OpenVPN calling the ifconfig or netsh (windows version of ifconfig) commands which normally occurs prior to --up script execution. ifconfig_remote The remote VPN endpoint IP address specified in the --ifconfig option (second parameter) when --dev tun is used. Set prior to OpenVPN calling the ifconfig or netsh (windows version of ifconfig) commands which normally occurs prior to --up script execution. ifconfig_netmask The subnet mask of the virtual ethernet segment that is specified as the second parameter to --ifconfig when --dev tap is being used. Set prior to OpenVPN calling the ifconfig or netsh (windows version of ifconfig) commands which normally occurs prior to --up script execution. ifconfig_pool_local_ip The local virtual IP address for the TUN/TAP tunnel taken from an --ifconfig-push directive if specified, or otherwise from the ifconfig pool (controlled by the --ifconfig-pool config file directive). Only set for --dev tun tunnels. This option is set on the server prior to execution of the --client-connect and --client-disconnect scripts. ifconfig_pool_netmask The virtual IP netmask for the TUN/TAP tunnel taken from an --ifconfig-push directive if specified, or otherwise from the ifconfig pool (controlled by the --ifconfig-pool config file directive). Only set for --dev tap tunnels. This option is set on the server prior to execution of the --client-connect and --client-disconnect scripts. ifconfig_pool_remote_ip The remote virtual IP address for the TUN/TAP tunnel taken from an --ifconfig-push directive if specified, or otherwise from the ifconfig pool (controlled by the --ifconfig-pool config file directive). This option is set on the server prior to execution of the --client-connect and --client-disconnect scripts. link_mtu The maximum packet size (not including the IP header) of tunnel data in UDP tunnel transport mode. Set prior to --up or --down script execution. local The --local parameter. Set on program initiation and reset on SIGHUP. local_port The local port number or name, specified by --port or --lport. Set on program initiation and reset on SIGHUP. password The password provided by a connecting client. Set prior to --auth-user-pass-verify script execution only when the via-env modifier is specified, and deleted from the environment after the script returns. proto The --proto parameter. Set on program initiation and reset on SIGHUP. remote_{n} The --remote parameter. Set on program initiation and reset on SIGHUP. remote_port_{n} The remote port number, specified by --port or --rport. Set on program initiation and reset on SIGHUP. route_net_gateway The pre-existing default IP gateway in the system routing table. Set prior to --up script execution. route_vpn_gateway The default gateway used by --route options, as specified in either the --route-gateway option or the second parameter to --ifconfig when --dev tun is specified. Set prior to --up script execution. route_{parm}_{n} A set of variables which define each route to be added, and are set prior to --up script execution. parm will be one of network, netmask\u0026quot;, gateway, or metric. n is the OpenVPN route number, starting from 1. If the network or gateway are resolvable DNS names, their IP address translations will be recorded rather than their names as denoted on the command line or configuration file. route_ipv6_{parm}_{n} A set of variables which define each IPv6 route to be added, and are set prior to --up script execution. parm will be one of network, gateway or metric. route_ipv6_network_{n} contains netmask as /nnn, unlike IPv4 where it is passed in a separate environment variable. n is the OpenVPN route number, starting from 1. If the network or gateway are resolvable DNS names, their IP address translations will be recorded rather than their names as denoted on the command line or configuration file. peer_cert Temporary file name containing the client certificate upon connection. Useful in conjunction with --tls-verify. script_context Set to \u0026quot;init\u0026quot; or \u0026quot;restart\u0026quot; prior to up/down script execution. For more information, see documentation for --up. script_type Prior to execution of any script, this variable is set to the type of script being run. It can be one of the following: up, down, ipchange, route-up, tls-verify, auth-user-pass-verify, client-connect, client-disconnect or learn-address. Set prior to execution of any script. signal The reason for exit or restart. Can be one of sigusr1, sighup, sigterm, sigint, inactive (controlled by --inactive option), ping-exit (controlled by --ping-exit option), ping-restart (controlled by --ping-restart option), connection-reset (triggered on TCP connection reset), error or unknown (unknown signal). This variable is set just prior to down script execu‐ tion. time_ascii Client connection timestamp, formatted as a human-readable time string. Set prior to execution of the --client-connect script. time_duration The duration (in seconds) of the client session which is now disconnecting. Set prior to execution of the --client-disconnect script. time_unix Client connection timestamp, formatted as a unix integer date/time value. Set prior to execution of the --client-connect script. tls_digest_{n} / tls_digest_sha256_{n} Contains the certificate SHA1 / SHA256 fingerprint, where n is the verification level. Only set for TLS connections. Set prior to execution of --tls-verify script. tls_id_{n} A series of certificate fields from the remote peer, where n is the verification level. Only set for TLS connections. Set prior to execution of --tls-verify script. tls_serial_{n} The serial number of the certificate from the remote peer, where n is the verification level. Only set for TLS connections. Set prior to execution of --tls-verify script. This is in the form of a decimal string like \u0026quot;933971680\u0026quot;, which is suitable for doing serial-based OCSP queries (with OpenSSL, do not prepend \u0026quot;0x\u0026quot; to the string) If something goes wrong while reading the value from the certificate it will be an empty string, so your code should check that. See the contrib/OCSP_check/OCSP_check.sh script for an example. tls_serial_hex_{n} Like tls_serial_{n}, but in hex form (e.g. 12:34:56:78:9A). tun_mtu The MTU of the TUN/TAP device. Set prior to --up or --down script execution. trusted_ip / trusted_ip6) Actual IP address of connecting client or peer which has been authenticated. Set prior to execution of --ipchange, --client-connect and --client-disconnect scripts. If using ipv6 end‐ points (udp6, tcp6), trusted_ip6 will be set instead. trusted_port Actual port number of connecting client or peer which has been authenticated. Set prior to execution of --ipchange, --client-connect and --client-disconnect scripts. untrusted_ip / untrusted_ip6 Actual IP address of connecting client or peer which has not been authenticated yet. Sometimes used to nmap the connecting host in a --tls-verify script to ensure it is firewalled prop‐ erly. Set prior to execution of --tls-verify and --auth-user-pass-verify scripts. If using ipv6 endpoints (udp6, tcp6), untrusted_ip6 will be set instead. untrusted_port Actual port number of connecting client or peer which has not been authenticated yet. Set prior to execution of --tls-verify and --auth-user-pass-verify scripts. username The username provided by a connecting client. Set prior to --auth-user-pass-verify script execution only when the via-env modifier is specified. X509_{n}_{subject_field} An X509 subject field from the remote peer certificate, where n is the verification level. Only set for TLS connections. Set prior to execution of --tls-verify script. This variable is similar to tls_id_{n} except the component X509 subject fields are broken out, and no string remapping occurs on these field values (except for remapping of control characters to \u0026quot;_\u0026quot;). For example, the following variables would be set on the OpenVPN server using the sample client certificate in sample-keys (client.crt). Note that the verification level is 0 for the client certificate and 1 for the CA certificate. X509_0_emailAddress=me@myhost.mydomain X509_0_CN=Test-Client X509_0_O=OpenVPN-TEST X509_0_ST=NA X509_0_C=KG X509_1_emailAddress=me@myhost.mydomain X509_1_O=OpenVPN-TEST X509_1_L=BISHKEK X509_1_ST=NA X509_1_C=KG Management Interface Options OpenVPN provides a feature rich socket based management interface for both server and client mode operations. --management args Enable a management server on a socket-name Unix socket on those platforms supporting it, or on a designated TCP port. Valid syntaxes: management socket-name unix # management socket-name unix pw-file # (recommended) management IP port # (INSECURE) management IP port pw-file # pw-file, if specified, is a password file where the password must be on first line. Instead of a filename it can use the keyword stdin which will prompt the user for a password to use when OpenVPN is starting. For unix sockets, the default behaviour is to create a unix domain socket that may be connected to by any process. Use the --management-client-user and --management-client-group direc‐ tives to restrict access. The management interface provides a special mode where the TCP management link can operate over the tunnel itself. To enable this mode, set IP to tunnel. Tunnel mode will cause the man‐ agement interface to listen for a TCP connection on the local VPN address of the TUN/TAP interface. *BEWARE* of enabling the management interface over TCP. In these cases you should ALWAYS make use of pw-file to password protect the management interface. Any user who can connect to this TCP IP:port will be able to manage and control (and interfere with) the OpenVPN process. It is also strongly recommended to set IP to 127.0.0.1 (localhost) to restrict accessibil‐ ity of the management server to local clients. While the management port is designed for programmatic control of OpenVPN by other applications, it is possible to telnet to the port, using a telnet client in \u0026quot;raw\u0026quot; mode. Once con‐ nected, type help for a list of commands. For detailed documentation on the management interface, see the management-notes.txt file in the management folder of the OpenVPN source distribution. --management-client Management interface will connect as a TCP/unix domain client to IP:port specified by --management rather than listen as a TCP server or on a unix domain socket. If the client connection fails to connect or is disconnected, a SIGTERM signal will be generated causing OpenVPN to quit. --management-client-auth Gives management interface client the responsibility to authenticate clients after their client certificate has been verified. See management-notes.txt in OpenVPN distribution for de‐ tailed notes. --management-client-group g When the management interface is listening on a unix domain socket, only allow connections from group g. --management-client-pf Management interface clients must specify a packet filter file for each connecting client. See management-notes.txt in OpenVPN distribution for detailed notes. --management-client-user u When the management interface is listening on a unix domain socket, only allow connections from user u. --management-external-cert certificate-hint Allows usage for external certificate instead of --cert option (client-only). certificate-hint is an arbitrary string which is passed to a management interface client as an argument of NEED-CERTIFICATE notification. Requires --management-external-key. --management-external-key args Allows usage for external private key file instead of --key option (client-only). Valid syntaxes: management-external-key management-external-key nopadding management-external-key pkcs1 management-external-key nopadding pkcs1 The optional parameters nopadding and pkcs1 signal support for different padding algorithms. See doc/mangement-notes.txt for a complete description of this feature. --management-forget-disconnect Make OpenVPN forget passwords when management session disconnects. This directive does not affect the --http-proxy username/password. It is always cached. --management-hold Start OpenVPN in a hibernating state, until a client of the management interface explicitly starts it with the hold release command. --management-log-cache n Cache the most recent n lines of log file history for usage by the management channel. --management-query-passwords Query management channel for private key password and --auth-user-pass username/password. Only query the management channel for inputs which ordinarily would have been queried from the console. --management-query-proxy Query management channel for proxy server information for a specific --remote (client-only). --management-query-remote Allow management interface to override --remote directives (client-only). --management-signal Send SIGUSR1 signal to OpenVPN if management session disconnects. This is useful when you wish to disconnect an OpenVPN session on user logoff. For --management-client this option is not needed since a disconnect will always generate a SIGTERM. --management-up-down Report tunnel up/down events to management interface. Plug-in Interface Options OpenVPN can be extended by loading external plug-in modules at runtime. These plug-ins must be prebuilt and adhere to the OpenVPN Plug-In API. --plugin args Loads an OpenVPN plug-in module. Valid syntax: plugin module-name plugin module-name \u0026quot;arguments\u0026quot; The module-name needs to be the first argument, indicating the plug-in to load. The second argument is an optional init string which will be passed directly to the plug-in. If the init consists of multiple arguments it must be enclosed in double-quotes (\u0026quot;). Multiple plugin modules may be loaded into one OpenVPN process. The module-name argument can be just a filename or a filename with a relative or absolute path. The format of the filename and path defines if the plug-in will be loaded from a default plug-in directory or outside this directory. --plugin path Effective directory used ===================== ============================= myplug.so DEFAULT_DIR/myplug.so subdir/myplug.so DEFAULT_DIR/subdir/myplug.so ./subdir/myplug.so CWD/subdir/myplug.so /usr/lib/my/plug.so /usr/lib/my/plug.so DEFAULT_DIR is replaced by the default plug-in directory, which is configured at the build time of OpenVPN. CWD is the current directory where OpenVPN was started or the directory Open‐ VPN have switched into via the --cd option before the --plugin option. For more information and examples on how to build OpenVPN plug-in modules, see the README file in the plugin folder of the OpenVPN source distribution. If you are using an RPM install of OpenVPN, see /usr/share/openvpn/plugin. The documentation is in doc and the actual plugin modules are in lib. Multiple plugin modules can be cascaded, and modules can be used in tandem with scripts. The modules will be called by OpenVPN in the order that they are declared in the config file. If both a plugin and script are configured for the same callback, the script will be called last. If the return code of the module/script controls an authentication function (such as tls-verify, auth-user-pass-verify, or client-connect), then every module and script must return success (0) in order for the connection to be authenticated. WARNING: Plug-ins may do deferred execution, meaning the plug-in will return the control back to the main OpenVPN process and provide the plug-in result later on via a different thread or process. OpenVPN does NOT support multiple authentication plug-ins where more than one plugin tries to do deferred authentication. If this behaviour is detected, OpenVPN will shut down upon first authentication. Windows-Specific Options --allow-nonadmin TAP-adapter (Standalone) Set TAP-adapter to allow access from non-administrative accounts. If TAP-adapter is omitted, all TAP adapters on the system will be configured to allow non-admin access. The non-admin access setting will only persist for the length of time that the TAP-Win32 device object and driver remain loaded, and will need to be re-enabled after a reboot, or if the driver is unloaded and reloaded. This directive can only be used by an administrator. --block-outside-dns Block DNS servers on other network adapters to prevent DNS leaks. This option prevents any application from accessing TCP or UDP port 53 except one inside the tunnel. It uses Windows Filtering Platform (WFP) and works on Windows Vista or later. This option is considered unknown on non-Windows platforms and unsupported on Windows XP, resulting in fatal error. You may want to use --setenv opt or --ignore-unknown-option (not suitable for Windows XP) to ignore said error. Note that pushing unknown options from server does not trigger fatal errors. --cryptoapicert select-string (Windows/OpenSSL Only) Load the certificate and private key from the Windows Certificate System Store. Use this option instead of --cert and --key. This makes it possible to use any smart card, supported by Windows, but also any kind of certificate, residing in the Cert Store, where you have access to the private key. This option has been tested with a couple of different smart cards (GemSAFE, Cryptoflex, and Swedish Post Office eID) on the client side, and also an imported PKCS12 software certificate on the server side. To select a certificate, based on a substring search in the certificate's subject: cryptoapicert \u0026quot;SUBJ:Peter Runestig\u0026quot; To select a certificate, based on certificate's thumbprint: cryptoapicert \u0026quot;THUMB:f6 49 24 41 01 b4 ...\u0026quot; The thumbprint hex string can easily be copy-and-pasted from the Windows Certificate Store GUI. --dhcp-release Ask Windows to release the TAP adapter lease on shutdown. This option has no effect now, as it is enabled by default starting with OpenVPN 2.4.1. --dhcp-renew Ask Windows to renew the TAP adapter lease on startup. This option is normally unnecessary, as Windows automatically triggers a DHCP renegotiation on the TAP adapter when it comes up, however if you set the TAP-Win32 adapter Media Status property to \u0026quot;Always Connected\u0026quot;, you may need this flag. --ip-win32 method When using --ifconfig on Windows, set the TAP-Win32 adapter IP address and netmask using method. Don't use this option unless you are also using --ifconfig. manual Don't set the IP address or netmask automatically. Instead output a message to the console telling the user to configure the adapter manually and indicating the IP/netmask which OpenVPN expects the adapter to be set to. dynamic [offset] [lease-time] Automatically set the IP address and netmask by replying to DHCP query messages generated by the kernel. This mode is probably the \u0026quot;cleanest\u0026quot; solution for setting the TCP/IP properties since it uses the well-known DHCP protocol. There are, however, two prerequisites for using this mode: 1. The TCP/IP properties for the TAP-Win32 adapter must be set to \u0026quot;Obtain an IP address automatically\u0026quot;, and 2. OpenVPN needs to claim an IP address in the subnet for use as the virtual DHCP server address. By default in --dev tap mode, OpenVPN will take the normally unused first address in the subnet. For example, if your subnet is 192.168.4.0 netmask 255.255.255.0, then OpenVPN will take the IP address 192.168.4.0 to use as the virtual DHCP server address. In --dev tun mode, OpenVPN will cause the DHCP server to masquerade as if it were coming from the remote endpoint. The optional offset parameter is an integer which is \u0026gt; -256 and \u0026lt; 256 and which defaults to 0. If offset is positive, the DHCP server will masquerade as the IP address at network address + offset. If offset is negative, the DHCP server will masquerade as the IP address at broadcast address + offset. The Windows ipconfig /all command can be used to show what Windows thinks the DHCP server address is. OpenVPN will \u0026quot;claim\u0026quot; this address, so make sure to use a free address. Hav‐ ing said that, different OpenVPN instantiations, including different ends of the same connection, can share the same virtual DHCP server address. The lease-time parameter controls the lease time of the DHCP assignment given to the TAP-Win32 adapter, and is denoted in seconds. Normally a very long lease time is preferred because it prevents routes involving the TAP-Win32 adapter from being lost when the system goes to sleep. The default lease time is one year. netsh Automatically set the IP address and netmask using the Windows command-line \u0026quot;netsh\u0026quot; command. This method appears to work correctly on Windows XP but not Windows 2000. ipapi Automatically set the IP address and netmask using the Windows IP Helper API. This approach does not have ideal semantics, though testing has indicated that it works okay in practice. If you use this option, it is best to leave the TCP/IP properties for the TAP-Win32 adapter in their default state, i.e. \u0026quot;Obtain an IP address automatically.\u0026quot; adaptive (Default) Try dynamic method initially and fail over to netsh if the DHCP negotiation with the TAP-Win32 adapter does not succeed in 20 seconds. Such failures have been known to occur when certain third-party firewall packages installed on the client machine block the DHCP negotiation used by the TAP-Win32 adapter. Note that if the netsh failover occurs, the TAP-Win32 adapter TCP/IP properties will be reset from DHCP to static, and this will cause future OpenVPN startups using the adaptive mode to use netsh immediately, rather than trying dynamic first. To \u0026quot;unstick\u0026quot; the adaptive mode from using netsh, run OpenVPN at least once using the dynamic mode to restore the TAP-Win32 adapter TCP/IP properties to a DHCP configuration. --pause-exit Put up a \u0026quot;press any key to continue\u0026quot; message on the console prior to OpenVPN program exit. This option is automatically used by the Windows explorer when OpenVPN is run on a configura‐ tion file using the right-click explorer menu. --register-dns Run ipconfig /flushdns and ipconfig /registerdns on connection initiation. This is known to kick Windows into recognizing pushed DNS servers. --route-method m Which method m to use for adding routes on Windows? adaptive (default) Try IP helper API first. If that fails, fall back to the route.exe shell command. ipapi Use IP helper API. exe Call the route.exe shell command. --service args Should be used when OpenVPN is being automatically executed by another program in such a context that no interaction with the user via display or keyboard is possible. Valid syntax: service exit-event [0|1] In general, end-users should never need to explicitly use this option, as it is automatically added by the OpenVPN service wrapper when a given OpenVPN configuration is being run as a service. exit-event is the name of a Windows global event object, and OpenVPN will continuously monitor the state of this event object and exit when it becomes signaled. The second parameter indicates the initial state of exit-event and normally defaults to 0. Multiple OpenVPN processes can be simultaneously executed with the same exit-event parameter. In any case, the controlling process can signal exit-event, causing all such OpenVPN pro‐ cesses to exit. When executing an OpenVPN process using the --service directive, OpenVPN will probably not have a console window to output status/error messages, therefore it is useful to use --log or --log-append to write these messages to a file. --show-adapters (Standalone) Show available TAP-Win32 adapters which can be selected using the --dev-node option. On non-Windows systems, the ifconfig(8) command provides similar functionality. --show-net (Standalone) Show OpenVPN's view of the system routing table and network adapter list. --show-net-up Output OpenVPN's view of the system routing table and network adapter list to the syslog or log file after the TUN/TAP adapter has been brought up and any routes have been added. --show-valid-subnets (Standalone) Show valid subnets for --dev tun emulation. Since the TAP-Win32 driver exports an ethernet interface to Windows, and since TUN devices are point-to-point in nature, it is necessary for the TAP-Win32 driver to impose certain constraints on TUN endpoint address selection. Namely, the point-to-point endpoints used in TUN device emulation must be the middle two addresses of a /30 subnet (netmask 255.255.255.252). --tap-sleep n Cause OpenVPN to sleep for n seconds immediately after the TAP-Win32 adapter state is set to \u0026quot;connected\u0026quot;. This option is intended to be used to troubleshoot problems with the --ifconfig and --ip-win32 options, and is used to give the TAP-Win32 adapter time to come up before Windows IP Helper API operations are applied to it. --win-sys path Set the Windows system directory pathname to use when looking for system executables such as route.exe and netsh.exe. By default, if this directive is not specified, OpenVPN will use the SystemRoot environment variable. This option has changed behaviour since OpenVPN 2.3. Earlier you had to define --win-sys env to use the SystemRoot environment variable, otherwise it defaulted to C:\\\\WINDOWS. It is not needed to use the env keyword any more, and it will just be ignored. A warning is logged when this is found in the configuration file. --windows-driver drv Specifies which tun driver to use. Values are tap-windows6 (default) and wintun. This is a Windows-only option. wintun\u0026quot; requires --dev tun and the OpenVPN process to run elevated, or be invoked using the Interactive Service. Standalone Debug Options --show-gateway args (Standalone) Show current IPv4 and IPv6 default gateway and interface towards the gateway (if the protocol in question is enabled). Valid syntax: --show-gateway --show-gateway IPv6-target For IPv6 this queries the route towards ::/128, or the specified IPv6 target address if passed as argument. For IPv4 on Linux, Windows, MacOS and BSD it looks for a 0.0.0.0/0 route. If there are more specific routes, the result will not always be matching the route of the IPv4 packets to the VPN gateway. Advanced Expert Options These are options only required when special tweaking is needed, often used when debugging or testing out special usage scenarios. --hash-size args Set the size of the real address hash table to r and the virtual address table to v. Valid syntax: hash-size r v By default, both tables are sized at 256 buckets. --bcast-buffers n Allocate n buffers for broadcast datagrams (default 256). --persist-local-ip Preserve initially resolved local IP address and port number across SIGUSR1 or --ping-restart restarts. --persist-remote-ip Preserve most recently authenticated remote IP address and port number across SIGUSR1 or --ping-restart restarts. --prng args (Advanced) Change the PRNG (Pseudo-random number generator) parameters Valid syntaxes: prng alg prng alg nsl Changes the PRNG to use digest algorithm alg (default sha1), and set nsl (default 16) to the size in bytes of the nonce secret length (between 16 and 64). Set alg to none to disable the PRNG and use the OpenSSL RAND_bytes function instead for all of OpenVPN's pseudo-random number needs. --rcvbuf size Set the TCP/UDP socket receive buffer size. Defaults to operating system default. --shaper n Limit bandwidth of outgoing tunnel data to n bytes per second on the TCP/UDP port. Note that this will only work if mode is set to p2p. If you want to limit the bandwidth in both di‐ rections, use this option on both peers. OpenVPN uses the following algorithm to implement traffic shaping: Given a shaper rate of n bytes per second, after a datagram write of b bytes is queued on the TCP/UDP port, wait a minimum of (b / n) seconds before queuing the next write. It should be noted that OpenVPN supports multiple tunnels between the same two peers, allowing you to construct full-speed and reduced bandwidth tunnels at the same time, routing low-priority data such as off-site backups over the reduced bandwidth tunnel, and other data over the full-speed tunnel. Also note that for low bandwidth tunnels (under 1000 bytes per second), you should probably use lower MTU values as well (see above), otherwise the packet latency will grow so large as to trigger timeouts in the TLS layer and TCP connections running over the tunnel. OpenVPN allows n to be between 100 bytes/sec and 100 Mbytes/sec. --sndbuf size Set the TCP/UDP socket send buffer size. Defaults to operating system default. --tcp-queue-limit n Maximum number of output packets queued before TCP (default 64). When OpenVPN is tunneling data from a TUN/TAP device to a remote client over a TCP connection, it is possible that the TUN/TAP device might produce data at a faster rate than the TCP connection can support. When the number of output packets queued before sending to the TCP socket reaches this limit for a given client connection, OpenVPN will start to drop outgoing packets directed at this client. --txqueuelen n (Linux only) Set the TX queue length on the TUN/TAP interface. Currently defaults to operating system default. UNSUPPORTED OPTIONS Options listed in this section have been removed from OpenVPN and are no longer supported --client-cert-not-required Removed in OpenVPN 2.5. This should be replaxed with --verify-client-cert none. --ifconfig-pool-linear Removed in OpenVPN 2.5. This should be replaced with --topology p2p. --key-method Removed in OpenVPN 2.5. This option should not be used, as using the old key-method weakens the VPN tunnel security. The old key-method was also only needed when the remote side was older than OpenVPN 2.0. --no-iv Removed in OpenVPN 2.5. This option should not be used as it weakens the VPN tunnel security. This has been a NOOP option since OpenVPN 2.4. --no-replay Removed in OpenVPN 2.5. This option should not be used as it weakens the VPN tunnel security. --ns-cert-type Removed in OpenVPN 2.5. The nsCertType field is no longer supported in recent SSL/TLS libraries. If your certificates does not include key usage and extended key usage fields, they must be upgraded and the --remote-cert-tls option should be used instead. CONNECTION PROFILES Client configuration files may contain multiple remote servers which it will attempt to connect against. But there are some configuration options which are related to specific --remote op‐ tions. For these use cases, connection profiles are the solution. By enacpulating the --remote option and related options within \u0026lt;connection\u0026gt; and \u0026lt;/connection\u0026gt;, these options are handled as a group. An OpenVPN client will try each connection profile sequentially until it achieves a successful connection. --remote-random can be used to initially \u0026quot;scramble\u0026quot; the connection list. Here is an example of connection profile usage: client dev tun \u0026lt;connection\u0026gt; remote 198.19.34.56 1194 udp \u0026lt;/connection\u0026gt; \u0026lt;connection\u0026gt; remote 198.19.34.56 443 tcp \u0026lt;/connection\u0026gt; \u0026lt;connection\u0026gt; remote 198.19.34.56 443 tcp http-proxy 192.168.0.8 8080 \u0026lt;/connection\u0026gt; \u0026lt;connection\u0026gt; remote 198.19.36.99 443 tcp http-proxy 192.168.0.8 8080 \u0026lt;/connection\u0026gt; persist-key persist-tun pkcs12 client.p12 remote-cert-tls server verb 3 First we try to connect to a server at 198.19.34.56:1194 using UDP. If that fails, we then try to connect to 198.19.34.56:443 using TCP. If that also fails, then try connecting through an HTTP proxy at 192.168.0.8:8080 to 198.19.34.56:443 using TCP. Finally, try to connect through the same proxy to a server at 198.19.36.99:443 using TCP. The following OpenVPN options may be used inside of a \u0026lt;connection\u0026gt; block: bind, connect-retry, connect-retry-max, connect-timeout, explicit-exit-notify, float, fragment, http-proxy, http-proxy-option, key-direction, link-mtu, local, lport, mssfix, mtu-disc, nobind, port, proto, remote, rport, socks-proxy, tls-auth, tls-crypt, tun-mtu and, tun-mtu-extra. A defaulting mechanism exists for specifying options to apply to all \u0026lt;connection\u0026gt; profiles. If any of the above options (with the exception of remote ) appear outside of a \u0026lt;connection\u0026gt; block, but in a configuration file which has one or more \u0026lt;connection\u0026gt; blocks, the option setting will be used as a default for \u0026lt;connection\u0026gt; blocks which follow it in the configuration file. For example, suppose the nobind option were placed in the sample configuration file above, near the top of the file, before the first \u0026lt;connection\u0026gt; block. The effect would be as if nobind were declared in all \u0026lt;connection\u0026gt; blocks below it. INLINE FILE SUPPORT OpenVPN allows including files in the main configuration for the --ca, --cert, --dh, --extra-certs, --key, --pkcs12, --secret, --crl-verify, --http-proxy-user-pass, --tls-auth, --auth-gen-to‐ ken-secret, --tls-crypt and --tls-crypt-v2 options. Each inline file started by the line \u0026lt;option\u0026gt; and ended by the line \u0026lt;/option\u0026gt; Here is an example of an inline file usage \u0026lt;cert\u0026gt; -----BEGIN CERTIFICATE----- [...] -----END CERTIFICATE----- \u0026lt;/cert\u0026gt; When using the inline file feature with --pkcs12 the inline file has to be base64 encoded. Encoding of a .p12 file into base64 can be done for example with OpenSSL by running openssl base64 -in input.p12 SIGNALS SIGHUP Cause OpenVPN to close all TUN/TAP and network connections, restart, re-read the configuration file (if any), and reopen TUN/TAP and network connections. SIGUSR1 Like SIGHUP`, except don't re-read configuration file, and possibly don't close and reopen TUN/TAP device, re-read key files, preserve local IP address/port, or preserve most recently authenticated remote IP address/port based on --persist-tun, --persist-key, --persist-local-ip and --persist-remote-ip options respectively (see above). This signal may also be internally generated by a timeout condition, governed by the --ping-restart option. This signal, when combined with --persist-remote-ip, may be sent when the underlying parameters of the host's network interface change such as when the host is a DHCP client and is as‐ signed a new IP address. See --ipchange for more information. SIGUSR2 Causes OpenVPN to display its current statistics (to the syslog file if --daemon is used, or stdout otherwise). SIGINT, SIGTERM Causes OpenVPN to exit gracefully. FAQ https://community.openvpn.net/openvpn/wiki/FAQ HOWTO For a more comprehensive guide to setting up OpenVPN in a production setting, see the OpenVPN HOWTO at https://openvpn.net/community-resources/how-to/ PROTOCOL For a description of OpenVPN's underlying protocol, see https://openvpn.net/community-resources/openvpn-protocol/ WEB OpenVPN's web site is at https://openvpn.net/ Go here to download the latest version of OpenVPN, subscribe to the mailing lists, read the mailing list archives, or browse the SVN repository. BUGS Report all bugs to the OpenVPN team info@openvpn.net SEE ALSO openvpn-examples(5), dhcpcd(8), ifconfig(8), openssl(1), route(8), scp(1) ssh(1) NOTES This product includes software developed by the OpenSSL Project (https://www.openssl.org/) For more information on the TLS protocol, see http://www.ietf.org/rfc/rfc2246.txt For more information on the LZO real-time compression library see https://www.oberhumer.com/opensource/lzo/ COPYRIGHT Copyright (C) 2002-2020 OpenVPN Inc This program is free software; you can redistribute it and/or modify it under the terms of the GNU General Public License version 2 as published by the Free Software Foundation. AUTHORS James Yonan james@openvpn.net OPENVPN(8) "}),e.add({id:27,href:"/docs/tools/utility/ouch/",title:"Ouch",description:`Description # ouch is a command-line tool to apply operations on files.
Installation # brew install ouch Usage # ouch d foo.tar.gz Resources # ouch Similar # tar unzip unrar 7z xz bzip2 gzip zip p7zip help # A command-line utility for easily compressing and decompressing files and directories. Supported formats: tar, zip, bz/bz2, gz, lz4, xz/lz/lzma, zst. Repository: https://github.com/ouch-org/ouch Usage: ouch [OPTIONS] \u0026lt;COMMAND\u0026gt; Commands: compress Compress one or more files into one output file [aliases: c] decompress Decompresses one or more files, optionally into another folder [aliases: d] list List contents of an archive [aliases: l] help Print this message or the help of the given subcommand(s) Options: -y, --yes Skip [Y/n] questions positively -n, --no Skip [Y/n] questions negatively -A, --accessible Activate accessibility mode, reducing visual noise [env: ACCESSIBLE=] -H, --hidden Ignores hidden files -q, --quiet Silences output -g, --gitignore Ignores files matched by git's ignore files -h, --help Print help (see a summary with '-h') -V, --version Print version `,content:`Description # ouch is a command-line tool to apply operations on files.
Installation # brew install ouch Usage # ouch d foo.tar.gz Resources # ouch Similar # tar unzip unrar 7z xz bzip2 gzip zip p7zip help # A command-line utility for easily compressing and decompressing files and directories. Supported formats: tar, zip, bz/bz2, gz, lz4, xz/lz/lzma, zst. Repository: https://github.com/ouch-org/ouch Usage: ouch [OPTIONS] \u0026lt;COMMAND\u0026gt; Commands: compress Compress one or more files into one output file [aliases: c] decompress Decompresses one or more files, optionally into another folder [aliases: d] list List contents of an archive [aliases: l] help Print this message or the help of the given subcommand(s) Options: -y, --yes Skip [Y/n] questions positively -n, --no Skip [Y/n] questions negatively -A, --accessible Activate accessibility mode, reducing visual noise [env: ACCESSIBLE=] -H, --hidden Ignores hidden files -q, --quiet Silences output -g, --gitignore Ignores files matched by git's ignore files -h, --help Print help (see a summary with '-h') -V, --version Print version `}),e.add({id:28,href:"/docs/tools/utility/neovim/",title:"Neovim",description:`Description # Neovim is a fork of Vim that is focused on extensibility and agility.
Installation # brew install neovim Usage # nvim help in new tab :help Resources # Neovim Neovim on GitHub vim-plug Vim Awesome Vim Awesome - Plugins Vim Awesome - Themes Vim Awesome - Colorschemes Vim Awesome - Scripts Vim Awesome - Tools Vim Awesome - Tutorials Vim Awesome - Books Vim Awesome - Videos Vim cheat sheet Vim Cheat Sheet Vim Tutorial Vim Tutorial help # NVIM(1) BSD General Commands Manual NVIM(1) NAME nvim — edit text SYNOPSIS nvim [options] [file .`,content:"Description # Neovim is a fork of Vim that is focused on extensibility and agility.\nInstallation # brew install neovim Usage # nvim help in new tab :help Resources # Neovim Neovim on GitHub vim-plug Vim Awesome Vim Awesome - Plugins Vim Awesome - Themes Vim Awesome - Colorschemes Vim Awesome - Scripts Vim Awesome - Tools Vim Awesome - Tutorials Vim Awesome - Books Vim Awesome - Videos Vim cheat sheet Vim Cheat Sheet Vim Tutorial Vim Tutorial help # NVIM(1) BSD General Commands Manual NVIM(1) NAME nvim — edit text SYNOPSIS nvim [options] [file ...] nvim [options] - nvim [options] -t tag nvim [options] -q [errorfile] DESCRIPTION nvim is a text editor based on Vim. Start nvim followed by any number of options and/or files: nvim [options] [file ...] Commands in nvim begin with colon (‘:’). Type \u0026quot;:help subject\u0026quot; to get help on a specific subject. Use \u0026lt;Tab\u0026gt; and CTRL-D to complete subjects (\u0026quot;:help cmdline-completion\u0026quot;). The \u0026quot;quickref\u0026quot; help section is a condensed reference of editor features: :help quickref If you are new to Vim/Nvim, start with the 30-minute tutorial: :Tutor After installing/updating Nvim, it's a good idea to run the self-check: :checkhealth file ... File(s) to edit. Opens one buffer per file. To switch between buffers, use the :next and :previous commands. - Reads text from standard input until EOF, then opens a buffer with that text. User input is read from standard error, which should be a terminal. OPTIONS -t tag Finds tag in the tags file, the associated file becomes the current file and the associated command is executed. Cursor is positioned at the tag location in the file. :help tag- commands -q [errorfile] QuickFix mode. Display the first error in errorfile. If errorfile is omitted, the value of the 'errorfile' option is used (defaults to errors.err). Further errors can be jumped to with the :cnext command. :help quickfix -- End of options. Remaining arguments are treated as literal file names, including filenames starting with hyphen (‘-’). -e Ex mode, reading stdin as Ex commands. :help Ex-mode -E Ex mode, reading stdin as text. :help Ex-mode -es Silent (non-interactive) Ex mode, reading stdin as Ex commands. Useful for scripting because it does NOT start a UI, unlike -e. :help silent-mode -Es Silent (non-interactive) Ex mode, reading stdin as text. Useful for scripting because it does NOT start a UI, unlike -E. :help silent-mode -d Diff mode. Show the difference between two to eight files, similar to sdiff(1). :help diff -R Read-only mode. Sets the 'readonly' option. Implies -n. Buffers can still be edited, but cannot be written to disk if already associated with a file. To overwrite a file, add an exclamation mark to the relevant Ex command, such as :w!. :help 'readonly' -m Resets the 'write' option, to disable file modifications. Writing to a file is disabled, but buffers can still be modified. -M Resets the 'write' and 'modifiable' options, to disable file and buffer modifications. -b Binary mode. :help edit-binary -l Lisp mode. Sets the 'lisp' and 'showmatch' options. -A Arabic mode. Sets the 'arabic' option. -H Hebrew mode. Sets the 'hkmap' and 'rightleft' options. -V[N][file] Verbose mode. Prints debug messages. N is the 'verbose' level, defaults to 10. If file is specified, append messages to file instead of printing them. :help 'verbose' -D Debug mode for VimL (Vim script). Started when executing the first command from a script. :help debug-mode -n Disable the use of swap files. Sets the 'updatecount' option to 0. Can be useful for editing files on a slow medium. -r [file] Recovery mode. If file is omitted then list swap files with recovery information. Otherwise the swap file file is used to recover a crashed session. The swap file has the same name as the file it's associated with, but with ‘.swp’ appended. :help recovery -L [file] Alias for -r. -u vimrc Use vimrc instead of the default ~/.config/nvim/init.vim. If vimrc is NORC, do not load any initialization files (except plugins). If vimrc is NONE, loading plugins is also skipped. :help initialization -i shada Use shada instead of the default ~/.local/state/nvim/shada/main.shada. If shada is NONE, do not read or write a ShaDa file. :help shada --noplugin Skip loading plugins. Implied by -u NONE. --clean Start Nvim with \u0026quot;factory defaults\u0026quot; (no user config and plugins, no shada). :help --clean -o[N] Open N windows stacked horizontally. If N is omitted, open one window for each file. If N is less than the number of file arguments, allocate windows for the first N files and hide the rest. -O[N] Like -o, but tile windows vertically. -p[N] Like -o, but for tab pages. +[linenum] For the first file, position the cursor on line linenum. If linenum is omitted, position the cursor on the last line of the file. +5 and -c 5 on the command-line are equivalent to :5 inside nvim. +/[pattern] For the first file, position the cursor on the first occurrence of pattern. If pattern is omitted, the most recent search pattern is used (if any). +/foo and -c /foo on the com‐ mand-line are equivalent to /foo and :/foo inside nvim. :help search-pattern +command, -c command Execute command after reading the first file. Up to 10 instances allowed. \u0026quot;+foo\u0026quot; and -c \u0026quot;foo\u0026quot; are equivalent. --cmd command Like -c, but execute command before processing any vimrc. Up to 10 instances of these can be used independently from instances of -c. -S [session] Source session after the first file argument has been read. Equivalent to -c \u0026quot;source session\u0026quot;. session cannot start with a hyphen (‘-’). If session is omitted then Session.vim is used, if found. :help session-file -s scriptin Read normal mode commands from scriptin. The same can be done with the command :source! scriptin. If the end of the file is reached before nvim exits, further characters are read from the keyboard. -w scriptout Append all typed characters to scriptout. Can be used for creating a script to be used with -s or :source!. -W scriptout Like -w, but truncate scriptout. --startuptime file During startup, append timing messages to file. Can be used to diagnose slow startup times. --api-info Dump API metadata serialized to msgpack and exit. --embed Use standard input and standard output as a msgpack-rpc channel. :help --embed --headless Do not start a UI. When supplied with --embed this implies that the embedding application does not intend to (immediately) start a UI. Also useful for \u0026quot;scraping\u0026quot; messages in a pipe. :help --headless --listen address Start RPC server on this pipe or TCP socket. -h, --help Print usage information and exit. -v, --version Print version information and exit. ENVIRONMENT NVIM_LOG_FILE Low-level log file, usually found at ~/.local/state/nvim/log. :help $NVIM_LOG_FILE VIM Used to locate user files, such as init.vim. System-dependent. :help $VIM VIMRUNTIME Used to locate runtime files (documentation, syntax highlighting, etc.). XDG_CONFIG_HOME Path to the user-local configuration directory, see FILES. Defaults to ~/.config. :help xdg XDG_STATE_HOME Like XDG_CONFIG_HOME, but used to store data not generally edited by the user, namely swap, backup, and ShaDa files. Defaults to ~/.local/state. :help xdg XDG_DATA_HOME Like XDG_CONFIG_HOME, but used to store data not generally edited by the user, things like runtime files. Defaults to ~/.local/share. :help xdg VIMINIT Ex commands to be executed at startup. :help VIMINIT SHELL Used to initialize the 'shell' option, which decides the default shell used by features like :terminal, :!, and system(). FILES ~/.config/nvim/init.vim User-local nvim configuration file. ~/.config/nvim User-local nvim configuration directory. See also XDG_CONFIG_HOME. $VIM/sysinit.vim System-global nvim configuration file. $VIM System-global nvim runtime directory. AUTHORS Nvim was started by Thiago de Arruda. Most of Vim was written by Bram Moolenaar. Vim is based on Stevie, worked on by Tim Thompson, Tony Andrews, and G.R. (Fred) Walter. :help credits BSD December 17, 2017 BSD "}),e.add({id:29,href:"/docs/tools/utility/mdcat/",title:"Mdcat",description:`Description # mdcat is a command-line tool that renders markdown files to the terminal.
Installation # brew install mdcat Usage # mdcat README.md Resources # mdcat help # cat for markdown: Show markdown documents in terminals Usage: mdcat [OPTIONS] [FILENAMES]... Arguments: [FILENAMES]... Files to read. If - read from standard input instead [default: -] Options: -c, --no-colour Disable all colours and other styles --columns \u0026lt;COLUMNS\u0026gt; Maximum number of columns to use for output -l, --local Do not load remote resources like images --fail Exit immediately if any error occurs processing an input file --detect-terminal Print detected terminal name and exit --ansi Skip terminal detection and only use ANSI formatting -p, --paginate Paginate the output of mdcat with a pager like less -P, --no-pager Do not paginate output (default).`,content:`Description # mdcat is a command-line tool that renders markdown files to the terminal.
Installation # brew install mdcat Usage # mdcat README.md Resources # mdcat help # cat for markdown: Show markdown documents in terminals Usage: mdcat [OPTIONS] [FILENAMES]... Arguments: [FILENAMES]... Files to read. If - read from standard input instead [default: -] Options: -c, --no-colour Disable all colours and other styles --columns \u0026lt;COLUMNS\u0026gt; Maximum number of columns to use for output -l, --local Do not load remote resources like images --fail Exit immediately if any error occurs processing an input file --detect-terminal Print detected terminal name and exit --ansi Skip terminal detection and only use ANSI formatting -p, --paginate Paginate the output of mdcat with a pager like less -P, --no-pager Do not paginate output (default). Overrides an earlier --paginate -h, --help Print help -V, --version Print version See 'man 1 mdcat' for more information. Report issues to \u0026lt;https://github.com/swsnr/mdcat\u0026gt;. `}),e.add({id:30,href:"/docs/tools/utility/monolith/",title:"Monolith",description:`Description # monolith is a command-line tool that converts web pages to plain text or PDF.
Installation # brew install monolith Usage # monolith https://example.com Resources # monolith help # monolith 2.7.0 Sunshine \u0026lt;sunshine@uberspace.net\u0026gt; Mahdi Robatipoor \u0026lt;mahdi.robatipoor@gmail.com\u0026gt; Emmanuel Delaborde \u0026lt;th3rac25@gmail.com\u0026gt; Emi Simpson \u0026lt;emi@alchemi.dev\u0026gt; rhysd \u0026lt;lin90162@yahoo.co.jp\u0026gt; _____ ______________ __________ ___________________ ___ | \\ / \\ | | | | | | | \\_/ __ \\_| __ | | ___ ___ |__| | | | | | | | | | | | | | | |\\ /| |__| _ |__| |____| | | | | __ | | | \\___/ | | \\ | | | | | | | |___| |__________| \\_____________________| |___| |___| |___| CLI tool for saving web pages as a single HTML file USAGE: monolith [OPTIONS] \u0026lt;target\u0026gt; ARGS: \u0026lt;target\u0026gt; URL or file path, use - for STDIN OPTIONS: -a, --no-audio Removes audio sources -b, --base-url \u0026lt;http://localhost/\u0026gt; Sets custom base URL -B, --blacklist-domains Treat list of specified domains as blacklist -c, --no-css Removes CSS -C, --charset \u0026lt;UTF-8\u0026gt; Enforces custom encoding -d, --domain \u0026lt;example.`,content:`Description # monolith is a command-line tool that converts web pages to plain text or PDF.
Installation # brew install monolith Usage # monolith https://example.com Resources # monolith help # monolith 2.7.0 Sunshine \u0026lt;sunshine@uberspace.net\u0026gt; Mahdi Robatipoor \u0026lt;mahdi.robatipoor@gmail.com\u0026gt; Emmanuel Delaborde \u0026lt;th3rac25@gmail.com\u0026gt; Emi Simpson \u0026lt;emi@alchemi.dev\u0026gt; rhysd \u0026lt;lin90162@yahoo.co.jp\u0026gt; _____ ______________ __________ ___________________ ___ | \\ / \\ | | | | | | | \\_/ __ \\_| __ | | ___ ___ |__| | | | | | | | | | | | | | | |\\ /| |__| _ |__| |____| | | | | __ | | | \\___/ | | \\ | | | | | | | |___| |__________| \\_____________________| |___| |___| |___| CLI tool for saving web pages as a single HTML file USAGE: monolith [OPTIONS] \u0026lt;target\u0026gt; ARGS: \u0026lt;target\u0026gt; URL or file path, use - for STDIN OPTIONS: -a, --no-audio Removes audio sources -b, --base-url \u0026lt;http://localhost/\u0026gt; Sets custom base URL -B, --blacklist-domains Treat list of specified domains as blacklist -c, --no-css Removes CSS -C, --charset \u0026lt;UTF-8\u0026gt; Enforces custom encoding -d, --domain \u0026lt;example.com\u0026gt; Specify domains to use for white/black-listing -e, --ignore-errors Ignore network errors -f, --no-frames Removes frames and iframes -F, --no-fonts Removes fonts -h, --help Print help information -i, --no-images Removes images -I, --isolate Cuts off document from the Internet -j, --no-js Removes JavaScript -k, --insecure Allows invalid X.509 (TLS) certificates -M, --no-metadata Excludes timestamp and source information -n, --unwrap-noscript Replaces NOSCRIPT elements with their contents -o, --output \u0026lt;document.html\u0026gt; Writes output to \u0026lt;file\u0026gt;, use - for STDOUT -s, --silent Suppresses verbosity -t, --timeout \u0026lt;60\u0026gt; Adjusts network request timeout -u, --user-agent \u0026lt;Firefox\u0026gt; Sets custom User-Agent string -v, --no-video Removes video sources -V, --version Print version information `}),e.add({id:31,href:"/docs/tools/utility/macchina/",title:"Macchina",description:`Description # macchina is a minimal, cross-platform system information tool written in Rust.
Installation # brew install macchina Usage # macchina Resources # macchina help # Usage: macchina [OPTIONS] Options: -v, --version Prints version information -o, --show \u0026lt;SHOW\u0026gt; Displays only the specified readouts -d, --doctor Checks the system for failures -U, --long-uptime Lengthens uptime output -S, --long-shell Lengthens shell output -K, --long-kernel Lengthens kernel output -C, --physical-cores Toggles between logical and physical cores -s, --current-shell Toggles between the current shell and the default one -t, --theme \u0026lt;THEME\u0026gt; Specify the name of the theme -l, --list-themes Lists all available themes: built-in and custom -c, --config \u0026lt;CONFIG\u0026gt; Specify a custom path for the configuration file --ascii-artists Lists the original artists of the ASCII art used by macchina -i, --interface \u0026lt;INTERFACE\u0026gt; Specify the network interface for the LocalIP readout -h, --help Print help `,content:`Description # macchina is a minimal, cross-platform system information tool written in Rust.
Installation # brew install macchina Usage # macchina Resources # macchina help # Usage: macchina [OPTIONS] Options: -v, --version Prints version information -o, --show \u0026lt;SHOW\u0026gt; Displays only the specified readouts -d, --doctor Checks the system for failures -U, --long-uptime Lengthens uptime output -S, --long-shell Lengthens shell output -K, --long-kernel Lengthens kernel output -C, --physical-cores Toggles between logical and physical cores -s, --current-shell Toggles between the current shell and the default one -t, --theme \u0026lt;THEME\u0026gt; Specify the name of the theme -l, --list-themes Lists all available themes: built-in and custom -c, --config \u0026lt;CONFIG\u0026gt; Specify a custom path for the configuration file --ascii-artists Lists the original artists of the ASCII art used by macchina -i, --interface \u0026lt;INTERFACE\u0026gt; Specify the network interface for the LocalIP readout -h, --help Print help `}),e.add({id:32,href:"/docs/tools/utility/jq/",title:"Jq",description:`Description # jq is like sed for JSON data - you can use it to slice and filter and map and transform structured data with the same ease that sed, awk, grep and friends let you play with text.
jq is written in portable C, and it has zero runtime dependencies. You can download a single binary, scp it to a far away machine of the same type, and expect it to work.`,content:"Description # jq is like sed for JSON data - you can use it to slice and filter and map and transform structured data with the same ease that sed, awk, grep and friends let you play with text.\njq is written in portable C, and it has zero runtime dependencies. You can download a single binary, scp it to a far away machine of the same type, and expect it to work.\njq can mangle the data format that you have into the one that you want with very little effort, and the program to do so is often shorter and simpler than you\u0026rsquo;d expect.\ninstall # brew install jq sample usage # curl 'https://api.github.com/repos/stedolan/jq/commits?per_page=5' | jq '.[0]' sample output # { \u0026quot;sha\u0026quot;: \u0026quot;d25341478381063d1c76e81b3a52e0592a7c997f\u0026quot;, \u0026quot;commit\u0026quot;: { \u0026quot;author\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;Stephen Dolan\u0026quot;, \u0026quot;email\u0026quot;: \u0026quot;mu@netsoc.tcd.ie\u0026quot;, \u0026quot;date\u0026quot;: \u0026quot;2013-06-22T16:30:59Z\u0026quot; }, \u0026quot;committer\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;Stephen Dolan\u0026quot;, \u0026quot;email\u0026quot;: \u0026quot;mu@netsoc.tcd.ie\u0026quot;, \u0026quot;date\u0026quot;: \u0026quot;2013-06-22T16:30:59Z\u0026quot; }, \u0026quot;message\u0026quot;: \u0026quot;Merge pull request #162 from stedolan/utf8-fixes\\n\\nUtf8 fixes. Closes #161\u0026quot;, \u0026quot;tree\u0026quot;: { \u0026quot;sha\u0026quot;: \u0026quot;6ab697a8dfb5a96e124666bf6d6213822599fb40\u0026quot;, \u0026quot;url\u0026quot;: \u0026quot;https://api.github.com/repos/stedolan/jq/git/trees/6ab697a8dfb5a96e124666bf6d6213822599fb40\u0026quot; }, \u0026quot;url\u0026quot;: \u0026quot;https://api.github.com/repos/stedolan/jq/git/commits/d25341478381063d1c76e81b3a52e0592a7c997f\u0026quot;, \u0026quot;comment_count\u0026quot;: 0 }, \u0026quot;url\u0026quot;: \u0026quot;https://api.github.com/repos/stedolan/jq/commits/d25341478381063d1c76e81b3a52e0592a7c997f\u0026quot;, \u0026quot;html_url\u0026quot;: \u0026quot;https://github.com/stedolan/jq/commit/d25341478381063d1c76e81b3a52e0592a7c997f\u0026quot;, \u0026quot;comments_url\u0026quot;: \u0026quot;https://api.github.com/repos/stedolan/jq/commits/d25341478381063d1c76e81b3a52e0592a7c997f/comments\u0026quot;, \u0026quot;author\u0026quot;: { \u0026quot;login\u0026quot;: \u0026quot;stedolan\u0026quot;, \u0026quot;id\u0026quot;: 79765, \u0026quot;avatar_url\u0026quot;: \u0026quot;https://avatars.githubusercontent.com/u/79765?v=3\u0026quot;, \u0026quot;gravatar_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan\u0026quot;, \u0026quot;html_url\u0026quot;: \u0026quot;https://github.com/stedolan\u0026quot;, \u0026quot;followers_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/followers\u0026quot;, \u0026quot;following_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/following{/other_user}\u0026quot;, \u0026quot;gists_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/gists{/gist_id}\u0026quot;, \u0026quot;starred_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/starred{/owner}{/repo}\u0026quot;, \u0026quot;subscriptions_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/subscriptions\u0026quot;, \u0026quot;organizations_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/orgs\u0026quot;, \u0026quot;repos_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/repos\u0026quot;, \u0026quot;events_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/events{/privacy}\u0026quot;, \u0026quot;received_events_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/received_events\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;User\u0026quot;, \u0026quot;site_admin\u0026quot;: false }, \u0026quot;committer\u0026quot;: { \u0026quot;login\u0026quot;: \u0026quot;stedolan\u0026quot;, \u0026quot;id\u0026quot;: 79765, \u0026quot;avatar_url\u0026quot;: \u0026quot;https://avatars.githubusercontent.com/u/79765?v=3\u0026quot;, \u0026quot;gravatar_id\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan\u0026quot;, \u0026quot;html_url\u0026quot;: \u0026quot;https://github.com/stedolan\u0026quot;, \u0026quot;followers_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/followers\u0026quot;, \u0026quot;following_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/following{/other_user}\u0026quot;, \u0026quot;gists_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/gists{/gist_id}\u0026quot;, \u0026quot;starred_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/starred{/owner}{/repo}\u0026quot;, \u0026quot;subscriptions_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/subscriptions\u0026quot;, \u0026quot;organizations_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/orgs\u0026quot;, \u0026quot;repos_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/repos\u0026quot;, \u0026quot;events_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/events{/privacy}\u0026quot;, \u0026quot;received_events_url\u0026quot;: \u0026quot;https://api.github.com/users/stedolan/received_events\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;User\u0026quot;, \u0026quot;site_admin\u0026quot;: false }, \u0026quot;parents\u0026quot;: [ { \u0026quot;sha\u0026quot;: \u0026quot;54b9c9bdb225af5d886466d72f47eafc51acb4f7\u0026quot;, \u0026quot;url\u0026quot;: \u0026quot;https://api.github.com/repos/stedolan/jq/commits/54b9c9bdb225af5d886466d72f47eafc51acb4f7\u0026quot;, \u0026quot;html_url\u0026quot;: \u0026quot;https://github.com/stedolan/jq/commit/54b9c9bdb225af5d886466d72f47eafc51acb4f7\u0026quot; }, { \u0026quot;sha\u0026quot;: \u0026quot;8b1b503609c161fea4b003a7179b3fbb2dd4345a\u0026quot;, \u0026quot;url\u0026quot;: \u0026quot;https://api.github.com/repos/stedolan/jq/commits/8b1b503609c161fea4b003a7179b3fbb2dd4345a\u0026quot;, \u0026quot;html_url\u0026quot;: \u0026quot;https://github.com/stedolan/jq/commit/8b1b503609c161fea4b003a7179b3fbb2dd4345a\u0026quot; } ] } help # JQ(1) JQ(1) NAME jq - Command-line JSON processor SYNOPSIS jq [options...] filter [files...] jq can transform JSON in various ways, by selecting, iterating, reducing and otherwise mangling JSON documents. For instance, running the command jq ´map(.price) | add´ will take an array of JSON objects as input and return the sum of their \u0026quot;price\u0026quot; fields. jq can accept text input as well, but by default, jq reads a stream of JSON entities (including numbers and other literals) from stdin. Whitespace is only needed to separate entities such as 1 and 2, and true and false. One or more files may be specified, in which case jq will read input from those instead. The options are described in the INVOKING JQ section; they mostly concern input and output formatting. The filter is written in the jq language and specifies how to transform the input file or document. FILTERS A jq program is a \u0026quot;filter\u0026quot;: it takes an input, and produces an output. There are a lot of builtin filters for extracting a particular field of an object, or converting a number to a string, or various other standard tasks. Filters can be combined in various ways - you can pipe the output of one filter into another filter, or collect the output of a filter into an array. Some filters produce multiple results, for instance there´s one that produces all the elements of its input array. Piping that filter into a second runs the second filter for each element of the array. Generally, things that would be done with loops and iteration in other languages are just done by gluing filters together in jq. It´s important to remember that every filter has an input and an output. Even literals like \u0026quot;hello\u0026quot; or 42 are filters - they take an input but always produce the same literal as output. Opera‐ tions that combine two filters, like addition, generally feed the same input to both and combine the results. So, you can implement an averaging filter as add / length - feeding the input ar‐ ray both to the add filter and the length filter and then performing the division. But that´s getting ahead of ourselves. :) Let´s start with something simpler: INVOKING JQ jq filters run on a stream of JSON data. The input to jq is parsed as a sequence of whitespace-separated JSON values which are passed through the provided filter one at a time. The output(s) of the filter are written to standard out, again as a sequence of whitespace-separated JSON data. Note: it is important to mind the shell´s quoting rules. As a general rule it´s best to always quote (with single-quote characters) the jq program, as too many characters with special meaning to jq are also shell meta-characters. For example, jq \u0026quot;foo\u0026quot; will fail on most Unix shells because that will be the same as jq foo, which will generally fail because foo is not defined. When using the Windows command shell (cmd.exe) it´s best to use double quotes around your jq program when given on the command-line (instead of the -f program-file option), but then double-quotes in the jq program need backslash escaping. You can affect how jq reads and writes its input and output using some command-line options: • --version: Output the jq version and exit with zero. • --seq: Use the application/json-seq MIME type scheme for separating JSON texts in jq´s input and output. This means that an ASCII RS (record separator) character is printed before each value on output and an ASCII LF (line feed) is printed after every output. Input JSON texts that fail to parse are ignored (but warned about), discarding all subsequent input until the next RS. This mode also parses the output of jq without the --seq option. • --stream: Parse the input in streaming fashion, outputing arrays of path and leaf values (scalars and empty arrays or empty objects). For example, \u0026quot;a\u0026quot; becomes [[],\u0026quot;a\u0026quot;], and [[],\u0026quot;a\u0026quot;,[\u0026quot;b\u0026quot;]] becomes [[0],[]], [[1],\u0026quot;a\u0026quot;], and [[1,0],\u0026quot;b\u0026quot;]. This is useful for processing very large inputs. Use this in conjunction with filtering and the reduce and foreach syntax to reduce large inputs incrementally. • --slurp/-s: Instead of running the filter for each JSON object in the input, read the entire input stream into a large array and run the filter just once. • --raw-input/-R: Don´t parse the input as JSON. Instead, each line of text is passed to the filter as a string. If combined with --slurp, then the entire input is passed to the filter as a single long string. • --null-input/-n: Don´t read any input at all! Instead, the filter is run once using null as the input. This is useful when using jq as a simple calculator or to construct JSON data from scratch. • --compact-output / -c: By default, jq pretty-prints JSON output. Using this option will result in more compact output by instead putting each JSON object on a single line. • --tab: Use a tab for each indentation level instead of two spaces. • --indent n: Use the given number of spaces (no more than 8) for indentation. • --color-output / -C and --monochrome-output / -M: By default, jq outputs colored JSON if writing to a terminal. You can force it to produce color even if writing to a pipe or a file using -C, and disable color with -M. Colors can be configured with the JQ_COLORS environment variable (see below). • --ascii-output / -a: jq usually outputs non-ASCII Unicode codepoints as UTF-8, even if the input specified them as escape sequences (like \u0026quot;\\u03bc\u0026quot;). Using this option, you can force jq to produce pure ASCII output with every non-ASCII character replaced with the equivalent escape sequence. • --unbuffered Flush the output after each JSON object is printed (useful if you´re piping a slow data source into jq and piping jq´s output elsewhere). • --sort-keys / -S: Output the fields of each object with the keys in sorted order. • --raw-output / -r: With this option, if the filter´s result is a string then it will be written directly to standard output rather than being formatted as a JSON string with quotes. This can be useful for making jq filters talk to non-JSON-based systems. • --join-output / -j: Like -r but jq won´t print a newline after each output. • -f filename / --from-file filename: Read filter from the file rather than from a command line, like awk´s -f option. You can also use ´#´ to make comments. • -Ldirectory / -L directory: Prepend directory to the search list for modules. If this option is used then no builtin search list is used. See the section on modules below. • -e / --exit-status: Sets the exit status of jq to 0 if the last output values was neither false nor null, 1 if the last output value was either false or null, or 4 if no valid result was ever produced. Nor‐ mally jq exits with 2 if there was any usage problem or system error, 3 if there was a jq program compile error, or 0 if the jq program ran. Another way to set the exit status is with the halt_error builtin function. • --arg name value: This option passes a value to the jq program as a predefined variable. If you run jq with --arg foo bar, then $foo is available in the program and has the value \u0026quot;bar\u0026quot;. Note that value will be treated as a string, so --arg foo 123 will bind $foo to \u0026quot;123\u0026quot;. Named arguments are also available to the jq program as $ARGS.named. • --argjson name JSON-text: This option passes a JSON-encoded value to the jq program as a predefined variable. If you run jq with --argjson foo 123, then $foo is available in the program and has the value 123. • --slurpfile variable-name filename: This option reads all the JSON texts in the named file and binds an array of the parsed JSON values to the given global variable. If you run jq with --argfile foo bar, then $foo is avail‐ able in the program and has an array whose elements correspond to the texts in the file named bar. • --argfile variable-name filename: Do not use. Use --slurpfile instead. (This option is like --slurpfile, but when the file has just one text, then that is used, else an array of texts is used as in --slurpfile.) • --args: Remaining arguments are positional string arguments. These are available to the jq program as $ARGS.positional[]. • --jsonargs: Remaining arguments are positional JSON text arguments. These are available to the jq program as $ARGS.positional[]. • --run-tests [filename]: Runs the tests in the given file or standard input. This must be the last option given and does not honor all preceding options. The input consists of comment lines, empty lines, and pro‐ gram lines followed by one input line, as many lines of output as are expected (one per output), and a terminating empty line. Compilation failure tests start with a line containing only \u0026quot;%%FAIL\u0026quot;, then a line containing the program to compile, then a line containing an error message to compare to the actual. Be warned that this option can change backwards-incompatibly. BASIC FILTERS Identity: . The absolute simplest filter is . . This is a filter that takes its input and produces it unchanged as output. That is, this is the identity operator. Since jq by default pretty-prints all output, this trivial program can be a useful way of formatting JSON output from, say, curl. jq ´.´ \u0026quot;Hello, world!\u0026quot; =\u0026gt; \u0026quot;Hello, world!\u0026quot; Object Identifier-Index: .foo, .foo.bar The simplest useful filter is .foo. When given a JSON object (aka dictionary or hash) as input, it produces the value at the key \u0026quot;foo\u0026quot;, or null if there´s none present. A filter of the form .foo.bar is equivalent to .foo|.bar. This syntax only works for simple, identifier-like keys, that is, keys that are all made of alphanumeric characters and underscore, and which do not start with a digit. If the key contains special characters, you need to surround it with double quotes like this: .\u0026quot;foo$\u0026quot;, or else .[\u0026quot;foo$\u0026quot;]. For example .[\u0026quot;foo::bar\u0026quot;] and .[\u0026quot;foo.bar\u0026quot;] work while .foo::bar does not, and .foo.bar means .[\u0026quot;foo\u0026quot;].[\u0026quot;bar\u0026quot;]. jq ´.foo´ {\u0026quot;foo\u0026quot;: 42, \u0026quot;bar\u0026quot;: \u0026quot;less interesting data\u0026quot;} =\u0026gt; 42 jq ´.foo´ {\u0026quot;notfoo\u0026quot;: true, \u0026quot;alsonotfoo\u0026quot;: false} =\u0026gt; null jq ´.[\u0026quot;foo\u0026quot;]´ {\u0026quot;foo\u0026quot;: 42} =\u0026gt; 42 Optional Object Identifier-Index: .foo? Just like .foo, but does not output even an error when . is not an array or an object. jq ´.foo?´ {\u0026quot;foo\u0026quot;: 42, \u0026quot;bar\u0026quot;: \u0026quot;less interesting data\u0026quot;} =\u0026gt; 42 jq ´.foo?´ {\u0026quot;notfoo\u0026quot;: true, \u0026quot;alsonotfoo\u0026quot;: false} =\u0026gt; null jq ´.[\u0026quot;foo\u0026quot;]?´ {\u0026quot;foo\u0026quot;: 42} =\u0026gt; 42 jq ´[.foo?]´ [1,2] =\u0026gt; [] Generic Object Index: .[\u0026lt;string\u0026gt;] You can also look up fields of an object using syntax like .[\u0026quot;foo\u0026quot;] (.foo above is a shorthand version of this, but only for identifier-like strings). Array Index: .[2] When the index value is an integer, .[\u0026lt;value\u0026gt;] can index arrays. Arrays are zero-based, so .[2] returns the third element. Negative indices are allowed, with -1 referring to the last element, -2 referring to the next to last element, and so on. jq ´.[0]´ [{\u0026quot;name\u0026quot;:\u0026quot;JSON\u0026quot;, \u0026quot;good\u0026quot;:true}, {\u0026quot;name\u0026quot;:\u0026quot;XML\u0026quot;, \u0026quot;good\u0026quot;:false}] =\u0026gt; {\u0026quot;name\u0026quot;:\u0026quot;JSON\u0026quot;, \u0026quot;good\u0026quot;:true} jq ´.[2]´ [{\u0026quot;name\u0026quot;:\u0026quot;JSON\u0026quot;, \u0026quot;good\u0026quot;:true}, {\u0026quot;name\u0026quot;:\u0026quot;XML\u0026quot;, \u0026quot;good\u0026quot;:false}] =\u0026gt; null jq ´.[-2]´ [1,2,3] =\u0026gt; 2 Array/String Slice: .[10:15] The .[10:15] syntax can be used to return a subarray of an array or substring of a string. The array returned by .[10:15] will be of length 5, containing the elements from index 10 (inclusive) to index 15 (exclusive). Either index may be negative (in which case it counts backwards from the end of the array), or omitted (in which case it refers to the start or end of the array). jq ´.[2:4]´ [\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;,\u0026quot;d\u0026quot;,\u0026quot;e\u0026quot;] =\u0026gt; [\u0026quot;c\u0026quot;, \u0026quot;d\u0026quot;] jq ´.[2:4]´ \u0026quot;abcdefghi\u0026quot; =\u0026gt; \u0026quot;cd\u0026quot; jq ´.[:3]´ [\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;,\u0026quot;d\u0026quot;,\u0026quot;e\u0026quot;] =\u0026gt; [\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;] jq ´.[-2:]´ [\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;,\u0026quot;d\u0026quot;,\u0026quot;e\u0026quot;] =\u0026gt; [\u0026quot;d\u0026quot;, \u0026quot;e\u0026quot;] Array/Object Value Iterator: .[] If you use the .[index] syntax, but omit the index entirely, it will return all of the elements of an array. Running .[] with the input [1,2,3] will produce the numbers as three separate re‐ sults, rather than as a single array. You can also use this on an object, and it will return all the values of the object. jq ´.[]´ [{\u0026quot;name\u0026quot;:\u0026quot;JSON\u0026quot;, \u0026quot;good\u0026quot;:true}, {\u0026quot;name\u0026quot;:\u0026quot;XML\u0026quot;, \u0026quot;good\u0026quot;:false}] =\u0026gt; {\u0026quot;name\u0026quot;:\u0026quot;JSON\u0026quot;, \u0026quot;good\u0026quot;:true}, {\u0026quot;name\u0026quot;:\u0026quot;XML\u0026quot;, \u0026quot;good\u0026quot;:false} jq ´.[]´ [] =\u0026gt; jq ´.[]´ {\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 1} =\u0026gt; 1, 1 .[]? Like .[], but no errors will be output if . is not an array or object. Comma: , If two filters are separated by a comma, then the same input will be fed into both and the two filters´ output value streams will be concatenated in order: first, all of the outputs produced by the left expression, and then all of the outputs produced by the right. For instance, filter .foo, .bar, produces both the \u0026quot;foo\u0026quot; fields and \u0026quot;bar\u0026quot; fields as separate outputs. jq ´.foo, .bar´ {\u0026quot;foo\u0026quot;: 42, \u0026quot;bar\u0026quot;: \u0026quot;something else\u0026quot;, \u0026quot;baz\u0026quot;: true} =\u0026gt; 42, \u0026quot;something else\u0026quot; jq ´.user, .projects[]´ {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;, \u0026quot;projects\u0026quot;: [\u0026quot;jq\u0026quot;, \u0026quot;wikiflow\u0026quot;]} =\u0026gt; \u0026quot;stedolan\u0026quot;, \u0026quot;jq\u0026quot;, \u0026quot;wikiflow\u0026quot; jq ´.[4,2]´ [\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;,\u0026quot;d\u0026quot;,\u0026quot;e\u0026quot;] =\u0026gt; \u0026quot;e\u0026quot;, \u0026quot;c\u0026quot; Pipe: | The | operator combines two filters by feeding the output(s) of the one on the left into the input of the one on the right. It´s pretty much the same as the Unix shell´s pipe, if you´re used to that. If the one on the left produces multiple results, the one on the right will be run for each of those results. So, the expression .[] | .foo retrieves the \u0026quot;foo\u0026quot; field of each element of the in‐ put array. Note that .a.b.c is the same as .a | .b | .c. Note too that . is the input value at the particular stage in a \u0026quot;pipeline\u0026quot;, specifically: where the . expression appears. Thus .a | . | .b is the same as .a.b, as the . in the middle refers to whatever value .a produced. jq ´.[] | .name´ [{\u0026quot;name\u0026quot;:\u0026quot;JSON\u0026quot;, \u0026quot;good\u0026quot;:true}, {\u0026quot;name\u0026quot;:\u0026quot;XML\u0026quot;, \u0026quot;good\u0026quot;:false}] =\u0026gt; \u0026quot;JSON\u0026quot;, \u0026quot;XML\u0026quot; Parenthesis Parenthesis work as a grouping operator just as in any typical programming language. jq ´(. + 2) * 5´ 1 =\u0026gt; 15 TYPES AND VALUES jq supports the same set of datatypes as JSON - numbers, strings, booleans, arrays, objects (which in JSON-speak are hashes with only string keys), and \u0026quot;null\u0026quot;. Booleans, null, strings and numbers are written the same way as in javascript. Just like everything else in jq, these simple values take an input and produce an output - 42 is a valid jq ex‐ pression that takes an input, ignores it, and returns 42 instead. Array construction: [] As in JSON, [] is used to construct arrays, as in [1,2,3]. The elements of the arrays can be any jq expression, including a pipeline. All of the results produced by all of the expressions are collected into one big array. You can use it to construct an array out of a known quantity of values (as in [.foo, .bar, .baz]) or to \u0026quot;collect\u0026quot; all the results of a filter into an array (as in [.items[].name]) Once you understand the \u0026quot;,\u0026quot; operator, you can look at jq´s array syntax in a different light: the expression [1,2,3] is not using a built-in syntax for comma-separated arrays, but is instead applying the [] operator (collect results) to the expression 1,2,3 (which produces three different results). If you have a filter X that produces four results, then the expression [X] will produce a single result, an array of four elements. jq ´[.user, .projects[]]´ {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;, \u0026quot;projects\u0026quot;: [\u0026quot;jq\u0026quot;, \u0026quot;wikiflow\u0026quot;]} =\u0026gt; [\u0026quot;stedolan\u0026quot;, \u0026quot;jq\u0026quot;, \u0026quot;wikiflow\u0026quot;] jq ´[ .[] | . * 2]´ [1, 2, 3] =\u0026gt; [2, 4, 6] Object Construction: {} Like JSON, {} is for constructing objects (aka dictionaries or hashes), as in: {\u0026quot;a\u0026quot;: 42, \u0026quot;b\u0026quot;: 17}. If the keys are \u0026quot;identifier-like\u0026quot;, then the quotes can be left off, as in {a:42, b:17}. Keys generated by expressions need to be parenthesized, e.g., {(\u0026quot;a\u0026quot;+\u0026quot;b\u0026quot;):59}. The value can be any expression (although you may need to wrap it in parentheses if it´s a complicated one), which gets applied to the {} expression´s input (remember, all filters have an in‐ put and an output). {foo: .bar} will produce the JSON object {\u0026quot;foo\u0026quot;: 42} if given the JSON object {\u0026quot;bar\u0026quot;:42, \u0026quot;baz\u0026quot;:43} as its input. You can use this to select particular fields of an object: if the input is an object with \u0026quot;user\u0026quot;, \u0026quot;title\u0026quot;, \u0026quot;id\u0026quot;, and \u0026quot;content\u0026quot; fields and you just want \u0026quot;user\u0026quot; and \u0026quot;title\u0026quot;, you can write {user: .user, title: .title} Because that is so common, there´s a shortcut syntax for it: {user, title}. If one of the expressions produces multiple results, multiple dictionaries will be produced. If the input´s {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;,\u0026quot;titles\u0026quot;:[\u0026quot;JQ Primer\u0026quot;, \u0026quot;More JQ\u0026quot;]} then the expression {user, title: .titles[]} will produce two outputs: {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;JQ Primer\u0026quot;} {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;More JQ\u0026quot;} Putting parentheses around the key means it will be evaluated as an expression. With the same input as above, {(.user): .titles} produces {\u0026quot;stedolan\u0026quot;: [\u0026quot;JQ Primer\u0026quot;, \u0026quot;More JQ\u0026quot;]} jq ´{user, title: .titles[]}´ {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;,\u0026quot;titles\u0026quot;:[\u0026quot;JQ Primer\u0026quot;, \u0026quot;More JQ\u0026quot;]} =\u0026gt; {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;JQ Primer\u0026quot;}, {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;, \u0026quot;title\u0026quot;: \u0026quot;More JQ\u0026quot;} jq ´{(.user): .titles}´ {\u0026quot;user\u0026quot;:\u0026quot;stedolan\u0026quot;,\u0026quot;titles\u0026quot;:[\u0026quot;JQ Primer\u0026quot;, \u0026quot;More JQ\u0026quot;]} =\u0026gt; {\u0026quot;stedolan\u0026quot;: [\u0026quot;JQ Primer\u0026quot;, \u0026quot;More JQ\u0026quot;]} Recursive Descent: .. Recursively descends ., producing every value. This is the same as the zero-argument recurse builtin (see below). This is intended to resemble the XPath // operator. Note that ..a does not work; use ..|.a instead. In the example below we use ..|.a? to find all the values of object keys \u0026quot;a\u0026quot; in any object found \u0026quot;below\u0026quot; .. This is particularly useful in conjunction with path(EXP) (also see below) and the ? operator. jq ´..|.a?´ [[{\u0026quot;a\u0026quot;:1}]] =\u0026gt; 1 BUILTIN OPERATORS AND FUNCTIONS Some jq operator (for instance, +) do different things depending on the type of their arguments (arrays, numbers, etc.). However, jq never does implicit type conversions. If you try to add a string to an object you´ll get an error message and no result. Addition: + The operator + takes two filters, applies them both to the same input, and adds the results together. What \u0026quot;adding\u0026quot; means depends on the types involved: • Numbers are added by normal arithmetic. • Arrays are added by being concatenated into a larger array. • Strings are added by being joined into a larger string. • Objects are added by merging, that is, inserting all the key-value pairs from both objects into a single combined object. If both objects contain a value for the same key, the object on the right of the + wins. (For recursive merge use the * operator.) null can be added to any value, and returns the other value unchanged. jq ´.a + 1´ {\u0026quot;a\u0026quot;: 7} =\u0026gt; 8 jq ´.a + .b´ {\u0026quot;a\u0026quot;: [1,2], \u0026quot;b\u0026quot;: [3,4]} =\u0026gt; [1,2,3,4] jq ´.a + null´ {\u0026quot;a\u0026quot;: 1} =\u0026gt; 1 jq ´.a + 1´ {} =\u0026gt; 1 jq ´{a: 1} + {b: 2} + {c: 3} + {a: 42}´ null =\u0026gt; {\u0026quot;a\u0026quot;: 42, \u0026quot;b\u0026quot;: 2, \u0026quot;c\u0026quot;: 3} Subtraction: - As well as normal arithmetic subtraction on numbers, the - operator can be used on arrays to remove all occurrences of the second array´s elements from the first array. jq ´4 - .a´ {\u0026quot;a\u0026quot;:3} =\u0026gt; 1 jq ´. - [\u0026quot;xml\u0026quot;, \u0026quot;yaml\u0026quot;]´ [\u0026quot;xml\u0026quot;, \u0026quot;yaml\u0026quot;, \u0026quot;json\u0026quot;] =\u0026gt; [\u0026quot;json\u0026quot;] Multiplication, division, modulo: *, /, and % These infix operators behave as expected when given two numbers. Division by zero raises an error. x % y computes x modulo y. Multiplying a string by a number produces the concatenation of that string that many times. \u0026quot;x\u0026quot; * 0 produces null. Dividing a string by another splits the first using the second as separators. Multiplying two objects will merge them recursively: this works like addition but if both objects contain a value for the same key, and the values are objects, the two are merged with the same strategy. jq ´10 / . * 3´ 5 =\u0026gt; 6 jq ´. / \u0026quot;, \u0026quot;´ \u0026quot;a, b,c,d, e\u0026quot; =\u0026gt; [\u0026quot;a\u0026quot;,\u0026quot;b,c,d\u0026quot;,\u0026quot;e\u0026quot;] jq ´{\u0026quot;k\u0026quot;: {\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 2}} * {\u0026quot;k\u0026quot;: {\u0026quot;a\u0026quot;: 0,\u0026quot;c\u0026quot;: 3}}´ null =\u0026gt; {\u0026quot;k\u0026quot;: {\u0026quot;a\u0026quot;: 0, \u0026quot;b\u0026quot;: 2, \u0026quot;c\u0026quot;: 3}} jq ´.[] | (1 / .)?´ [1,0,-1] =\u0026gt; 1, -1 length The builtin function length gets the length of various different types of value: • The length of a string is the number of Unicode codepoints it contains (which will be the same as its JSON-encoded length in bytes if it´s pure ASCII). • The length of an array is the number of elements. • The length of an object is the number of key-value pairs. • The length of null is zero. jq ´.[] | length´ [[1,2], \u0026quot;string\u0026quot;, {\u0026quot;a\u0026quot;:2}, null] =\u0026gt; 2, 6, 1, 0 utf8bytelength The builtin function utf8bytelength outputs the number of bytes used to encode a string in UTF-8. jq ´utf8bytelength´ \u0026quot;\\u03bc\u0026quot; =\u0026gt; 2 keys, keys_unsorted The builtin function keys, when given an object, returns its keys in an array. The keys are sorted \u0026quot;alphabetically\u0026quot;, by unicode codepoint order. This is not an order that makes particular sense in any particular language, but you can count on it being the same for any two objects with the same set of keys, regardless of locale settings. When keys is given an array, it returns the valid indices for that array: the integers from 0 to length-1. The keys_unsorted function is just like keys, but if the input is an object then the keys will not be sorted, instead the keys will roughly be in insertion order. jq ´keys´ {\u0026quot;abc\u0026quot;: 1, \u0026quot;abcd\u0026quot;: 2, \u0026quot;Foo\u0026quot;: 3} =\u0026gt; [\u0026quot;Foo\u0026quot;, \u0026quot;abc\u0026quot;, \u0026quot;abcd\u0026quot;] jq ´keys´ [42,3,35] =\u0026gt; [0,1,2] has(key) The builtin function has returns whether the input object has the given key, or the input array has an element at the given index. has($key) has the same effect as checking whether $key is a member of the array returned by keys, although has will be faster. jq ´map(has(\u0026quot;foo\u0026quot;))´ [{\u0026quot;foo\u0026quot;: 42}, {}] =\u0026gt; [true, false] jq ´map(has(2))´ [[0,1], [\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;]] =\u0026gt; [false, true] in The builtin function in returns whether or not the input key is in the given object, or the input index corresponds to an element in the given array. It is, essentially, an inversed version of has. jq ´.[] | in({\u0026quot;foo\u0026quot;: 42})´ [\u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;] =\u0026gt; true, false jq ´map(in([0,1]))´ [2, 0] =\u0026gt; [false, true] map(x), map_values(x) For any filter x, map(x) will run that filter for each element of the input array, and return the outputs in a new array. map(.+1) will increment each element of an array of numbers. Similarly, map_values(x) will run that filter for each element, but it will return an object when an object is passed. map(x) is equivalent to [.[] | x]. In fact, this is how it´s defined. Similarly, map_values(x) is defined as .[] |= x. jq ´map(.+1)´ [1,2,3] =\u0026gt; [2,3,4] jq ´map_values(.+1)´ {\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 2, \u0026quot;c\u0026quot;: 3} =\u0026gt; {\u0026quot;a\u0026quot;: 2, \u0026quot;b\u0026quot;: 3, \u0026quot;c\u0026quot;: 4} path(path_expression) Outputs array representations of the given path expression in .. The outputs are arrays of strings (object keys) and/or numbers (array indices). Path expressions are jq expressions like .a, but also .[]. There are two types of path expressions: ones that can match exactly, and ones that cannot. For example, .a.b.c is an exact match path expression, while .a[].b is not. path(exact_path_expression) will produce the array representation of the path expression even if it does not exist in ., if . is null or an array or an object. path(pattern) will produce array representations of the paths matching pattern if the paths exist in .. Note that the path expressions are not different from normal expressions. The expression path(..|select(type==\u0026quot;boolean\u0026quot;)) outputs all the paths to boolean values in ., and only those paths. jq ´path(.a[0].b)´ null =\u0026gt; [\u0026quot;a\u0026quot;,0,\u0026quot;b\u0026quot;] jq ´[path(..)]´ {\u0026quot;a\u0026quot;:[{\u0026quot;b\u0026quot;:1}]} =\u0026gt; [[],[\u0026quot;a\u0026quot;],[\u0026quot;a\u0026quot;,0],[\u0026quot;a\u0026quot;,0,\u0026quot;b\u0026quot;]] del(path_expression) The builtin function del removes a key and its corresponding value from an object. jq ´del(.foo)´ {\u0026quot;foo\u0026quot;: 42, \u0026quot;bar\u0026quot;: 9001, \u0026quot;baz\u0026quot;: 42} =\u0026gt; {\u0026quot;bar\u0026quot;: 9001, \u0026quot;baz\u0026quot;: 42} jq ´del(.[1, 2])´ [\u0026quot;foo\u0026quot;, \u0026quot;bar\u0026quot;, \u0026quot;baz\u0026quot;] =\u0026gt; [\u0026quot;foo\u0026quot;] getpath(PATHS) The builtin function getpath outputs the values in . found at each path in PATHS. jq ´getpath([\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;])´ null =\u0026gt; null jq ´[getpath([\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;], [\u0026quot;a\u0026quot;,\u0026quot;c\u0026quot;])]´ {\u0026quot;a\u0026quot;:{\u0026quot;b\u0026quot;:0, \u0026quot;c\u0026quot;:1}} =\u0026gt; [0, 1] setpath(PATHS; VALUE) The builtin function setpath sets the PATHS in . to VALUE. jq ´setpath([\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;]; 1)´ null =\u0026gt; {\u0026quot;a\u0026quot;: {\u0026quot;b\u0026quot;: 1}} jq ´setpath([\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;]; 1)´ {\u0026quot;a\u0026quot;:{\u0026quot;b\u0026quot;:0}} =\u0026gt; {\u0026quot;a\u0026quot;: {\u0026quot;b\u0026quot;: 1}} jq ´setpath([0,\u0026quot;a\u0026quot;]; 1)´ null =\u0026gt; [{\u0026quot;a\u0026quot;:1}] delpaths(PATHS) The builtin function delpaths sets the PATHS in .. PATHS must be an array of paths, where each path is an array of strings and numbers. jq ´delpaths([[\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;]])´ {\u0026quot;a\u0026quot;:{\u0026quot;b\u0026quot;:1},\u0026quot;x\u0026quot;:{\u0026quot;y\u0026quot;:2}} =\u0026gt; {\u0026quot;a\u0026quot;:{},\u0026quot;x\u0026quot;:{\u0026quot;y\u0026quot;:2}} to_entries, from_entries, with_entries These functions convert between an object and an array of key-value pairs. If to_entries is passed an object, then for each k: v entry in the input, the output array includes {\u0026quot;key\u0026quot;: k, \u0026quot;value\u0026quot;: v}. from_entries does the opposite conversion, and with_entries(foo) is a shorthand for to_entries | map(foo) | from_entries, useful for doing some operation to all keys and values of an object. from_entries accepts key, Key, name, Name, value and Value as keys. jq ´to_entries´ {\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 2} =\u0026gt; [{\u0026quot;key\u0026quot;:\u0026quot;a\u0026quot;, \u0026quot;value\u0026quot;:1}, {\u0026quot;key\u0026quot;:\u0026quot;b\u0026quot;, \u0026quot;value\u0026quot;:2}] jq ´from_entries´ [{\u0026quot;key\u0026quot;:\u0026quot;a\u0026quot;, \u0026quot;value\u0026quot;:1}, {\u0026quot;key\u0026quot;:\u0026quot;b\u0026quot;, \u0026quot;value\u0026quot;:2}] =\u0026gt; {\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 2} jq ´with_entries(.key |= \u0026quot;KEY_\u0026quot; + .)´ {\u0026quot;a\u0026quot;: 1, \u0026quot;b\u0026quot;: 2} =\u0026gt; {\u0026quot;KEY_a\u0026quot;: 1, \u0026quot;KEY_b\u0026quot;: 2} select(boolean_expression) The function select(foo) produces its input unchanged if foo returns true for that input, and produces no output otherwise. It´s useful for filtering lists: [1,2,3] | map(select(. \u0026gt;= 2)) will give you [2,3]. jq ´map(select(. \u0026gt;= 2))´ [1,5,3,0,7] =\u0026gt; [5,3,7] jq ´.[] | select(.id == \u0026quot;second\u0026quot;)´ [{\u0026quot;id\u0026quot;: \u0026quot;first\u0026quot;, \u0026quot;val\u0026quot;: 1}, {\u0026quot;id\u0026quot;: \u0026quot;second\u0026quot;, \u0026quot;val\u0026quot;: 2}] =\u0026gt; {\u0026quot;id\u0026quot;: \u0026quot;second\u0026quot;, \u0026quot;val\u0026quot;: 2} arrays, objects, iterables, booleans, numbers, normals, finites, strings, nulls, values, scalars These built-ins select only inputs that are arrays, objects, iterables (arrays or objects), booleans, numbers, normal numbers, finite numbers, strings, null, non-null values, and non-iter‐ ables, respectively. jq ´.[]|numbers´ [[],{},1,\u0026quot;foo\u0026quot;,null,true,false] =\u0026gt; 1 empty empty returns no results. None at all. Not even null. It´s useful on occasion. You´ll know if you need it :) jq ´1, empty, 2´ null =\u0026gt; 1, 2 jq ´[1,2,empty,3]´ null =\u0026gt; [1,2,3] error(message) Produces an error, just like .a applied to values other than null and objects would, but with the given message as the error´s value. Errors can be caught with try/catch; see below. halt Stops the jq program with no further outputs. jq will exit with exit status 0. halt_error, halt_error(exit_code) Stops the jq program with no further outputs. The input will be printed on stderr as raw output (i.e., strings will not have double quotes) with no decoration, not even a newline. The given exit_code (defaulting to 5) will be jq´s exit status. For example, \u0026quot;Error: somthing went wrong\\n\u0026quot;|halt_error(1). $__loc__ Produces an object with a \u0026quot;file\u0026quot; key and a \u0026quot;line\u0026quot; key, with the filename and line number where $__loc__ occurs, as values. jq ´try error(\u0026quot;\\($__loc__)\u0026quot;) catch .´ null =\u0026gt; \u0026quot;{\\\u0026quot;file\\\u0026quot;:\\\u0026quot;\u0026lt;top-level\u0026gt;\\\u0026quot;,\\\u0026quot;line\\\u0026quot;:1}\u0026quot; paths, paths(node_filter), leaf_paths paths outputs the paths to all the elements in its input (except it does not output the empty list, representing . itself). paths(f) outputs the paths to any values for which f is true. That is, paths(numbers) outputs the paths to all numeric values. leaf_paths is an alias of paths(scalars); leaf_paths is deprecated and will be removed in the next major release. jq ´[paths]´ [1,[[],{\u0026quot;a\u0026quot;:2}]] =\u0026gt; [[0],[1],[1,0],[1,1],[1,1,\u0026quot;a\u0026quot;]] jq ´[paths(scalars)]´ [1,[[],{\u0026quot;a\u0026quot;:2}]] =\u0026gt; [[0],[1,1,\u0026quot;a\u0026quot;]] add The filter add takes as input an array, and produces as output the elements of the array added together. This might mean summed, concatenated or merged depending on the types of the elements of the input array - the rules are the same as those for the + operator (described above). If the input is an empty array, add returns null. jq ´add´ [\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,\u0026quot;c\u0026quot;] =\u0026gt; \u0026quot;abc\u0026quot; jq ´add´ [1, 2, 3] =\u0026gt; 6 jq ´add´ [] =\u0026gt; null any, any(condition), any(generator; condition) The filter any takes as input an array of boolean values, and produces true as output if any of the elements of the array are true. If the input is an empty array, any returns false. The any(condition) form applies the given condition to the elements of the input array. The any(generator; condition) form applies the given condition to all the outputs of the given generator. jq ´any´ [true, false] =\u0026gt; true jq ´any´ [false, false] =\u0026gt; false jq ´any´ [] =\u0026gt; false all, all(condition), all(generator; condition) The filter all takes as input an array of boolean values, and produces true as output if all of the elements of the array are true. The all(condition) form applies the given condition to the elements of the input array. The all(generator; condition) form applies the given condition to all the outputs of the given generator. If the input is an empty array, all returns true. jq ´all´ [true, false] =\u0026gt; false jq ´all´ [true, true] =\u0026gt; true jq ´all´ [] =\u0026gt; true flatten, flatten(depth) The filter flatten takes as input an array of nested arrays, and produces a flat array in which all arrays inside the original array have been recursively replaced by their values. You can pass an argument to it to specify how many levels of nesting to flatten. flatten(2) is like flatten, but going only up to two levels deep. jq ´flatten´ [1, [2], [[3]]] =\u0026gt; [1, 2, 3] jq ´flatten(1)´ [1, [2], [[3]]] =\u0026gt; [1, 2, [3]] jq ´flatten´ [[]] =\u0026gt; [] jq ´flatten´ [{\u0026quot;foo\u0026quot;: \u0026quot;bar\u0026quot;}, [{\u0026quot;foo\u0026quot;: \u0026quot;baz\u0026quot;}]] =\u0026gt; [{\u0026quot;foo\u0026quot;: \u0026quot;bar\u0026quot;}, {\u0026quot;foo\u0026quot;: \u0026quot;baz\u0026quot;}] range(upto), range(from;upto) range(from;upto;by) The range function produces a range of numbers. range(4;10) produces 6 numbers, from 4 (inclusive) to 10 (exclusive). The numbers are produced as separate outputs. Use [range(4;10)] to get a range as an array. The one argument form generates numbers from 0 to the given number, with an increment of 1. The two argument form generates numbers from from to upto with an increment of 1. The three argument form generates numbers from to upto with an increment of by. jq ´range(2;4)´ null =\u0026gt; 2, 3 jq ´[range(2;4)]´ null =\u0026gt; [2,3] jq ´[range(4)]´ null =\u0026gt; [0,1,2,3] jq ´[range(0;10;3)]´ null =\u0026gt; [0,3,6,9] jq ´[range(0;10;-1)]´ null =\u0026gt; [] jq ´[range(0;-5;-1)]´ null =\u0026gt; [0,-1,-2,-3,-4] floor The floor function returns the floor of its numeric input. jq ´floor´ 3.14159 =\u0026gt; 3 sqrt The sqrt function returns the square root of its numeric input. jq ´sqrt´ 9 =\u0026gt; 3 tonumber The tonumber function parses its input as a number. It will convert correctly-formatted strings to their numeric equivalent, leave numbers alone, and give an error on all other input. jq ´.[] | tonumber´ [1, \u0026quot;1\u0026quot;] =\u0026gt; 1, 1 tostring The tostring function prints its input as a string. Strings are left unchanged, and all other values are JSON-encoded. jq ´.[] | tostring´ [1, \u0026quot;1\u0026quot;, [1]] =\u0026gt; \u0026quot;1\u0026quot;, \u0026quot;1\u0026quot;, \u0026quot;[1]\u0026quot; type The type function returns the type of its argument as a string, which is one of null, boolean, number, string, array or object. jq ´map(type)´ [0, false, [], {}, null, \u0026quot;hello\u0026quot;] =\u0026gt; [\u0026quot;number\u0026quot;, \u0026quot;boolean\u0026quot;, \u0026quot;array\u0026quot;, \u0026quot;object\u0026quot;, \u0026quot;null\u0026quot;, \u0026quot;string\u0026quot;] infinite, nan, isinfinite, isnan, isfinite, isnormal Some arithmetic operations can yield infinities and \u0026quot;not a number\u0026quot; (NaN) values. The isinfinite builtin returns true if its input is infinite. The isnan builtin returns true if its input is a NaN. The infinite builtin returns a positive infinite value. The nan builtin returns a NaN. The isnormal builtin returns true if its input is a normal number. Note that division by zero raises an error. Currently most arithmetic operations operating on infinities, NaNs, and sub-normals do not raise errors. jq ´.[] | (infinite * .) \u0026lt; 0´ [-1, 1] =\u0026gt; true, false jq ´infinite, nan | type´ null =\u0026gt; \u0026quot;number\u0026quot;, \u0026quot;number\u0026quot; sort, sort_by(path_expression) The sort functions sorts its input, which must be an array. Values are sorted in the following order: • null • false • true • numbers • strings, in alphabetical order (by unicode codepoint value) • arrays, in lexical order • objects The ordering for objects is a little complex: first they´re compared by comparing their sets of keys (as arrays in sorted order), and if their keys are equal then the values are compared key by key. sort may be used to sort by a particular field of an object, or by applying any jq filter. sort_by(foo) compares two elements by comparing the result of foo on each element. jq ´sort´ [8,3,null,6] =\u0026gt; [null,3,6,8] jq ´sort_by(.foo)´ [{\u0026quot;foo\u0026quot;:4, \u0026quot;bar\u0026quot;:10}, {\u0026quot;foo\u0026quot;:3, \u0026quot;bar\u0026quot;:100}, {\u0026quot;foo\u0026quot;:2, \u0026quot;bar\u0026quot;:1}] =\u0026gt; [{\u0026quot;foo\u0026quot;:2, \u0026quot;bar\u0026quot;:1}, {\u0026quot;foo\u0026quot;:3, \u0026quot;bar\u0026quot;:100}, {\u0026quot;foo\u0026quot;:4, \u0026quot;bar\u0026quot;:10}] group_by(path_expression) group_by(.foo) takes as input an array, groups the elements having the same .foo field into separate arrays, and produces all of these arrays as elements of a larger array, sorted by the value of the .foo field. Any jq expression, not just a field access, may be used in place of .foo. The sorting order is the same as described in the sort function above. jq ´group_by(.foo)´ [{\u0026quot;foo\u0026quot;:1, \u0026quot;bar\u0026quot;:10}, {\u0026quot;foo\u0026quot;:3, \u0026quot;bar\u0026quot;:100}, {\u0026quot;foo\u0026quot;:1, \u0026quot;bar\u0026quot;:1}] =\u0026gt; [[{\u0026quot;foo\u0026quot;:1, \u0026quot;bar\u0026quot;:10}, {\u0026quot;foo\u0026quot;:1, \u0026quot;bar\u0026quot;:1}], [{\u0026quot;foo\u0026quot;:3, \u0026quot;bar\u0026quot;:100}]] min, max, min_by(path_exp), max_by(path_exp) Find the minimum or maximum element of the input array. The min_by(path_exp) and max_by(path_exp) functions allow you to specify a particular field or property to examine, e.g. min_by(.foo) finds the object with the smallest foo field. jq ´min´ [5,4,2,7] =\u0026gt; 2 jq ´max_by(.foo)´ [{\u0026quot;foo\u0026quot;:1, \u0026quot;bar\u0026quot;:14}, {\u0026quot;foo\u0026quot;:2, \u0026quot;bar\u0026quot;:3}] =\u0026gt; {\u0026quot;foo\u0026quot;:2, \u0026quot;bar\u0026quot;:3} unique, unique_by(path_exp) The unique function takes as input an array and produces an array of the same elements, in sorted order, with duplicates removed. The unique_by(path_exp) function will keep only one element for each value obtained by applying the argument. Think of it as making an array by taking one element out of every group produced by group. jq ´unique´ [1,2,5,3,5,3,1,3] =\u0026gt; [1,2,3,5] jq ´unique_by(.foo)´ [{\u0026quot;foo\u0026quot;: 1, \u0026quot;bar\u0026quot;: 2}, {\u0026quot;foo\u0026quot;: 1, \u0026quot;bar\u0026quot;: 3}, {\u0026quot;foo\u0026quot;: 4, \u0026quot;bar\u0026quot;: 5}] =\u0026gt; [{\u0026quot;foo\u0026quot;: 1, \u0026quot;bar\u0026quot;: 2}, {\u0026quot;foo\u0026quot;: 4, \u0026quot;bar\u0026quot;: 5}] jq ´unique_by(length)´ [\u0026quot;chunky\u0026quot;, \u0026quot;bacon\u0026quot;, \u0026quot;kitten\u0026quot;, \u0026quot;cicada\u0026quot;, \u0026quot;asparagus\u0026quot;] =\u0026gt; [\u0026quot;bacon\u0026quot;, \u0026quot;chunky\u0026quot;, \u0026quot;asparagus\u0026quot;] reverse This function reverses an array. jq ´reverse´ [1,2,3,4] =\u0026gt; [4,3,2,1] contains(element) The filter contains(b) will produce true if b is completely contained within the input. A string B is contained in a string A if B is a substring of A. An array B is contained in an array A if all elements in B are contained in any element in A. An object B is contained in object A if all of the values in B are contained in the value in A with the same key. All other types are as‐ sumed to be contained in each other if they are equal. jq ´contains(\u0026quot;bar\u0026quot;)´ \u0026quot;foobar\u0026quot; =\u0026gt; true jq ´contains([\u0026quot;baz\u0026quot;, \u0026quot;bar\u0026quot;])´ [\u0026quot;foobar\u0026quot;, \u0026quot;foobaz\u0026quot;, \u0026quot;blarp\u0026quot;] =\u0026gt; true jq ´contains([\u0026quot;bazzzzz\u0026quot;, \u0026quot;bar\u0026quot;])´ [\u0026quot;foobar\u0026quot;, \u0026quot;foobaz\u0026quot;, \u0026quot;blarp\u0026quot;] =\u0026gt; false jq ´contains({foo: 12, bar: [{barp: 12}]})´ {\u0026quot;foo\u0026quot;: 12, \u0026quot;bar\u0026quot;:[1,2,{\u0026quot;barp\u0026quot;:12, \u0026quot;blip\u0026quot;:13}]} =\u0026gt; true jq ´contains({foo: 12, bar: [{barp: 15}]})´ {\u0026quot;foo\u0026quot;: 12, \u0026quot;bar\u0026quot;:[1,2,{\u0026quot;barp\u0026quot;:12, \u0026quot;blip\u0026quot;:13}]} =\u0026gt; false indices(s) Outputs an array containing the indices in . where s occurs. The input may be an array, in which case if s is an array then the indices output will be those where all elements in . match those of s. jq ´indices(\u0026quot;, \u0026quot;)´ \u0026quot;a,b, cd, efg, hijk\u0026quot; =\u0026gt; [3,7,12] jq ´indices(1)´ [0,1,2,1,3,1,4] =\u0026gt; [1,3,5] jq ´indices([1,2])´ [0,1,2,3,1,4,2,5,1,2,6,7] =\u0026gt; [1,8] index(s), rindex(s) Outputs the index of the first (index) or last (rindex) occurrence of s in the input. jq ´index(\u0026quot;, \u0026quot;)´ \u0026quot;a,b, cd, efg, hijk\u0026quot; =\u0026gt; 3 jq ´rindex(\u0026quot;, \u0026quot;)´ \u0026quot;a,b, cd, efg, hijk\u0026quot; =\u0026gt; 12 inside The filter inside(b) will produce true if the input is completely contained within b. It is, essentially, an inversed version of contains. jq ´inside(\u0026quot;foobar\u0026quot;)´ \u0026quot;bar\u0026quot; =\u0026gt; true jq ´inside([\u0026quot;foobar\u0026quot;, \u0026quot;foobaz\u0026quot;, \u0026quot;blarp\u0026quot;])´ [\u0026quot;baz\u0026quot;, \u0026quot;bar\u0026quot;] =\u0026gt; true jq ´inside([\u0026quot;foobar\u0026quot;, \u0026quot;foobaz\u0026quot;, \u0026quot;blarp\u0026quot;])´ [\u0026quot;bazzzzz\u0026quot;, \u0026quot;bar\u0026quot;] =\u0026gt; false jq ´inside({\u0026quot;foo\u0026quot;: 12, \u0026quot;bar\u0026quot;:[1,2,{\u0026quot;barp\u0026quot;:12, \u0026quot;blip\u0026quot;:13}]})´ {\u0026quot;foo\u0026quot;: 12, \u0026quot;bar\u0026quot;: [{\u0026quot;barp\u0026quot;: 12}]} =\u0026gt; true jq ´inside({\u0026quot;foo\u0026quot;: 12, \u0026quot;bar\u0026quot;:[1,2,{\u0026quot;barp\u0026quot;:12, \u0026quot;blip\u0026quot;:13}]})´ {\u0026quot;foo\u0026quot;: 12, \u0026quot;bar\u0026quot;: [{\u0026quot;barp\u0026quot;: 15}]} =\u0026gt; false startswith(str) Outputs true if . starts with the given string argument. jq ´[.[]|startswith(\u0026quot;foo\u0026quot;)]´ [\u0026quot;fo\u0026quot;, \u0026quot;foo\u0026quot;, \u0026quot;barfoo\u0026quot;, \u0026quot;foobar\u0026quot;, \u0026quot;barfoob\u0026quot;] =\u0026gt; [false, true, false, true, false] endswith(str) Outputs true if . ends with the given string argument. jq ´[.[]|endswith(\u0026quot;foo\u0026quot;)]´ [\u0026quot;foobar\u0026quot;, \u0026quot;barfoo\u0026quot;] =\u0026gt; [false, true] combinations, combinations(n) Outputs all combinations of the elements of the arrays in the input array. If given an argument n, it outputs all combinations of n repetitions of the input array. jq ´combinations´ [[1,2], [3, 4]] =\u0026gt; [1, 3], [1, 4], [2, 3], [2, 4] jq ´combinations(2)´ [0, 1] =\u0026gt; [0, 0], [0, 1], [1, 0], [1, 1] ltrimstr(str) Outputs its input with the given prefix string removed, if it starts with it. jq ´[.[]|ltrimstr(\u0026quot;foo\u0026quot;)]´ [\u0026quot;fo\u0026quot;, \u0026quot;foo\u0026quot;, \u0026quot;barfoo\u0026quot;, \u0026quot;foobar\u0026quot;, \u0026quot;afoo\u0026quot;] =\u0026gt; [\u0026quot;fo\u0026quot;,\u0026quot;\u0026quot;,\u0026quot;barfoo\u0026quot;,\u0026quot;bar\u0026quot;,\u0026quot;afoo\u0026quot;] rtrimstr(str) Outputs its input with the given suffix string removed, if it ends with it. jq ´[.[]|rtrimstr(\u0026quot;foo\u0026quot;)]´ [\u0026quot;fo\u0026quot;, \u0026quot;foo\u0026quot;, \u0026quot;barfoo\u0026quot;, \u0026quot;foobar\u0026quot;, \u0026quot;foob\u0026quot;] =\u0026gt; [\u0026quot;fo\u0026quot;,\u0026quot;\u0026quot;,\u0026quot;bar\u0026quot;,\u0026quot;foobar\u0026quot;,\u0026quot;foob\u0026quot;] explode Converts an input string into an array of the string´s codepoint numbers. jq ´explode´ \u0026quot;foobar\u0026quot; =\u0026gt; [102,111,111,98,97,114] implode The inverse of explode. jq ´implode´ [65, 66, 67] =\u0026gt; \u0026quot;ABC\u0026quot; split(str) Splits an input string on the separator argument. jq ´split(\u0026quot;, \u0026quot;)´ \u0026quot;a, b,c,d, e, \u0026quot; =\u0026gt; [\u0026quot;a\u0026quot;,\u0026quot;b,c,d\u0026quot;,\u0026quot;e\u0026quot;,\u0026quot;\u0026quot;] join(str) Joins the array of elements given as input, using the argument as separator. It is the inverse of split: that is, running split(\u0026quot;foo\u0026quot;) | join(\u0026quot;foo\u0026quot;) over any input string returns said input string. Numbers and booleans in the input are converted to strings. Null values are treated as empty strings. Arrays and objects in the input are not supported. jq ´join(\u0026quot;, \u0026quot;)´ [\u0026quot;a\u0026quot;,\u0026quot;b,c,d\u0026quot;,\u0026quot;e\u0026quot;] =\u0026gt; \u0026quot;a, b,c,d, e\u0026quot; jq ´join(\u0026quot; \u0026quot;)´ [\u0026quot;a\u0026quot;,1,2.3,true,null,false] =\u0026gt; \u0026quot;a 1 2.3 true false\u0026quot; ascii_downcase, ascii_upcase Emit a copy of the input string with its alphabetic characters (a-z and A-Z) converted to the specified case. while(cond; update) The while(cond; update) function allows you to repeatedly apply an update to . until cond is false. Note that while(cond; update) is internally defined as a recursive jq function. Recursive calls within while will not consume additional memory if update produces at most one output for each input. See advanced topics below. jq ´[while(.\u0026lt;100; .*2)]´ 1 =\u0026gt; [1,2,4,8,16,32,64] until(cond; next) The until(cond; next) function allows you to repeatedly apply the expression next, initially to . then to its own output, until cond is true. For example, this can be used to implement a fac‐ torial function (see below). Note that until(cond; next) is internally defined as a recursive jq function. Recursive calls within until() will not consume additional memory if next produces at most one output for each in‐ put. See advanced topics below. jq ´[.,1]|until(.[0] \u0026lt; 1; [.[0] - 1, .[1] * .[0]])|.[1]´ 4 =\u0026gt; 24 recurse(f), recurse, recurse(f; condition), recurse_down The recurse(f) function allows you to search through a recursive structure, and extract interesting data from all levels. Suppose your input represents a filesystem: {\u0026quot;name\u0026quot;: \u0026quot;/\u0026quot;, \u0026quot;children\u0026quot;: [ {\u0026quot;name\u0026quot;: \u0026quot;/bin\u0026quot;, \u0026quot;children\u0026quot;: [ {\u0026quot;name\u0026quot;: \u0026quot;/bin/ls\u0026quot;, \u0026quot;children\u0026quot;: []}, {\u0026quot;name\u0026quot;: \u0026quot;/bin/sh\u0026quot;, \u0026quot;children\u0026quot;: []}]}, {\u0026quot;name\u0026quot;: \u0026quot;/home\u0026quot;, \u0026quot;children\u0026quot;: [ {\u0026quot;name\u0026quot;: \u0026quot;/home/stephen\u0026quot;, \u0026quot;children\u0026quot;: [ {\u0026quot;name\u0026quot;: \u0026quot;/home/stephen/jq\u0026quot;, \u0026quot;children\u0026quot;: []}]}]}]} Now suppose you want to extract all of the filenames present. You need to retrieve .name, .children[].name, .children[].children[].name, and so on. You can do this with: recurse(.children[]) | .name When called without an argument, recurse is equivalent to recurse(.[]?). recurse(f) is identical to recurse(f; . != null) and can be used without concerns about recursion depth. recurse(f; condition) is a generator which begins by emitting . and then emits in turn .|f, .|f|f, .|f|f|f, ... so long as the computed value satisfies the condition. For example, to generate all the integers, at least in principle, one could write recurse(.+1; true). For legacy reasons, recurse_down exists as an alias to calling recurse without arguments. This alias is considered deprecated and will be removed in the next major release. The recursive calls in recurse will not consume additional memory whenever f produces at most a single output for each input. jq ´recurse(.foo[])´ {\u0026quot;foo\u0026quot;:[{\u0026quot;foo\u0026quot;: []}, {\u0026quot;foo\u0026quot;:[{\u0026quot;foo\u0026quot;:[]}]}]} =\u0026gt; {\u0026quot;foo\u0026quot;:[{\u0026quot;foo\u0026quot;:[]},{\u0026quot;foo\u0026quot;:[{\u0026quot;foo\u0026quot;:[]}]}]}, {\u0026quot;foo\u0026quot;:[]}, {\u0026quot;foo\u0026quot;:[{\u0026quot;foo\u0026quot;:[]}]}, {\u0026quot;foo\u0026quot;:[]} jq ´recurse´ {\u0026quot;a\u0026quot;:0,\u0026quot;b\u0026quot;:[1]} =\u0026gt; {\u0026quot;a\u0026quot;:0,\u0026quot;b\u0026quot;:[1]}, 0, [1], 1 jq ´recurse(. * .; . \u0026lt; 20)´ 2 =\u0026gt; 2, 4, 16 walk(f) The walk(f) function applies f recursively to every component of the input entity. When an array is encountered, f is first applied to its elements and then to the array itself; when an object is encountered, f is first applied to all the values and then to the object. In practice, f will usually test the type of its input, as illustrated in the following examples. The first example highlights the usefulness of processing the elements of an array of arrays before processing the array itself. The second example shows how all the keys of all the objects within the input can be considered for alteration. jq ´walk(if type == \u0026quot;array\u0026quot; then sort else . end)´ [[4, 1, 7], [8, 5, 2], [3, 6, 9]] =\u0026gt; [[1,4,7],[2,5,8],[3,6,9]] jq ´walk( if type == \u0026quot;object\u0026quot; then with_entries( .key |= sub( \u0026quot;^_+\u0026quot;; \u0026quot;\u0026quot;) ) else . end )´ [ { \u0026quot;_a\u0026quot;: { \u0026quot;__b\u0026quot;: 2 } } ] =\u0026gt; [{\u0026quot;a\u0026quot;:{\u0026quot;b\u0026quot;:2}}] $ENV, env $ENV is an object representing the environment variables as set when the jq program started. env outputs an object representing jq´s current environment. At the moment there is no builtin for setting environment variables. jq ´$ENV.PAGER´ null =\u0026gt; \u0026quot;less\u0026quot; jq ´env.PAGER´ null =\u0026gt; \u0026quot;less\u0026quot; transpose Transpose a possibly jagged matrix (an array of arrays). Rows are padded with nulls so the result is always rectangular. jq ´transpose´ [[1], [2,3]] =\u0026gt; [[1,2],[null,3]] bsearch(x) bsearch(x) conducts a binary search for x in the input array. If the input is sorted and contains x, then bsearch(x) will return its index in the array; otherwise, if the array is sorted, it will return (-1 - ix) where ix is an insertion point such that the array would still be sorted after the insertion of x at ix. If the array is not sorted, bsearch(x) will return an integer that is probably of no interest. jq ´bsearch(0)´ [0,1] =\u0026gt; 0 jq ´bsearch(0)´ [1,2,3] =\u0026gt; -1 jq ´bsearch(4) as $ix | if $ix \u0026lt; 0 then .[-(1+$ix)] = 4 else . end´ [1,2,3] =\u0026gt; [1,2,3,4] String interpolation - \\(foo) Inside a string, you can put an expression inside parens after a backslash. Whatever the expression returns will be interpolated into the string. jq ´\u0026quot;The input was \\(.), which is one less than \\(.+1)\u0026quot;´ 42 =\u0026gt; \u0026quot;The input was 42, which is one less than 43\u0026quot; Convert to/from JSON The tojson and fromjson builtins dump values as JSON texts or parse JSON texts into values, respectively. The tojson builtin differs from tostring in that tostring returns strings unmodified, while tojson encodes strings as JSON strings. jq ´[.[]|tostring]´ [1, \u0026quot;foo\u0026quot;, [\u0026quot;foo\u0026quot;]] =\u0026gt; [\u0026quot;1\u0026quot;,\u0026quot;foo\u0026quot;,\u0026quot;[\\\u0026quot;foo\\\u0026quot;]\u0026quot;] jq ´[.[]|tojson]´ [1, \u0026quot;foo\u0026quot;, [\u0026quot;foo\u0026quot;]] =\u0026gt; [\u0026quot;1\u0026quot;,\u0026quot;\\\u0026quot;foo\\\u0026quot;\u0026quot;,\u0026quot;[\\\u0026quot;foo\\\u0026quot;]\u0026quot;] jq ´[.[]|tojson|fromjson]´ [1, \u0026quot;foo\u0026quot;, [\u0026quot;foo\u0026quot;]] =\u0026gt; [1,\u0026quot;foo\u0026quot;,[\u0026quot;foo\u0026quot;]] Format strings and escaping The @foo syntax is used to format and escape strings, which is useful for building URLs, documents in a language like HTML or XML, and so forth. @foo can be used as a filter on its own, the possible escapings are: @text: Calls tostring, see that function for details. @json: Serializes the input as JSON. @html: Applies HTML/XML escaping, by mapping the characters \u0026lt;\u0026gt;\u0026amp;´\u0026quot; to their entity equivalents \u0026amp;lt;, \u0026amp;gt;, \u0026amp;amp;, \u0026amp;apos;, \u0026amp;quot;. @uri: Applies percent-encoding, by mapping all reserved URI characters to a %XX sequence. @csv: The input must be an array, and it is rendered as CSV with double quotes for strings, and quotes escaped by repetition. @tsv: The input must be an array, and it is rendered as TSV (tab-separated values). Each input array will be printed as a single line. Fields are separated by a single tab (ascii 0x09). Input characters line-feed (ascii 0x0a), carriage-return (ascii 0x0d), tab (ascii 0x09) and backslash (ascii 0x5c) will be output as escape sequences \\n, \\r, \\t, \\\\ respectively. @sh: The input is escaped suitable for use in a command-line for a POSIX shell. If the input is an array, the output will be a series of space-separated strings. @base64: The input is converted to base64 as specified by RFC 4648. @base64d: The inverse of @base64, input is decoded as specified by RFC 4648. Note: If the decoded string is not UTF-8, the results are undefined. This syntax can be combined with string interpolation in a useful way. You can follow a @foo token with a string literal. The contents of the string literal will not be escaped. However, all interpolations made inside that string literal will be escaped. For instance, @uri \u0026quot;https://www.google.com/search?q=\\(.search)\u0026quot; will produce the following output for the input {\u0026quot;search\u0026quot;:\u0026quot;what is jq?\u0026quot;}: \u0026quot;https://www.google.com/search?q=what%20is%20jq%3F\u0026quot; Note that the slashes, question mark, etc. in the URL are not escaped, as they were part of the string literal. jq ´@html´ \u0026quot;This works if x \u0026lt; y\u0026quot; =\u0026gt; \u0026quot;This works if x \u0026amp;lt; y\u0026quot; jq ´@sh \u0026quot;echo \\(.)\u0026quot;´ \u0026quot;O´Hara´s Ale\u0026quot; =\u0026gt; \u0026quot;echo ´O´\\\\´´Hara´\\\\´´s Ale´\u0026quot; jq ´@base64´ \u0026quot;This is a message\u0026quot; =\u0026gt; \u0026quot;VGhpcyBpcyBhIG1lc3NhZ2U=\u0026quot; jq ´@base64d´ \u0026quot;VGhpcyBpcyBhIG1lc3NhZ2U=\u0026quot; =\u0026gt; \u0026quot;This is a message\u0026quot; Dates jq provides some basic date handling functionality, with some high-level and low-level builtins. In all cases these builtins deal exclusively with time in UTC. The fromdateiso8601 builtin parses datetimes in the ISO 8601 format to a number of seconds since the Unix epoch (1970-01-01T00:00:00Z). The todateiso8601 builtin does the inverse. The fromdate builtin parses datetime strings. Currently fromdate only supports ISO 8601 datetime strings, but in the future it will attempt to parse datetime strings in more formats. The todate builtin is an alias for todateiso8601. The now builtin outputs the current time, in seconds since the Unix epoch. Low-level jq interfaces to the C-library time functions are also provided: strptime, strftime, strflocaltime, mktime, gmtime, and localtime. Refer to your host operating system´s documentation for the format strings used by strptime and strftime. Note: these are not necessarily stable interfaces in jq, particularly as to their localization functionality. The gmtime builtin consumes a number of seconds since the Unix epoch and outputs a \u0026quot;broken down time\u0026quot; representation of Greenwhich Meridian time as an array of numbers representing (in this order): the year, the month (zero-based), the day of the month (one-based), the hour of the day, the minute of the hour, the second of the minute, the day of the week, and the day of the year -- all one-based unless otherwise stated. The day of the week number may be wrong on some systems for dates before March 1st 1900, or after December 31 2099. The localtime builtin works like the gmtime builtin, but using the local timezone setting. The mktime builtin consumes \u0026quot;broken down time\u0026quot; representations of time output by gmtime and strptime. The strptime(fmt) builtin parses input strings matching the fmt argument. The output is in the \u0026quot;broken down time\u0026quot; representation consumed by gmtime and output by mktime. The strftime(fmt) builtin formats a time (GMT) with the given format. The strflocaltime does the same, but using the local timezone setting. The format strings for strptime and strftime are described in typical C library documentation. The format string for ISO 8601 datetime is \u0026quot;%Y-%m-%dT%H:%M:%SZ\u0026quot;. jq may not support some or all of this date functionality on some systems. In particular, the %u and %j specifiers for strptime(fmt) are not supported on macOS. jq ´fromdate´ \u0026quot;2015-03-05T23:51:47Z\u0026quot; =\u0026gt; 1425599507 jq ´strptime(\u0026quot;%Y-%m-%dT%H:%M:%SZ\u0026quot;)´ \u0026quot;2015-03-05T23:51:47Z\u0026quot; =\u0026gt; [2015,2,5,23,51,47,4,63] jq ´strptime(\u0026quot;%Y-%m-%dT%H:%M:%SZ\u0026quot;)|mktime´ \u0026quot;2015-03-05T23:51:47Z\u0026quot; =\u0026gt; 1425599507 SQL-Style Operators jq provides a few SQL-style operators. INDEX(stream; index_expression): This builtin produces an object whose keys are computed by the given index expression applied to each value from the given stream. JOIN($idx; stream; idx_expr; join_expr): This builtin joins the values from the given stream to the given index. The index´s keys are computed by applying the given index expression to each value from the given stream. An ar‐ ray of the value in the stream and the corresponding value from the index is fed to the given join expression to produce each result. JOIN($idx; stream; idx_expr): Same as JOIN($idx; stream; idx_expr; .). JOIN($idx; idx_expr): This builtin joins the input . to the given index, applying the given index expression to . to compute the index key. The join operation is as described above. IN(s): This builtin outputs true if . appears in the given stream, otherwise it outputs false. IN(source; s): This builtin outputs true if any value in the source stream appears in the second stream, otherwise it outputs false. builtins Returns a list of all builtin functions in the format name/arity. Since functions with the same name but different arities are considered separate functions, all/0, all/1, and all/2 would all be present in the list. CONDITIONALS AND COMPARISONS ==, != The expression ´a == b´ will produce ´true´ if the result of a and b are equal (that is, if they represent equivalent JSON documents) and ´false´ otherwise. In particular, strings are never considered equal to numbers. If you´re coming from Javascript, jq´s == is like Javascript´s === - considering values equal only when they have the same type as well as the same value. != is \u0026quot;not equal\u0026quot;, and ´a != b´ returns the opposite value of ´a == b´ jq ´.[] == 1´ [1, 1.0, \u0026quot;1\u0026quot;, \u0026quot;banana\u0026quot;] =\u0026gt; true, true, false, false if-then-else if A then B else C end will act the same as B if A produces a value other than false or null, but act the same as C otherwise. Checking for false or null is a simpler notion of \u0026quot;truthiness\u0026quot; than is found in Javascript or Python, but it means that you´ll sometimes have to be more explicit about the condition you want: you can´t test whether, e.g. a string is empty using if .name then A else B end, you´ll need something more like if (.name | length) \u0026gt; 0 then A else B end instead. If the condition A produces multiple results, then B is evaluated once for each result that is not false or null, and C is evaluated once for each false or null. More cases can be added to an if using elif A then B syntax. jq ´if . == 0 then \u0026quot;zero\u0026quot; elif . == 1 then \u0026quot;one\u0026quot; else \u0026quot;many\u0026quot; end´ 2 =\u0026gt; \u0026quot;many\u0026quot; \u0026gt;, \u0026gt;=, \u0026lt;=, \u0026lt; The comparison operators \u0026gt;, \u0026gt;=, \u0026lt;=, \u0026lt; return whether their left argument is greater than, greater than or equal to, less than or equal to or less than their right argument (respectively). The ordering is the same as that described for sort, above. jq ´. \u0026lt; 5´ 2 =\u0026gt; true and/or/not jq supports the normal Boolean operators and/or/not. They have the same standard of truth as if expressions - false and null are considered \u0026quot;false values\u0026quot;, and anything else is a \u0026quot;true value\u0026quot;. If an operand of one of these operators produces multiple results, the operator itself will produce a result for each input. not is in fact a builtin function rather than an operator, so it is called as a filter to which things can be piped rather than with special syntax, as in .foo and .bar | not. These three only produce the values \u0026quot;true\u0026quot; and \u0026quot;false\u0026quot;, and so are only useful for genuine Boolean operations, rather than the common Perl/Python/Ruby idiom of \u0026quot;value_that_may_be_null or de‐ fault\u0026quot;. If you want to use this form of \u0026quot;or\u0026quot;, picking between two values rather than evaluating a condition, see the \u0026quot;//\u0026quot; operator below. jq ´42 and \u0026quot;a string\u0026quot;´ null =\u0026gt; true jq ´(true, false) or false´ null =\u0026gt; true, false jq ´(true, true) and (true, false)´ null =\u0026gt; true, false, true, false jq ´[true, false | not]´ null =\u0026gt; [false, true] Alternative operator: // A filter of the form a // b produces the same results as a, if a produces results other than false and null. Otherwise, a // b produces the same results as b. This is useful for providing defaults: .foo // 1 will evaluate to 1 if there´s no .foo element in the input. It´s similar to how or is sometimes used in Python (jq´s or operator is reserved for strictly Boolean operations). jq ´.foo // 42´ {\u0026quot;foo\u0026quot;: 19} =\u0026gt; 19 jq ´.foo // 42´ {} =\u0026gt; 42 try-catch Errors can be caught by using try EXP catch EXP. The first expression is executed, and if it fails then the second is executed with the error message. The output of the handler, if any, is output as if it had been the output of the expression to try. The try EXP form uses empty as the exception handler. jq ´try .a catch \u0026quot;. is not an object\u0026quot;´ true =\u0026gt; \u0026quot;. is not an object\u0026quot; jq ´[.[]|try .a]´ [{}, true, {\u0026quot;a\u0026quot;:1}] =\u0026gt; [null, 1] jq ´try error(\u0026quot;some exception\u0026quot;) catch .´ true =\u0026gt; \u0026quot;some exception\u0026quot; Breaking out of control structures A convenient use of try/catch is to break out of control structures like reduce, foreach, while, and so on. For example: # Repeat an expression until it raises \u0026quot;break\u0026quot; as an # error, then stop repeating without re-raising the error. # But if the error caught is not \u0026quot;break\u0026quot; then re-raise it. try repeat(exp) catch .==\u0026quot;break\u0026quot; then empty else error; jq has a syntax for named lexical labels to \u0026quot;break\u0026quot; or \u0026quot;go (back) to\u0026quot;: label $out | ... break $out ... The break $label_name expression will cause the program to to act as though the nearest (to the left) label $label_name produced empty. The relationship between the break and corresponding label is lexical: the label has to be \u0026quot;visible\u0026quot; from the break. To break out of a reduce, for example: label $out | reduce .[] as $item (null; if .==false then break $out else ... end) The following jq program produces a syntax error: break $out because no label $out is visible. Error Suppression / Optional Operator: ? The ? operator, used as EXP?, is shorthand for try EXP. jq ´[.[]|(.a)?]´ [{}, true, {\u0026quot;a\u0026quot;:1}] =\u0026gt; [null, 1] REGULAR EXPRESSIONS (PCRE) jq uses the Oniguruma regular expression library, as do php, ruby, TextMate, Sublime Text, etc, so the description here will focus on jq specifics. The jq regex filters are defined so that they can be used using one of these patterns: STRING | FILTER( REGEX ) STRING | FILTER( REGEX; FLAGS ) STRING | FILTER( [REGEX] ) STRING | FILTER( [REGEX, FLAGS] ) where: * STRING, REGEX and FLAGS are jq strings and subject to jq string interpolation; * REGEX, after string interpolation, should be a valid PCRE regex; * FILTER is one of test, match, or capture, as described below. FLAGS is a string consisting of one of more of the supported flags: • g - Global search (find all matches, not just the first) • i - Case insensitive search • m - Multi line mode (´.´ will match newlines) • n - Ignore empty matches • p - Both s and m modes are enabled • s - Single line mode (´^´ -\u0026gt; ´\\A´, ´$´ -\u0026gt; ´\\Z´) • l - Find longest possible matches • x - Extended regex format (ignore whitespace and comments) To match whitespace in an x pattern use an escape such as \\s, e.g. • test( \u0026quot;a\\sb\u0026quot;, \u0026quot;x\u0026quot; ). Note that certain flags may also be specified within REGEX, e.g. • jq -n ´(\u0026quot;test\u0026quot;, \u0026quot;TEst\u0026quot;, \u0026quot;teST\u0026quot;, \u0026quot;TEST\u0026quot;) | test( \u0026quot;(?i)te(?-i)st\u0026quot; )´ evaluates to: true, true, false, false. test(val), test(regex; flags) Like match, but does not return match objects, only true or false for whether or not the regex matches the input. jq ´test(\u0026quot;foo\u0026quot;)´ \u0026quot;foo\u0026quot; =\u0026gt; true jq ´.[] | test(\u0026quot;a b c # spaces are ignored\u0026quot;; \u0026quot;ix\u0026quot;)´ [\u0026quot;xabcd\u0026quot;, \u0026quot;ABC\u0026quot;] =\u0026gt; true, true match(val), match(regex; flags) match outputs an object for each match it finds. Matches have the following fields: • offset - offset in UTF-8 codepoints from the beginning of the input • length - length in UTF-8 codepoints of the match • string - the string that it matched • captures - an array of objects representing capturing groups. Capturing group objects have the following fields: • offset - offset in UTF-8 codepoints from the beginning of the input • length - length in UTF-8 codepoints of this capturing group • string - the string that was captured • name - the name of the capturing group (or null if it was unnamed) Capturing groups that did not match anything return an offset of -1 jq ´match(\u0026quot;(abc)+\u0026quot;; \u0026quot;g\u0026quot;)´ \u0026quot;abc abc\u0026quot; =\u0026gt; {\u0026quot;offset\u0026quot;: 0, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;abc\u0026quot;, \u0026quot;captures\u0026quot;: [{\u0026quot;offset\u0026quot;: 0, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;abc\u0026quot;, \u0026quot;name\u0026quot;: null}]}, {\u0026quot;offset\u0026quot;: 4, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;abc\u0026quot;, \u0026quot;captures\u0026quot;: [{\u0026quot;offset\u0026quot;: 4, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;abc\u0026quot;, \u0026quot;name\u0026quot;: null}]} jq ´match(\u0026quot;foo\u0026quot;)´ \u0026quot;foo bar foo\u0026quot; =\u0026gt; {\u0026quot;offset\u0026quot;: 0, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;foo\u0026quot;, \u0026quot;captures\u0026quot;: []} jq ´match([\u0026quot;foo\u0026quot;, \u0026quot;ig\u0026quot;])´ \u0026quot;foo bar FOO\u0026quot; =\u0026gt; {\u0026quot;offset\u0026quot;: 0, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;foo\u0026quot;, \u0026quot;captures\u0026quot;: []}, {\u0026quot;offset\u0026quot;: 8, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;FOO\u0026quot;, \u0026quot;captures\u0026quot;: []} jq ´match(\u0026quot;foo (?\u0026lt;bar123\u0026gt;bar)? foo\u0026quot;; \u0026quot;ig\u0026quot;)´ \u0026quot;foo bar foo foo foo\u0026quot; =\u0026gt; {\u0026quot;offset\u0026quot;: 0, \u0026quot;length\u0026quot;: 11, \u0026quot;string\u0026quot;: \u0026quot;foo bar foo\u0026quot;, \u0026quot;captures\u0026quot;: [{\u0026quot;offset\u0026quot;: 4, \u0026quot;length\u0026quot;: 3, \u0026quot;string\u0026quot;: \u0026quot;bar\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;bar123\u0026quot;}]}, {\u0026quot;offset\u0026quot;: 12, \u0026quot;length\u0026quot;: 8, \u0026quot;string\u0026quot;: \u0026quot;foo foo\u0026quot;, \u0026quot;captures\u0026quot;: [{\u0026quot;offset\u0026quot;: -1, \u0026quot;length\u0026quot;: 0, \u0026quot;string\u0026quot;: null, \u0026quot;name\u0026quot;: \u0026quot;bar123\u0026quot;}]} jq ´[ match(\u0026quot;.\u0026quot;; \u0026quot;g\u0026quot;)] | length´ \u0026quot;abc\u0026quot; =\u0026gt; 3 capture(val), capture(regex; flags) Collects the named captures in a JSON object, with the name of each capture as the key, and the matched string as the corresponding value. jq ´capture(\u0026quot;(?\u0026lt;a\u0026gt;[a-z]+)-(?\u0026lt;n\u0026gt;[0-9]+)\u0026quot;)´ \u0026quot;xyzzy-14\u0026quot; =\u0026gt; { \u0026quot;a\u0026quot;: \u0026quot;xyzzy\u0026quot;, \u0026quot;n\u0026quot;: \u0026quot;14\u0026quot; } scan(regex), scan(regex; flags) Emit a stream of the non-overlapping substrings of the input that match the regex in accordance with the flags, if any have been specified. If there is no match, the stream is empty. To cap‐ ture all the matches for each input string, use the idiom [ expr ], e.g. [ scan(regex) ]. split(regex; flags) For backwards compatibility, split splits on a string, not a regex. splits(regex), splits(regex; flags) These provide the same results as their split counterparts, but as a stream instead of an array. sub(regex; tostring) sub(regex; string; flags) Emit the string obtained by replacing the first match of regex in the input string with tostring, after interpolation. tostring should be a jq string, and may contain references to named cap‐ tures. The named captures are, in effect, presented as a JSON object (as constructed by capture) to tostring, so a reference to a captured variable named \u0026quot;x\u0026quot; would take the form: \u0026quot;(.x)\u0026quot;. gsub(regex; string), gsub(regex; string; flags) gsub is like sub but all the non-overlapping occurrences of the regex are replaced by the string, after interpolation. ADVANCED FEATURES Variables are an absolute necessity in most programming languages, but they´re relegated to an \u0026quot;advanced feature\u0026quot; in jq. In most languages, variables are the only means of passing around data. If you calculate a value, and you want to use it more than once, you´ll need to store it in a variable. To pass a value to another part of the program, you´ll need that part of the program to define a variable (as a function parameter, object member, or whatever) in which to place the data. It is also possible to define functions in jq, although this is is a feature whose biggest use is defining jq´s standard library (many jq functions such as map and find are in fact written in jq). jq has reduction operators, which are very powerful but a bit tricky. Again, these are mostly used internally, to define some useful bits of jq´s standard library. It may not be obvious at first, but jq is all about generators (yes, as often found in other languages). Some utilities are provided to help deal with generators. Some minimal I/O support (besides reading JSON from standard input, and writing JSON to standard output) is available. Finally, there is a module/library system. Variable / Symbolic Binding Operator: ... as $identifier | ... In jq, all filters have an input and an output, so manual plumbing is not necessary to pass a value from one part of a program to the next. Many expressions, for instance a + b, pass their in‐ put to two distinct subexpressions (here a and b are both passed the same input), so variables aren´t usually necessary in order to use a value twice. For instance, calculating the average value of an array of numbers requires a few variables in most languages - at least one to hold the array, perhaps one for each element or for a loop counter. In jq, it´s simply add / length - the add expression is given the array and produces its sum, and the length expression is given the array and produces its length. So, there´s generally a cleaner way to solve most problems in jq than defining variables. Still, sometimes they do make things easier, so jq lets you define variables using expression as $variable. All variable names start with $. Here´s a slightly uglier version of the array-averaging example: length as $array_length | add / $array_length We´ll need a more complicated problem to find a situation where using variables actually makes our lives easier. Suppose we have an array of blog posts, with \u0026quot;author\u0026quot; and \u0026quot;title\u0026quot; fields, and another object which is used to map author usernames to real names. Our input looks like: {\u0026quot;posts\u0026quot;: [{\u0026quot;title\u0026quot;: \u0026quot;Frist psot\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;anon\u0026quot;}, {\u0026quot;title\u0026quot;: \u0026quot;A well-written article\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;person1\u0026quot;}], \u0026quot;realnames\u0026quot;: {\u0026quot;anon\u0026quot;: \u0026quot;Anonymous Coward\u0026quot;, \u0026quot;person1\u0026quot;: \u0026quot;Person McPherson\u0026quot;}} We want to produce the posts with the author field containing a real name, as in: {\u0026quot;title\u0026quot;: \u0026quot;Frist psot\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;Anonymous Coward\u0026quot;} {\u0026quot;title\u0026quot;: \u0026quot;A well-written article\u0026quot;, \u0026quot;author\u0026quot;: \u0026quot;Person McPherson\u0026quot;} We use a variable, $names, to store the realnames object, so that we can refer to it later when looking up author usernames: .realnames as $names | .posts[] | {title, author: $names[.author]} The expression exp as $x | ... means: for each value of expression exp, run the rest of the pipeline with the entire original input, and with $x set to that value. Thus as functions as some‐ thing of a foreach loop. Just as {foo} is a handy way of writing {foo: .foo}, so {$foo} is a handy way of writing {foo:$foo}. Multiple variables may be declared using a single as expression by providing a pattern that matches the structure of the input (this is known as \u0026quot;destructuring\u0026quot;): . as {realnames: $names, posts: [$first, $second]} | ... The variable declarations in array patterns (e.g., . as [$first, $second]) bind to the elements of the array in from the element at index zero on up, in order. When there is no value at the index for an array pattern element, null is bound to that variable. Variables are scoped over the rest of the expression that defines them, so .realnames as $names | (.posts[] | {title, author: $names[.author]}) will work, but (.realnames as $names | .posts[]) | {title, author: $names[.author]} won´t. For programming language theorists, it´s more accurate to say that jq variables are lexically-scoped bindings. In particular there´s no way to change the value of a binding; one can only setup a new binding with the same name, but which will not be visible where the old one was. jq ´.bar as $x | .foo | . + $x´ {\u0026quot;foo\u0026quot;:10, \u0026quot;bar\u0026quot;:200} =\u0026gt; 210 jq ´. as $i|[(.*2|. as $i| $i), $i]´ 5 =\u0026gt; [10,5] jq ´. as [$a, $b, {c: $c}] | $a + $b + $c´ [2, 3, {\u0026quot;c\u0026quot;: 4, \u0026quot;d\u0026quot;: 5}] =\u0026gt; 9 jq ´.[] as [$a, $b] | {a: $a, b: $b}´ [[0], [0, 1], [2, 1, 0]] =\u0026gt; {\u0026quot;a\u0026quot;:0,\u0026quot;b\u0026quot;:null}, {\u0026quot;a\u0026quot;:0,\u0026quot;b\u0026quot;:1}, {\u0026quot;a\u0026quot;:2,\u0026quot;b\u0026quot;:1} Defining Functions You can give a filter a name using \u0026quot;def\u0026quot; syntax: def increment: . + 1; From then on, increment is usable as a filter just like a builtin function (in fact, this is how many of the builtins are defined). A function may take arguments: def map(f): [.[] | f]; Arguments are passed as filters (functions with no arguments), not as values. The same argument may be referenced multiple times with different inputs (here f is run for each element of the input array). Arguments to a function work more like callbacks than like value arguments. This is important to understand. Consider: def foo(f): f|f; 5|foo(.*2) The result will be 20 because f is .*2, and during the first invocation of f . will be 5, and the second time it will be 10 (5 * 2), so the result will be 20. Function arguments are filters, and filters expect an input when invoked. If you want the value-argument behaviour for defining simple functions, you can just use a variable: def addvalue(f): f as $f | map(. + $f); Or use the short-hand: def addvalue($f): ...; With either definition, addvalue(.foo) will add the current input´s .foo field to each element of the array. Do note that calling addvalue(.[]) will cause the map(. + $f) part to be evaluated once per value in the value of . at the call site. Multiple definitions using the same function name are allowed. Each re-definition replaces the previous one for the same number of function arguments, but only for references from functions (or main program) subsequent to the re-definition. See also the section below on scoping. jq ´def addvalue(f): . + [f]; map(addvalue(.[0]))´ [[1,2],[10,20]] =\u0026gt; [[1,2,1], [10,20,10]] jq ´def addvalue(f): f as $x | map(. + $x); addvalue(.[0])´ [[1,2],[10,20]] =\u0026gt; [[1,2,1,2], [10,20,1,2]] Scoping There are two types of symbols in jq: value bindings (a.k.a., \u0026quot;variables\u0026quot;), and functions. Both are scoped lexically, with expressions being able to refer only to symbols that have been de‐ fined \u0026quot;to the left\u0026quot; of them. The only exception to this rule is that functions can refer to themselves so as to be able to create recursive functions. For example, in the following expression there is a binding which is visible \u0026quot;to the right\u0026quot; of it, ... | .*3 as $times_three | [. + $times_three] | ..., but not \u0026quot;to the left\u0026quot;. Consider this expression now, ... | (.*3 as $times_three | [.+ $times_three]) | ...: here the binding $times_three is not visible past the closing parenthesis. Reduce The reduce syntax in jq allows you to combine all of the results of an expression by accumulating them into a single answer. As an example, we´ll pass [3,2,1] to this expression: reduce .[] as $item (0; . + $item) For each result that .[] produces, . + $item is run to accumulate a running total, starting from 0. In this example, .[] produces the results 3, 2, and 1, so the effect is similar to running something like this: 0 | (3 as $item | . + $item) | (2 as $item | . + $item) | (1 as $item | . + $item) jq ´reduce .[] as $item (0; . + $item)´ [10,2,5,3] =\u0026gt; 20 isempty(exp) Returns true if exp produces no outputs, false otherwise. jq ´isempty(empty)´ null =\u0026gt; true limit(n; exp) The limit function extracts up to n outputs from exp. jq ´[limit(3;.[])]´ [0,1,2,3,4,5,6,7,8,9] =\u0026gt; [0,1,2] first(expr), last(expr), nth(n; expr) The first(expr) and last(expr) functions extract the first and last values from expr, respectively. The nth(n; expr) function extracts the nth value output by expr. This can be defined as def nth(n; expr): last(limit(n + 1; expr));. Note that nth(n; expr) doesn´t support negative values of n. jq ´[first(range(.)), last(range(.)), nth(./2; range(.))]´ 10 =\u0026gt; [0,9,5] first, last, nth(n) The first and last functions extract the first and last values from any array at .. The nth(n) function extracts the nth value of any array at .. jq ´[range(.)]|[first, last, nth(5)]´ 10 =\u0026gt; [0,9,5] foreach The foreach syntax is similar to reduce, but intended to allow the construction of limit and reducers that produce intermediate results (see example). The form is foreach EXP as $var (INIT; UPDATE; EXTRACT). Like reduce, INIT is evaluated once to produce a state value, then each output of EXP is bound to $var, UPDATE is evaluated for each output of EXP with the current state and with $var visible. Each value output by UPDATE replaces the previous state. Finally, EXTRACT is evaluated for each new state to extract an output of foreach. This is mostly useful only for constructing reduce- and limit-like functions. But it is much more general, as it allows for partial reductions (see the example below). jq ´[foreach .[] as $item ([[],[]]; if $item == null then [[],.[0]] else [(.[0] + [$item]),[]] end; if $item == null then .[1] else empty end)]´ [1,2,3,4,null,\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;,null] =\u0026gt; [[1,2,3,4],[\u0026quot;a\u0026quot;,\u0026quot;b\u0026quot;]] Recursion As described above, recurse uses recursion, and any jq function can be recursive. The while builtin is also implemented in terms of recursion. Tail calls are optimized whenever the expression to the left of the recursive call outputs its last value. In practice this means that the expression to the left of the recursive call should not produce more than one output for each input. For example: def recurse(f): def r: ., (f | select(. != null) | r); r; def while(cond; update): def _while: if cond then ., (update | _while) else empty end; _while; def repeat(exp): def _repeat: exp, _repeat; _repeat; Generators and iterators Some jq operators and functions are actually generators in that they can produce zero, one, or more values for each input, just as one might expect in other programming languages that have generators. For example, .[] generates all the values in its input (which must be an array or an object), range(0; 10) generates the integers between 0 and 10, and so on. Even the comma operator is a generator, generating first the values generated by the expression to the left of the comma, then for each of those, the values generate by the expression on the right of the comma. The empty builtin is the generator that produces zero outputs. The empty builtin backtracks to the preceding generator expression. All jq functions can be generators just by using builtin generators. It is also possible to define new generators using only recursion and the comma operator. If the recursive call(s) is(are) \u0026quot;in tail position\u0026quot; then the generator will be efficient. In the example below the recursive call by _range to itself is in tail position. The example shows off three advanced topics: tail re‐ cursion, generator construction, and sub-functions. jq ´def range(init; upto; by): def _range: if (by \u0026gt; 0 and . \u0026lt; upto) or (by \u0026lt; 0 and . \u0026gt; upto) then ., ((.+by)|_range) else . end; if by == 0 then init else init|_range end | select((by \u0026gt; 0 and . \u0026lt; upto) or (by \u0026lt; 0 and . \u0026gt; upto)); range(0; 10; 3)´ null =\u0026gt; 0, 3, 6, 9 jq ´def while(cond; update): def _while: if cond then ., (update | _while) else empty end; _while; [while(.\u0026lt;100; .*2)]´ 1 =\u0026gt; [1,2,4,8,16,32,64] MATH jq currently only has IEEE754 double-precision (64-bit) floating point number support. Besides simple arithmetic operators such as +, jq also has most standard math functions from the C math library. C math functions that take a single input argument (e.g., sin()) are available as zero-argument jq functions. C math functions that take two input arguments (e.g., pow()) are available as two-argument jq functions that ignore .. C math functions that take three input ar‐ guments are available as three-argument jq functions that ignore .. Availability of standard math functions depends on the availability of the corresponding math functions in your operating system and C math library. Unavailable math functions will be defined but will raise an error. One-input C math functions: acos acosh asin asinh atan atanh cbrt ceil cos cosh erf erfc exp exp10 exp2 expm1 fabs floor gamma j0 j1 lgamma log log10 log1p log2 logb nearbyint pow10 rint round significand sin sinh sqrt tan tanh tgamma trunc y0 y1. Two-input C math functions: atan2 copysign drem fdim fmax fmin fmod frexp hypot jn ldexp modf nextafter nexttoward pow remainder scalb scalbln yn. Three-input C math functions: fma. See your system´s manual for more information on each of these. I/O At this time jq has minimal support for I/O, mostly in the form of control over when inputs are read. Two builtins functions are provided for this, input and inputs, that read from the same sources (e.g., stdin, files named on the command-line) as jq itself. These two builtins, and jq´s own reading actions, can be interleaved with each other. Two builtins provide minimal output capabilities, debug, and stderr. (Recall that a jq program´s output values are always output as JSON texts on stdout.) The debug builtin can have applica‐ tion-specific behavior, such as for executables that use the libjq C API but aren´t the jq executable itself. The stderr builtin outputs its input in raw mode to stder with no additional deco‐ ration, not even a newline. Most jq builtins are referentially transparent, and yield constant and repeatable value streams when applied to constant inputs. This is not true of I/O builtins. input Outputs one new input. inputs Outputs all remaining inputs, one by one. This is primarily useful for reductions over a program´s inputs. debug Causes a debug message based on the input value to be produced. The jq executable wraps the input value with [\u0026quot;DEBUG:\u0026quot;, \u0026lt;input-value\u0026gt;] and prints that and a newline on stderr, compactly. This may change in the future. stderr Prints its input in raw and compact mode to stderr with no additional decoration, not even a newline. input_filename Returns the name of the file whose input is currently being filtered. Note that this will not work well unless jq is running in a UTF-8 locale. input_line_number Returns the line number of the input currently being filtered. STREAMING With the --stream option jq can parse input texts in a streaming fashion, allowing jq programs to start processing large JSON texts immediately rather than after the parse completes. If you have a single JSON text that is 1GB in size, streaming it will allow you to process it much more quickly. However, streaming isn´t easy to deal with as the jq program will have [\u0026lt;path\u0026gt;, \u0026lt;leaf-value\u0026gt;] (and a few other forms) as inputs. Several builtins are provided to make handling streams easier. The examples below use the streamed form of [0,[1]], which is [[0],0],[[1,0],1],[[1,0]],[[1]]. Streaming forms include [\u0026lt;path\u0026gt;, \u0026lt;leaf-value\u0026gt;] (to indicate any scalar value, empty array, or empty object), and [\u0026lt;path\u0026gt;] (to indicate the end of an array or object). Future versions of jq run with --stream and -seq may output additional forms such as [\u0026quot;error message\u0026quot;] when an input text fails to parse. truncate_stream(stream_expression) Consumes a number as input and truncates the corresponding number of path elements from the left of the outputs of the given streaming expression. jq ´[1|truncate_stream([[0],1],[[1,0],2],[[1,0]],[[1]])]´ 1 =\u0026gt; [[[0],2],[[0]]] fromstream(stream_expression) Outputs values corresponding to the stream expression´s outputs. jq ´fromstream(1|truncate_stream([[0],1],[[1,0],2],[[1,0]],[[1]]))´ null =\u0026gt; [2] tostream The tostream builtin outputs the streamed form of its input. jq ´. as $dot|fromstream($dot|tostream)|.==$dot´ [0,[1,{\u0026quot;a\u0026quot;:1},{\u0026quot;b\u0026quot;:2}]] =\u0026gt; true ASSIGNMENT Assignment works a little differently in jq than in most programming languages. jq doesn´t distinguish between references to and copies of something - two objects or arrays are either equal or not equal, without any further notion of being \u0026quot;the same object\u0026quot; or \u0026quot;not the same object\u0026quot;. If an object has two fields which are arrays, .foo and .bar, and you append something to .foo, then .bar will not get bigger, even if you´ve previously set .bar = .foo. If you´re used to pro‐ gramming in languages like Python, Java, Ruby, Javascript, etc. then you can think of it as though jq does a full deep copy of every object before it does the assignment (for performance it doesn´t actually do that, but that´s the general idea). This means that it´s impossible to build circular values in jq (such as an array whose first element is itself). This is quite intentional, and ensures that anything a jq program can produce can be represented in JSON. All the assignment operators in jq have path expressions on the left-hand side (LHS). The right-hand side (RHS) procides values to set to the paths named by the LHS path expressions. Values in jq are always immutable. Internally, assignment works by using a reduction to compute new, replacement values for . that have had all the desired assignments applied to ., then out‐ putting the modified value. This might be made clear by this example: {a:{b:{c:1}}} | (.a.b|=3), .. This will output {\u0026quot;a\u0026quot;:{\u0026quot;b\u0026quot;:3}} and {\u0026quot;a\u0026quot;:{\u0026quot;b\u0026quot;:{\u0026quot;c\u0026quot;:1}}} because the last sub-expression, ., sees the original value, not the modified value. Most users will want to use modification assignment operators, such as |= or +=, rather than =. Note that the LHS of assignment operators refers to a value in .. Thus $var.foo = 1 won´t work as expected ($var.foo is not a valid or useful path expression in .); use $var | .foo = 1 in‐ stead. Note too that .a,.b=0 does not set .a and .b, but (.a,.b)=0 sets both. Update-assignment: |= This is the \u0026quot;update\u0026quot; operator ´|=´. It takes a filter on the right-hand side and works out the new value for the property of . being assigned to by running the old value through this expres‐ sion. For instance, (.foo, .bar) |= .+1 will build an object with the \u0026quot;foo\u0026quot; field set to the input´s \u0026quot;foo\u0026quot; plus 1, and the \u0026quot;bar\u0026quot; field set to the input´s \u0026quot;bar\u0026quot; plus 1. The left-hand side can be any general path expression; see path(). Note that the left-hand side of ´|=´ refers to a value in .. Thus $var.foo |= . + 1 won´t work as expected ($var.foo is not a valid or useful path expression in .); use $var | .foo |= . + 1 instead. If the right-hand side outputs no values (i.e., empty), then the left-hand side path will be deleted, as with del(path). If the right-hand side outputs multiple values, only the first one will be used (COMPATIBILITY NOTE: in jq 1.5 and earlier releases, it used to be that only the last one was used). jq ´(..|select(type==\u0026quot;boolean\u0026quot;)) |= if . then 1 else 0 end´ [true,false,[5,true,[true,[false]],false]] =\u0026gt; [1,0,[5,1,[1,[0]],0]] Arithmetic update-assignment: +=, -=, *=, /=, %=, //= jq has a few operators of the form a op= b, which are all equivalent to a |= . op b. So, += 1 can be used to increment values, being the same as |= . + 1. jq ´.foo += 1´ {\u0026quot;foo\u0026quot;: 42} =\u0026gt; {\u0026quot;foo\u0026quot;: 43} Plain assignment: = This is the plain assignment operator. Unlike the others, the input to the right-hand-side (RHS) is the same as the input to the left-hand-side (LHS) rather than the value at the LHS path, and all values output by the RHS will be used (as shown below). If the RHS of ´=´ produces multiple values, then for each such value jq will set the paths on the left-hand side to the value and then it will output the modified .. For example, (.a,.b)=range(2) outputs {\u0026quot;a\u0026quot;:0,\u0026quot;b\u0026quot;:0}, then {\u0026quot;a\u0026quot;:1,\u0026quot;b\u0026quot;:1}. The \u0026quot;update\u0026quot; assignment forms (see above) do not do this. This example should show the difference between ´=´ and ´|=´: Provide input ´{\u0026quot;a\u0026quot;: {\u0026quot;b\u0026quot;: 10}, \u0026quot;b\u0026quot;: 20}´ to the programs: .a = .b .a |= .b The former will set the \u0026quot;a\u0026quot; field of the input to the \u0026quot;b\u0026quot; field of the input, and produce the output {\u0026quot;a\u0026quot;: 20, \u0026quot;b\u0026quot;: 20}. The latter will set the \u0026quot;a\u0026quot; field of the input to the \u0026quot;a\u0026quot; field´s \u0026quot;b\u0026quot; field, producing {\u0026quot;a\u0026quot;: 10, \u0026quot;b\u0026quot;: 20}. Another example of the difference between ´=´ and ´|=´: null|(.a,.b)=range(3) outputs ´{\u0026quot;a\u0026quot;:0,\u0026quot;b\u0026quot;:0}´, ´{\u0026quot;a\u0026quot;:1,\u0026quot;b\u0026quot;:1}´, and ´{\u0026quot;a\u0026quot;:2,\u0026quot;b\u0026quot;:2}´, while null|(.a,.b)|=range(3) outputs just ´{\u0026quot;a\u0026quot;:0,\u0026quot;b\u0026quot;:0}´. Complex assignments Lots more things are allowed on the left-hand side of a jq assignment than in most languages. We´ve already seen simple field accesses on the left hand side, and it´s no surprise that array accesses work just as well: .posts[0].title = \u0026quot;JQ Manual\u0026quot; What may come as a surprise is that the expression on the left may produce multiple results, referring to different points in the input document: .posts[].comments |= . + [\u0026quot;this is great\u0026quot;] That example appends the string \u0026quot;this is great\u0026quot; to the \u0026quot;comments\u0026quot; array of each post in the input (where the input is an object with a field \u0026quot;posts\u0026quot; which is an array of posts). When jq encounters an assignment like ´a = b´, it records the \u0026quot;path\u0026quot; taken to select a part of the input document while executing a. This path is then used to find which part of the input to change while executing the assignment. Any filter may be used on the left-hand side of an equals - whichever paths it selects from the input will be where the assignment is performed. This is a very powerful operation. Suppose we wanted to add a comment to blog posts, using the same \u0026quot;blog\u0026quot; input above. This time, we only want to comment on the posts written by \u0026quot;stedolan\u0026quot;. We can find those posts using the \u0026quot;select\u0026quot; function described earlier: .posts[] | select(.author == \u0026quot;stedolan\u0026quot;) The paths provided by this operation point to each of the posts that \u0026quot;stedolan\u0026quot; wrote, and we can comment on each of them in the same way that we did before: (.posts[] | select(.author == \u0026quot;stedolan\u0026quot;) | .comments) |= . + [\u0026quot;terrible.\u0026quot;] MODULES jq has a library/module system. Modules are files whose names end in .jq. Modules imported by a program are searched for in a default search path (see below). The import and include directives allow the importer to alter this path. Paths in the a search path are subject to various substitutions. For paths starting with \u0026quot;~/\u0026quot;, the user´s home directory is substituted for \u0026quot;~\u0026quot;. For paths starting with \u0026quot;$ORIGIN/\u0026quot;, the path of the jq executable is substituted for \u0026quot;$ORIGIN\u0026quot;. For paths starting with \u0026quot;./\u0026quot; or paths that are \u0026quot;.\u0026quot;, the path of the including file is substituted for \u0026quot;.\u0026quot;. For top-level programs given on the command-line, the current directory is used. Import directives can optionally specify a search path to which the default is appended. The default search path is the search path given to the -L command-line option, else [\u0026quot;~/.jq\u0026quot;, \u0026quot;$ORIGIN/../lib/jq\u0026quot;, \u0026quot;$ORIGIN/../lib\u0026quot;]. Null and empty string path elements terminate search path processing. A dependency with relative path \u0026quot;foo/bar\u0026quot; would be searched for in \u0026quot;foo/bar.jq\u0026quot; and \u0026quot;foo/bar/bar.jq\u0026quot; in the given search path. This is intended to allow modules to be placed in a directory along with, for example, version control files, README files, and so on, but also to allow for single-file modules. Consecutive components with the same name are not allowed to avoid ambiguities (e.g., \u0026quot;foo/foo\u0026quot;). For example, with -L$HOME/.jq a module foo can be found in $HOME/.jq/foo.jq and $HOME/.jq/foo/foo.jq. If \u0026quot;$HOME/.jq\u0026quot; is a file, it is sourced into the main program. import RelativePathString as NAME [\u0026lt;metadata\u0026gt;]; Imports a module found at the given path relative to a directory in a search path. A \u0026quot;.jq\u0026quot; suffix will be added to the relative path string. The module´s symbols are prefixed with \u0026quot;NAME::\u0026quot;. The optional metadata must be a constant jq expression. It should be an object with keys like \u0026quot;homepage\u0026quot; and so on. At this time jq only uses the \u0026quot;search\u0026quot; key/value of the metadata. The meta‐ data is also made available to users via the modulemeta builtin. The \u0026quot;search\u0026quot; key in the metadata, if present, should have a string or array value (array of strings); this is the search path to be prefixed to the top-level search path. include RelativePathString [\u0026lt;metadata\u0026gt;]; Imports a module found at the given path relative to a directory in a search path as if it were included in place. A \u0026quot;.jq\u0026quot; suffix will be added to the relative path string. The module´s sym‐ bols are imported into the caller´s namespace as if the module´s content had been included directly. The optional metadata must be a constant jq expression. It should be an object with keys like \u0026quot;homepage\u0026quot; and so on. At this time jq only uses the \u0026quot;search\u0026quot; key/value of the metadata. The meta‐ data is also made available to users via the modulemeta builtin. import RelativePathString as $NAME [\u0026lt;metadata\u0026gt;]; Imports a JSON file found at the given path relative to a directory in a search path. A \u0026quot;.json\u0026quot; suffix will be added to the relative path string. The file´s data will be available as $NAME::NAME. The optional metadata must be a constant jq expression. It should be an object with keys like \u0026quot;homepage\u0026quot; and so on. At this time jq only uses the \u0026quot;search\u0026quot; key/value of the metadata. The meta‐ data is also made available to users via the modulemeta builtin. The \u0026quot;search\u0026quot; key in the metadata, if present, should have a string or array value (array of strings); this is the search path to be prefixed to the top-level search path. module \u0026lt;metadata\u0026gt;; This directive is entirely optional. It´s not required for proper operation. It serves only the purpose of providing metadata that can be read with the modulemeta builtin. The metadata must be a constant jq expression. It should be an object with keys like \u0026quot;homepage\u0026quot;. At this time jq doesn´t use this metadata, but it is made available to users via the modulemeta builtin. modulemeta Takes a module name as input and outputs the module´s metadata as an object, with the module´s imports (including metadata) as an array value for the \u0026quot;deps\u0026quot; key. Programs can use this to query a module´s metadata, which they could then use to, for example, search for, download, and install missing dependencies. COLORS To configure alternative colors just set the JQ_COLORS environment variable to colon-delimited list of partial terminal escape sequences like \u0026quot;1;31\u0026quot;, in this order: • color for null • color for false • color for true • color for numbers • color for strings • color for arrays • color for objects The default color scheme is the same as setting \u0026quot;JQ_COLORS=1;30:0;39:0;39:0;39:0;32:1;39:1;39\u0026quot;. This is not a manual for VT100/ANSI escapes. However, each of these color specifications should consist of two numbers separated by a semi-colon, where the first number is one of these: • 1 (bright) • 2 (dim) • 4 (underscore) • 5 (blink) • 7 (reverse) • 8 (hidden) and the second is one of these: • 30 (black) • 31 (red) • 32 (green) • 33 (yellow) • 34 (blue) • 35 (magenta) • 36 (cyan) • 37 (white) BUGS Presumably. Report them or discuss them at: https://github.com/stedolan/jq/issues AUTHOR Stephen Dolan \u0026lt;mu@netsoc.tcd.ie\u0026gt; December 2017 JQ(1) "}),e.add({id:33,href:"/docs/tools/utility/jql/",title:"Jql",description:`Description # JQL is a command-line tool for querying JSON data. It is similar to jq, but with a more SQL-like syntax.
install # brew install jql sample usage # jql '.' example.json { \u0026quot;some\u0026quot;: { \u0026quot;property\u0026quot;: \u0026quot;value\u0026quot; } } jql '\u0026quot;some\u0026quot;.\u0026quot;property\u0026quot;' example.json sample output # value help # A JSON query language CLI tool Usage: jql [OPTIONS] [selectors] [JSON] Arguments: [selectors] Selectors to apply [JSON] JSON file to use Options: -c, --check Checks if the input is valid JSON -f, --from-file \u0026lt;FILE\u0026gt; Reads selectors from file rather than from a command line -i, --inline Inlines JSON output -r, --raw-output Writes raw string selection directly to standard output without JSON double-quotes -s, --stream Reads a stream of JSON data line by line -h, --help Print help -V, --version Print version `,content:`Description # JQL is a command-line tool for querying JSON data. It is similar to jq, but with a more SQL-like syntax.
install # brew install jql sample usage # jql '.' example.json { \u0026quot;some\u0026quot;: { \u0026quot;property\u0026quot;: \u0026quot;value\u0026quot; } } jql '\u0026quot;some\u0026quot;.\u0026quot;property\u0026quot;' example.json sample output # value help # A JSON query language CLI tool Usage: jql [OPTIONS] [selectors] [JSON] Arguments: [selectors] Selectors to apply [JSON] JSON file to use Options: -c, --check Checks if the input is valid JSON -f, --from-file \u0026lt;FILE\u0026gt; Reads selectors from file rather than from a command line -i, --inline Inlines JSON output -r, --raw-output Writes raw string selection directly to standard output without JSON double-quotes -s, --stream Reads a stream of JSON data line by line -h, --help Print help -V, --version Print version `}),e.add({id:34,href:"/docs/tools/utility/htmlq/",title:"Htmlq",description:`Description # htmlq is a command-line tool to query HTML/XML documents.
Installation # brew install htmlq Usage # curl bing.com | htmlq a Resources # htmlq css selectors Similar # jq xmlstarlet xidel xmllint xml xq xsltproc xpath xargs xsv help # htmlq 0.4.0 Michael Maclean \u0026lt;michael@mgdm.net\u0026gt; Runs CSS selectors on HTML USAGE: htmlq [FLAGS] [OPTIONS] [--] [selector]... FLAGS: -B, --detect-base Try to detect the base URL from the \u0026lt;base\u0026gt; tag in the document.`,content:"Description # htmlq is a command-line tool to query HTML/XML documents.\nInstallation # brew install htmlq Usage # curl bing.com | htmlq a Resources # htmlq css selectors Similar # jq xmlstarlet xidel xmllint xml xq xsltproc xpath xargs xsv help # htmlq 0.4.0 Michael Maclean \u0026lt;michael@mgdm.net\u0026gt; Runs CSS selectors on HTML USAGE: htmlq [FLAGS] [OPTIONS] [--] [selector]... FLAGS: -B, --detect-base Try to detect the base URL from the \u0026lt;base\u0026gt; tag in the document. If not found, default to the value of --base, if supplied -h, --help Prints help information -w, --ignore-whitespace When printing text nodes, ignore those that consist entirely of whitespace -p, --pretty Pretty-print the serialised output -t, --text Output only the contents of text nodes inside selected elements -V, --version Prints version information OPTIONS: -a, --attribute \u0026lt;attribute\u0026gt; Only return this attribute (if present) from selected elements -b, --base \u0026lt;base\u0026gt; Use this URL as the base for links -f, --filename \u0026lt;FILE\u0026gt; The input file. Defaults to stdin -o, --output \u0026lt;FILE\u0026gt; The output file. Defaults to stdout -r, --remove-nodes \u0026lt;SELECTOR\u0026gt;... Remove nodes matching this expression before output. May be specified multiple times ARGS: \u0026lt;selector\u0026gt;... The CSS expression to select [default: html] ```bash "}),e.add({id:35,href:"/docs/tools/utility/ipcalc/",title:"Ipcalc",description:`Description # ipcalc is a command line tool for network address calculations.
Installation # brew install ipcalc Usage # ipcalc 192.168.0.1/24 Output # Address: 192.168.0.1 Network: 192.168.0.0/24 Netmask: 255.255.255.0 = 24 Broadcast: 192.168.0.255 Address space: Private Use HostMin: 192.168.0.1 HostMax: 192.168.0.254 Hosts/Net: 254 Resources # ipcalc help # Usage: ipcalc [OPTION...] -c, --check Validate IP address -r, --random-private=PREFIX Generate a random private IP network using the supplied prefix or mask. -S, --split=PREFIX Split the provided network using the provided prefix/netmask -d, --deaggregate=IP1-IP2 Deaggregate the provided address range -i, --info Print information on the provided IP address (default) --all-info Print verbose information on the provided IP address Specific info options: --reverse-dns Print network in a the reverse DNS format -a, --address Display IP address -b, --broadcast Display calculated broadcast address -m, --netmask Display netmask for IP -n, --network Display network address -p, --prefix Display network prefix --minaddr Display the minimum address in the network --maxaddr Display the maximum address in the network --addresses Display the maximum number of addresses in the network --addrspace Display the address space the network resides on -h, --hostname Show hostname determined via DNS -o, --lookup-host=STRING Show IP as determined via DNS -g, --geoinfo Show Geographic information about the provided IP Other options: -4, --ipv4 Explicitly specify the IPv4 address family -6, --ipv6 Explicitly specify the IPv6 address family --class-prefix When specified the default prefix will be determined by the IPv4 address class --no-decorate Print only the requested information -j, --json JSON output -s, --silent Don't ever display error messages -v, --version Display program version -?`,content:`Description # ipcalc is a command line tool for network address calculations.
Installation # brew install ipcalc Usage # ipcalc 192.168.0.1/24 Output # Address: 192.168.0.1 Network: 192.168.0.0/24 Netmask: 255.255.255.0 = 24 Broadcast: 192.168.0.255 Address space: Private Use HostMin: 192.168.0.1 HostMax: 192.168.0.254 Hosts/Net: 254 Resources # ipcalc help # Usage: ipcalc [OPTION...] -c, --check Validate IP address -r, --random-private=PREFIX Generate a random private IP network using the supplied prefix or mask. -S, --split=PREFIX Split the provided network using the provided prefix/netmask -d, --deaggregate=IP1-IP2 Deaggregate the provided address range -i, --info Print information on the provided IP address (default) --all-info Print verbose information on the provided IP address Specific info options: --reverse-dns Print network in a the reverse DNS format -a, --address Display IP address -b, --broadcast Display calculated broadcast address -m, --netmask Display netmask for IP -n, --network Display network address -p, --prefix Display network prefix --minaddr Display the minimum address in the network --maxaddr Display the maximum address in the network --addresses Display the maximum number of addresses in the network --addrspace Display the address space the network resides on -h, --hostname Show hostname determined via DNS -o, --lookup-host=STRING Show IP as determined via DNS -g, --geoinfo Show Geographic information about the provided IP Other options: -4, --ipv4 Explicitly specify the IPv4 address family -6, --ipv6 Explicitly specify the IPv6 address family --class-prefix When specified the default prefix will be determined by the IPv4 address class --no-decorate Print only the requested information -j, --json JSON output -s, --silent Don't ever display error messages -v, --version Display program version -?, --help Show this help message --usage Display brief usage message `}),e.add({id:36,href:"/docs/tools/utility/irssi/",title:"Irssi",description:`Description # irssi is a terminal-based IRC client.
Installation # brew install irssi Usage # irssi in program /connect irc.freenode.net /join #channel Resources # irssi irssi on GitHub New users guide # New to IRC # Internet Relay Chat was created in 1988 and has hardly changed. It can be used to exchange text messages (one message = single line) with other people, either privately (called query, PM, private message, MSG) or in a room (channel).`,content:`Description # irssi is a terminal-based IRC client.
Installation # brew install irssi Usage # irssi in program /connect irc.freenode.net /join #channel Resources # irssi irssi on GitHub New users guide # New to IRC # Internet Relay Chat was created in 1988 and has hardly changed. It can be used to exchange text messages (one message = single line) with other people, either privately (called query, PM, private message, MSG) or in a room (channel). Pictures are shared by uploading them to a temporary host like https://uguu.se/ and then pasting the HTTP links. Code snippets or longer texts are shared by pasting them to a Pastebin like https://paste.opensuse.org/ and then sharing the HTTP link.
IRC does not have message history. You can only receive replies while your computer is turned on and connected to the channel you want to follow. Some people run their IRC programs on remote servers for that reason.
IRC is organised into networks. Each network consists of many servers. It (mostly) does not matter which server you connect to as long as it belongs to the network you want to use. Irssi supports connections to many networks at the same time.
Each network contains many channels, rooms that are often dedicated to discussing a specific topic. You can find many channels on https://netsplit.de/ or using a search engine with the keyword \u0026ldquo;IRC\u0026rdquo;. Irssi supports joining many channels at the same time.
There is a rather large IRC network catering to free and open-source software and peer directed projects at https://libera.chat/ and a smaller one at https://www.oftc.net/ \u0026ndash; many free software projects still have support channels on these IRC networks (although some have moved to Matrix or proprietary platforms like Discord).
First start # After (compiling and) installing Irssi, to start it, open a shell (Terminal) and type:
irssi You should be greeted by a blinking cursor behind [(status)]. You are now in the status window of Irssi. Window is the Irssi name for what you might nowadays call a \u0026ldquo;Web browser tab\u0026rdquo;.
If you\u0026rsquo;re confused about what you are seeing on the Irssi screen, you can find an annotated screenshot of it at .
If you want, you can pick a nick name (handle) that will be shown to others reading your messages now, by typing
/set nick whatyouwant Each command or message can be sent by pressing Enter. Commands in Irssi start with a /. If there is no /, then the line that you wrote will be sent as a message to the channel that you have open, for everyone to see.
Leaving # Type /quit to get out of Irssi.
Connecting to a network # Irssi comes with some predefined networks. You can see the current list of networks by typing
/network (the list will be shown in your status window)
To connect to one of the networks in the list, type /connect networkname, for example:
/connect liberachat You should see several messages scroll by. After a while, you should be connected to the Libera Chat network.
:::{attention} Irssi version 1.2 or older may be lacking the liberachat network entry. See https://github.com/shabble/irssi-docs/wiki/liberachat for how to add it. :::
Nickname registration # Many IRC networks (but not all) offer a way to register a user account. Sometimes (but not on all networks) the account registration also includes reserving a nick for you. How to register also differs by network. Some channels only allow users with registered accounts to join them, so it may be very important for you to register a user account.
User accounts are always specific to a network.
For the Libera Chat network, you can find instructions how to register and set up your account with Irssi on https://github.com/shabble/irssi-docs/wiki/liberachat#configure-sasl-automated-log-in
Joining a channel # Once you are connected to a network, you can join channels by typing /join #channelname, for example:
/join #irssi Now, a new window will open and you can send messages to the channel.
Changing windows # You can change between windows using the Ctrl+n or Ctrl+p keys, or\u0026ndash;if your terminal is configured properly\u0026ndash;using Alt+1, Alt+2, \u0026hellip; See for a list of all default key bindings.
Removing clutter # By default, Irssi shows when someone joins or leaves a channel. These messages can waste a lot of lines and obscure the actual chat. To hide them, type
/window hidelevel +joins +parts +quits To get them back
/window hidelevel -joins -parts -quits If you want to hide them by default, /set window_default_hidelevel hidden joins parts quits
Adding a new network # If you want to join a network that is not there, you first need to find at least one server of that network. Let\u0026rsquo;s say you have found the room #hackint on netsplit.de and want to join it. Then you can find that the server is irc.hackint.org, port 6697, SSL (TLS) on. To add it to Irssi, use the commands:
/network add hackint /server add -tls -network hackint irc.hackint.org 6697 Then, you can connect to the newly added network with
/connect hackint Multiple networks # If you are connected to multiple networks, you can change which one you are \u0026ldquo;talking\u0026rdquo; to (which one to send commands) by using the Ctrl+x key in the status window.
On-line help # Most /commands have a help page, you can read it with
/help commandname or on-line.
The settings that can be changed with /SET are described on \u0026ndash; the settingshelp script can be used to read it from within /help
About Scripts # You can enhance your Irssi by installing scripts. Many Perl scripts written by other Irssi users can be found on https://scripts.irssi.org/
Most of them should be compatible with Irssi 1.4 (but some may not, also see the Full Change log for some incompatible ones)
`}),e.add({id:37,href:"/docs/tools/utility/exa/",title:"Exa",description:`Description # exa is a modern replacement for ls.
Installation # brew install exa Usage # exa Resources # exa exa User Guide help # Usage: exa [options] [files...] META OPTIONS -?, --help show list of command-line options -v, --version show version of exa DISPLAY OPTIONS -1, --oneline display one entry per line -l, --long display extended file metadata as a table -G, --grid display entries as a grid (default) -x, --across sort the grid across, rather than downwards -R, --recurse recurse into directories -T, --tree recurse into directories as a tree -F, --classify display type indicator by file names --colo[u]r=WHEN when to use terminal colours (always, auto, never) --colo[u]r-scale highlight levels of file sizes distinctly --icons display icons --no-icons don't display icons (always overrides --icons) FILTERING AND SORTING OPTIONS -a, --all show hidden and 'dot' files -d, --list-dirs list directories as files; don't list their contents -L, --level DEPTH limit the depth of recursion -r, --reverse reverse the sort order -s, --sort SORT_FIELD which field to sort by --group-directories-first list directories before other files -D, --only-dirs list only directories -I, --ignore-glob GLOBS glob patterns (pipe-separated) of files to ignore --git-ignore ignore files mentioned in '.`,content:`Description # exa is a modern replacement for ls.
Installation # brew install exa Usage # exa Resources # exa exa User Guide help # Usage: exa [options] [files...] META OPTIONS -?, --help show list of command-line options -v, --version show version of exa DISPLAY OPTIONS -1, --oneline display one entry per line -l, --long display extended file metadata as a table -G, --grid display entries as a grid (default) -x, --across sort the grid across, rather than downwards -R, --recurse recurse into directories -T, --tree recurse into directories as a tree -F, --classify display type indicator by file names --colo[u]r=WHEN when to use terminal colours (always, auto, never) --colo[u]r-scale highlight levels of file sizes distinctly --icons display icons --no-icons don't display icons (always overrides --icons) FILTERING AND SORTING OPTIONS -a, --all show hidden and 'dot' files -d, --list-dirs list directories as files; don't list their contents -L, --level DEPTH limit the depth of recursion -r, --reverse reverse the sort order -s, --sort SORT_FIELD which field to sort by --group-directories-first list directories before other files -D, --only-dirs list only directories -I, --ignore-glob GLOBS glob patterns (pipe-separated) of files to ignore --git-ignore ignore files mentioned in '.gitignore' Valid sort fields: name, Name, extension, Extension, size, type, modified, accessed, created, inode, and none. date, time, old, and new all refer to modified. LONG VIEW OPTIONS -b, --binary list file sizes with binary prefixes -B, --bytes list file sizes in bytes, without any prefixes -g, --group list each file's group -h, --header add a header row to each column -H, --links list each file's number of hard links -i, --inode list each file's inode number -m, --modified use the modified timestamp field -n, --numeric list numeric user and group IDs -S, --blocks show number of file system blocks -t, --time FIELD which timestamp field to list (modified, accessed, created) -u, --accessed use the accessed timestamp field -U, --created use the created timestamp field --changed use the changed timestamp field --time-style how to format timestamps (default, iso, long-iso, full-iso) --no-permissions suppress the permissions field --octal-permissions list each file's permission in octal format --no-filesize suppress the filesize field --no-user suppress the user field --no-time suppress the time field --git list each file's Git status, if tracked or ignored -@, --extended list each file's extended attributes and sizes `}),e.add({id:38,href:"/docs/tools/utility/expect/",title:"Expect",description:`Description # expect is a tool for automating interactive applications such as telnet, ftp, passwd, fsck, rlogin, tip, etc.
Installation # brew install expect Usage # expect -c 'spawn telnet \u0026lt;host\u0026gt; \u0026lt;port\u0026gt;; expect \u0026quot;login:\u0026quot;; send \u0026quot;\u0026lt;username\u0026gt;\\r\u0026quot;; expect \u0026quot;Password:\u0026quot;; send \u0026quot;\u0026lt;password\u0026gt;\\r\u0026quot;; interact' Resources # expect Similar # tcl help # EXPECT(1) General Commands Manual EXPECT(1) NAME expect - programmed dialogue with interactive programs, Version 5 SYNOPSIS expect [ -dDhinNv ] [ -c cmds ] [ [ -[f|b] ] cmdfile ] [ args ] INTRODUCTION Expect is a program that \u0026quot;talks\u0026quot; to other interactive programs according to a script.`,content:"Description # expect is a tool for automating interactive applications such as telnet, ftp, passwd, fsck, rlogin, tip, etc.\nInstallation # brew install expect Usage # expect -c 'spawn telnet \u0026lt;host\u0026gt; \u0026lt;port\u0026gt;; expect \u0026quot;login:\u0026quot;; send \u0026quot;\u0026lt;username\u0026gt;\\r\u0026quot;; expect \u0026quot;Password:\u0026quot;; send \u0026quot;\u0026lt;password\u0026gt;\\r\u0026quot;; interact' Resources # expect Similar # tcl help # EXPECT(1) General Commands Manual EXPECT(1) NAME expect - programmed dialogue with interactive programs, Version 5 SYNOPSIS expect [ -dDhinNv ] [ -c cmds ] [ [ -[f|b] ] cmdfile ] [ args ] INTRODUCTION Expect is a program that \u0026quot;talks\u0026quot; to other interactive programs according to a script. Following the script, Expect knows what can be expected from a program and what the correct response should be. An interpreted language provides branching and high-level control structures to direct the dialogue. In addition, the user can take control and interact directly when desired, af‐ terward returning control to the script. Expectk is a mixture of Expect and Tk. It behaves just like Expect and Tk's wish. Expect can also be used directly in C or C++ (that is, without Tcl). See libexpect(3). The name \u0026quot;Expect\u0026quot; comes from the idea of send/expect sequences popularized by uucp, kermit and other modem control programs. However unlike uucp, Expect is generalized so that it can be run as a user-level command with any program and task in mind. Expect can actually talk to several programs at the same time. For example, here are some things Expect can do: • Cause your computer to dial you back, so that you can login without paying for the call. • Start a game (e.g., rogue) and if the optimal configuration doesn't appear, restart it (again and again) until it does, then hand over control to you. • Run fsck, and in response to its questions, answer \u0026quot;yes\u0026quot;, \u0026quot;no\u0026quot; or give control back to you, based on predetermined criteria. • Connect to another network or BBS (e.g., MCI Mail, CompuServe) and automatically retrieve your mail so that it appears as if it was originally sent to your local system. • Carry environment variables, current directory, or any kind of information across rlogin, telnet, tip, su, chgrp, etc. There are a variety of reasons why the shell cannot perform these tasks. (Try, you'll see.) All are possible with Expect. In general, Expect is useful for running any program which requires interaction between the program and the user. All that is necessary is that the interaction can be characterized program‐ matically. Expect can also give the user back control (without halting the program being controlled) if desired. Similarly, the user can return control to the script at any time. USAGE Expect reads cmdfile for a list of commands to execute. Expect may also be invoked implicitly on systems which support the #! notation by marking the script executable, and making the first line in your script: #!/usr/local/bin/expect -f Of course, the path must accurately describe where Expect lives. /usr/local/bin is just an example. The -c flag prefaces a command to be executed before any in the script. The command should be quoted to prevent being broken up by the shell. This option may be used multiple times. Multi‐ ple commands may be executed with a single -c by separating them with semicolons. Commands are executed in the order they appear. (When using Expectk, this option is specified as -command.) The -d flag enables some diagnostic output, which primarily reports internal activity of commands such as expect and interact. This flag has the same effect as \u0026quot;exp_internal 1\u0026quot; at the begin‐ ning of an Expect script, plus the version of Expect is printed. (The strace command is useful for tracing statements, and the trace command is useful for tracing variable assignments.) (When using Expectk, this option is specified as -diag.) The -D flag enables an interactive debugger. An integer value should follow. The debugger will take control before the next Tcl procedure if the value is non-zero or if a ^C is pressed (or a breakpoint is hit, or other appropriate debugger command appears in the script). See the README file or SEE ALSO (below) for more information on the debugger. (When using Expectk, this op‐ tion is specified as -Debug.) The -f flag prefaces a file from which to read commands from. The flag itself is optional as it is only useful when using the #! notation (see above), so that other arguments may be supplied on the command line. (When using Expectk, this option is specified as -file.) By default, the command file is read into memory and executed in its entirety. It is occasionally desirable to read files one line at a time. For example, stdin is read this way. In order to force arbitrary files to be handled this way, use the -b flag. (When using Expectk, this option is specified as -buffer.) Note that stdio-buffering may still take place however this shouldn't cause problems when reading from a fifo or stdin. If the string \u0026quot;-\u0026quot; is supplied as a filename, standard input is read instead. (Use \u0026quot;./-\u0026quot; to read from a file actually named \u0026quot;-\u0026quot;.) -h causes Expect to print its usage message and exit. The -i flag causes Expect to interactively prompt for commands instead of reading them from a file. Prompting is terminated via the exit command or upon EOF. See interpreter (below) for more information. -i is assumed if neither a command file nor -c is used. (When using Expectk, this option is specified as -interactive.) -- may be used to delimit the end of the options. This is useful if you want to pass an option-like argument to your script without it being interpreted by Expect. This can usefully be placed in the #! line to prevent any flag-like interpretation by Expect. For example, the following will leave the original arguments (including the script name) in the variable argv. #!/usr/local/bin/expect -- Note that the usual getopt(3) and execve(2) conventions must be observed when adding arguments to the #! line. The file $exp_library/expect.rc is sourced automatically if present, unless the -N flag is used. (When using Expectk, this option is specified as -NORC.) Immediately after this, the file ~/.expect.rc is sourced automatically, unless the -n flag is used. If the environment variable DOTDIR is defined, it is treated as a directory and .expect.rc is read from there. (When using Expectk, this option is specified as -norc.) This sourcing occurs only after executing any -c flags. -v causes Expect to print its version number and exit. (The corresponding flag in Expectk, which uses long flag names, is -version.) Optional args are constructed into a list and stored in the variable named argv. argc is initialized to the length of argv. argv0 is defined to be the name of the script (or binary if no script is used). For example, the following prints out the name of the script and the first three arguments: send_user \u0026quot;$argv0 [lrange $argv 0 2]\\n\u0026quot; COMMANDS Expect uses Tcl (Tool Command Language). Tcl provides control flow (e.g., if, for, break), expression evaluation and several other features such as recursion, procedure definition, etc. Com‐ mands used here but not defined (e.g., set, if, exec) are Tcl commands (see tcl(3)). Expect supports additional commands, described below. Unless otherwise specified, commands return the empty string. Commands are listed alphabetically so that they can be quickly located. However, new users may find it easier to start by reading the descriptions of spawn, send, expect, and interact, in that order. Note that the best introduction to the language (both Expect and Tcl) is provided in the book \u0026quot;Exploring Expect\u0026quot; (see SEE ALSO below). Examples are included in this help but they are very limited since this help is meant primarily as reference material. Note that in the text of this help, \u0026quot;Expect\u0026quot; with an uppercase \u0026quot;E\u0026quot; refers to the Expect program while \u0026quot;expect\u0026quot; with a lower-case \u0026quot;e\u0026quot; refers to the expect command within the Expect pro‐ gram.) close [-slave] [-onexec 0|1] [-i spawn_id] closes the connection to the current process. Most interactive programs will detect EOF on their stdin and exit; thus close usually suffices to kill the process as well. The -i flag declares the process to close corresponding to the named spawn_id. Both expect and interact will detect when the current process exits and implicitly do a close. But if you kill the process by, say, \u0026quot;exec kill $pid\u0026quot;, you will need to explicitly call close. The -onexec flag determines whether the spawn id will be closed in any new spawned processes or if the process is overlayed. To leave a spawn id open, use the value 0. A non-zero inte‐ ger value will force the spawn closed (the default) in any new processes. The -slave flag closes the slave associated with the spawn id. (See \u0026quot;spawn -pty\u0026quot;.) When the connection is closed, the slave is automatically closed as well if still open. No matter whether the connection is closed implicitly or explicitly, you should call wait to clear up the corresponding kernel process slot. close does not call wait since there is no guarantee that closing a process connection will cause it to exit. See wait below for more info. debug [[-now] 0|1] controls a Tcl debugger allowing you to step through statements, set breakpoints, etc. With no arguments, a 1 is returned if the debugger is not running, otherwise a 0 is returned. With a 1 argument, the debugger is started. With a 0 argument, the debugger is stopped. If a 1 argument is preceded by the -now flag, the debugger is started immediately (i.e., in the middle of the debug command itself). Otherwise, the debugger is started with the next Tcl statement. The debug command does not change any traps. Compare this to starting Expect with the -D flag (see above). See the README file or SEE ALSO (below) for more information on the debugger. disconnect disconnects a forked process from the terminal. It continues running in the background. The process is given its own process group (if possible). Standard I/O is redirected to /dev/null. The following fragment uses disconnect to continue running the script in the background. if {[fork]!=0} exit disconnect . . . The following script reads a password, and then runs a program every hour that demands a password each time it is run. The script supplies the password so that you only have to type it once. (See the stty command which demonstrates how to turn off password echoing.) send_user \u0026quot;password?\\ \u0026quot; expect_user -re \u0026quot;(.*)\\n\u0026quot; for {} 1 {} { if {[fork]!=0} {sleep 3600;continue} disconnect spawn priv_prog expect Password: send \u0026quot;$expect_out(1,string)\\r\u0026quot; . . . exit } An advantage to using disconnect over the shell asynchronous process feature (\u0026amp;) is that Expect can save the terminal parameters prior to disconnection, and then later apply them to new ptys. With \u0026amp;, Expect does not have a chance to read the terminal's parameters since the terminal is already disconnected by the time Expect receives control. exit [-opts] [status] causes Expect to exit or otherwise prepare to do so. The -onexit flag causes the next argument to be used as an exit handler. Without an argument, the current exit handler is returned. The -noexit flag causes Expect to prepare to exit but stop short of actually returning control to the operating system. The user-defined exit handler is run as well as Expect's own in‐ ternal handlers. No further Expect commands should be executed. This is useful if you are running Expect with other Tcl extensions. The current interpreter (and main window if in the Tk environment) remain so that other Tcl extensions can clean up. If Expect's exit is called again (however this might occur), the handlers are not rerun. Upon exiting, all connections to spawned processes are closed. Closure will be detected as an EOF by spawned processes. exit takes no other actions beyond what the normal _exit(2) pro‐ cedure does. Thus, spawned processes that do not check for EOF may continue to run. (A variety of conditions are important to determining, for example, what signals a spawned process will be sent, but these are system-dependent, typically documented under exit(3).) Spawned processes that continue to run will be inherited by init. status (or 0 if not specified) is returned as the exit status of Expect. exit is implicitly executed if the end of the script is reached. exp_continue [-continue_timer] The command exp_continue allows expect itself to continue executing rather than returning as it normally would. By default exp_continue resets the timeout timer. The -continue_timer flag prevents timer from being restarted. (See expect for more information.) exp_internal [-f file] value causes further commands to send diagnostic information internal to Expect to stderr if value is non-zero. This output is disabled if value is 0. The diagnostic information includes ev‐ ery character received, and every attempt made to match the current output against the patterns. If the optional file is supplied, all normal and debugging output is written to that file (regardless of the value of value). Any previous diagnostic output file is closed. The -info flag causes exp_internal to return a description of the most recent non-info arguments given. exp_open [args] [-i spawn_id] returns a Tcl file identifier that corresponds to the original spawn id. The file identifier can then be used as if it were opened by Tcl's open command. (The spawn id should no longer be used. A wait should not be executed. The -leaveopen flag leaves the spawn id open for access through Expect commands. A wait must be executed on the spawn id. exp_pid [-i spawn_id] returns the process id corresponding to the currently spawned process. If the -i flag is used, the pid returned corresponds to that of the given spawn id. exp_send is an alias for send. exp_send_error is an alias for send_error. exp_send_log is an alias for send_log. exp_send_tty is an alias for send_tty. exp_send_user is an alias for send_user. exp_version [[-exit] version] is useful for assuring that the script is compatible with the current version of Expect. With no arguments, the current version of Expect is returned. This version may then be encoded in your script. If you actually know that you are not using features of recent versions, you can specify an earlier version. Versions consist of three numbers separated by dots. First is the major number. Scripts written for versions of Expect with a different major number will almost certainly not work. exp_version returns an error if the major numbers do not match. Second is the minor number. Scripts written for a version with a greater minor number than the current version may depend upon some new feature and might not run. exp_version returns an error if the major numbers match, but the script minor number is greater than that of the running Expect. Third is a number that plays no part in the version comparison. However, it is incremented when the Expect software distribution is changed in any way, such as by additional documenta‐ tion or optimization. It is reset to 0 upon each new minor version. With the -exit flag, Expect prints an error and exits if the version is out of date. expect [[-opts] pat1 body1] ... [-opts] patn [bodyn] waits until one of the patterns matches the output of a spawned process, a specified time period has passed, or an end-of-file is seen. If the final body is empty, it may be omitted. Patterns from the most recent expect_before command are implicitly used before any other patterns. Patterns from the most recent expect_after command are implicitly used after any other patterns. If the arguments to the entire expect statement require more than one line, all the arguments may be \u0026quot;braced\u0026quot; into one so as to avoid terminating each line with a backslash. In this one case, the usual Tcl substitutions will occur despite the braces. If a pattern is the keyword eof, the corresponding body is executed upon end-of-file. If a pattern is the keyword timeout, the corresponding body is executed upon timeout. If no time‐ out keyword is used, an implicit null action is executed upon timeout. The default timeout period is 10 seconds but may be set, for example to 30, by the command \u0026quot;set timeout 30\u0026quot;. An infinite timeout may be designated by the value -1. If a pattern is the keyword default, the corresponding body is executed upon either timeout or end-of-file. If a pattern matches, then the corresponding body is executed. expect returns the result of the body (or the empty string if no pattern matched). In the event that multiple patterns match, the one appearing first is used to select a body. Each time new output arrives, it is compared to each pattern in the order they are listed. Thus, you may test for absence of a match by making the last pattern something guaranteed to appear, such as a prompt. In situations where there is no prompt, you must use timeout (just like you would if you were interacting manually). Patterns are specified in three ways. By default, patterns are specified as with Tcl's string match command. (Such patterns are also similar to C-shell regular expressions usually re‐ ferred to as \u0026quot;glob\u0026quot; patterns). The -gl flag may be used to protect patterns that might otherwise match expect flags from doing so. Any pattern beginning with a \u0026quot;-\u0026quot; should be protected this way. (All strings starting with \u0026quot;-\u0026quot; are reserved for future options.) For example, the following fragment looks for a successful login. (Note that abort is presumed to be a procedure defined elsewhere in the script.) expect { busy {puts busy\\n ; exp_continue} failed abort \u0026quot;invalid password\u0026quot; abort timeout abort connected } Quotes are necessary on the fourth pattern since it contains a space, which would otherwise separate the pattern from the action. Patterns with the same action (such as the 3rd and 4th) require listing the actions again. This can be avoid by using regexp-style patterns (see below). More information on forming glob-style patterns can be found in the Tcl manual. Regexp-style patterns follow the syntax defined by Tcl's regexp (short for \u0026quot;regular expression\u0026quot;) command. regexp patterns are introduced with the flag -re. The previous example can be rewritten using a regexp as: expect { busy {puts busy\\n ; exp_continue} -re \u0026quot;failed|invalid password\u0026quot; abort timeout abort connected } Both types of patterns are \u0026quot;unanchored\u0026quot;. This means that patterns do not have to match the entire string, but can begin and end the match anywhere in the string (as long as everything else matches). Use ^ to match the beginning of a string, and $ to match the end. Note that if you do not wait for the end of a string, your responses can easily end up in the middle of the string as they are echoed from the spawned process. While still producing correct results, the output can look unnatural. Thus, use of $ is encouraged if you can exactly describe the characters at the end of a string. Note that in many editors, the ^ and $ match the beginning and end of lines respectively. However, because expect is not line oriented, these characters match the beginning and end of the data (as opposed to lines) currently in the expect matching buffer. (Also, see the note below on \u0026quot;system indigestion.\u0026quot;) The -ex flag causes the pattern to be matched as an \u0026quot;exact\u0026quot; string. No interpretation of *, ^, etc is made (although the usual Tcl conventions must still be observed). Exact patterns are always unanchored. The -nocase flag causes uppercase characters of the output to compare as if they were lowercase characters. The pattern is not affected. While reading output, more than 2000 bytes can force earlier bytes to be \u0026quot;forgotten\u0026quot;. This may be changed with the function match_max. (Note that excessively large values can slow down the pattern matcher.) If patlist is full_buffer, the corresponding body is executed if match_max bytes have been received and no other patterns have matched. Whether or not the full_buffer keyword is used, the forgotten characters are written to expect_out(buffer). If patlist is the keyword null, and nulls are allowed (via the remove_nulls command), the corresponding body is executed if a single ASCII 0 is matched. It is not possible to match 0 bytes via glob or regexp patterns. Upon matching a pattern (or eof or full_buffer), any matching and previously unmatched output is saved in the variable expect_out(buffer). Up to 9 regexp substring matches are saved in the variables expect_out(1,string) through expect_out(9,string). If the -indices flag is used before a pattern, the starting and ending indices (in a form suitable for lrange) of the 10 strings are stored in the variables expect_out(X,start) and expect_out(X,end) where X is a digit, corresponds to the substring position in the buffer. 0 refers to strings which matched the entire pattern and is generated for glob patterns as well as regexp patterns. For example, if a process has produced output of \u0026quot;abcdefgh\\n\u0026quot;, the result of: expect \u0026quot;cd\u0026quot; is as if the following statements had executed: set expect_out(0,string) cd set expect_out(buffer) abcd and \u0026quot;efgh\\n\u0026quot; is left in the output buffer. If a process produced the output \u0026quot;abbbcabkkkka\\n\u0026quot;, the result of: expect -indices -re \u0026quot;b(b*).*(k+)\u0026quot; is as if the following statements had executed: set expect_out(0,start) 1 set expect_out(0,end) 10 set expect_out(0,string) bbbcabkkkk set expect_out(1,start) 2 set expect_out(1,end) 3 set expect_out(1,string) bb set expect_out(2,start) 10 set expect_out(2,end) 10 set expect_out(2,string) k set expect_out(buffer) abbbcabkkkk and \u0026quot;a\\n\u0026quot; is left in the output buffer. The pattern \u0026quot;*\u0026quot; (and -re \u0026quot;.*\u0026quot;) will flush the output buffer without reading any more output from the process. Normally, the matched output is discarded from Expect's internal buffers. This may be prevented by prefixing a pattern with the -notransfer flag. This flag is especially useful in ex‐ perimenting (and can be abbreviated to \u0026quot;-not\u0026quot; for convenience while experimenting). The spawn id associated with the matching output (or eof or full_buffer) is stored in expect_out(spawn_id). The -timeout flag causes the current expect command to use the following value as a timeout instead of using the value of the timeout variable. By default, patterns are matched against output from the current process, however the -i flag declares the output from the named spawn_id list be matched against any following patterns (up to the next -i). The spawn_id list should either be a whitespace separated list of spawn_ids or a variable referring to such a list of spawn_ids. For example, the following example waits for \u0026quot;connected\u0026quot; from the current process, or \u0026quot;busy\u0026quot;, \u0026quot;failed\u0026quot; or \u0026quot;invalid password\u0026quot; from the spawn_id named by $proc2. expect { -i $proc2 busy {puts busy\\n ; exp_continue} -re \u0026quot;failed|invalid password\u0026quot; abort timeout abort connected } The value of the global variable any_spawn_id may be used to match patterns to any spawn_ids that are named with all other -i flags in the current expect command. The spawn_id from a -i flag with no associated pattern (i.e., followed immediately by another -i) is made available to any other patterns in the same expect command associated with any_spawn_id. The -i flag may also name a global variable in which case the variable is read for a list of spawn ids. The variable is reread whenever it changes. This provides a way of changing the I/O source while the command is in execution. Spawn ids provided this way are called \u0026quot;indirect\u0026quot; spawn ids. Actions such as break and continue cause control structures (i.e., for, proc) to behave in the usual way. The command exp_continue allows expect itself to continue executing rather than returning as it normally would. This is useful for avoiding explicit loops or repeated expect statements. The following example is part of a fragment to automate rlogin. The exp_continue avoids having to write a sec‐ ond expect statement (to look for the prompt again) if the rlogin prompts for a password. expect { Password: { stty -echo send_user \u0026quot;password (for $user) on $host: \u0026quot; expect_user -re \u0026quot;(.*)\\n\u0026quot; send_user \u0026quot;\\n\u0026quot; send \u0026quot;$expect_out(1,string)\\r\u0026quot; stty echo exp_continue } incorrect { send_user \u0026quot;invalid password or account\\n\u0026quot; exit } timeout { send_user \u0026quot;connection to $host timed out\\n\u0026quot; exit } eof { send_user \\ \u0026quot;connection to host failed: $expect_out(buffer)\u0026quot; exit } -re $prompt } For example, the following fragment might help a user guide an interaction that is already totally automated. In this case, the terminal is put into raw mode. If the user presses \u0026quot;+\u0026quot;, a variable is incremented. If \u0026quot;p\u0026quot; is pressed, several returns are sent to the process, perhaps to poke it in some way, and \u0026quot;i\u0026quot; lets the user interact with the process, effectively stealing away control from the script. In each case, the exp_continue allows the current expect to continue pattern matching after executing the current action. stty raw -echo expect_after { -i $user_spawn_id \u0026quot;p\u0026quot; {send \u0026quot;\\r\\r\\r\u0026quot;; exp_continue} \u0026quot;+\u0026quot; {incr foo; exp_continue} \u0026quot;i\u0026quot; {interact; exp_continue} \u0026quot;quit\u0026quot; exit } By default, exp_continue resets the timeout timer. The timer is not restarted, if exp_continue is called with the -continue_timer flag. expect_after [expect_args] works identically to the expect_before except that if patterns from both expect and expect_after can match, the expect pattern is used. See the expect_before command for more informa‐ tion. expect_background [expect_args] takes the same arguments as expect, however it returns immediately. Patterns are tested whenever new input arrives. The pattern timeout and default are meaningless to expect_background and are silently discarded. Otherwise, the expect_background command uses expect_before and expect_after patterns just like expect does. When expect_background actions are being evaluated, background processing for the same spawn id is blocked. Background processing is unblocked when the action completes. While back‐ ground processing is blocked, it is possible to do a (foreground) expect on the same spawn id. It is not possible to execute an expect while an expect_background is unblocked. expect_background for a particular spawn id is deleted by declaring a new expect_background with the same spawn id. Declaring expect_background with no pattern removes the given spawn id from the ability to match patterns in the background. expect_before [expect_args] takes the same arguments as expect, however it returns immediately. Pattern-action pairs from the most recent expect_before with the same spawn id are implicitly added to any following expect commands. If a pattern matches, it is treated as if it had been specified in the expect command itself, and the associated body is executed in the context of the expect command. If patterns from both expect_before and expect can match, the expect_before pattern is used. If no pattern is specified, the spawn id is not checked for any patterns. Unless overridden by a -i flag, expect_before patterns match against the spawn id defined at the time that the expect_before command was executed (not when its pattern is matched). The -info flag causes expect_before to return the current specifications of what patterns it will match. By default, it reports on the current spawn id. An optional spawn id specifica‐ tion may be given for information on that spawn id. For example expect_before -info -i $proc At most one spawn id specification may be given. The flag -indirect suppresses direct spawn ids that come only from indirect specifications. Instead of a spawn id specification, the flag \u0026quot;-all\u0026quot; will cause \u0026quot;-info\u0026quot; to report on all spawn ids. The output of the -info flag can be reused as the argument to expect_before. expect_tty [expect_args] is like expect but it reads characters from /dev/tty (i.e. keystrokes from the user). By default, reading is performed in cooked mode. Thus, lines must end with a return in order for expect to see them. This may be changed via stty (see the stty command below). expect_user [expect_args] is like expect but it reads characters from stdin (i.e. keystrokes from the user). By default, reading is performed in cooked mode. Thus, lines must end with a return in order for ex‐ pect to see them. This may be changed via stty (see the stty command below). fork creates a new process. The new process is an exact copy of the current Expect process. On success, fork returns 0 to the new (child) process and returns the process ID of the child process to the parent process. On failure (invariably due to lack of resources, e.g., swap space, memory), fork returns -1 to the parent process, and no child process is created. Forked processes exit via the exit command, just like the original process. Forked processes are allowed to write to the log files. If you do not disable debugging or logging in most of the processes, the result can be confusing. Some pty implementations may be confused by multiple readers and writers, even momentarily. Thus, it is safest to fork before spawning processes. interact [string1 body1] ... [stringn [bodyn]] gives control of the current process to the user, so that keystrokes are sent to the current process, and the stdout and stderr of the current process are returned. String-body pairs may be specified as arguments, in which case the body is executed when the corresponding string is entered. (By default, the string is not sent to the current process.) The interpreter command is assumed, if the final body is missing. If the arguments to the entire interact statement require more than one line, all the arguments may be \u0026quot;braced\u0026quot; into one so as to avoid terminating each line with a backslash. In this one case, the usual Tcl substitutions will occur despite the braces. For example, the following command runs interact with the following string-body pairs defined: When ^Z is pressed, Expect is suspended. (The -reset flag restores the terminal modes.) When ^A is pressed, the user sees \u0026quot;you typed a control-A\u0026quot; and the process is sent a ^A. When $ is pressed, the user sees the date. When ^C is pressed, Expect exits. If \u0026quot;foo\u0026quot; is en‐ tered, the user sees \u0026quot;bar\u0026quot;. When ~~ is pressed, the Expect interpreter runs interactively. set CTRLZ \\032 interact { -reset $CTRLZ {exec kill -STOP [pid]} \\001 {send_user \u0026quot;you typed a control-A\\n\u0026quot;; send \u0026quot;\\001\u0026quot; } $ {send_user \u0026quot;The date is [clock format [clock seconds]].\u0026quot;} \\003 exit foo {send_user \u0026quot;bar\u0026quot;} ~~ } In string-body pairs, strings are matched in the order they are listed as arguments. Strings that partially match are not sent to the current process in anticipation of the remainder coming. If characters are then entered such that there can no longer possibly be a match, only the part of the string will be sent to the process that cannot possibly begin another match. Thus, strings that are substrings of partial matches can match later, if the original strings that was attempting to be match ultimately fails. By default, string matching is exact with no wild cards. (In contrast, the expect command uses glob-style patterns by default.) The -ex flag may be used to protect patterns that might otherwise match interact flags from doing so. Any pattern beginning with a \u0026quot;-\u0026quot; should be protected this way. (All strings starting with \u0026quot;-\u0026quot; are reserved for future options.) The -re flag forces the string to be interpreted as a regexp-style pattern. In this case, matching substrings are stored in the variable interact_out similarly to the way expect stores its output in the variable expect_out. The -indices flag is similarly supported. The pattern eof introduces an action that is executed upon end-of-file. A separate eof pattern may also follow the -output flag in which case it is matched if an eof is detected while writing output. The default eof action is \u0026quot;return\u0026quot;, so that interact simply returns upon any EOF. The pattern timeout introduces a timeout (in seconds) and action that is executed after no characters have been read for a given time. The timeout pattern applies to the most recently specified process. There is no default timeout. The special variable \u0026quot;timeout\u0026quot; (used by the expect command) has no affect on this timeout. For example, the following statement could be used to autologout users who have not typed anything for an hour but who still get frequent system messages: interact -input $user_spawn_id timeout 3600 return -output \\ $spawn_id If the pattern is the keyword null, and nulls are allowed (via the remove_nulls command), the corresponding body is executed if a single ASCII 0 is matched. It is not possible to match 0 bytes via glob or regexp patterns. Prefacing a pattern with the flag -iwrite causes the variable interact_out(spawn_id) to be set to the spawn_id which matched the pattern (or eof). Actions such as break and continue cause control structures (i.e., for, proc) to behave in the usual way. However return causes interact to return to its caller, while inter_return causes interact to cause a return in its caller. For example, if \u0026quot;proc foo\u0026quot; called interact which then executed the action inter_return, proc foo would return. (This means that if in‐ teract calls interpreter interactively typing return will cause the interact to continue, while inter_return will cause the interact to return to its caller.) During interact, raw mode is used so that all characters may be passed to the current process. If the current process does not catch job control signals, it will stop if sent a stop signal (by default ^Z). To restart it, send a continue signal (such as by \u0026quot;kill -CONT \u0026lt;pid\u0026gt;\u0026quot;). If you really want to send a SIGSTOP to such a process (by ^Z), consider spawning csh first and then running your program. On the other hand, if you want to send a SIGSTOP to Expect itself, first call interpreter (perhaps by using an escape character), and then press ^Z. String-body pairs can be used as a shorthand for avoiding having to enter the interpreter and execute commands interactively. The previous terminal mode is used while the body of a string-body pair is being executed. For speed, actions execute in raw mode by default. The -reset flag resets the terminal to the mode it had before interact was executed (invariably, cooked mode). Note that characters entered when the mode is being switched may be lost (an unfortunate feature of the terminal driver on some systems). The only reason to use -reset is if your action depends on running in cooked mode. The -echo flag sends characters that match the following pattern back to the process that generated them as each character is read. This may be useful when the user needs to see feed‐ back from partially typed patterns. If a pattern is being echoed but eventually fails to match, the characters are sent to the spawned process. If the spawned process then echoes them, the user will see the characters twice. -echo is probably only appropriate in situations where the user is unlikely to not complete the pattern. For example, the following excerpt is from rftp, the recursive-ftp script, where the user is prompted to enter ~g, ~p, or ~l, to get, put, or list the current directory recursively. These are so far away from the normal ftp commands, that the user is unlikely to type ~ followed by anything else, except mistakenly, in which case, they'll probably just ignore the result anyway. interact { -echo ~g {getcurdirectory 1} -echo ~l {getcurdirectory 0} -echo ~p {putcurdirectory} } The -nobuffer flag sends characters that match the following pattern on to the output process as characters are read. This is useful when you wish to let a program echo back the pattern. For example, the following might be used to monitor where a person is dialing (a Hayes-style modem). Each time \u0026quot;atd\u0026quot; is seen the script logs the rest of the line. proc lognumber {} { interact -nobuffer -re \u0026quot;(.*)\\r\u0026quot; return puts $log \u0026quot;[clock format [clock seconds]]: dialed $interact_out(1,string)\u0026quot; } interact -nobuffer \u0026quot;atd\u0026quot; lognumber During interact, previous use of log_user is ignored. In particular, interact will force its output to be logged (sent to the standard output) since it is presumed the user doesn't wish to interact blindly. The -o flag causes any following key-body pairs to be applied to the output of the current process. This can be useful, for example, when dealing with hosts that send unwanted charac‐ ters during a telnet session. By default, interact expects the user to be writing stdin and reading stdout of the Expect process itself. The -u flag (for \u0026quot;user\u0026quot;) makes interact look for the user as the process named by its argument (which must be a spawned id). This allows two unrelated processes to be joined together without using an explicit loop. To aid in debugging, Expect diagnostics always go to stderr (or stdout for certain logging and debugging information). For the same reason, the interpreter command will read interactively from stdin. For example, the following fragment creates a login process. Then it dials the user (not shown), and finally connects the two together. Of course, any process may be substituted for login. A shell, for example, would allow the user to work without supplying an account and password. spawn login set login $spawn_id spawn tip modem # dial back out to user # connect user to login interact -u $login To send output to multiple processes, list each spawn id list prefaced by a -output flag. Input for a group of output spawn ids may be determined by a spawn id list prefaced by a -input flag. (Both -input and -output may take lists in the same form as the -i flag in the expect command, except that any_spawn_id is not meaningful in interact.) All following flags and strings (or patterns) apply to this input until another -input flag appears. If no -input appears, -output implies \u0026quot;-input $user_spawn_id -output\u0026quot;. (Similarly, with patterns that do not have -input.) If one -input is specified, it overrides $user_spawn_id. If a second -input is specified, it overrides $spawn_id. Additional -input flags may be specified. The two implied input processes default to having their outputs specified as $spawn_id and $user_spawn_id (in reverse). If a -input flag appears with no -output flag, characters from that process are discarded. The -i flag introduces a replacement for the current spawn_id when no other -input or -output flags are used. A -i flag implies a -o flag. It is possible to change the processes that are being interacted with by using indirect spawn ids. (Indirect spawn ids are described in the section on the expect command.) Indirect spawn ids may be specified with the -i, -u, -input, or -output flags. interpreter [args] causes the user to be interactively prompted for Expect and Tcl commands. The result of each command is printed. Actions such as break and continue cause control structures (i.e., for, proc) to behave in the usual way. However return causes interpreter to return to its caller, while inter_return causes interpreter to cause a return in its caller. For example, if \u0026quot;proc foo\u0026quot; called interpreter which then executed the action inter_return, proc foo would return. Any other command causes interpreter to continue prompting for new commands. By default, the prompt contains two integers. The first integer describes the depth of the evaluation stack (i.e., how many times Tcl_Eval has been called). The second integer is the Tcl history identifier. The prompt can be set by defining a procedure called \u0026quot;prompt1\u0026quot; whose return value becomes the next prompt. If a statement has open quotes, parens, braces, or brackets, a secondary prompt (by default \u0026quot;+\u0026gt; \u0026quot;) is issued upon newline. The secondary prompt may be set by defining a procedure called \u0026quot;prompt2\u0026quot;. During interpreter, cooked mode is used, even if the its caller was using raw mode. If stdin is closed, interpreter will return unless the -eof flag is used, in which case the subsequent argument is invoked. log_file [args] [[-a] file] If a filename is provided, log_file will record a transcript of the session (beginning at that point) in the file. log_file will stop recording if no argument is given. Any previous log file is closed. Instead of a filename, a Tcl file identifier may be provided by using the -open or -leaveopen flags. This is similar to the spawn command. (See spawn for more info.) The -a flag forces output to be logged that was suppressed by the log_user command. By default, the log_file command appends to old files rather than truncating them, for the convenience of being able to turn logging off and on multiple times in one session. To trun‐ cate files, use the -noappend flag. The -info flag causes log_file to return a description of the most recent non-info arguments given. log_user -info|0|1 By default, the send/expect dialogue is logged to stdout (and a logfile if open). The logging to stdout is disabled by the command \u0026quot;log_user 0\u0026quot; and reenabled by \u0026quot;log_user 1\u0026quot;. Logging to the logfile is unchanged. The -info flag causes log_user to return a description of the most recent non-info arguments given. match_max [-d] [-i spawn_id] [size] defines the size of the buffer (in bytes) used internally by expect. With no size argument, the current size is returned. With the -d flag, the default size is set. (The initial default is 2000.) With the -i flag, the size is set for the named spawn id, otherwise it is set for the current process. overlay [-# spawn_id] [-# spawn_id] [...] program [args] executes program args in place of the current Expect program, which terminates. A bare hyphen argument forces a hyphen in front of the command name as if it was a login shell. All spawn_ids are closed except for those named as arguments. These are mapped onto the named file identifiers. Spawn_ids are mapped to file identifiers for the new program to inherit. For example, the following line runs chess and allows it to be controlled by the current process - say, a chess master. overlay -0 $spawn_id -1 $spawn_id -2 $spawn_id chess This is more efficient than \u0026quot;interact -u\u0026quot;, however, it sacrifices the ability to do programmed interaction since the Expect process is no longer in control. Note that no controlling terminal is provided. Thus, if you disconnect or remap standard input, programs that do job control (shells, login, etc) will not function properly. parity [-d] [-i spawn_id] [value] defines whether parity should be retained or stripped from the output of spawned processes. If value is zero, parity is stripped, otherwise it is not stripped. With no value argument, the current value is returned. With the -d flag, the default parity value is set. (The initial default is 1, i.e., parity is not stripped.) With the -i flag, the parity value is set for the named spawn id, otherwise it is set for the current process. remove_nulls [-d] [-i spawn_id] [value] defines whether nulls are retained or removed from the output of spawned processes before pattern matching or storing in the variable expect_out or interact_out. If value is 1, nulls are removed. If value is 0, nulls are not removed. With no value argument, the current value is returned. With the -d flag, the default value is set. (The initial default is 1, i.e., nulls are removed.) With the -i flag, the value is set for the named spawn id, otherwise it is set for the current process. Whether or not nulls are removed, Expect will record null bytes to the log and stdout. send [-flags] string Sends string to the current process. For example, the command send \u0026quot;hello world\\r\u0026quot; sends the characters, h e l l o \u0026lt;blank\u0026gt; w o r l d \u0026lt;return\u0026gt; to the current process. (Tcl includes a printf-like command (called format) which can build arbitrarily complex strings.) Characters are sent immediately although programs with line-buffered input will not read the characters until a return character is sent. A return character is denoted \u0026quot;\\r\u0026quot;. The -- flag forces the next argument to be interpreted as a string rather than a flag. Any string can be preceded by \u0026quot;--\u0026quot; whether or not it actually looks like a flag. This provides a reliable mechanism to specify variable strings without being tripped up by those that accidentally look like flags. (All strings starting with \u0026quot;-\u0026quot; are reserved for future options.) The -i flag declares that the string be sent to the named spawn_id. If the spawn_id is user_spawn_id, and the terminal is in raw mode, newlines in the string are translated to return- newline sequences so that they appear as if the terminal was in cooked mode. The -raw flag disables this translation. The -null flag sends null characters (0 bytes). By default, one null is sent. An integer may follow the -null to indicate how many nulls to send. The -break flag generates a break condition. This only makes sense if the spawn id refers to a tty device opened via \u0026quot;spawn -open\u0026quot;. If you have spawned a process such as tip, you should use tip's convention for generating a break. The -s flag forces output to be sent \u0026quot;slowly\u0026quot;, thus avoid the common situation where a computer outtypes an input buffer that was designed for a human who would never outtype the same buffer. This output is controlled by the value of the variable \u0026quot;send_slow\u0026quot; which takes a two element list. The first element is an integer that describes the number of bytes to send atomically. The second element is a real number that describes the number of seconds by which the atomic sends must be separated. For example, \u0026quot;set send_slow {10 .001}\u0026quot; would force \u0026quot;send -s\u0026quot; to send strings with 1 millisecond in between each 10 characters sent. The -h flag forces output to be sent (somewhat) like a human actually typing. Human-like delays appear between the characters. (The algorithm is based upon a Weibull distribution, with modifications to suit this particular application.) This output is controlled by the value of the variable \u0026quot;send_human\u0026quot; which takes a five element list. The first two elements are av‐ erage interarrival time of characters in seconds. The first is used by default. The second is used at word endings, to simulate the subtle pauses that occasionally occur at such tran‐ sitions. The third parameter is a measure of variability where .1 is quite variable, 1 is reasonably variable, and 10 is quite invariable. The extremes are 0 to infinity. The last two parameters are, respectively, a minimum and maximum interarrival time. The minimum and maximum are used last and \u0026quot;clip\u0026quot; the final time. The ultimate average can be quite different from the given average if the minimum and maximum clip enough values. As an example, the following command emulates a fast and consistent typist: set send_human {.1 .3 1 .05 2} send -h \u0026quot;I'm hungry. Let's do lunch.\u0026quot; while the following might be more suitable after a hangover: set send_human {.4 .4 .2 .5 100} send -h \u0026quot;Goodd party lash night!\u0026quot; Note that errors are not simulated, although you can set up error correction situations yourself by embedding mistakes and corrections in a send argument. The flags for sending null characters, for sending breaks, for forcing slow output and for human-style output are mutually exclusive. Only the one specified last will be used. Further‐ more, no string argument can be specified with the flags for sending null characters or breaks. It is a good idea to precede the first send to a process by an expect. expect will wait for the process to start, while send cannot. In particular, if the first send completes before the process starts running, you run the risk of having your data ignored. In situations where interactive programs offer no initial prompt, you can precede send by a delay as in: # To avoid giving hackers hints on how to break in, # this system does not prompt for an external password. # Wait for 5 seconds for exec to complete spawn telnet very.secure.gov sleep 5 send password\\r exp_send is an alias for send. If you are using Expectk or some other variant of Expect in the Tk environment, send is defined by Tk for an entirely different purpose. exp_send is pro‐ vided for compatibility between environments. Similar aliases are provided for other Expect's other send commands. send_error [-flags] string is like send, except that the output is sent to stderr rather than the current process. send_log [--] string is like send, except that the string is only sent to the log file (see log_file.) The arguments are ignored if no log file is open. send_tty [-flags] string is like send, except that the output is sent to /dev/tty rather than the current process. send_user [-flags] string is like send, except that the output is sent to stdout rather than the current process. sleep seconds causes the script to sleep for the given number of seconds. Seconds may be a decimal number. Interrupts (and Tk events if you are using Expectk) are processed while Expect sleeps. spawn [args] program [args] creates a new process running program args. Its stdin, stdout and stderr are connected to Expect, so that they may be read and written by other Expect commands. The connection is bro‐ ken by close or if the process itself closes any of the file identifiers. When a process is started by spawn, the variable spawn_id is set to a descriptor referring to that process. The process described by spawn_id is considered the current process. spawn_id may be read or written, in effect providing job control. user_spawn_id is a global variable containing a descriptor which refers to the user. For example, when spawn_id is set to this value, expect behaves like expect_user. error_spawn_id is a global variable containing a descriptor which refers to the standard error. For example, when spawn_id is set to this value, send behaves like send_error. tty_spawn_id is a global variable containing a descriptor which refers to /dev/tty. If /dev/tty does not exist (such as in a cron, at, or batch script), then tty_spawn_id is not de‐ fined. This may be tested as: if {[info vars tty_spawn_id]} { # /dev/tty exists } else { # /dev/tty doesn't exist # probably in cron, batch, or at script } spawn returns the UNIX process id. If no process is spawned, 0 is returned. The variable spawn_out(slave,name) is set to the name of the pty slave device. By default, spawn echoes the command name and arguments. The -noecho flag stops spawn from doing this. The -console flag causes console output to be redirected to the spawned process. This is not supported on all systems. Internally, spawn uses a pty, initialized the same way as the user's tty. This is further initialized so that all settings are \u0026quot;sane\u0026quot; (according to stty(1)). If the variable stty_init is defined, it is interpreted in the style of stty arguments as further configuration. For example, \u0026quot;set stty_init raw\u0026quot; will cause further spawned processes's terminals to start in raw mode. -nottycopy skips the initialization based on the user's tty. -nottyinit skips the \u0026quot;sane\u0026quot; initialization. Normally, spawn takes little time to execute. If you notice spawn taking a significant amount of time, it is probably encountering ptys that are wedged. A number of tests are run on ptys to avoid entanglements with errant processes. (These take 10 seconds per wedged pty.) Running Expect with the -d option will show if Expect is encountering many ptys in odd states. If you cannot kill the processes to which these ptys are attached, your only recourse may be to reboot. If program cannot be spawned successfully because exec(2) fails (e.g. when program doesn't exist), an error message will be returned by the next interact or expect command as if program had run and produced the error message as output. This behavior is a natural consequence of the implementation of spawn. Internally, spawn forks, after which the spawned process has no way to communicate with the original Expect process except by communication via the spawn_id. The -open flag causes the next argument to be interpreted as a Tcl file identifier (i.e., returned by open.) The spawn id can then be used as if it were a spawned process. (The file identifier should no longer be used.) This lets you treat raw devices, files, and pipelines as spawned processes without using a pty. 0 is returned to indicate there is no associated process. When the connection to the spawned process is closed, so is the Tcl file identifier. The -leaveopen flag is similar to -open except that -leaveopen causes the file identifier to be left open even after the spawn id is closed. The -pty flag causes a pty to be opened but no process spawned. 0 is returned to indicate there is no associated process. Spawn_id is set as usual. The variable spawn_out(slave,fd) is set to a file identifier corresponding to the pty slave. It can be closed using \u0026quot;close -slave\u0026quot;. The -ignore flag names a signal to be ignored in the spawned process. Otherwise, signals get the default behavior. Signals are named as in the trap command, except that each signal re‐ quires a separate flag. strace level causes following statements to be printed before being executed. (Tcl's trace command traces variables.) level indicates how far down in the call stack to trace. For example, the fol‐ lowing command runs Expect while tracing the first 4 levels of calls, but none below that. expect -c \u0026quot;strace 4\u0026quot; script.exp The -info flag causes strace to return a description of the most recent non-info arguments given. stty args changes terminal modes similarly to the external stty command. By default, the controlling terminal is accessed. Other terminals can be accessed by appending \u0026quot;\u0026lt; /dev/tty...\u0026quot; to the command. (Note that the arguments should not be grouped into a single argument.) Requests for status return it as the result of the command. If no status is requested and the controlling terminal is accessed, the previous status of the raw and echo attributes are returned in a form which can later be used by the command. For example, the arguments raw or -cooked put the terminal into raw mode. The arguments -raw or cooked put the terminal into cooked mode. The arguments echo and -echo put the terminal into echo and noecho mode respectively. The following example illustrates how to temporarily disable echoing. This could be used in otherwise-automatic scripts to avoid embedding passwords in them. (See more discussion on this under EXPECT HINTS below.) stty -echo send_user \u0026quot;Password: \u0026quot; expect_user -re \u0026quot;(.*)\\n\u0026quot; set password $expect_out(1,string) stty echo system args gives args to sh(1) as input, just as if it had been typed as a command from a terminal. Expect waits until the shell terminates. The return status from sh is handled the same way that exec handles its return status. In contrast to exec which redirects stdin and stdout to the script, system performs no redirection (other than that indicated by the string itself). Thus, it is possible to use programs which must talk directly to /dev/tty. For the same reason, the results of system are not recorded in the log. timestamp [args] returns a timestamp. With no arguments, the number of seconds since the epoch is returned. The -format flag introduces a string which is returned but with substitutions made according to the POSIX rules for strftime. For example %a is replaced by an abbreviated weekday name (i.e., Sat). Others are: %a abbreviated weekday name %A full weekday name %b abbreviated month name %B full month name %c date-time as in: Wed Oct 6 11:45:56 1993 %d day of the month (01-31) %H hour (00-23) %I hour (01-12) %j day (001-366) %m month (01-12) %M minute (00-59) %p am or pm %S second (00-61) %u day (1-7, Monday is first day of week) %U week (00-53, first Sunday is first day of week one) %V week (01-53, ISO 8601 style) %w day (0-6) %W week (00-53, first Monday is first day of week one) %x date-time as in: Wed Oct 6 1993 %X time as in: 23:59:59 %y year (00-99) %Y year as in: 1993 %Z timezone (or nothing if not determinable) %% a bare percent sign Other % specifications are undefined. Other characters will be passed through untouched. Only the C locale is supported. The -seconds flag introduces a number of seconds since the epoch to be used as a source from which to format. Otherwise, the current time is used. The -gmt flag forces timestamp output to use the GMT timezone. With no flag, the local timezone is used. trap [[command] signals] causes the given command to be executed upon future receipt of any of the given signals. The command is executed in the global scope. If command is absent, the signal action is re‐ turned. If command is the string SIG_IGN, the signals are ignored. If command is the string SIG_DFL, the signals are result to the system default. signals is either a single signal or a list of signals. Signals may be specified numerically or symbolically as per signal(3). The \u0026quot;SIG\u0026quot; prefix may be omitted. With no arguments (or the argument -number), trap returns the signal number of the trap command currently being executed. The -code flag uses the return code of the command in place of whatever code Tcl was about to return when the command originally started running. The -interp flag causes the command to be evaluated using the interpreter active at the time the command started running rather than when the trap was declared. The -name flag causes the trap command to return the signal name of the trap command currently being executed. The -max flag causes the trap command to return the largest signal number that can be set. For example, the command \u0026quot;trap {send_user \u0026quot;Ouch!\u0026quot;} SIGINT\u0026quot; will print \u0026quot;Ouch!\u0026quot; each time the user presses ^C. By default, SIGINT (which can usually be generated by pressing ^C) and SIGTERM cause Expect to exit. This is due to the following trap, created by default when Expect starts. trap exit {SIGINT SIGTERM} If you use the -D flag to start the debugger, SIGINT is redefined to start the interactive debugger. This is due to the following trap: trap {exp_debug 1} SIGINT The debugger trap can be changed by setting the environment variable EXPECT_DEBUG_INIT to a new trap command. You can, of course, override both of these just by adding trap commands to your script. In particular, if you have your own \u0026quot;trap exit SIGINT\u0026quot;, this will override the debugger trap. This is useful if you want to prevent users from getting to the debugger at all. If you want to define your own trap on SIGINT but still trap to the debugger when it is running, use: if {![exp_debug]} {trap mystuff SIGINT} Alternatively, you can trap to the debugger using some other signal. trap will not let you override the action for SIGALRM as this is used internally to Expect. The disconnect command sets SIGALRM to SIG_IGN (ignore). You can reenable this as long as you disable it during subsequent spawn commands. See signal(3) for more info. wait [args] delays until a spawned process (or the current process if none is named) terminates. wait normally returns a list of four integers. The first integer is the pid of the process that was waited upon. The second integer is the corresponding spawn id. The third integer is -1 if an operating system error occurred, or 0 otherwise. If the third integer was 0, the fourth integer is the status returned by the spawned process. If the third integer was -1, the fourth integer is the value of errno set by the operating system. The global variable errorCode is also set. Additional elements may appear at the end of the return value from wait. An optional fifth element identifies a class of information. Currently, the only possible value for this ele‐ ment is CHILDKILLED in which case the next two values are the C-style signal name and a short textual description. The -i flag declares the process to wait corresponding to the named spawn_id (NOT the process id). Inside a SIGCHLD handler, it is possible to wait for any spawned process by using the spawn id -1. The -nowait flag causes the wait to return immediately with the indication of a successful wait. When the process exits (later), it will automatically disappear without the need for an explicit wait. The wait command may also be used wait for a forked process using the arguments \u0026quot;-i -1\u0026quot;. Unlike its use with spawned processes, this command can be executed at any time. There is no control over which process is reaped. However, the return value can be checked for the process id. LIBRARIES Expect automatically knows about two built-in libraries for Expect scripts. These are defined by the directories named in the variables exp_library and exp_exec_library. Both are meant to contain utility files that can be used by other scripts. exp_library contains architecture-independent files. exp_exec_library contains architecture-dependent files. Depending on your system, both directories may be totally empty. The existence of the file $exp_exec_library/cat-buffers describes whether your /bin/cat buffers by default. PRETTY-PRINTING A vgrind definition is available for pretty-printing Expect scripts. Assuming the vgrind definition supplied with the Expect distribution is correctly installed, you can use it as: vgrind -lexpect file EXAMPLES It many not be apparent how to put everything together that the help describes. I encourage you to read and try out the examples in the example directory of the Expect distribution. Some of them are real programs. Others are simply illustrative of certain techniques, and of course, a couple are just quick hacks. The INSTALL file has a quick overview of these programs. The Expect papers (see SEE ALSO) are also useful. While some papers use syntax corresponding to earlier versions of Expect, the accompanying rationales are still valid and go into a lot more detail than this help. CAVEATS Extensions may collide with Expect's command names. For example, send is defined by Tk for an entirely different purpose. For this reason, most of the Expect commands are also available as \u0026quot;exp_XXXX\u0026quot;. Commands and variables beginning with \u0026quot;exp\u0026quot;, \u0026quot;inter\u0026quot;, \u0026quot;spawn\u0026quot;, and \u0026quot;timeout\u0026quot; do not have aliases. Use the extended command names if you need this compatibility between environ‐ ments. Expect takes a rather liberal view of scoping. In particular, variables read by commands specific to the Expect program will be sought first from the local scope, and if not found, in the global scope. For example, this obviates the need to place \u0026quot;global timeout\u0026quot; in every procedure you write that uses expect. On the other hand, variables written are always in the local scope (unless a \u0026quot;global\u0026quot; command has been issued). The most common problem this causes is when spawn is executed in a procedure. Outside the procedure, spawn_id no longer exists, so the spawned process is no longer accessible simply because of scoping. Add a \u0026quot;global spawn_id\u0026quot; to such a procedure. If you cannot enable the multispawning capability (i.e., your system supports neither select (BSD *.*), poll (SVR\u0026gt;2), nor something equivalent), Expect will only be able to control a single process at a time. In this case, do not attempt to set spawn_id, nor should you execute processes via exec while a spawned process is running. Furthermore, you will not be able to expect from multiple processes (including the user as one) at the same time. Terminal parameters can have a big effect on scripts. For example, if a script is written to look for echoing, it will misbehave if echoing is turned off. For this reason, Expect forces sane terminal parameters by default. Unfortunately, this can make things unpleasant for other programs. As an example, the emacs shell wants to change the \u0026quot;usual\u0026quot; mappings: newlines get mapped to newlines instead of carriage-return newlines, and echoing is disabled. This allows one to use emacs to edit the input line. Unfortunately, Expect cannot possibly guess this. You can request that Expect not override its default setting of terminal parameters, but you must then be very careful when writing scripts for such environments. In the case of emacs, avoid depending upon things like echoing and end-of-line mappings. The commands that accepted arguments braced into a single list (the expect variants and interact) use a heuristic to decide if the list is actually one argument or many. The heuristic can fail only in the case when the list actually does represent a single argument which has multiple embedded \\n's with non-whitespace characters between them. This seems sufficiently improbable, however the argument \u0026quot;-nobrace\u0026quot; can be used to force a single argument to be handled as a single argument. This could conceivably be used with machine-generated Expect code. Similarly, -brace forces a single argument to be handle as multiple patterns/actions. BUGS It was really tempting to name the program \u0026quot;sex\u0026quot; (for either \u0026quot;Smart EXec\u0026quot; or \u0026quot;Send-EXpect\u0026quot;), but good sense (or perhaps just Puritanism) prevailed. On some systems, when a shell is spawned, it complains about not being able to access the tty but runs anyway. This means your system has a mechanism for gaining the controlling tty that Ex‐ pect doesn't know about. Please find out what it is, and send this information back to me. Ultrix 4.1 (at least the latest versions around here) considers timeouts of above 1000000 to be equivalent to 0. Digital UNIX 4.0A (and probably other versions) refuses to allocate ptys if you define a SIGCHLD handler. See grantpt page for more info. IRIX 6.0 does not handle pty permissions correctly so that if Expect attempts to allocate a pty previously used by someone else, it fails. Upgrade to IRIX 6.1. Telnet (verified only under SunOS 4.1.2) hangs if TERM is not set. This is a problem under cron, at and in cgi scripts, which do not define TERM. Thus, you must set it explicitly - to what type is usually irrelevant. It just has to be set to something! The following probably suffices for most cases. set env(TERM) vt100 Tip (verified only under BSDI BSD/OS 3.1 i386) hangs if SHELL and HOME are not set. This is a problem under cron, at and in cgi scripts, which do not define these environment variables. Thus, you must set them explicitly - to what type is usually irrelevant. It just has to be set to something! The following probably suffices for most cases. set env(SHELL) /bin/sh set env(HOME) /usr/local/bin Some implementations of ptys are designed so that the kernel throws away any unread output after 10 to 15 seconds (actual number is implementation-dependent) after the process has closed the file descriptor. Thus Expect programs such as spawn date sleep 20 expect will fail. To avoid this, invoke non-interactive programs with exec rather than spawn. While such situations are conceivable, in practice I have never encountered a situation in which the final output of a truly interactive program would be lost due to this behavior. On the other hand, Cray UNICOS ptys throw away any unread output immediately after the process has closed the file descriptor. I have reported this to Cray and they are working on a fix. Sometimes a delay is required between a prompt and a response, such as when a tty interface is changing UART settings or matching baud rates by looking for start/stop bits. Usually, all this is require is to sleep for a second or two. A more robust technique is to retry until the hardware is ready to receive input. The following example uses both strategies: send \u0026quot;speed 9600\\r\u0026quot;; sleep 1 expect { timeout {send \u0026quot;\\r\u0026quot;; exp_continue} $prompt } trap -code will not work with any command that sits in Tcl's event loop, such as sleep. The problem is that in the event loop, Tcl discards the return codes from async event handlers. A workaround is to set a flag in the trap code. Then check the flag immediately after the command (i.e., sleep). The expect_background command ignores -timeout arguments and has no concept of timeouts in general. EXPECT HINTS There are a couple of things about Expect that may be non-intuitive. This section attempts to address some of these things with a couple of suggestions. A common expect problem is how to recognize shell prompts. Since these are customized differently by differently people and different shells, portably automating rlogin can be difficult with‐ out knowing the prompt. A reasonable convention is to have users store a regular expression describing their prompt (in particular, the end of it) in the environment variable EXPECT_PROMPT. Code like the following can be used. If EXPECT_PROMPT doesn't exist, the code still has a good chance of functioning correctly. set prompt \u0026quot;(%|#|\\\\$) $\u0026quot; ;# default prompt catch {set prompt $env(EXPECT_PROMPT)} expect -re $prompt I encourage you to write expect patterns that include the end of whatever you expect to see. This avoids the possibility of answering a question before seeing the entire thing. In addition, while you may well be able to answer questions before seeing them entirely, if you answer early, your answer may appear echoed back in the middle of the question. In other words, the result‐ ing dialogue will be correct but look scrambled. Most prompts include a space character at the end. For example, the prompt from ftp is 'f', 't', 'p', '\u0026gt;' and \u0026lt;blank\u0026gt;. To match this prompt, you must account for each of these characters. It is a common mistake not to include the blank. Put the blank in explicitly. If you use a pattern of the form X*, the * will match all the output received from the end of X to the last thing received. This sounds intuitive but can be somewhat confusing because the phrase \u0026quot;last thing received\u0026quot; can vary depending upon the speed of the computer and the processing of I/O both by the kernel and the device driver. In particular, humans tend to see program output arriving in huge chunks (atomically) when in reality most programs produce output one line at a time. Assuming this is the case, the * in the pattern of the previous paragraph may only match the end of the current line even though there seems to be more, because at the time of the match that was all the output that had been re‐ ceived. expect has no way of knowing that further output is coming unless your pattern specifically accounts for it. Even depending on line-oriented buffering is unwise. Not only do programs rarely make promises about the type of buffering they do, but system indigestion can break output lines up so that lines break at seemingly random places. Thus, if you can express the last few characters of a prompt when writing patterns, it is wise to do so. If you are waiting for a pattern in the last output of a program and the program emits something else instead, you will not be able to detect that with the timeout keyword. The reason is that expect will not timeout - instead it will get an eof indication. Use that instead. Even better, use both. That way if that line is ever moved around, you won't have to edit the line itself. Newlines are usually converted to carriage return, linefeed sequences when output by the terminal driver. Thus, if you want a pattern that explicitly matches the two lines, from, say, printf(\u0026quot;foo\\nbar\u0026quot;), you should use the pattern \u0026quot;foo\\r\\nbar\u0026quot;. A similar translation occurs when reading from the user, via expect_user. In this case, when you press return, it will be translated to a newline. If Expect then passes that to a program which sets its terminal to raw mode (like telnet), there is going to be a problem, as the program expects a true return. (Some programs are actually forgiving in that they will automatically translate newlines to returns, but most don't.) Unfortunately, there is no way to find out that a program put its terminal into raw mode. Rather than manually replacing newlines with returns, the solution is to use the command \u0026quot;stty raw\u0026quot;, which will stop the translation. Note, however, that this means that you will no longer get the cooked line-editing features. interact implicitly sets your terminal to raw mode so this problem will not arise then. It is often useful to store passwords (or other private information) in Expect scripts. This is not recommended since anything that is stored on a computer is susceptible to being accessed by anyone. Thus, interactively prompting for passwords from a script is a smarter idea than embedding them literally. Nonetheless, sometimes such embedding is the only possibility. Unfortunately, the UNIX file system has no direct way of creating scripts which are executable but unreadable. Systems which support setgid shell scripts may indirectly simulate this as fol‐ lows: Create the Expect script (that contains the secret data) as usual. Make its permissions be 750 (-rwxr-x---) and owned by a trusted group, i.e., a group which is allowed to read it. If neces‐ sary, create a new group for this purpose. Next, create a /bin/sh script with permissions 2751 (-rwxr-s--x) owned by the same group as before. The result is a script which may be executed (and read) by anyone. When invoked, it runs the Expect script. SEE ALSO Tcl(3), libexpect(3) \u0026quot;Exploring Expect: A Tcl-Based Toolkit for Automating Interactive Programs\u0026quot; by Don Libes, pp. 602, ISBN 1-56592-090-2, O'Reilly and Associates, 1995. \u0026quot;expect: Curing Those Uncontrollable Fits of Interactivity\u0026quot; by Don Libes, Proceedings of the Summer 1990 USENIX Conference, Anaheim, California, June 11-15, 1990. \u0026quot;Using expect to Automate System Administration Tasks\u0026quot; by Don Libes, Proceedings of the 1990 USENIX Large Installation Systems Administration Conference, Colorado Springs, Colorado, October 17-19, 1990. \u0026quot;Tcl: An Embeddable Command Language\u0026quot; by John Ousterhout, Proceedings of the Winter 1990 USENIX Conference, Washington, D.C., January 22-26, 1990. \u0026quot;expect: Scripts for Controlling Interactive Programs\u0026quot; by Don Libes, Computing Systems, Vol. 4, No. 2, University of California Press Journals, November 1991. \u0026quot;Regression Testing and Conformance Testing Interactive Programs\u0026quot;, by Don Libes, Proceedings of the Summer 1992 USENIX Conference, pp. 135-144, San Antonio, TX, June 12-15, 1992. \u0026quot;Kibitz - Connecting Multiple Interactive Programs Together\u0026quot;, by Don Libes, Software - Practice \u0026amp; Experience, John Wiley \u0026amp; Sons, West Sussex, England, Vol. 23, No. 5, May, 1993. \u0026quot;A Debugger for Tcl Applications\u0026quot;, by Don Libes, Proceedings of the 1993 Tcl/Tk Workshop, Berkeley, CA, June 10-11, 1993. AUTHOR Don Libes, National Institute of Standards and Technology ACKNOWLEDGMENTS Thanks to John Ousterhout for Tcl, and Scott Paisley for inspiration. Thanks to Rob Savoye for Expect's autoconfiguration code. The HISTORY file documents much of the evolution of expect. It makes interesting reading and might give you further insight to this software. Thanks to the people mentioned in it who sent me bug fixes and gave other assistance. Design and implementation of Expect was paid for in part by the U.S. government and is therefore in the public domain. However the author and NIST would like credit if this program and docu‐ mentation or portions of them are used. 29 December 1994 EXPECT(1) "}),e.add({id:39,href:"/docs/tools/utility/hexyl/",title:"Hexyl",description:`Description # hexyl is a command-line hex viewer.
Installation # brew install hexyl Usage # hexyl file Resources # hexyl help # hexyl 0.10.0 A command-line hex viewer USAGE: hexyl [OPTIONS] [FILE] ARGS: \u0026lt;FILE\u0026gt; The file to display. If no FILE argument is given, read from STDIN. OPTIONS: -n, --length \u0026lt;N\u0026gt; Only read N bytes from the input. The N argument can also include a unit with a decimal prefix (kB, MB, .`,content:"Description # hexyl is a command-line hex viewer.\nInstallation # brew install hexyl Usage # hexyl file Resources # hexyl help # hexyl 0.10.0 A command-line hex viewer USAGE: hexyl [OPTIONS] [FILE] ARGS: \u0026lt;FILE\u0026gt; The file to display. If no FILE argument is given, read from STDIN. OPTIONS: -n, --length \u0026lt;N\u0026gt; Only read N bytes from the input. The N argument can also include a unit with a decimal prefix (kB, MB, ..) or binary prefix (kiB, MiB, ..), or can be specified using a hex number. The short option '-l' can be used as an alias. Examples: --length=64, --length=4KiB, --length=0xff -c, --bytes \u0026lt;N\u0026gt; An alias for -n/--length -s, --skip \u0026lt;N\u0026gt; Skip the first N bytes of the input. The N argument can also include a unit (see `--length` for details) A negative value is valid and will seek from the end of the file. --block-size \u0026lt;SIZE\u0026gt; Sets the size of the `block` unit to SIZE (default is 512). Examples: --block-size=1024, --block-size=4kB -v, --no-squeezing Displays all input data. Otherwise any number of groups of output lines which would be identical to the preceding group of lines, are replaced with a line comprised of a single asterisk. --color \u0026lt;WHEN\u0026gt; When to use colors. The auto-mode only displays colors if the output goes to an interactive terminal [default: always] [possible values: always, auto, never] -p, --plain Display output with --no-characters, --no-position, --border=none, and --color=never. --border \u0026lt;STYLE\u0026gt; Whether to draw a border with Unicode characters, ASCII characters, or none at all [default: unicode] [possible values: unicode, ascii, none] -C, --no-characters Whether to display the character panel on the right. -P, --no-position Whether to display the position panel on the left. -o, --display-offset \u0026lt;N\u0026gt; Add N bytes to the displayed file position. The N argument can also include a unit (see `--length` for details) A negative value is valid and calculates an offset relative to the end of the file. -h, --help Print help information -V, --version Print version information "}),e.add({id:40,href:"/docs/tools/utility/dos2unix/",title:"Dos2unix",description:`Description # dos2unix is a command-line tool for converting DOS/Mac/Unix text files to Unix text files.
Installation # brew install dos2unix Usage # dos2unix input.txt Resources # dos2unix help # dos2unix(1) 2022-06-05 dos2unix(1) NAME dos2unix - DOS/Mac to Unix and vice versa text file format converter SYNOPSIS dos2unix [options] [FILE ...] [-n INFILE OUTFILE ...] unix2dos [options] [FILE ...] [-n INFILE OUTFILE ...] DESCRIPTION The Dos2unix package includes utilities \u0026quot;dos2unix\u0026quot; and \u0026quot;unix2dos\u0026quot; to convert plain text files in DOS or Mac format to Unix format and vice versa.`,content:"Description # dos2unix is a command-line tool for converting DOS/Mac/Unix text files to Unix text files.\nInstallation # brew install dos2unix Usage # dos2unix input.txt Resources # dos2unix help # dos2unix(1) 2022-06-05 dos2unix(1) NAME dos2unix - DOS/Mac to Unix and vice versa text file format converter SYNOPSIS dos2unix [options] [FILE ...] [-n INFILE OUTFILE ...] unix2dos [options] [FILE ...] [-n INFILE OUTFILE ...] DESCRIPTION The Dos2unix package includes utilities \u0026quot;dos2unix\u0026quot; and \u0026quot;unix2dos\u0026quot; to convert plain text files in DOS or Mac format to Unix format and vice versa. In DOS/Windows text files a line break, also known as newline, is a combination of two characters: a Carriage Return (CR) followed by a Line Feed (LF). In Unix text files a line break is a single character: the Line Feed (LF). In Mac text files, prior to Mac OS X, a line break was single Carriage Return (CR) character. Nowadays Mac OS uses Unix style (LF) line breaks. Besides line breaks Dos2unix can also convert the encoding of files. A few DOS code pages can be converted to Unix Latin-1. And Windows Unicode (UTF-16) files can be converted to Unix Unicode (UTF-8) files. Binary files are automatically skipped, unless conversion is forced. Non-regular files, such as directories and FIFOs, are automatically skipped. Symbolic links and their targets are by default kept untouched. Symbolic links can optionally be replaced, or the output can be written to the symbolic link target. Writing to a symbolic link target is not supported on Windows. Dos2unix was modelled after dos2unix under SunOS/Solaris. There is one important difference with the original SunOS/Solaris version. This version does by default in-place conversion (old file mode), while the original SunOS/Solaris version only supports paired conversion (new file mode). See also options \u0026quot;-o\u0026quot; and \u0026quot;-n\u0026quot;. Another difference is that the SunOS/Solaris version uses by default iso mode conversion while this version uses by default ascii mode conversion. OPTIONS -- Treat all following options as file names. Use this option if you want to convert files whose names start with a dash. For instance to convert a file named \u0026quot;-foo\u0026quot;, you can use this command: dos2unix -- -foo Or in new file mode: dos2unix -n -- -foo out.txt --allow-chown Allow file ownership change in old file mode. When this option is used, the conversion will not be aborted when the user and/or group ownership of the original file can't be preserved in old file mode. Conversion will continue and the converted file will get the same new ownership as if it was converted in new file mode. See also options \u0026quot;-o\u0026quot; and \u0026quot;-n\u0026quot;. This option is only available if dos2unix has support for preserving the user and group ownership of files. -ascii Convert only line breaks. This is the default conversion mode. -iso Conversion between DOS and ISO-8859-1 character set. See also section CONVERSION MODES. -1252 Use Windows code page 1252 (Western European). -437 Use DOS code page 437 (US). This is the default code page used for ISO conversion. -850 Use DOS code page 850 (Western European). -860 Use DOS code page 860 (Portuguese). -863 Use DOS code page 863 (French Canadian). -865 Use DOS code page 865 (Nordic). -7 Convert 8 bit characters to 7 bit space. -b, --keep-bom Keep Byte Order Mark (BOM). When the input file has a BOM, write a BOM in the output file. This is the default behavior when converting to DOS line breaks. See also option \u0026quot;-r\u0026quot;. -c, --convmode CONVMODE Set conversion mode. Where CONVMODE is one of: ascii, 7bit, iso, mac with ascii being the default. -D, --display-enc ENCODING Set encoding of displayed text. Where ENCODING is one of: ansi, unicode, unicodebom, utf8, utf8bom with ansi being the default. This option is only available in dos2unix for Windows with Unicode file name support. This option has no effect on the actual file names read and written, only on how they are displayed. There are several methods for displaying text in a Windows console based on the encoding of the text. They all have their own advantages and disadvantages. ansi Dos2unix's default method is to use ANSI encoded text. The advantage is that it is backwards compatible. It works with raster and TrueType fonts. In some regions you may need to change the active DOS OEM code page to the Windows system ANSI code page using the \u0026quot;chcp\u0026quot; command, because dos2unix uses the Windows system code page. The disadvantage of ansi is that international file names with characters not inside the system default code page are not displayed properly. You will see a question mark, or a wrong symbol instead. When you don't work with foreign file names this method is OK. unicode, unicodebom The advantage of unicode (the Windows name for UTF-16) encoding is that text is usually properly displayed. There is no need to change the active code page. You may need to set the console's font to a TrueType font to have international characters displayed properly. When a character is not included in the TrueType font you usually see a small square, sometimes with a question mark in it. When you use the ConEmu console all text is displayed properly, because ConEmu automatically selects a good font. The disadvantage of unicode is that it is not compatible with ASCII. The output is not easy to handle when you redirect it to another program. When method \u0026quot;unicodebom\u0026quot; is used the Unicode text will be preceded with a BOM (Byte Order Mark). A BOM is required for correct redirection or piping in PowerShell. utf8, utf8bom The advantage of utf8 is that it is compatible with ASCII. You need to set the console's font to a TrueType font. With a TrueType font the text is displayed similar as with the \u0026quot;unicode\u0026quot; encoding. The disadvantage is that when you use the default raster font all non-ASCII characters are displayed wrong. Not only unicode file names, but also translated messages become unreadable. On Windows configured for an East-Asian region you may see a lot of flickering of the console when the messages are displayed. In a ConEmu console the utf8 encoding method works well. When method \u0026quot;utf8bom\u0026quot; is used the UTF-8 text will be preceded with a BOM (Byte Order Mark). A BOM is required for correct redirection or piping in PowerShell. The default encoding can be changed with environment variable DOS2UNIX_DISPLAY_ENC by setting it to \u0026quot;unicode\u0026quot;, \u0026quot;unicodebom\u0026quot;, \u0026quot;utf8\u0026quot;, or \u0026quot;utf8bom\u0026quot;. -f, --force Force conversion of binary files. -gb, --gb18030 On Windows UTF-16 files are by default converted to UTF-8, regardless of the locale setting. Use this option to convert UTF-16 files to GB18030. This option is only available on Windows. See also section GB18030. -h, --help Display help and exit. -i[FLAGS], --info[=FLAGS] FILE ... Display file information. No conversion is done. The following information is printed, in this order: number of DOS line breaks, number of Unix line breaks, number of Mac line breaks, byte order mark, text or binary, file name. Example output: 6 0 0 no_bom text dos.txt 0 6 0 no_bom text unix.txt 0 0 6 no_bom text mac.txt 6 6 6 no_bom text mixed.txt 50 0 0 UTF-16LE text utf16le.txt 0 50 0 no_bom text utf8unix.txt 50 0 0 UTF-8 text utf8dos.txt 2 418 219 no_bom binary dos2unix.exe Note that sometimes a binary file can be mistaken for a text file. See also option \u0026quot;-s\u0026quot;. Optionally extra flags can be set to change the output. One or more flags can be added. 0 Print the file information lines followed by a null character instead of a newline character. This enables correct interpretation of file names with spaces or quotes when flag c is used. Use this flag in combination with xargs(1) option \u0026quot;-0\u0026quot; or \u0026quot;--null\u0026quot;. d Print number of DOS line breaks. u Print number of Unix line breaks. m Print number of Mac line breaks. b Print the byte order mark. t Print if file is text or binary. c Print only the files that would be converted. With the \u0026quot;c\u0026quot; flag dos2unix will print only the files that contain DOS line breaks, unix2dos will print only file names that have Unix line breaks. h Print a header. p Show file names without path. Examples: Show information for all *.txt files: dos2unix -i *.txt Show only the number of DOS line breaks and Unix line breaks: dos2unix -idu *.txt Show only the byte order mark: dos2unix --info=b *.txt List the files that have DOS line breaks: dos2unix -ic *.txt List the files that have Unix line breaks: unix2dos -ic *.txt Convert only files that have DOS line breaks and leave the other files untouched: dos2unix -ic0 *.txt | xargs -0 dos2unix Find text files that have DOS line breaks: find -name '*.txt' -print0 | xargs -0 dos2unix -ic -k, --keepdate Keep the date stamp of output file same as input file. -L, --license Display program's license. -l, --newline Add additional newline. dos2unix: Only DOS line breaks are changed to two Unix line breaks. In Mac mode only Mac line breaks are changed to two Unix line breaks. unix2dos: Only Unix line breaks are changed to two DOS line breaks. In Mac mode Unix line breaks are changed to two Mac line breaks. -m, --add-bom Write a Byte Order Mark (BOM) in the output file. By default an UTF-8 BOM is written. When the input file is UTF-16, and the option \u0026quot;-u\u0026quot; is used, an UTF-16 BOM will be written. Never use this option when the output encoding is other than UTF-8, UTF-16, or GB18030. See also section UNICODE. -n, --newfile INFILE OUTFILE ... New file mode. Convert file INFILE and write output to file OUTFILE. File names must be given in pairs and wildcard names should not be used or you will lose your files. The person who starts the conversion in new file (paired) mode will be the owner of the converted file. The read/write permissions of the new file will be the permissions of the original file minus the umask(1) of the person who runs the conversion. --no-allow-chown Don't allow file ownership change in old file mode (default). Abort conversion when the user and/or group ownership of the original file can't be preserved in old file mode. See also options \u0026quot;-o\u0026quot; and \u0026quot;-n\u0026quot;. This option is only available if dos2unix has support for preserving the user and group ownership of files. -o, --oldfile FILE ... Old file mode. Convert file FILE and overwrite output to it. The program defaults to run in this mode. Wildcard names may be used. In old file (in-place) mode the converted file gets the same owner, group, and read/write permissions as the original file. Also when the file is converted by another user who has write permissions on the file (e.g. user root). The conversion will be aborted when it is not possible to preserve the original values. Change of owner could mean that the original owner is not able to read the file any more. Change of group could be a security risk, the file could be made readable for persons for whom it is not intended. Preservation of owner, group, and read/write permissions is only supported on Unix. To check if dos2unix has support for preserving the user and group ownership of files type \u0026quot;dos2unix -V\u0026quot;. Conversion is always done via a temporary file. When an error occurs halfway the conversion, the temporary file is deleted and the original file stays intact. When the conversion is successful, the original file is replaced with the temporary file. You may have write permission on the original file, but no permission to put the same user and/or group ownership properties on the temporary file as the original file has. This means you are not able to preserve the user and/or group ownership of the original file. In this case you can use option \u0026quot;--allow-chown\u0026quot; to continue with the conversion: dos2unix --allow-chown foo.txt Another option is to use new file mode: dos2unix -n foo.txt foo.txt The advantage of the \u0026quot;--allow-chown\u0026quot; option is that you can use wildcards, and the ownership properties will be preserved when possible. -q, --quiet Quiet mode. Suppress all warnings and messages. The return value is zero. Except when wrong command-line options are used. -r, --remove-bom Remove Byte Order Mark (BOM). Do not write a BOM in the output file. This is the default behavior when converting to Unix line breaks. See also option \u0026quot;-b\u0026quot;. -s, --safe Skip binary files (default). The skipping of binary files is done to avoid accidental mistakes. Be aware that the detection of binary files is not 100% foolproof. Input files are scanned for binary symbols which are typically not found in text files. It is possible that a binary file contains only normal text characters. Such a binary file will mistakenly be seen as a text file. -u, --keep-utf16 Keep the original UTF-16 encoding of the input file. The output file will be written in the same UTF-16 encoding, little or big endian, as the input file. This prevents transformation to UTF-8. An UTF-16 BOM will be written accordingly. This option can be disabled with the \u0026quot;-ascii\u0026quot; option. -ul, --assume-utf16le Assume that the input file format is UTF-16LE. When there is a Byte Order Mark in the input file the BOM has priority over this option. When you made a wrong assumption (the input file was not in UTF-16LE format) and the conversion succeeded, you will get an UTF-8 output file with wrong text. You can undo the wrong conversion with iconv(1) by converting the UTF-8 output file back to UTF-16LE. This will bring back the original file. The assumption of UTF-16LE works as a conversion mode. By switching to the default ascii mode the UTF-16LE assumption is turned off. -ub, --assume-utf16be Assume that the input file format is UTF-16BE. This option works the same as option \u0026quot;-ul\u0026quot;. -v, --verbose Display verbose messages. Extra information is displayed about Byte Order Marks and the amount of converted line breaks. -F, --follow-symlink Follow symbolic links and convert the targets. -R, --replace-symlink Replace symbolic links with converted files (original target files remain unchanged). -S, --skip-symlink Keep symbolic links and targets unchanged (default). -V, --version Display version information and exit. MAC MODE In normal mode line breaks are converted from DOS to Unix and vice versa. Mac line breaks are not converted. In Mac mode line breaks are converted from Mac to Unix and vice versa. DOS line breaks are not changed. To run in Mac mode use the command-line option \u0026quot;-c mac\u0026quot; or use the commands \u0026quot;mac2unix\u0026quot; or \u0026quot;unix2mac\u0026quot;. CONVERSION MODES ascii In mode \u0026quot;ascii\u0026quot; only line breaks are converted. This is the default conversion mode. Although the name of this mode is ASCII, which is a 7 bit standard, the actual mode is 8 bit. Use always this mode when converting Unicode UTF-8 files. 7bit In this mode all 8 bit non-ASCII characters (with values from 128 to 255) are converted to a 7 bit space. iso Characters are converted between a DOS character set (code page) and ISO character set ISO-8859-1 (Latin-1) on Unix. DOS characters without ISO-8859-1 equivalent, for which conversion is not possible, are converted to a dot. The same counts for ISO-8859-1 characters without DOS counterpart. When only option \u0026quot;-iso\u0026quot; is used dos2unix will try to determine the active code page. When this is not possible dos2unix will use default code page CP437, which is mainly used in the USA. To force a specific code page use options \u0026quot;-437\u0026quot; (US), \u0026quot;-850\u0026quot; (Western European), \u0026quot;-860\u0026quot; (Portuguese), \u0026quot;-863\u0026quot; (French Canadian), or \u0026quot;-865\u0026quot; (Nordic). Windows code page CP1252 (Western European) is also supported with option \u0026quot;-1252\u0026quot;. For other code pages use dos2unix in combination with iconv(1). Iconv can convert between a long list of character encodings. Never use ISO conversion on Unicode text files. It will corrupt UTF-8 encoded files. Some examples: Convert from DOS default code page to Unix Latin-1: dos2unix -iso -n in.txt out.txt Convert from DOS CP850 to Unix Latin-1: dos2unix -850 -n in.txt out.txt Convert from Windows CP1252 to Unix Latin-1: dos2unix -1252 -n in.txt out.txt Convert from Windows CP1252 to Unix UTF-8 (Unicode): iconv -f CP1252 -t UTF-8 in.txt | dos2unix \u0026gt; out.txt Convert from Unix Latin-1 to DOS default code page: unix2dos -iso -n in.txt out.txt Convert from Unix Latin-1 to DOS CP850: unix2dos -850 -n in.txt out.txt Convert from Unix Latin-1 to Windows CP1252: unix2dos -1252 -n in.txt out.txt Convert from Unix UTF-8 (Unicode) to Windows CP1252: unix2dos \u0026lt; in.txt | iconv -f UTF-8 -t CP1252 \u0026gt; out.txt See also \u0026lt;http://czyborra.com/charsets/codepages.html\u0026gt; and \u0026lt;http://czyborra.com/charsets/iso8859.html\u0026gt;. UNICODE Encodings There exist different Unicode encodings. On Unix and Linux Unicode files are typically encoded in UTF-8 encoding. On Windows Unicode text files can be encoded in UTF-8, UTF-16, or UTF-16 big endian, but are mostly encoded in UTF-16 format. Conversion Unicode text files can have DOS, Unix or Mac line breaks, like regular text files. All versions of dos2unix and unix2dos can convert UTF-8 encoded files, because UTF-8 was designed for backward compatibility with ASCII. Dos2unix and unix2dos with Unicode UTF-16 support, can read little and big endian UTF-16 encoded text files. To see if dos2unix was built with UTF-16 support type \u0026quot;dos2unix -V\u0026quot;. On Unix/Linux UTF-16 encoded files are converted to the locale character encoding. Use the locale(1) command to find out what the locale character encoding is. When conversion is not possible a conversion error will occur and the file will be skipped. On Windows UTF-16 files are by default converted to UTF-8. UTF-8 formatted text files are well supported on both Windows and Unix/Linux. UTF-16 and UTF-8 encoding are fully compatible, there will no text be lost in the conversion. When an UTF-16 to UTF-8 conversion error occurs, for instance when the UTF-16 input file contains an error, the file will be skipped. When option \u0026quot;-u\u0026quot; is used, the output file will be written in the same UTF-16 encoding as the input file. Option \u0026quot;-u\u0026quot; prevents conversion to UTF-8. Dos2unix and unix2dos have no option to convert UTF-8 files to UTF-16. ISO and 7-bit mode conversion do not work on UTF-16 files. Byte Order Mark On Windows Unicode text files typically have a Byte Order Mark (BOM), because many Windows programs (including Notepad) add BOMs by default. See also \u0026lt;http://en.wikipedia.org/wiki/Byte_order_mark\u0026gt;. On Unix Unicode files typically don't have a BOM. It is assumed that text files are encoded in the locale character encoding. Dos2unix can only detect if a file is in UTF-16 format if the file has a BOM. When an UTF-16 file doesn't have a BOM, dos2unix will see the file as a binary file. Use option \u0026quot;-ul\u0026quot; or \u0026quot;-ub\u0026quot; to convert an UTF-16 file without BOM. Dos2unix writes by default no BOM in the output file. With option \u0026quot;-b\u0026quot; Dos2unix writes a BOM when the input file has a BOM. Unix2dos writes by default a BOM in the output file when the input file has a BOM. Use option \u0026quot;-r\u0026quot; to remove the BOM. Dos2unix and unix2dos write always a BOM when option \u0026quot;-m\u0026quot; is used. Unicode file names on Windows Dos2unix has optional support for reading and writing Unicode file names in the Windows Command Prompt. That means that dos2unix can open files that have characters in the name that are not part of the default system ANSI code page. To see if dos2unix for Windows was built with Unicode file name support type \u0026quot;dos2unix -V\u0026quot;. There are some issues with displaying Unicode file names in a Windows console. See option \u0026quot;-D\u0026quot;, \u0026quot;--display-enc\u0026quot;. The file names may be displayed wrongly in the console, but the files will be written with the correct name. Unicode examples Convert from Windows UTF-16 (with BOM) to Unix UTF-8: dos2unix -n in.txt out.txt Convert from Windows UTF-16LE (without BOM) to Unix UTF-8: dos2unix -ul -n in.txt out.txt Convert from Unix UTF-8 to Windows UTF-8 with BOM: unix2dos -m -n in.txt out.txt Convert from Unix UTF-8 to Windows UTF-16: unix2dos \u0026lt; in.txt | iconv -f UTF-8 -t UTF-16 \u0026gt; out.txt GB18030 GB18030 is a Chinese government standard. A mandatory subset of the GB18030 standard is officially required for all software products sold in China. See also \u0026lt;http://en.wikipedia.org/wiki/GB_18030\u0026gt;. GB18030 is fully compatible with Unicode, and can be considered an unicode transformation format. Like UTF-8, GB18030 is compatible with ASCII. GB18030 is also compatible with Windows code page 936, also known as GBK. On Unix/Linux UTF-16 files are converted to GB18030 when the locale encoding is set to GB18030. Note that this will only work if the locale is supported by the system. Use command \u0026quot;locale -a\u0026quot; to get the list of supported locales. On Windows you need to use option \u0026quot;-gb\u0026quot; to convert UTF-16 files to GB18030. GB18030 encoded files can have a Byte Order Mark, like Unicode files. EXAMPLES Read input from 'stdin' and write output to 'stdout': dos2unix \u0026lt; a.txt cat a.txt | dos2unix Convert and replace a.txt. Convert and replace b.txt: dos2unix a.txt b.txt dos2unix -o a.txt b.txt Convert and replace a.txt in ascii conversion mode: dos2unix a.txt Convert and replace a.txt in ascii conversion mode, convert and replace b.txt in 7bit conversion mode: dos2unix a.txt -c 7bit b.txt dos2unix -c ascii a.txt -c 7bit b.txt dos2unix -ascii a.txt -7 b.txt Convert a.txt from Mac to Unix format: dos2unix -c mac a.txt mac2unix a.txt Convert a.txt from Unix to Mac format: unix2dos -c mac a.txt unix2mac a.txt Convert and replace a.txt while keeping original date stamp: dos2unix -k a.txt dos2unix -k -o a.txt Convert a.txt and write to e.txt: dos2unix -n a.txt e.txt Convert a.txt and write to e.txt, keep date stamp of e.txt same as a.txt: dos2unix -k -n a.txt e.txt Convert and replace a.txt, convert b.txt and write to e.txt: dos2unix a.txt -n b.txt e.txt dos2unix -o a.txt -n b.txt e.txt Convert c.txt and write to e.txt, convert and replace a.txt, convert and replace b.txt, convert d.txt and write to f.txt: dos2unix -n c.txt e.txt -o a.txt b.txt -n d.txt f.txt RECURSIVE CONVERSION In a Unix shell the find(1) and xargs(1) commands can be used to run dos2unix recursively over all text files in a directory tree. For instance to convert all .txt files in the directory tree under the current directory type: find . -name '*.txt' -print0 |xargs -0 dos2unix The find(1) option \u0026quot;-print0\u0026quot; and corresponding xargs(1) option \u0026quot;-0\u0026quot; are needed when there are files with spaces or quotes in the name. Otherwise these options can be omitted. Another option is to use find(1) with the \u0026quot;-exec\u0026quot; option: find . -name '*.txt' -exec dos2unix {} \\; In a Windows Command Prompt the following command can be used: for /R %G in (*.txt) do dos2unix \u0026quot;%G\u0026quot; PowerShell users can use the following command in Windows PowerShell: get-childitem -path . -filter '*.txt' -recurse | foreach-object {dos2unix $_.Fullname} LOCALIZATION LANG The primary language is selected with the environment variable LANG. The LANG variable consists out of several parts. The first part is in small letters the language code. The second is optional and is the country code in capital letters, preceded with an underscore. There is also an optional third part: character encoding, preceded with a dot. A few examples for POSIX standard type shells: export LANG=nl Dutch export LANG=nl_NL Dutch, The Netherlands export LANG=nl_BE Dutch, Belgium export LANG=es_ES Spanish, Spain export LANG=es_MX Spanish, Mexico export LANG=en_US.iso88591 English, USA, Latin-1 encoding export LANG=en_GB.UTF-8 English, UK, UTF-8 encoding For a complete list of language and country codes see the gettext manual: \u0026lt;http://www.gnu.org/software/gettext/manual/html_node/Usual-Language-Codes.html\u0026gt; On Unix systems you can use the command locale(1) to get locale specific information. LANGUAGE With the LANGUAGE environment variable you can specify a priority list of languages, separated by colons. Dos2unix gives preference to LANGUAGE over LANG. For instance, first Dutch and then German: \u0026quot;LANGUAGE=nl:de\u0026quot;. You have to first enable localization, by setting LANG (or LC_ALL) to a value other than \u0026quot;C\u0026quot;, before you can use a language priority list through the LANGUAGE variable. See also the gettext manual: \u0026lt;http://www.gnu.org/software/gettext/manual/html_node/The-LANGUAGE-variable.html\u0026gt; If you select a language which is not available you will get the standard English messages. DOS2UNIX_LOCALEDIR With the environment variable DOS2UNIX_LOCALEDIR the LOCALEDIR set during compilation can be overruled. LOCALEDIR is used to find the language files. The GNU default value is \u0026quot;/usr/local/share/locale\u0026quot;. Option --version will display the LOCALEDIR that is used. Example (POSIX shell): export DOS2UNIX_LOCALEDIR=$HOME/share/locale RETURN VALUE On success, zero is returned. When a system error occurs the last system error will be returned. For other errors 1 is returned. The return value is always zero in quiet mode, except when wrong command-line options are used. STANDARDS \u0026lt;http://en.wikipedia.org/wiki/Text_file\u0026gt; \u0026lt;http://en.wikipedia.org/wiki/Carriage_return\u0026gt; \u0026lt;http://en.wikipedia.org/wiki/Newline\u0026gt; \u0026lt;http://en.wikipedia.org/wiki/Unicode\u0026gt; AUTHORS Benjamin Lin - \u0026lt;blin@socs.uts.edu.au\u0026gt;, Bernd Johannes Wuebben (mac2unix mode) - \u0026lt;wuebben@kde.org\u0026gt;, Christian Wurll (add extra newline) - \u0026lt;wurll@ira.uka.de\u0026gt;, Erwin Waterlander - \u0026lt;waterlan@xs4all.nl\u0026gt; (maintainer) Project page: \u0026lt;http://waterlan.home.xs4all.nl/dos2unix.html\u0026gt; SourceForge page: \u0026lt;http://sourceforge.net/projects/dos2unix/\u0026gt; SEE ALSO file(1) find(1) iconv(1) locale(1) xargs(1) dos2unix 2022-06-05 dos2unix(1) "}),e.add({id:41,href:"/docs/tools/utility/dust/",title:"Dust",description:`Description # dust is a more intuitive version of du in rust.
Installation # brew install dust Usage # dust Resources # dust help # Like du but more intuitive USAGE: dust [OPTIONS] [--] [inputs]... ARGS: \u0026lt;inputs\u0026gt;... OPTIONS: -b, --no-percent-bars No percent bars or percentages will be displayed -c, --no-colors No colors will be printed (Useful for commands like: watch) -d, --depth \u0026lt;depth\u0026gt; Depth to show -D, --only-dir Only directories will be displayed.`,content:"Description # dust is a more intuitive version of du in rust.\nInstallation # brew install dust Usage # dust Resources # dust help # Like du but more intuitive USAGE: dust [OPTIONS] [--] [inputs]... ARGS: \u0026lt;inputs\u0026gt;... OPTIONS: -b, --no-percent-bars No percent bars or percentages will be displayed -c, --no-colors No colors will be printed (Useful for commands like: watch) -d, --depth \u0026lt;depth\u0026gt; Depth to show -D, --only-dir Only directories will be displayed. -e, --filter \u0026lt;filter\u0026gt; Only include filepaths matching this regex. For png files type: -e \u0026quot;\\.png$\u0026quot; -f, --filecount Directory 'size' is number of child files/dirs not disk size -F, --only-file Only files will be displayed. (Finds your largest files) -h, --help Print help information -H, --si print sizes in powers of 1000 (e.g., 1.1G) -i, --ignore_hidden Do not display hidden files -L, --dereference-links dereference sym links - Treat sym links as directories and go into them -n, --number-of-lines \u0026lt;number_of_lines\u0026gt; Number of lines of output to show. (Default is terminal_height - 10) -p, --full-paths Subdirectories will not have their path shortened -P, --no-progress Disable the progress indication. -r, --reverse Print tree upside down (biggest highest) -R, --screen-reader For screen readers. Removes bars. Adds new column: depth level (May want to use -p too for full path) -s, --apparent-size Use file length instead of blocks --skip-total No total row will be displayed -t, --file_types show only these file types -v, --invert-filter \u0026lt;invert_filter\u0026gt; Exclude filepaths matching this regex. To ignore png files type: -v \u0026quot;\\.png$\u0026quot; -V, --version Print version information -w, --terminal_width \u0026lt;width\u0026gt; Specify width of output overriding the auto detection of terminal width -x, --limit-filesystem Only count the files and directories on the same filesystem as the supplied directory -X, --ignore-directory \u0026lt;ignore_directory\u0026gt; Exclude any file or directory with this name -z, --min-size \u0026lt;min_size\u0026gt; Minimum size file to include in output "}),e.add({id:42,href:"/docs/tools/utility/bat/",title:"Bat",description:`Description # bat is a cat clone with syntax highlighting and Git integration.
Installation # brew install bat Usage # bat file --language rust Resources # bat help # bat 0.22.1 A cat(1) clone with syntax highlighting and Git integration. USAGE: bat [OPTIONS] [FILE]... bat \u0026lt;SUBCOMMAND\u0026gt; ARGS: \u0026lt;FILE\u0026gt;... File(s) to print / concatenate. Use a dash ('-') or no argument at all to read from standard input. OPTIONS: -A, --show-all Show non-printable characters like space, tab or newline.`,content:"Description # bat is a cat clone with syntax highlighting and Git integration.\nInstallation # brew install bat Usage # bat file --language rust Resources # bat help # bat 0.22.1 A cat(1) clone with syntax highlighting and Git integration. USAGE: bat [OPTIONS] [FILE]... bat \u0026lt;SUBCOMMAND\u0026gt; ARGS: \u0026lt;FILE\u0026gt;... File(s) to print / concatenate. Use a dash ('-') or no argument at all to read from standard input. OPTIONS: -A, --show-all Show non-printable characters like space, tab or newline. This option can also be used to print binary files. Use '--tabs' to control the width of the tab-placeholders. -p, --plain Only show plain style, no decorations. This is an alias for '--style=plain'. When '-p' is used twice ('-pp'), it also disables automatic paging (alias for '--style=plain --paging=never'). -l, --language \u0026lt;language\u0026gt; Explicitly set the language for syntax highlighting. The language can be specified as a name (like 'C++' or 'LaTeX') or possible file extension (like 'cpp', 'hpp' or 'md'). Use '--list-languages' to show all supported language names and file extensions. -H, --highlight-line \u0026lt;N:M\u0026gt; Highlight the specified line ranges with a different background color For example: '--highlight-line 40' highlights line 40 '--highlight-line 30:40' highlights lines 30 to 40 '--highlight-line :40' highlights lines 1 to 40 '--highlight-line 40:' highlights lines 40 to the end of the file '--highlight-line 30:+10' highlights lines 30 to 40 --file-name \u0026lt;name\u0026gt; Specify the name to display for a file. Useful when piping data to bat from STDIN when bat does not otherwise know the filename. Note that the provided file name is also used for syntax detection. -d, --diff Only show lines that have been added/removed/modified with respect to the Git index. Use --diff-context=N to control how much context you want to see. --diff-context \u0026lt;N\u0026gt; Include N lines of context around added/removed/modified lines when using '--diff'. --tabs \u0026lt;T\u0026gt; Set the tab width to T spaces. Use a width of 0 to pass tabs through directly --wrap \u0026lt;mode\u0026gt; Specify the text-wrapping mode (*auto*, never, character). The '--terminal-width' option can be used in addition to control the output width. --terminal-width \u0026lt;width\u0026gt; Explicitly set the width of the terminal instead of determining it automatically. If prefixed with '+' or '-', the value will be treated as an offset to the actual terminal width. See also: '--wrap'. -n, --number Only show line numbers, no other decorations. This is an alias for '--style=numbers' --color \u0026lt;when\u0026gt; Specify when to use colored output. The automatic mode only enables colors if an interactive terminal is detected - colors are automatically disabled if the output goes to a pipe. Possible values: *auto*, never, always. --italic-text \u0026lt;when\u0026gt; Specify when to use ANSI sequences for italic text in the output. Possible values: always, *never*. --decorations \u0026lt;when\u0026gt; Specify when to use the decorations that have been specified via '--style'. The automatic mode only enables decorations if an interactive terminal is detected. Possible values: *auto*, never, always. -f, --force-colorization Alias for '--decorations=always --color=always'. This is useful if the output of bat is piped to another program, but you want to keep the colorization/decorations. --paging \u0026lt;when\u0026gt; Specify when to use the pager. To disable the pager, use --paging=never' or its alias,'-P'. To disable the pager permanently, set BAT_PAGER to an empty string. To control which pager is used, see the '--pager' option. Possible values: *auto*, never, always. --pager \u0026lt;command\u0026gt; Determine which pager is used. This option will override the PAGER and BAT_PAGER environment variables. The default pager is 'less'. To control when the pager is used, see the '--paging' option. Example: '--pager \u0026quot;less -RF\u0026quot;'. -m, --map-syntax \u0026lt;glob:syntax\u0026gt; Map a glob pattern to an existing syntax name. The glob pattern is matched on the full path and the filename. For example, to highlight *.build files with the Python syntax, use -m '*.build:Python'. To highlight files named '.myignore' with the Git Ignore syntax, use -m '.myignore:Git Ignore'. Note that the right-hand side is the *name* of the syntax, not a file extension. --ignored-suffix \u0026lt;ignored-suffix\u0026gt; Ignore extension. For example: 'bat --ignored-suffix \u0026quot;.dev\u0026quot; my_file.json.dev' will use JSON syntax, and ignore '.dev' --theme \u0026lt;theme\u0026gt; Set the theme for syntax highlighting. Use '--list-themes' to see all available themes. To set a default theme, add the '--theme=\u0026quot;...\u0026quot;' option to the configuration file or export the BAT_THEME environment variable (e.g.: export BAT_THEME=\u0026quot;...\u0026quot;). --list-themes Display a list of supported themes for syntax highlighting. --style \u0026lt;components\u0026gt; Configure which elements (line numbers, file headers, grid borders, Git modifications, ..) to display in addition to the file contents. The argument is a comma-separated list of components to display (e.g. 'numbers,changes,grid') or a pre-defined style ('full'). To set a default style, add the '--style=\u0026quot;..\u0026quot;' option to the configuration file or export the BAT_STYLE environment variable (e.g.: export BAT_STYLE=\u0026quot;..\u0026quot;). Possible values: * default: enables recommended style components (default). * full: enables all available components. * auto: same as 'default', unless the output is piped. * plain: disables all available components. * changes: show Git modification markers. * header: alias for 'header-filename'. * header-filename: show filenames before the content. * header-filesize: show file sizes before the content. * grid: vertical/horizontal lines to separate side bar and the header from the content. * rule: horizontal lines to delimit files. * numbers: show line numbers in the side bar. * snip: draw separation lines between distinct line ranges. -r, --line-range \u0026lt;N:M\u0026gt; Only print the specified range of lines for each file. For example: '--line-range 30:40' prints lines 30 to 40 '--line-range :40' prints lines 1 to 40 '--line-range 40:' prints lines 40 to the end of the file '--line-range 40' only prints line 40 '--line-range 30:+10' prints lines 30 to 40 -L, --list-languages Display a list of supported languages for syntax highlighting. -u, --unbuffered This option exists for POSIX-compliance reasons ('u' is for 'unbuffered'). The output is always unbuffered - this option is simply ignored. --diagnostic Show diagnostic information for bug reports. --acknowledgements Show acknowledgements. -h, --help Print this help message. -V, --version Print version information SUBCOMMANDS: cache Modify the syntax-definition and theme cache Note: `bat -h` prints a short and concise overview while `bat --help` gives all details. "}),e.add({id:43,href:"/docs/tools/utility/bottom/",title:"Bottom",description:"Description # bottom is a cross-platform graphical process/system monitor with a customizable interface and a multitude of features.\nInstallation # brew install bottom Usage # btm Resources # bottom``` help # bottom 0.8.0 Clement Tsang \u0026lt;cjhtsang@uwaterloo.ca\u0026gt; A customizable cross-platform graphical process/system monitor for the terminal. Supports Linux, macOS, and Windows. USAGE: btm [FLAG] FLAGS: -a, --hide_avg_cpu Hides the average CPU usage from being shown. --autohide_time Automatically hides the time scale in graphs after being shown for a brief moment when zoomed in/out.",content:"Description # bottom is a cross-platform graphical process/system monitor with a customizable interface and a multitude of features.\nInstallation # brew install bottom Usage # btm Resources # bottom``` help # bottom 0.8.0 Clement Tsang \u0026lt;cjhtsang@uwaterloo.ca\u0026gt; A customizable cross-platform graphical process/system monitor for the terminal. Supports Linux, macOS, and Windows. USAGE: btm [FLAG] FLAGS: -a, --hide_avg_cpu Hides the average CPU usage from being shown. --autohide_time Automatically hides the time scale in graphs after being shown for a brief moment when zoomed in/out. If time is disabled via --hide_time then this will have no effect. -b, --basic Hides graphs and uses a more basic look. Design is largely inspired by htop's. --battery Shows the battery widget in default or basic mode. No effect on custom layouts. -c, --celsius Sets the temperature type to Celsius. This is the default option. -C, --config \u0026lt;CONFIG PATH\u0026gt; Sets the location of the config file. Expects a config file in the TOML format. If it doesn't exist, one is created. --color \u0026lt;COLOR SCHEME\u0026gt; Use a pre-defined color scheme. Currently supported values are: +------------------------------------------------------------+ | default | +------------------------------------------------------------+ | default-light (default but for use with light backgrounds) | +------------------------------------------------------------+ | gruvbox (a bright theme with 'retro groove' colors) | +------------------------------------------------------------+ | gruvbox-light (gruvbox but for use with light backgrounds) | +------------------------------------------------------------+ | nord (an arctic, north-bluish color palette) | +------------------------------------------------------------+ | nord-light (nord but for use with light backgrounds) | +------------------------------------------------------------+ Defaults to \u0026quot;default\u0026quot;. -d, --time_delta \u0026lt;MS\u0026gt; The amount of time in milliseconds changed when zooming in/out. The minimum is 1s (1000), and defaults to 15s (15000). --default_widget_count \u0026lt;INT\u0026gt; Sets the n'th selected widget type to use as the default widget. Requires 'default_widget_type' to also be set, and defaults to 1. This reads from left to right, top to bottom. For example, suppose we have a layout that looks like: +-------------------+-----------------------+ | CPU (1) | CPU (2) | +---------+---------+-------------+---------+ | Process | CPU (3) | Temperature | CPU (4) | +---------+---------+-------------+---------+ And we set our default widget type to 'CPU'. If we set '--default_widget_count 1', then it would use the CPU (1) as the default widget. If we set '--default_widget_count 3', it would use CPU (3) as the default instead. --default_widget_type \u0026lt;WIDGET TYPE\u0026gt; Sets which widget type to use as the default widget. For the default layout, this defaults to the 'process' widget. For a custom layout, it defaults to the first widget it sees. For example, suppose we have a layout that looks like: +-------------------+-----------------------+ | CPU (1) | CPU (2) | +---------+---------+-------------+---------+ | Process | CPU (3) | Temperature | CPU (4) | +---------+---------+-------------+---------+ Setting '--default_widget_type Temp' will make the Temperature widget selected by default. Supported widget names: +--------------------------+ | cpu | +--------------------------+ | mem, memory | +--------------------------+ | net, network | +--------------------------+ | proc, process, processes | +--------------------------+ | temp, temperature | +--------------------------+ | disk | +--------------------------+ | batt, battery | +--------------------------+ --disable_advanced_kill Hides advanced options to stop a process on Unix-like systems. The only option shown is 15 (TERM). --disable_click Disables mouse clicks from interacting with the program. -e, --expanded Expand the default widget upon starting the app. Same as pressing \u0026quot;e\u0026quot; inside the app. Use with \u0026quot;default_widget_type\u0026quot; and \u0026quot;default_widget_count\u0026quot; to select desired expanded widget. This flag has no effect in basic mode (--basic) --enable_gpu_memory Enable collecting and displaying GPU memory usage. -f, --fahrenheit Sets the temperature type to Fahrenheit. -g, --group Groups processes with the same name by default. -h, --help Prints help information. Use --help for info. --hide_table_gap Hides the spacing between table headers and entries. --hide_time Completely hides the time scale from being shown. -k, --kelvin Sets the temperature type to Kelvin. -l, --left_legend Puts the CPU chart legend to the left side rather than the right side. -m, --dot_marker Uses a dot marker for graphs as opposed to the default braille marker. --mem_as_value Defaults to showing process memory usage by value. Otherwise, it defaults to showing it by percentage. -n, --unnormalized_cpu Shows process CPU usage without averaging over the number of CPU cores in the system. --network_use_binary_prefix Displays the network widget with binary prefixes (i.e. kibibits, mebibits) rather than a decimal prefix (i.e. kilobits, megabits). Defaults to decimal prefixes. --network_use_bytes Displays the network widget using bytes. Defaults to bits. --network_use_log Displays the network widget with a log scale. Defaults to a non-log scale. --process_command Show processes as their commands by default in the process widget. -r, --rate \u0026lt;MS\u0026gt; Sets a refresh rate in milliseconds. The minimum is 250ms, and defaults to 1000ms. Smaller values may take more computer resources. -R, --regex When searching for a process, enables regex by default. --retention \u0026lt;time\u0026gt; How much data is stored at once in terms of time. Takes in human- readable time spans (e.g. 10m, 1h), with a minimum of 1 minute. Note higher values will take up more memory. Defaults to 10 minutes. -S, --case_sensitive When searching for a process, enables case sensitivity by default. --show_table_scroll_position Shows the list scroll position tracker in the widget title for table widgets. -t, --default_time_value \u0026lt;MS\u0026gt; Default time value for graphs in milliseconds. The minimum time is 30s (30000), and the default is 60s (60000). -T, --tree Defaults to showing the process widget in tree mode. -u, --current_usage Sets process CPU% usage to be based on the current system CPU% usage rather than total CPU usage. --use_old_network_legend DEPRECATED - uses an older (pre-0.4), separate network widget legend. This display is not tested anymore and could be broken. -V, --version Prints version information. -W, --whole_word When searching for a process, return results that match the entire query by default. "}),e.add({id:44,href:"/docs/tools/utility/discount/",title:"Discount",description:`Description # discount is a Markdown to HTML converter.
Installation # brew install discount Usage # markdown input.md \u0026gt; output.html markdown input.md -o output.html Resources # discount help # usage: markdown [-5dVGnSTxX] [-b url-base] [-E flags] [-F bitmap] [-f {+-}flags] [-s text] [-t text] [-C prefix] [-o file] [-html5] [-base url-base] [-debug] [-version] [-style] [-toc] [-squash] [-codefmt] [file] `,content:`Description # discount is a Markdown to HTML converter.
Installation # brew install discount Usage # markdown input.md \u0026gt; output.html markdown input.md -o output.html Resources # discount help # usage: markdown [-5dVGnSTxX] [-b url-base] [-E flags] [-F bitmap] [-f {+-}flags] [-s text] [-t text] [-C prefix] [-o file] [-html5] [-base url-base] [-debug] [-version] [-style] [-toc] [-squash] [-codefmt] [file] `}),e.add({id:45,href:"/docs/tools/utility/argon2/",title:"Argon2",description:`Description # Argon2 is a password-hashing function that summarizes the state of the art in the design of memory-hard functions and can be used to hash passwords for credential storage, key derivation, or other applications.
Installation # brew install argon2 Usage # echo -n \u0026quot;password\u0026quot; | argon2 somesalt -t 2 -m 16 -p 4 -l 24 Resources # Argon2 help # Usage: argon2 [-h] salt [-i|-d|-id] [-t iterations] [-m log2(memory in KiB) | -k memory in KiB] [-p parallelism] [-l hash length] [-e|-r] [-v (10|13)] Password is read from stdin Parameters: salt The salt to use, at least 8 characters -i Use Argon2i (this is the default) -d Use Argon2d instead of Argon2i -id Use Argon2id instead of Argon2i -t N Sets the number of iterations to N (default = 3) -m N Sets the memory usage of 2^N KiB (default 12) -k N Sets the memory usage of N KiB (default 4096) -p N Sets parallelism to N threads (default 1) -l N Sets hash output length to N bytes (default 32) -e Output only encoded hash -r Output only the raw bytes of the hash -v (10|13) Argon2 version (defaults to the most recent version, currently 13) -h Print argon2 usage `,content:`Description # Argon2 is a password-hashing function that summarizes the state of the art in the design of memory-hard functions and can be used to hash passwords for credential storage, key derivation, or other applications.
Installation # brew install argon2 Usage # echo -n \u0026quot;password\u0026quot; | argon2 somesalt -t 2 -m 16 -p 4 -l 24 Resources # Argon2 help # Usage: argon2 [-h] salt [-i|-d|-id] [-t iterations] [-m log2(memory in KiB) | -k memory in KiB] [-p parallelism] [-l hash length] [-e|-r] [-v (10|13)] Password is read from stdin Parameters: salt The salt to use, at least 8 characters -i Use Argon2i (this is the default) -d Use Argon2d instead of Argon2i -id Use Argon2id instead of Argon2i -t N Sets the number of iterations to N (default = 3) -m N Sets the memory usage of 2^N KiB (default 12) -k N Sets the memory usage of N KiB (default 4096) -p N Sets parallelism to N threads (default 1) -l N Sets hash output length to N bytes (default 32) -e Output only encoded hash -r Output only the raw bytes of the hash -v (10|13) Argon2 version (defaults to the most recent version, currently 13) -h Print argon2 usage `}),e.add({id:46,href:"/docs/tools/utility/atuin/",title:"Atuin",description:"Description # atuin is a blazing fast shell history tracker, written in Rust.\nInstallation # brew install atuin echo 'eval \u0026quot;$(atuin init zsh)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc Resources # atuin Similar # zsh-history-substring-search zsh-autosuggestions zsh-syntax-highlighting zsh-history-substring-search help # atuin 12.0.0 Ellie Huxtable \u0026lt;e@elm.sh\u0026gt; Magical shell history Usage: atuin \u0026lt;COMMAND\u0026gt; Commands: history Manipulate shell history import Import shell history from file stats Calculate statistics for your history search Interactive history search sync Sync with the configured server login Login to the configured server logout Log out register Register with the configured server key Print the encryption key for transfer to another machine server Start an atuin server init Output shell setup uuid Generate a UUID contributors gen-completions Generate shell completions help Print this message or the help of the given subcommand(s) Options: -h, --help Print help -V, --version Print version ",content:"Description # atuin is a blazing fast shell history tracker, written in Rust.\nInstallation # brew install atuin echo 'eval \u0026quot;$(atuin init zsh)\u0026quot;' \u0026gt;\u0026gt; ~/.zshrc Resources # atuin Similar # zsh-history-substring-search zsh-autosuggestions zsh-syntax-highlighting zsh-history-substring-search help # atuin 12.0.0 Ellie Huxtable \u0026lt;e@elm.sh\u0026gt; Magical shell history Usage: atuin \u0026lt;COMMAND\u0026gt; Commands: history Manipulate shell history import Import shell history from file stats Calculate statistics for your history search Interactive history search sync Sync with the configured server login Login to the configured server logout Log out register Register with the configured server key Print the encryption key for transfer to another machine server Start an atuin server init Output shell setup uuid Generate a UUID contributors gen-completions Generate shell completions help Print this message or the help of the given subcommand(s) Options: -h, --help Print help -V, --version Print version "}),e.add({id:47,href:"/docs/tools/know/testssl/",title:"Testssl",description:`Description # testssl.sh is a free command line tool which checks a server\u0026rsquo;s service on any port for the support of TLS/SSL ciphers, protocols as well as some cryptographic flaws.
install # brew install testssl website # https://testssl.sh
sample usage # testssl.sh example.com help # TESTSSL(1) General Commands Manual TESTSSL(1) NAME testssl NAME testssl -- check encryption of SSL/TLS servers SYNOPSIS testssl [OPTIONS] \u0026lt;URI\u0026gt;, testssl [OPTIONS] --file \u0026lt;FILE\u0026gt; or testssl [BANNER OPTIONS] DESCRIPTION testssl is a free command line tool which checks a server's service on any port for the support of TLS/SSL ciphers, protocols as well as cryptographic flaws and much more.`,content:"Description # testssl.sh is a free command line tool which checks a server\u0026rsquo;s service on any port for the support of TLS/SSL ciphers, protocols as well as some cryptographic flaws.\ninstall # brew install testssl website # https://testssl.sh\nsample usage # testssl.sh example.com help # TESTSSL(1) General Commands Manual TESTSSL(1) NAME testssl NAME testssl -- check encryption of SSL/TLS servers SYNOPSIS testssl [OPTIONS] \u0026lt;URI\u0026gt;, testssl [OPTIONS] --file \u0026lt;FILE\u0026gt; or testssl [BANNER OPTIONS] DESCRIPTION testssl is a free command line tool which checks a server's service on any port for the support of TLS/SSL ciphers, protocols as well as cryptographic flaws and much more. The output rates findings by color (screen) or severity (file output) so that you are able to tell whether something is good or bad. The (screen) output has several sections in which classes of checks are being performed. To ease readability on the screen it aligns and indents the output properly. Only you see the result. You also can use it internally on your LAN. Except DNS lookups or unless you instruct testssl to check for revocation of certificates it doesn't use any other hosts or even third parties for any test. REQUIREMENTS Testssl.sh is out of the box portable: it runs under any Unix-like stack: Linux, *BSD, MacOS X, WSL=Windows Subsystem for Linux, Cygwin and MSYS2. bash is a prerequisite, also version 3 is still supported. Standard utilities like awk, sed, tr and head are also needed. This can be of a BSD, System 5 or GNU flavor whereas grep from System V is not yet supported. Any OpenSSL or LibreSSL version is needed as a helper. Unlike previous versions of testssl almost every check is done via (TCP) sockets. In addition statically linked OpenSSL binaries for ma‐ jor operating systems are supplied in ./bin/. GENERAL testssl URI as the default invocation does the so-called default run which does a number of checks and puts out the results colorized (ANSI and termcap) on the screen. It does every check listed below except -E which are (order of appearance): 0) displays a banner (see below), does a DNS lookup also for further IP addresses and does for the returned IP address a reverse lookup. Last but not least a service check is being done. 1) SSL/TLS protocol check 2) standard cipher categories to give you upfront an idea for the ciphers supported 3) checks (perfect) forward secrecy: ciphers and elliptical curves 4) server preferences (server order) 5) server defaults (certificate info, TLS extensions, session information) 6) HTTP header (if HTTP detected or being forced via --assume-http) 7) vulnerabilities 8) testing each of 370 preconfigured ciphers 9) client simulation OPTIONS AND PARAMETERS Options are either short or long options. Any long or short option requiring a value can be called with or without an equal sign. E.g. testssl -t=smtp --wide --openssl=/usr/bin/openssl \u0026lt;URI\u0026gt; (short options with equal sign) is equivalent to testssl --starttls smtp --wide --openssl /usr/bin/openssl \u0026lt;URI\u0026gt; (long option without equal sign). Some command line options can also be preset via ENV variables. WIDE=true OPENSSL=/usr/bin/openssl testssl --starttls=smtp \u0026lt;URI\u0026gt; would be the equivalent to the aforementioned examples. Preference has the command line over any environment variables. \u0026lt;URI\u0026gt; or --file \u0026lt;FILE\u0026gt; always needs to be the last parameter. BANNER OPTIONS --help (or no arg) display command line help -b, --banner displays testssl banner, including license, usage conditions, version of testssl, detected openssl version, its path to it, # of ciphers of openssl, its build date and the archi‐ tecture. -v, --version same as before -V [pattern] , --local [pattern] pretty print all local ciphers supported by openssl version. If a pattern is supplied it performs a match (ignore case) on any of the strings supplied in the wide output, see below. The pattern will be searched in the any of the columns: hexcode, cipher suite name (OpenSSL or IANA), key exchange, encryption, bits. It does a word pattern match for non-numbers, for number just a normal match applies. Numbers here are defined as [0-9,A-F]. This means (attention: catch) that the pattern CBC is matched as non-word, but AES as word. INPUT PARAMETERS URI can be a hostname, an IPv4 or IPv6 address (restriction see below) or an URL. IPv6 addresses need to be in square brackets. For any given parameter port 443 is assumed unless specified by appending a colon and a port number. The only preceding protocol specifier allowed is https. You need to be aware that checks for an IP address might not hit the vhost you want. DNS resolution (A/AAAA record) is being performed unless you have an /etc/hosts entry for the hostname. --file \u0026lt;fname\u0026gt; or the equivalent -iL \u0026lt;fname\u0026gt; are mass testing options. Per default it implicitly turns on --warnings batch. In its first incarnation the mass testing option reads command lines from fname. fname consists of command lines of testssl, one line per instance. Comments after # are ignored, EOF signals the end of fname any subsequent lines will be ignored too. You can also supply additional options which will be inherited to each child, e.g. When invoking testssl --wide --log --file \u0026lt;fname\u0026gt; . Each single line in fname is parsed upon execution. If there's a con‐ flicting option and serial mass testing option is being performed the check will be aborted at the time it occurs and depending on the output option potentially leaving you with an output file without footer. In parallel mode the mileage varies, likely a line won't be scanned. Alternatively fname can be in nmap's grep(p)able output format (-oG). Only open ports will be considered. Multiple ports per line are allowed. The ports can be different and will be tested by testssl according to common practice in the internet, i.e. if nmap shows in its output an open port 25, automatically -t smtp will be added before the URI whereas port 465 will be treated as a plain TLS/SSL port, not requiring an STARTTLS SMTP handshake upfront. This is done by an internal table which correlates nmap's open port detected to the STARTTLS/plain text decision from testssl. Nmap's output always returns IP addresses and only if there's a PTR DNS record available a hostname. As it is not checked by nmap whether the hostname matches the IP (A or AAAA record), testssl does this automatically for you. If the A record of the hostname matches the IP address, the hostname is used and not the IP address. Please keep in mind that checks against an IP ad‐ dress might not hit the vhost you maybe were aiming at and thus it may lead to different results. A typical internal conversion to testssl file format from nmap's grep(p)able format could look like: 10.10.12.16:443 10.10.12.16:1443 -t smtp host.example.com:25 host.example.com:443 host.example.com:631 -t ftp 10.10.12.11:21 10.10.12.11:8443 Please note that fname has to be in Unix format. DOS carriage returns won't be accepted. Instead of the command line switch the environment variable FNAME will be honored too. --mode \u0026lt;serial|parallel\u0026gt;. Mass testing to be done serial (default) or parallel (--parallel is shortcut for the latter, --serial is the opposite option). Per default mass testing is being run in serial mode, i.e. one line after the other is processed and invoked. The variable MASS_TESTING_MODE can be defined to be either equal serial or parallel. --warnings \u0026lt;batch|off\u0026gt;. The warnings parameter determines how testssl will deal with situations where user input normally will be necessary. There are two options. batch doesn't wait for a confirming keypress when a client- or server-side problem is encountered. As of 3.0 it just then terminates the particular scan. This is automatically chosen for mass testing (--file). off just skips the warning, the confirmation but continues the scan, independent whether it makes sense or not. Please note that there are conflicts where testssl will still ask for confirmation which are the ones which otherwise would have a drastic impact on the results. Almost any other decision will be made in the future as a best guess by testssl. The same can be achieved by set‐ ting the environment variable WARNINGS. --connect-timeout \u0026lt;seconds\u0026gt; This is useful for socket TCP connections to a node. If the node does not complete a TCP handshake (e.g. because it is down or behind a firewall or there's an IDS or a tarpit) testssl may usually hang for around 2 minutes or even much more. This parameter instructs testssl to wait at most seconds for the handshake to complete before giving up. This op‐ tion only works if your OS has a timeout binary installed. CONNECT_TIMEOUT is the corresponding environment variable. --openssl-timeout \u0026lt;seconds\u0026gt; This is especially useful for all connects using openssl and practically useful for mass testing. It avoids the openssl connect to hang for ~2 minutes. The expected parameter seconds instructs testssl to wait before the openssl connect will be terminated. The option is only available if your OS has a timeout binary installed. As there are different imple‐ mentations of timeout: It automatically calls the binary with the right parameters. OPENSSL_TIMEOUT is the equivalent environment variable. --basicauth \u0026lt;user:pass\u0026gt; This can be set to provide HTTP basic auth credentials which are used during checks for security headers. BASICAUTH is the ENV variable you can use instead. SPECIAL INVOCATIONS -t \u0026lt;protocol\u0026gt;, --starttls \u0026lt;protocol\u0026gt; does a default run against a STARTTLS enabled protocol. protocol must be one of ftp, smtp, pop3, imap, xmpp, telnet, ldap, irc, lmtp, nntp, postgres, mysql. For the latter four you need e.g. the supplied OpenSSL or OpenSSL version 1.1.1. Please note: MongoDB doesn't offer a STARTTLS connection, LDAP currently only works with --ssl-native. telnet and irc is WIP. --xmpphost \u0026lt;jabber_domain\u0026gt; is an additional option for STARTTLS enabled XMPP: It expects the jabber domain as a parameter. This is only needed if the domain is different from the URI supplied. --mx \u0026lt;domain|host\u0026gt; tests all MX records (STARTTLS on port 25) from high to low priority, one after the other. --ip \u0026lt;ip\u0026gt; tests either the supplied IPv4 or IPv6 address instead of resolving host(s) in \u0026lt;URI\u0026gt;. IPv6 addresses need to be supplied in square brackets. --ip=one means: just test the first A record DNS returns (useful for multiple IPs). If -6 and --ip=one was supplied an AAAA record will be picked if available. The --ip option might be also useful if you want to resolve the sup‐ plied hostname to a different IP, similar as if you would edit /etc/hosts or /c/Windows/System32/drivers/etc/hosts. --ip=proxy tries a DNS resolution via proxy. --proxy \u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; does ANY check via the specified proxy. --proxy=auto inherits the proxy setting from the environment. The hostname supplied will be resolved to the first A record. In ad‐ dition if you want lookups via proxy you can specify DNS_VIA_PROXY=true. OCSP revocation checking (-S --phone-out) is not supported by OpenSSL via proxy. As supplying a proxy is an indicator for port 80 and 443 outgoing being blocked in your network an OCSP revocation check won't be performed. However if IGN_OCSP_PROXY=true has been supplied it will be tried directly. Authentica‐ tion to the proxy is not supported. Proxying via IPv6 addresses is not possible, no HTTPS or SOCKS proxy is supported. -6 does (also) IPv6 checks. Please note that testssl doesn't perform checks on an IPv6 address automatically, because of two reasons: testssl does no connectivity checks for IPv6 and it cannot determine reliably whether the OpenSSL binary you're using has IPv6 s_client support. -6 assumes both is the case. If both conditions are met and you in general prefer to test for IPv6 branches as well you can add HAS_IPv6 to your shell environment. Besides the OpenSSL binary supplied IPv6 is known to work with vanilla OpenSSL \u0026gt;= 1.1.0 and older versions \u0026gt;=1.0.2 in RHEL/Cen‐ tOS/FC and Gentoo. --ssl-native Instead of using a mixture of bash sockets and a few openssl s_client connects, testssl uses the latter (almost) only. This is faster at the moment but provides less accurate re‐ sults, especially for the client simulation and for cipher support. For all checks you will see a warning if testssl cannot tell if a particular check cannot be performed. For some checks how‐ ever you might end up getting false negatives without a warning. This option is only recommended if you prefer speed over accuracy or you know that your target has sufficient overlap with the protocols and cipher provided by your openssl binary. --openssl \u0026lt;path_to_openssl\u0026gt; testssl tries very hard to find automagically the binary supplied (where the tree of testssl resides, from the directory where testssl has been started from, etc.). If all that doesn't work it falls back to openssl supplied from the OS ($PATH). With this option you can point testssl to your binary of choice and override any internal magic to find the openssl binary. (Environment preset via OPENSSL=\u0026lt;path_to_openssl\u0026gt;). TUNING OPTIONS --bugs does some workarounds for buggy servers like padding for old F5 devices. The option is passed as -bug to openssl when needed, see s_client(1), environment preset via BUGS=\u0026quot;-bugs\u0026quot; (1x dash). For the socket part testssl has always workarounds in place to cope with broken server implementations. --assuming-http testssl normally does upfront an application protocol detection. In cases where HTTP cannot be automatically detected you may want to use this option. It enforces testssl not to skip HTTP specific tests (HTTP header) and to run a browser based client simulation. Please note that sometimes also the severity depends on the application protocol, e.g. SHA1 signed cer‐ tificates, the lack of any SAN matches and some vulnerabilities will be punished harder when checking a web server as opposed to a mail server. -n, --nodns \u0026lt;min|none\u0026gt; tells testssl which DNS lookups should be performed. min uses only forward DNS resolution (A and AAAA record or MX record) and skips CAA lookups and PTR records from the IP address back to a DNS name. none performs no DNS lookups at all. For the latter you either have to supply the IP address as a target, to use --ip or have the IP address in /etc/hosts. The use of the switch is only useful if you either can't or are not willing to perform DNS lookups. The latter can apply e.g. to some pentests. In general this option could e.g. help you to avoid timeouts by DNS lookups. NODNS is the environment variable for this. --sneaky For HTTP header checks testssl uses normally the server friendly HTTP user agent TLS tester from ${URL}. With this option your traces are less verbose and a Firefox user agent is be‐ ing used. Be aware that it doesn't hide your activities. That is just not possible (environment preset via SNEAKY=true). --ids-friendly is a switch which may help to get a scan finished which otherwise would be blocked by a server side IDS. This switch skips tests for the following vulnerabilities: Heartbleed, CCS Injection, Ticketbleed and ROBOT. The environment variable OFFENSIVE set to false will achieve the same result. Please be advised that as an alternative or as a general approach you can try to apply evasion techniques by changing the variables USLEEP_SND and / or USLEEP_REC and maybe MAX_WAITSOCK. --phone-out Checking for revoked certificates via CRL and OCSP is not done per default. This switch instructs testssl to query external -- in a sense of the current run -- URIs. By using this switch you acknowledge that the check might have privacy issues, a download of several megabytes (CRL file) may happen and there may be network connectivity problems while contacting the end‐ point which testssl doesn't handle. PHONE_OUT is the environment variable for this which needs to be set to true if you want this. --add-ca \u0026lt;cafile\u0026gt; enables you to add your own CA(s) for trust chain checks. cafile can be a single path or multiple paths as a comma separated list of root CA files. Internally they will be added during runtime to all CA stores. This is (only) useful for internal hosts whose certificates is issued by internal CAs. Alternatively ADDITIONAL_CA_FILES is the environment variable for this. SINGLE CHECK OPTIONS Any single check switch supplied as an argument prevents testssl from doing a default run. It just takes this and if supplied other options and runs them - in the order they would also appear in the default run. -e, --each-cipher checks each of the (currently configured) 370 ciphers via openssl + sockets remotely on the server and reports back the result in wide mode. If you want to display each ci‐ pher tested you need to add --show-each. Per default it lists the following parameters: hexcode, OpenSSL cipher suite name, key exchange, encryption bits, IANA/RFC cipher suite name. Please note the --mapping parameter changes what cipher suite names you will see here and at which position. Also please note that the bit length for the encryption is shown and not the security length, albeit it'll be sorted by the latter. For 3DES due to the Meet-in-the-Middle problem the bit size of 168 bits is equivalent to the security size of 112 bits. -E, --cipher-per-proto is similar to -e, --each-cipher. It checks each of the possible ciphers, here: per protocol. If you want to display each cipher tested you need to add --show-each. The output is sorted by security strength, it lists the encryption bits though. -s, --std, --standard tests certain lists of cipher suites / cipher categories by strength. Those lists are (openssl ciphers $LIST, $LIST from below:) ○ NULL encryption ciphers: 'NULL:eNULL' ○ Anonymous NULL ciphers: 'aNULL:ADH' ○ Export ciphers (w/o the preceding ones): 'EXPORT:!ADH:!NULL' ○ LOW (64 Bit + DES ciphers, without EXPORT ciphers): 'LOW:DES:RC2:RC4:!ADH:!EXP:!NULL:!eNULL' ○ 3DES + IDEA Ciphers: '3DES:IDEA:!aNULL:!ADH' ○ Average grade Ciphers: 'HIGH:MEDIUM:AES:CAMELLIA:ARIA:!IDEA:!CHACHA20:!3DES:!RC2:!RC4:!AESCCM8:!AESCCM:!AESGCM:!ARIAGCM:!aNULL' ○ Strong grade Ciphers (AEAD): 'AESGCM:CHACHA20:CamelliaGCM:AESCCM8:AESCCM' -f, --pfs, --fs,--nsa Checks robust (perfect) forward secrecy key exchange. \u0026quot;Robust\u0026quot; means that ciphers having intrinsic severe weaknesses like Null Authentication or Encryption, 3DES and RC4 won't be considered here. There shouldn't be the wrong impression that a secure key exchange has been taking place and everything is fine when in reality the encryption sucks. Also this sec‐ tion lists the available elliptical curves and Diffie Hellman groups, as well as FFDHE groups (TLS 1.2 and TLS 1.3). -p, --protocols checks TLS/SSL protocols SSLv2, SSLv3, TLS 1.0 through TLS 1.3 and for HTTP: SPDY (NPN) and ALPN, a.k.a. HTTP/2. For TLS 1.3 several drafts (from 18 on) and final are supported and being tested for. -P, --preference displays the servers preferences: cipher order, with used openssl client: negotiated protocol and cipher. If there's a cipher order enforced by the server it displays it for each protocol (openssl+sockets). If there's not, it displays instead which ciphers from the server were picked with each protocol. -S, --server_defaults displays information from the server hello(s): ○ Available TLS extensions, ○ TLS ticket + session ID information/capabilities, ○ session resumption capabilities, ○ Time skew relative to localhost (most server implementations return random values). ○ Several certificate information ○ signature algorithm, ○ key size, ○ key usage and extended key usage, ○ fingerprints and serial ○ Common Name (CN), Subject Alternative Name (SAN), Issuer, ○ Trust via hostname + chain of trust against supplied certificates ○ EV certificate detection ○ experimental \u0026quot;eTLS\u0026quot; detection ○ validity: start + end time, how many days to go (warning for certificate lifetime \u0026gt;=5 years) ○ revocation info (CRL, OCSP, OCSP stapling + must staple). When --phone-out supplied it checks against the certificate issuer whether the host certificate has been revoked (plain OCSP, CRL). ○ displaying DNS Certification Authority Authorization resource record ○ Certificate Transparency info (if provided by server). For the trust chain check 5 certificate stores are provided. If the test against one of the trust stores failed, the one is being identified and the reason for the failure is displayed - in addition the ones which succeeded are displayed too. You can configure your own CA via ADDITIONAL_CA_FILES, see section FILES below. If the server provides no matching record in Subject Alter‐ native Name (SAN) but in Common Name (CN), it will be indicated as this is deprecated. Also for multiple server certificates are being checked for as well as for the certificate reply to a non-SNI (Server Name Indication) client hello to the IP address. Regarding the TLS clock skew: it displays the time difference to the client. Only a few TLS stacks nowadays still support this and return the local clock gmt_unix_time, e.g. IIS, openssl \u0026lt; 1.0.1f. In addition to the HTTP date you could e.g. derive that there are different hosts where your TLS and your HTTP request ended -- if the time deltas differ significantly. -x \u0026lt;pattern\u0026gt;, --single-cipher \u0026lt;pattern\u0026gt; tests matched pattern of ciphers against a server. Patterns are similar to -V pattern , --local pattern, see above about matching. -h, --header, --headers if the service is HTTP (either by detection or by enforcing via --assume-http. It tests several HTTP headers like ○ HTTP Strict Transport Security (HSTS) ○ HTTP Public Key Pinning (HPKP) ○ Server banner ○ HTTP date+time ○ Server banner like Linux or other Unix vendor headers ○ Application banner (PHP, RoR, OWA, SharePoint, Wordpress, etc) ○ Reverse proxy headers ○ Web server modules ○ IPv4 address in header ○ Cookie (including Secure/HTTPOnly flags) ○ Decodes BIG IP F5 non-encrypted cookies ○ Security headers (X-Frame-Options, X-XSS-Protection, Expect-CT,... , CSP headers). Nonsense is not yet detected here. -c, --client-simulation This simulates a handshake with a number of standard clients so that you can figure out which client cannot or can connect to your site. For the latter case the proto‐ col, cipher and curve is displayed, also if there's Forward Secrecy. testssl uses a handselected set of clients which are retrieved by the SSLlabs API. The output is aligned in columns when combined with the --wide option. If you want the full nine yards of clients displayed use the environment variable ALL_CLIENTS. -g, --grease checks several server implementation bugs like tolerance to size limitations and GREASE, see https://www.ietf.org/archive/id/draft-ietf-tls-grease-01.txt . This checks doesn't run per default. VULNERABILITIES -U, --vulnerable, --vulnerabilities Just tests all (of the following) vulnerabilities. The environment variable VULN_THRESHLD determines after which value a separate headline for each vulnera‐ bility is being displayed. Default is 1 which means if you check for two vulnerabilities, only the general headline for vulnerabilities section is displayed -- in addition to the vulnerability and the result. Otherwise each vulnerability or vulnerability section gets its own headline in addition to the output of the name of the vulnerability and test result. A vulnerability section is comprised of more than one check, e.g. the renegotiation vulnerability check has two checks, so has Logjam. -H, --heartbleed Checks for Heartbleed, a memory leakage in openssl. Unless the server side doesn't support the heartbeat extension it is likely that this check runs into a timeout. The sec‐ onds to wait for a reply can be adjusted with HEARTBLEED_MAX_WAITSOCK. 8 is the default. -I, --ccs, --ccs-injection Checks for CCS Injection which is an openssl vulnerability. Sometimes also here the check needs to wait for a reply. The predefined timeout of 5 seconds can be changed with the environment variable CCS_MAX_WAITSOCK. -T, --ticketbleed Checks for Ticketbleed memory leakage in BigIP loadbalancers. -BB, --robot Checks for vulnerability to ROBOT / (Return Of Bleichenbacher's Oracle Threat) attack. -R, --renegotiation Tests renegotiation vulnerabilities. Currently there's a check for Secure Renegotiation and for Secure Client-Initiated Renegotiation. Please be aware that vulnerable servers to the latter can likely be DoSed very easily (HTTP). A check for Insecure Client-Initiated Renegotiation is not yet implemented. -C, --compression, --crime Checks for CRIME (Compression Ratio Info-leak Made Easy) vulnerability in TLS. CRIME in SPDY is not yet being checked for. -B, --breach Checks for BREACH (Browser Reconnaissance and Exfiltration via Adaptive Compression of Hypertext) vulnerability. As for this vulnerability HTTP level compression is a prerequisite it'll be not tested if HTTP cannot be detected or the detection is not enforced via --assume-http. Please note that only the URL supplied (normally \u0026quot;/\u0026quot; ) is being tested. -O, --poodle Tests for SSL POODLE (Padding Oracle On Downgraded Legacy Encryption) vulnerability. It basically checks for the existence of CBC ciphers in SSLv3. -Z, --tls-fallback Checks TLS_FALLBACK_SCSV mitigation. TLS_FALLBACK_SCSV is basically a ciphersuite appended to the Client Hello trying to prevent protocol downgrade attacks by a Man in the Middle. -W, --sweet32 Checks for vulnerability to SWEET32 by testing 64 bit block ciphers (3DES, RC2 and IDEA). -F, --freak Checks for FREAK vulnerability (Factoring RSA Export Keys) by testing for EXPORT RSA ciphers -D, --drown Checks for DROWN vulnerability (Decrypting RSA with Obsolete and Weakened eNcryption) by checking whether the SSL 2 protocol is available at the target. Please note that if you use the same RSA certificate elsewhere you might be vulnerable too. testssl doesn't check for this but provides a helpful link @ censys.io which provides this service. -J, --logjam Checks for LOGJAM vulnerability by checking for DH EXPORT ciphers. It also checks for \u0026quot;common primes\u0026quot; which are preconfigured DH keys. DH keys =\u0026lt; 1024 Bit will be penalized. Also FFDHE groups (TLS 1.2) will be displayed here. -A, --beast Checks BEAST vulnerabilities in SSL 3 and TLS 1.0 by testing the usage of CBC ciphers. -L, --lucky13 Checks for LUCKY13 vulnerability. It checks for the presence of CBC ciphers in TLS versions 1.0 - 1.2. -4, --rc4, --appelbaum Checks which RC4 stream ciphers are being offered. OUTPUT OPTIONS -q, --quiet Normally testssl displays a banner on stdout with several version information, usage rights and a warning. This option suppresses it. Please note that by choosing this option you acknowledge usage terms and the warning normally appearing in the banner. --wide Except the \u0026quot;each cipher output\u0026quot; all tests displays the single cipher name (scheme see below). This option enables testssl to display also for the following sections the same output as for testing each ciphers: BEAST, PFS, RC4. The client simulation has also a wide mode. The difference here is restricted to a column aligned output and a proper headline. The environment vari‐ able WIDE can be used instead. --mapping \u0026lt;openssl|iana|no-openssl|no-iana\u0026gt; ○ openssl: use the OpenSSL cipher suite name as the primary name cipher suite name form (default), ○ iana: use the IANA cipher suite name as the primary name cipher suite name form. ○ no-openssl: don't display the OpenSSL cipher suite name, display IANA names only. ○ no-iana: don't display the IANA cipher suite name, display OpenSSL names only. Please note that in testssl 3,0 you can still use rfc instead of iana and no-rfc instead of no-iana but it'll disappear after 3.0. --show-each This is an option for all wide modes only: it displays all ciphers tested -- not only succeeded ones. SHOW_EACH_C is your friend if you prefer to set this via the shell environ‐ ment. --color \u0026lt;0|1|2|3\u0026gt; determines the use of colors on the screen and in the log file: 2 is the default and makes use of ANSI and termcap escape codes on your terminal. 1 just uses non-colored mark-up like bold, italics, underline, reverse. 0 means no mark-up at all = no escape codes. This is also what you want when you want a log file without any escape codes. 3 will color ciphers and EC according to an internal (not yet perfect) rating. Setting the environment variable COLOR to the value achieves the same result. Please not that OpenBSD and early FreeBSD do not support italics. --colorblind Swaps green and blue colors in the output, so that this percentage of folks (up to 8% of males, see https://en.wikipedia.org/wiki/Color_blindness) can distinguish those findings better. COLORBLIND is the according variable if you want to set this in the environment. --debug \u0026lt;0-6\u0026gt; This gives you additional output on the screen (2-6), only useful for debugging. DEBUG is the according environment variable which you can use. There are six levels (0 is the de‐ fault, thus it has no effect): 1. screen output normal but leaves useful debug output in /tmp/testssl.XXXXXX/ . The info about the exact directory is included in the screen output in the end of the run. 2. lists more what's going on, status (high level) and connection errors, a few general debug output 3. even slightly more info: hexdumps + other info 4. display bytes sent via sockets 5. display bytes received via sockets 6. whole 9 yards FILE OUTPUT OPTIONS --log, --logging Logs stdout also to ${NODE}-p${port}${YYYYMMDD-HHMM}.log in current working directory of the shell. Depending on the color output option (see above) the output file will con‐ tain color and other markup escape codes, unless you specify --color 0 too. cat and -- if properly configured less -- will show the output properly formatted on your terminal. The output shows a banner with the almost the same information as on the screen. In addition it shows the command line of the testssl instance. Please note that the resulting log file is formatted according to the width of your screen while running testssl. You can override the width with the environment variable TERM_WIDTH. --logfile \u0026lt;logfile\u0026gt; or -oL \u0026lt;logfile\u0026gt; Instead of the previous option you may want to use this one if you want to log into a directory or if you rather want to specify the log file name your‐ self. If logfile is a directory the output will put into logfile/${NODE}-p${port}${YYYYMMDD-HHMM}.log. If logfile is a file it will use that file name, an absolute path is also permitted here. LOGFILE is the variable you need to set if you prefer to work environment variables instead. Please note that the resulting log file is formatted according to the width of your screen while running testssl. You can override the width with the environment variable TERM_WIDTH. --json Logs additionally to JSON file ${NODE}-p${port}${YYYYMMDD-HHMM}.json in the current working directory of the shell. The resulting JSON file is opposed to --json-pretty flat -- which means each section is self contained and has an identifier for each single check, the hostname/IP address, the port, severity and the finding. For vulnerabilities it may contain a CVE and CWE entry too. The output doesn't contain a banner or a footer. --jsonfile \u0026lt;jsonfile\u0026gt; or -oj \u0026lt;jsonfile\u0026gt; Instead of the previous option you may want to use this one if you want to log the JSON out put into a directory or if you rather want to specify the log file name yourself. If jsonfile is a directory the output will put into logfile/${NODE}-p${port}${YYYYMMDD-HHMM}.json. If jsonfile is a file it will use that file name, an absolute path is also permitted here. --json-pretty Logs additionally to JSON file ${NODE}-p${port}${YYYYMMDD-HHMM}.json in the current working directory of the shell. The resulting JSON file is opposed to --json non-flat -- which means it is structured. The structure contains a header similar to the banner on the screen, including the command line, scan host, openssl binary used, testssl version and epoch of the start time. Then for every test section of testssl it contains a separate JSON object/section. Each finding has a key/value pair identifier with the identifier for each single check, the severity and the finding. For vulnerabilities it may contain a CVE and CWE entry too. The footer lists the scan time in seconds. --jsonfile-pretty \u0026lt;jsonfile\u0026gt; or -oJ \u0026lt;jsonfile\u0026gt; Similar to the aforementioned --jsonfile or --logfile it logs the output in pretty JSON format (see --json-pretty) into a file or a directory. For further explanation see --jsonfile or --logfile. --csv Logs additionally to a CSV file ${NODE}-p${port}${YYYYMMDD-HHMM}.csv in the current working directory of the shell. The output contains a header with the keys, the values are the same as in the flat JSON format (identifier for each single check, the hostname/IP address, the port, severity, the finding and for vulnerabilities a CVE and CWE number). --csvfile \u0026lt;csvfile\u0026gt; or -oC \u0026lt;csvfile\u0026gt; Similar to the aforementioned --jsonfile or --logfile it logs the output in CSV format (see --cvs) additionally into a file or a directory. For further ex‐ planation see --jsonfile or --logfile. --html Logs additionally to an HTML file ${NODE}-p${port}${YYYYMMDD-HHMM}.html in the current working directory of the shell. It contains a 1:1 output of the console. In former versions there was a non-native option to use \u0026quot;aha\u0026quot; (Ansi HTML Adapter: github.com/theZiz/aha) like testssl [options] \u0026lt;URI\u0026gt; | aha \u0026gt;output.html. This is not necessary anymore. --htmlfile \u0026lt;htmlfile\u0026gt; or -oH \u0026lt;htmlfile\u0026gt; Similar to the aforementioned --jsonfile or --logfile it logs the output in HTML format (see --html) additionally into a file or a directory. For fur‐ ther explanation see --jsonfile or --logfile. -oA \u0026lt;filename\u0026gt; / --outFile \u0026lt;filename\u0026gt; Similar to nmap it does a file output to all available file formats: LOG, JSON pretty, CSV, HTML. If the filename supplied is equal auto the filename is automatically generated using '${NODE}-p${port}${YYYYMMDD-HHMM}.${EXT}' with the according extension. If a directory is provided all output files will put into \u0026lt;file‐ name\u0026gt;/${NODE}-p${port}${YYYYMMDD-HHMM}.{log,json,csv,html}. -oa \u0026lt;filename\u0026gt; / --outfile \u0026lt;filename\u0026gt; Does the same as the previous option but uses flat JSON instead. --hints This option is not in use yet. This option is meant to give hints how to fix a finding or at least a help to improve something. GIVE_HINTS is the environment variable for this. --severity \u0026lt;severity\u0026gt; For CSV and both JSON outputs this will only add findings to the output file if a severity is equal or higher than the severity value specified. Allowed are \u0026lt;LOW|MEDIUM|HIGH|CRITICAL\u0026gt;. WARN is another level which translates to a client-side scanning error or problem. Thus you will always see them in a file if they occur. --append Normally, if an output file already exists and it has a file size greater zero, testssl will prompt you to manually remove the file exit with an error. --append however will append to this file, without a header. The environment variable APPEND does the same. Be careful using this switch/variable. A complementary option which overwrites an existing file doesn't exist per design. --outprefix \u0026lt;fname_prefix\u0026gt; Prepend output filename prefix fname_prefix before ${NODE}-. You can use as well the environment variable FNAME_PREFIX. Using this any output files will be named \u0026lt;fname_prefix\u0026gt;-${NODE}-p${port}${YYYYMMDD-HHMM}.\u0026lt;format\u0026gt; when no file name of the respective output option was specified. If you do not like the separator '-' you can as well supply a \u0026lt;fname_prefix\u0026gt; ending in '.', '_' or ','. In this case or if you already supplied '-' no additional '-' will be appended to \u0026lt;fname_prefix\u0026gt;. A few file output options can also be preset via environment variables. COLOR RATINGS Testssl.sh makes use of (the eight) standard terminal colors. The color scheme is as follows: ○ light red: a critical finding ○ red: a high finding ○ brown: a medium finding ○ yellow: a low finding ○ green (blue if COLORBLIND is set): something which is either in general a good thing or a negative result of a check which otherwise results in a high finding ○ light green (light blue if COLORBLIND is set) : something which is either in general a very good thing or a negative result of a check which otherwise results in a critical finding ○ no color at places where also a finding can be expected: a finding on an info level ○ cyan: currently only used for --show-each or an additional hint ○ magenta: signals a warning condition, e.g. either a local lack of capabilities on the client side or another problem ○ light magenta: a fatal error which either requires strict consent from the user to continue or a condition which leaves no other choice for testssl to quit What is labeled as \u0026quot;light\u0026quot; above appears as such on the screen but is technically speaking \u0026quot;bold\u0026quot;. Besides --color=3 will color ciphers according to an internal and rough rating. Markup (without any color) is used in the following manner: ○ bold: for the name of the test ○ underline + bold: for the headline of each test section ○ underline: for a sub-headline ○ italics: for strings just reflecting a value read from the server TUNING via ENV variables and more options Except the environment variables mentioned above which can replace command line options here a some which cannot be set otherwise. Variables used for tuning are preset with reasonable values. There should be no reason to change them unless you use testssl under special conditions. ○ TERM_WIDTH is a variable which overrides the auto-determined terminal width size. Setting this variable normally only makes sense if you log the output to a file using the --log, --logfile or -oL option. ○ DEBUG_ALLINONE / SETX: when setting one of those to true testssl falls back to the standard bash behavior, i.e. calling bash -x testssl it displays the bash debugging output not in an ex‐ ternal file /tmp/testssl-\u0026lt;XX\u0026gt;.log ○ DEBUGTIME: Profiling option. When using bash's debug mode and when this is set to true, it generates a separate text file with epoch times in /tmp/testssl-\u0026lt;XX\u0026gt;.time. They need to be con‐ catenated by paste /tmp/testssl-\u0026lt;XX\u0026gt;.{time,log} \u0026lt;!-- ○ FAST_SOCKET ○ SHOW_SIGALGO ○ FAST --\u0026gt; ○ EXPERIMENTAL=true is an option which is sometimes used in the development process to make testing easier. In released versions this has no effect. ○ ALL_CLIENTS=true runs a client simulation with all (currently 126) clients when testing HTTP. ○ UNBRACKTD_IPV6: needs to be set to true for some old versions of OpenSSL (like from Gentoo) which don't support [bracketed] IPv6 addresses ○ NO_ENGINE: if you have problems with garbled output containing the word 'engine' you might want to set this to true. It forces testssl not try to configure openssl's engine or a non exist‐ ing one from libressl ○ HEADER_MAXSLEEP: To wait how long before killing the process to retrieve a service banner / HTTP header ○ MAX_WAITSOCK: It instructs testssl to wait until the specified time before declaring a socket connection dead. Don't change this unless you're absolutely sure what you're doing. Value is in seconds. ○ CCS_MAX_WAITSOCK Is the similar to above but applies only to the CCS handshakes, for both of the two the two CCS payload. Don't change this unless you're absolutely sure what you're doing. Value is in seconds. ○ HEARTBLEED_MAX_WAITSOCK Is the similar to MAX_WAITSOCK but applies only to the ServerHello after sending the Heartbleed payload. Don't change this unless you're absolutely sure what you're doing. Value is in seconds. ○ MEASURE_TIME_FILE For seldom cases when you don't want the scan time to be included in the output you can set this to false. ○ STARTTLS_SLEEP is per default set to 10 (seconds). That's the value testssl waits for a string in the STARTTLS handshake before giving up. ○ MAX_PARALLEL is the maximum number of tests to run in parallel in parallel mass testing mode. The default value of 20 may be made larger on systems with faster processors. ○ MAX_WAIT_TEST is the maximum time (in seconds) to wait for a single test in parallel mass testing mode to complete. The default is 1200. ○ USLEEP_SND ○ USLEEP_REC --\u0026gt; ○ HSTS_MIN is preset to 179 (days). If you want warnings sooner or later for HTTP Strict Transport Security you can change this. ○ HPKP_MIN is preset to 30 (days). If you want warnings sooner or later for HTTP Public Key Pinning you can change this ○ DAYS2WARN1 is the first threshold when you'll be warning of a certificate expiration of a host, preset to 60 (days). For Let's Encrypt this value will be divided internally by 2. ○ DAYS2WARN2 is the second threshold when you'll be warning of a certificate expiration of a host, preset to 30 (days). For Let's Encrypt this value will be divided internally by 2. ○ TESTSSL_INSTALL_DIR is the derived installation directory of testssl. Relatively to that the bin and mandatory etc directory will be looked for. ○ CA_BUNDLES_PATH: If you have an own set of CA bundles or you want to point testssl to a specific location of a CA bundle, you can use this variable to set the directory which testssl will use. Please note that it overrides completely the builtin path of testssl which means that you will only test against the bundles you point to. Also you might want to use ~/utils/cre‐ ate_ca_hashes.sh to create the hashes for HPKP. ○ MAX_SOCKET_FAIL: A number which tells testssl how often a TCP socket connection may fail before the program gives up and terminates. The default is 2. You can increase it to a higher value if you frequently see a message like Fatal error: repeated openssl s_client connect problem, doesn't make sense to continue. ○ MAX_OSSL_FAIL: A number which tells testssl how often an OpenSSL s_client connect may fail before the program gives up and terminates. The default is 2. You can increase it to a higher value if you frequently see a message like Fatal error: repeated TCP connect problems, giving up. ○ MAX_HEADER_FAIL: A number which tells testssl how often a HTTP GET request over OpenSSL may return an empty file before the program gives up and terminates. The default is 3. Also here you can increase the threshold when you spot messages like Fatal error: repeated HTTP header connect problems, doesn't make sense to continue. EXAMPLES testssl testssl does a default run on https://testssl (protocols, standard cipher lists, PFS, server preferences, server defaults, vulnerabilities, testing all known 370 ciphers, client simulation. testssl testssl.net:443 does the same default run as above with the subtle difference that testssl.net has two IPv4 addresses. Both are tested. testssl --ip=one --wide https://testssl.net:443 does the same checks as above, with the difference that one IP address is being picked randomly. Displayed is everything where possible in wide format. testssl -6 https://testssl.net As opposed to the first example it also tests the IPv6 part -- supposed you have an IPv6 network and your openssl supports IPv6 (see above). testssl -t smtp smtp.gmail.com:25 Checks are done via a STARTTLS handshake on the plain text port 25. It checks every IP on smtp.gmail.com. testssl --starttls=imap imap.gmx.net:143 does the same on the plain text IMAP port. Please note that for plain TLS-encrypted ports you must not specify the protocol option when no STARTTLS handshake is offered: testssl smtp.gmail.com:465 just checks the encryption on the SMTPS port, testssl imap.gmx.net:993 on the IMAPS port. Also MongoDB which provides TLS support without STARTTLS can be tested directly. RFCs and other standards ○ RFC 2246: The TLS Protocol Version 1.0 ○ RFC 2818: HTTP Over TLS ○ RFC 2595: Using TLS with IMAP, POP3 and ACAP ○ RFC 3207: SMTP Service Extension for Secure SMTP over Transport Layer Security ○ RFC 3501: INTERNET MESSAGE ACCESS PROTOCOL - VERSION 4rev1 ○ RFC 4346: The Transport Layer Security (TLS) Protocol Version 1.1 ○ RFC 4366: Transport Layer Security (TLS) Extensions ○ RFC 4492: Elliptic Curve Cryptography (ECC) Cipher Suites for Transport Layer Security (TLS) ○ RFC 5077: Transport Layer Security (TLS) Session Resumption ○ RFC 5246: The Transport Layer Security (TLS) Protocol Version 1.2 ○ RFC 5280: Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile ○ RFC 5321: Simple Mail Transfer Protocol ○ RFC 5746: Transport Layer Security (TLS) Renegotiation Indication Extension ○ RFC 6066: Transport Layer Security (TLS) Extensions: Extension Definitions ○ RFC 6101: The Secure Sockets Layer (SSL) Protocol Version 3.0 ○ RFC 6120: Extensible Messaging and Presence Protocol (XMPP): Core ○ RFC 6125: Domain-Based Application Service Identity [..] ○ RFC 6797: HTTP Strict Transport Security (HSTS) ○ RFC 6961: The Transport Layer Security (TLS) Multiple Certificate Status Request Extension ○ RFC 7469: Public Key Pinning Extension for HTTP (HPKP) ○ RFC 7507: TLS Fallback Signaling Cipher Suite Value (SCSV) for Preventing Protocol Downgrade Attacks ○ RFC 7627: Transport Layer Security (TLS) Session Hash and Extended Master Secret Extension ○ RFC 7633: X.509v3 Transport Layer Security (TLS) Feature Extension ○ RFC 7465: Prohibiting RC4 Cipher Suites ○ RFC 7685: A Transport Layer Security (TLS) ClientHello Padding Extension ○ RFC 7905: ChaCha20-Poly1305 Cipher Suites for Transport Layer Security (TLS) ○ RFC 7919: Negotiated Finite Field Diffie-Hellman Ephemeral Parameters for Transport Layer Security ○ RFC 8143: Using Transport Layer Security (TLS) with Network News Transfer Protocol (NNTP) ○ RFC 8446: The Transport Layer Security (TLS) Protocol Version 1.3 ○ W3C CSP: Content Security Policy Level 1-3 ○ TLSWG Draft: The Transport Layer Security (TLS) Protocol Version 1.3 EXIT STATUS ○ 0 testssl finished successfully without errors and without ambiguous results ○ 1 testssl has encountered exactly one ambiguous situation or an error during run ○ 1+n same as previous. The errors or ambiguous results are added, also per IP. ○ 50-200 reserved for returning a vulnerability scoring for system monitoring or a CI tools ○ 242 (ERR_CHILD) Child received a signal from master ○ 244 (ERR_RESOURCE) Resources testssl needs couldn't be read ○ 245 (ERR_CLUELESS) Weird state, either though user options or testssl ○ 246 (ERR_CONNECT) Connectivity problem ○ 247 (ERR_DNSLOOKUP) Problem with resolving IP addresses or names ○ 248 (ERR_OTHERCLIENT) Other client problem ○ 249 (ERR_DNSBIN) Problem with DNS lookup binaries ○ 250 (ERR_OSSLBIN) Problem with OpenSSL binary ○ 251 (ERR_NOSUPPORT) Feature requested is not supported ○ 252 (ERR_FNAMEPARSE) Input file couldn't be parsed ○ 253 (ERR_FCREATE) Output file couldn't be created ○ 254 (ERR_CMDLINE) Cmd line couldn't be parsed ○ 255 (ERR_BASH) Bash version incorrect FILES etc/*pem are the certificate stores from Apple, Linux, Mozilla Firefox, Windows and Java. etc/client-simulation.txt contains client simulation data. etc/cipher-mapping.txt provides a mandatory file with mapping from OpenSSL cipher suites names to the ones from IANA / used in the RFCs. etc/tls_data.txt provides a mandatory file for ciphers (bash sockets) and key material. AUTHORS Developed by Dirk Wetter, David Cooper and many others, see CREDITS.md . COPYRIGHT Copyright © 2012 Dirk Wetter. License GPLv2: Free Software Foundation, Inc. This is free software: you are free to change and redistribute it under the terms of the license, see LICENSE. Attribution is important for the future of this project - also in the internet. Thus if you're offering a scanner based on testssl.sh as a public and/or paid service in the internet you are strongly encouraged to mention to your audience that you're using this program and where to get this program from. That helps us to get bugfixes, other feedback and more contributions. Usage WITHOUT ANY WARRANTY. USE at your OWN RISK! LIMITATION All native Windows platforms emulating Linux are known to be slow. BUGS Probably. Current known ones and interface for filing new ones: https://testssl.sh/bugs/ . SEE ALSO ciphers(1), openssl(1), s_client(1), x509(1), verify(1), ocsp(1), crl(1), bash(1) and the websites https://testssl.sh/ and https://github.com/drwetter/testssl.sh/ . August 2022 TESTSSL(1) ```bash "}),e.add({id:48,href:"/docs/tools/know/zmap/",title:"Zmap",description:`ZMap is a fast single-packet network scanner optimized for Internet-wide network surveys. On a computer with a gigabit connection, ZMap can scan the entire public IPv4 address space on a single port in under 45 minutes. With a 10gigE connection and PF_RING, ZMap can scan the IPv4 address space in 5 minutes.
brew install # brew install zmap sample usage # sudo zmap -p 22 69.52.0.0/16 -o output.app sample output # 69.`,content:"ZMap is a fast single-packet network scanner optimized for Internet-wide network surveys. On a computer with a gigabit connection, ZMap can scan the entire public IPv4 address space on a single port in under 45 minutes. With a 10gigE connection and PF_RING, ZMap can scan the IPv4 address space in 5 minutes.\nbrew install # brew install zmap sample usage # sudo zmap -p 22 69.52.0.0/16 -o output.app sample output # 69.52.32.195 repeat the above command with different ports to scan for different services\nsudo zmap -p 21 69.52.0.0/16 -o output.app sample output # 69.52.32.195 conclusion # This might be a firewall, the same ip behind multiple ports, or a honeypot.\nhelp # ZMAP(1) zmap ZMAP(1) NAME zmap - The Fast Internet Scanner SYNOPSIS zmap [ -p \u0026lt;port\u0026gt; ] [ -o \u0026lt;outfile\u0026gt; ] [ OPTIONS... ] [ ip/hostname/range ] DESCRIPTION ZMap is a network tool for scanning the entire Internet (or large samples). ZMap is capable of scanning the entire Internet in around 45 minutes on a gigabit network connection, reaching ~98% theoretical line speed. OPTIONS BASIC OPTIONS ip/hostname/range IP addresses or DNS hostnames to scan. Accepts IP ranges in CIDR block notation. Defaults to 0.0.0/8 -p, --target-port=port TCP or UDP port number to scan (for SYN scans and basic UDP scans) -o, --output-file=name When using an output module that uses a file, write results to this file. Use - for stdout. -b, --blacklist-file=path File of subnets to exclude, in CIDR notation, one-per line. It is recommended you use this to exclude RFC 1918 addresses, multicast, IANA reserved space, and other IANA special-purpose addresses. An example blacklist file blacklist.conf for this purpose. SCAN OPTIONS -n, --max-targets=n Cap the number of targets to probe. This can either be a number (e.g. -n 1000) or a percentage (e.g. -n 0.1%) of the scannable address space (after excluding blacklist) -N, --max-results=n Exit after receiving this many results -t, --max-runtime=secs Cap the length of time for sending packets -r, --rate=pps Set the send rate in packets/sec -B, --bandwidth=bps Set the send rate in bits/second (supports suffixes G, M, and K (e.g. -B 10M for 10 mbps). Thi s overrides the --rate flag. -c, --cooldown-time=secs How long to continue receiving after sending has completed (default=8) -e, --seed=n Seed used to select address permutation. Use this if you want to scan addresses in the same order for multiple ZMap runs. --shards=N Split the scan up into N shards/partitions among different instances of zmap (default=1). When sharding, --seed is required. --shard=n Set which shard to scan (default=0). Shards are 0-indexed in the range [0, N), where N is the total number of shards. When sharding --seed is required. -T, --sender-threads=n Threads used to send packets. ZMap will attempt to detect the optimal number of send threads based on the number of processor cores. -P, --probes=n Number of probes to send to each IP (default=1) -d, --dryrun Print out each packet to stdout instead of sending it (useful for debugging) NETWORK OPTIONS -s, --source-port=port|range Source port(s) to send packets from -S, --source-ip=ip|range Source address(es) to send packets from. Either single IP or range (e.g. 10.0.0.1-10.0.0.9) -G, --gateway-mac=addr Gateway MAC address to send packets to (in case auto-detection does not work) -i, --interface=name Network interface to use PROBE OPTIONS ZMap allows users to specify and write their own probe modules. Probe modules are responsible for generating probe packets to send, and processing responses from hosts. --list-probe-modules List available probe modules (e.g. tcp_synscan) -M, --probe-module=name Select probe module (default=tcp_synscan) --probe-args=args Arguments to pass to probe module --list-output-fields List the fields the selected probe module can send to the output module OUTPUT OPTIONS ZMap allows users to specify and write their own output modules for use with ZMap. Output modules are responsible for processing the fieldsets returned by the probe module, and outputing them to the user. Users can specify output fields, and write filters over the output fields. --list-output-modules List available output modules (e.g. tcp_synscan) -O, --output-module=name Select output module (default=csv) --output-args=args Arguments to pass to output module -f, --output-fields=fields Comma-separated list of fields to output --output-filter Specify an output filter over the fields defined by the probe module. See the output filter section for more details. ADDITIONAL OPTIONS -C, --config=filename Read a configuration file, which can specify any other options. -q, --quiet Do not print status updates once per second -g, --summary Print configuration and summary of results at the end of the scan -v, --verbosity=n Level of log detail (0-5, default=3) -h, --help Print help and exit -V, --version Print version and exit UDP PROBE MODULE OPTIONS These arguments are all passed using the --probe-args=args option. Only one argument may be passed at a time. file:/path/to/file Path to payload file to send to each host over UDP. template:/path/to/template Path to template file. For each destination host, the template file is populated, set as the UDP payload, and sent. text:\u0026lt;text\u0026gt; ASCII text to send to each destination host hex:\u0026lt;hex\u0026gt; Hex-encoded binary to send to each destination host template-fields Print information about the allowed template fields and exit. OUPUT FILTERS Results generated by a probe module can be filtered before being passed to the output module. Filters are defined over the output fields of a probe module. Filters are written in a simple fil‐ tering language, similar to SQL, and are passed to ZMap using the --output-filter option. Output filters are commonly used to filter out duplicate results, or to only pass only sucessful re‐ sponses to the output module. Filter expressions are of the form \u0026lt;fieldname\u0026gt; \u0026lt;operation\u0026gt; \u0026lt;value\u0026gt;. The type of \u0026lt;value\u0026gt; must be either a string or unsigned integer literal, and match the type of \u0026lt;fieldname\u0026gt;. The valid opera‐ tions for integer comparisons are = !=, ,, =,=. The operations for string comparisons are =, !=. The --list-output-fields flag will print what fields and types are available for the selected probe module, and then exit. Compound filter expressions may be constructed by combining filter expressions using parenthesis to specify order of operations, the \u0026amp;\u0026amp; (logical AND) and || (logical OR) operators. For example, a filter for only successful, non-duplicate responses would be written as: --output-filter=\u0026quot;success = 1 \u0026amp;\u0026amp; repeat = 0\u0026quot; zmap v2.1.1 September 2015 ZMAP(1) ```bash "}),e.add({id:49,href:"/docs/tools/know/smap/",title:"Smap",description:`Description # smap is a fast and multi-purpose subdomain enumeration tool. It supports multiple sources, user supplied resolvers, DNS wildcard filtering like shuffledns etc.
install # brew install smap sample usage # smap 69.52.32.195 sample output # Starting Nmap 9.99 ( https://nmap.org ) at 2023-02-14 23:28 CET Nmap scan report for filetransfer.blackrock.com (69.52.32.195) Host is up. PORT STATE SERVICE VERSION 21/tcp open ftp? 22/tcp open ssh? 80/tcp open http? 443/tcp open https?`,content:"Description # smap is a fast and multi-purpose subdomain enumeration tool. It supports multiple sources, user supplied resolvers, DNS wildcard filtering like shuffledns etc.\ninstall # brew install smap sample usage # smap 69.52.32.195 sample output # Starting Nmap 9.99 ( https://nmap.org ) at 2023-02-14 23:28 CET Nmap scan report for filetransfer.blackrock.com (69.52.32.195) Host is up. PORT STATE SERVICE VERSION 21/tcp open ftp? 22/tcp open ssh? 80/tcp open http? 443/tcp open https? Nmap done: 1 IP address (1 host up) scanned in 0.45 seconds webpage # https://github.com/s0md3v/Smap\nhelp # Smap 0.1.12 Usage: smap \u0026lt;targets here\u0026gt; TARGET SPECIFICATION: Valid targets are hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1 -iL \u0026lt;filename\u0026gt;: Input from list of hosts/networks. Use - as filename to use stdin input. OUTPUT: Specify a file to write the output or use - as filename to write it to stdout (terminal). Ex: -oX \u0026lt;filename\u0026gt; -oX XML -oG Greppable -oN Nmap -oA All 3 above -oJ JSON -oS Smap format -oP ip:port pairs ```bash "}),e.add({id:50,href:"/docs/tools/know/tcpdump/",title:"Tcpdump",description:`tcpdump # description # tcpdump is a tool for capturing and displaying network traffic. It is written in C and uses libpcap for packet capture. It is available for Windows, Linux and Mac OS X. It is licensed under the BSD license.
install # brew install tcpdump help # TCPDUMP(8) System Manager's Manual TCPDUMP(8) NAME tcpdump - dump traffic on a network SYNOPSIS tcpdump [ -AbdDefhHIJKlLnNOpqStuUvxX# ] [ -B buffer_size ] [ -c count ] [ --count ] [ -C file_size ] [ -E spi@ipaddr algo:secret,.`,content:"tcpdump # description # tcpdump is a tool for capturing and displaying network traffic. It is written in C and uses libpcap for packet capture. It is available for Windows, Linux and Mac OS X. It is licensed under the BSD license.\ninstall # brew install tcpdump help # TCPDUMP(8) System Manager's Manual TCPDUMP(8) NAME tcpdump - dump traffic on a network SYNOPSIS tcpdump [ -AbdDefhHIJKlLnNOpqStuUvxX# ] [ -B buffer_size ] [ -c count ] [ --count ] [ -C file_size ] [ -E spi@ipaddr algo:secret,... ] [ -F file ] [ -G rotate_seconds ] [ -i interface ] [ --immediate-mode ] [ -j tstamp_type ] [ -m module ] [ -M secret ] [ --number ] [ --print ] [ -Q in|out|inout ] [ -r file ] [ -s snaplen ] [ -T type ] [ --version ] [ -V file ] [ -w file ] [ -W filecount ] [ -y datalinktype ] [ -z postrotate-command ] [ -Z user ] [ --time-stamp-precision=tstamp_precision ] [ --micro ] [ --nano ] [ expression ] DESCRIPTION Tcpdump prints out a description of the contents of packets on a network interface that match the Boolean expression; the description is preceded by a time stamp, printed, by default, as hours, minutes, seconds, and fractions of a second since midnight. It can also be run with the -w flag, which causes it to save the packet data to a file for later analysis, and/or with the -r flag, which causes it to read from a saved packet file rather than to read packets from a network interface. It can also be run with the -V flag, which causes it to read a list of saved packet files. In all cases, only packets that match expression will be processed by tcpdump. Tcpdump will, if not run with the -c flag, continue capturing packets until it is interrupted by a SIGINT signal (generated, for example, by typing your interrupt character, typically control- C) or a SIGTERM signal (typically generated with the kill(1) command); if run with the -c flag, it will capture packets until it is interrupted by a SIGINT or SIGTERM signal or the specified number of packets have been processed. When tcpdump finishes capturing packets, it will report counts of: packets ``captured'' (this is the number of packets that tcpdump has received and processed); packets ``received by filter'' (the meaning of this depends on the OS on which you're running tcpdump, and possibly on the way the OS was configured - if a filter was specified on the command line, on some OSes it counts packets regardless of whether they were matched by the filter expression and, even if they were matched by the filter expression, regardless of whether tcpdump has read and processed them yet, on other OSes it counts only packets that were matched by the filter expression regardless of whether tcpdump has read and processed them yet, and on other OSes it counts only packets that were matched by the filter expression and were processed by tcpdump); packets ``dropped by kernel'' (this is the number of packets that were dropped, due to a lack of buffer space, by the packet capture mechanism in the OS on which tcpdump is running, if the OS reports that information to applications; if not, it will be reported as 0). On platforms that support the SIGINFO signal, such as most BSDs (including macOS) and Digital/Tru64 UNIX, it will report those counts when it receives a SIGINFO signal (generated, for example, by typing your ``status'' character, typically control-T, although on some platforms, such as macOS, the ``status'' character is not set by default, so you must set it with stty(1) in order to use it) and will continue capturing packets. On platforms that do not support the SIGINFO signal, the same can be achieved by using the SIGUSR1 signal. Using the SIGUSR2 signal along with the -w flag will forcibly flush the packet buffer into the output file. Reading packets from a network interface may require that you have special privileges; see the pcap(3PCAP) help for details. Reading a saved packet file doesn't require special privi‐ leges. OPTIONS -A Print each packet (minus its link level header) in ASCII. Handy for capturing web pages. -b Print the AS number in BGP packets in ASDOT notation rather than ASPLAIN notation. -B buffer_size --buffer-size=buffer_size Set the operating system capture buffer size to buffer_size, in units of KiB (1024 bytes). -c count Exit after receiving count packets. --count Print only on stderr the packet count when reading capture file(s) instead of parsing/printing the packets. If a filter is specified on the command line, tcpdump counts only packets that were matched by the filter expression. -C file_size Before writing a raw packet to a savefile, check whether the file is currently larger than file_size and, if so, close the current savefile and open a new one. Savefiles after the first savefile will have the name specified with the -w flag, with a number after it, starting at 1 and continuing upward. The units of file_size are millions of bytes (1,000,000 bytes, not 1,048,576 bytes). Note that when used with -Z option (enabled by default), privileges are dropped before opening the first savefile. -d Dump the compiled packet-matching code in a human readable form to standard output and stop. Please mind that although code compilation is always DLT-specific, typically it is impossible (and unnecessary) to specify which DLT to use for the dump because tcpdump uses either the DLT of the input pcap file specified with -r, or the default DLT of the network interface specified with -i, or the particular DLT of the network interface specified with -y and -i re‐ spectively. In these cases the dump shows the same exact code that would filter the input file or the network interface without -d. However, when neither -r nor -i is specified, specifying -d prevents tcpdump from guessing a suitable network interface (see -i). In this case the DLT defaults to EN10MB and can be set to another valid value manually with -y. -dd Dump packet-matching code as a C program fragment. -ddd Dump packet-matching code as decimal numbers (preceded with a count). -D --list-interfaces Print the list of the network interfaces available on the system and on which tcpdump can capture packets. For each network interface, a number and an interface name, possibly followed by a text description of the interface, are printed. The interface name or the number can be supplied to the -i flag to specify an interface on which to capture. This can be useful on systems that don't have a command to list them (e.g., Windows systems, or UNIX systems lacking ifconfig -a); the number can be useful on Windows 2000 and later systems, where the interface name is a somewhat complex string. The -D flag will not be supported if tcpdump was built with an older version of libpcap that lacks the pcap_findalldevs(3PCAP) function. -e Print the link-level header on each dump line. This can be used, for example, to print MAC layer addresses for protocols such as Ethernet and IEEE 802.11. -E Use spi@ipaddr algo:secret for decrypting IPsec ESP packets that are addressed to addr and contain Security Parameter Index value spi. This combination may be repeated with comma or newline separation. Note that setting the secret for IPv4 ESP packets is supported at this time. Algorithms may be des-cbc, 3des-cbc, blowfish-cbc, rc3-cbc, cast128-cbc, or none. The default is des-cbc. The ability to decrypt packets is only present if tcpdump was compiled with cryptography enabled. secret is the ASCII text for ESP secret key. If preceded by 0x, then a hex value will be read. The option assumes RFC2406 ESP, not RFC1827 ESP. The option is only for debugging purposes, and the use of this option with a true `secret' key is discouraged. By presenting IPsec se‐ cret key onto command line you make it visible to others, via ps(1) and other occasions. In addition to the above syntax, the syntax file name may be used to have tcpdump read the provided file in. The file is opened upon receiving the first ESP packet, so any special per‐ missions that tcpdump may have been given should already have been given up. -f Print `foreign' IPv4 addresses numerically rather than symbolically (this option is intended to get around serious brain damage in Sun's NIS server — usually it hangs forever translat‐ ing non-local internet numbers). The test for `foreign' IPv4 addresses is done using the IPv4 address and netmask of the interface on which capture is being done. If that address or netmask are not available, avail‐ able, either because the interface on which capture is being done has no address or netmask or because the capture is being done on the Linux \u0026quot;any\u0026quot; interface, which can capture on more than one interface, this option will not work correctly. -F file Use file as input for the filter expression. An additional expression given on the command line is ignored. -G rotate_seconds If specified, rotates the dump file specified with the -w option every rotate_seconds seconds. Savefiles will have the name specified by -w which should include a time format as de‐ fined by strftime(3). If no time format is specified, each new file will overwrite the previous. Whenever a generated filename is not unique, tcpdump will overwrite the pre-existing data; providing a time specification that is coarser than the capture period is therefore not advised. If used in conjunction with the -C option, filenames will take the form of `file\u0026lt;count\u0026gt;'. Note that when used with -Z option (enabled by default), privileges are dropped before opening the first savefile. -h --help Print the tcpdump and libpcap version strings, print a usage message, and exit. --version Print the tcpdump and libpcap version strings and exit. -H Attempt to detect 802.11s draft mesh headers. -i interface --interface=interface Listen, report the list of link-layer types, report the list of time stamp types, or report the results of compiling a filter expression on interface. If unspecified and if the -d flag is not given, tcpdump searches the system interface list for the lowest numbered, configured up interface (excluding loopback), which may turn out to be, for example, ``eth0''. On Linux systems with 2.2 or later kernels, an interface argument of ``any'' can be used to capture packets from all interfaces. Note that captures on the ``any'' device will not be done in promiscuous mode. If the -D flag is supported, an interface number as printed by that flag can be used as the interface argument, if no interface on the system has that number as a name. -I --monitor-mode Put the interface in \u0026quot;monitor mode\u0026quot;; this is supported only on IEEE 802.11 Wi-Fi interfaces, and supported only on some operating systems. Note that in monitor mode the adapter might disassociate from the network with which it's associated, so that you will not be able to use any wireless networks with that adapter. This could prevent accessing files on a network server, or resolving host names or network addresses, if you are capturing in monitor mode and are not connected to another network with an‐ other adapter. This flag will affect the output of the -L flag. If -I isn't specified, only those link-layer types available when not in monitor mode will be shown; if -I is specified, only those link-layer types available when in monitor mode will be shown. --immediate-mode Capture in \u0026quot;immediate mode\u0026quot;. In this mode, packets are delivered to tcpdump as soon as they arrive, rather than being buffered for efficiency. This is the default when printing pack‐ ets rather than saving packets to a ``savefile'' if the packets are being printed to a terminal rather than to a file or pipe. -j tstamp_type --time-stamp-type=tstamp_type Set the time stamp type for the capture to tstamp_type. The names to use for the time stamp types are given in pcap-tstamp(7); not all the types listed there will necessarily be valid for any given interface. -J --list-time-stamp-types List the supported time stamp types for the interface and exit. If the time stamp type cannot be set for the interface, no time stamp types are listed. --time-stamp-precision=tstamp_precision When capturing, set the time stamp precision for the capture to tstamp_precision. Note that availability of high precision time stamps (nanoseconds) and their actual accuracy is plat‐ form and hardware dependent. Also note that when writing captures made with nanosecond accuracy to a savefile, the time stamps are written with nanosecond resolution, and the file is written with a different magic number, to indicate that the time stamps are in seconds and nanoseconds; not all programs that read pcap savefiles will be able to read those captures. When reading a savefile, convert time stamps to the precision specified by timestamp_precision, and display them with that resolution. If the precision specified is less than the pre‐ cision of time stamps in the file, the conversion will lose precision. The supported values for timestamp_precision are micro for microsecond resolution and nano for nanosecond resolution. The default is microsecond resolution. --micro --nano Shorthands for --time-stamp-precision=micro or --time-stamp-precision=nano, adjusting the time stamp precision accordingly. When reading packets from a savefile, using --micro trun‐ cates time stamps if the savefile was created with nanosecond precision. In contrast, a savefile created with microsecond precision will have trailing zeroes added to the time stamp when --nano is used. -K --dont-verify-checksums Don't attempt to verify IP, TCP, or UDP checksums. This is useful for interfaces that perform some or all of those checksum calculation in hardware; otherwise, all outgoing TCP check‐ sums will be flagged as bad. -l Make stdout line buffered. Useful if you want to see the data while capturing it. E.g., tcpdump -l | tee dat or tcpdump -l \u0026gt; dat \u0026amp; tail -f dat Note that on Windows,``line buffered'' means ``unbuffered'', so that WinDump will write each character individually if -l is specified. -U is similar to -l in its behavior, but it will cause output to be ``packet-buffered'', so that the output is written to stdout at the end of each packet rather than at the end of each line; this is buffered on all platforms, including Windows. -L --list-data-link-types List the known data link types for the interface, in the specified mode, and exit. The list of known data link types may be dependent on the specified mode; for example, on some plat‐ forms, a Wi-Fi interface might support one set of data link types when not in monitor mode (for example, it might support only fake Ethernet headers, or might support 802.11 headers but not support 802.11 headers with radio information) and another set of data link types when in monitor mode (for example, it might support 802.11 headers, or 802.11 headers with radio information, only in monitor mode). -m module Load SMI MIB module definitions from file module. This option can be used several times to load several MIB modules into tcpdump. -M secret Use secret as a shared secret for validating the digests found in TCP segments with the TCP-MD5 option (RFC 2385), if present. -n Don't convert host addresses to names. This can be used to avoid DNS lookups. -nn Don't convert protocol and port numbers etc. to names either. -N Don't print domain name qualification of host names. E.g., if you give this flag then tcpdump will print ``nic'' instead of ``nic.ddn.mil''. -# --number Print an optional packet number at the beginning of the line. -O --no-optimize Do not run the packet-matching code optimizer. This is useful only if you suspect a bug in the optimizer. -p --no-promiscuous-mode Don't put the interface into promiscuous mode. Note that the interface might be in promiscuous mode for some other reason; hence, `-p' cannot be used as an abbreviation for `ether host {local-hw-addr} or ether broadcast'. --print Print parsed packet output, even if the raw packets are being saved to a file with the -w flag. -Q direction --direction=direction Choose send/receive direction direction for which packets should be captured. Possible values are `in', `out' and `inout'. Not available on all platforms. -q Quick (quiet?) output. Print less protocol information so output lines are shorter. -r file Read packets from file (which was created with the -w option or by other tools that write pcap or pcapng files). Standard input is used if file is ``-''. -S --absolute-tcp-sequence-numbers Print absolute, rather than relative, TCP sequence numbers. -s snaplen --snapshot-length=snaplen Snarf snaplen bytes of data from each packet rather than the default of 262144 bytes. Packets truncated because of a limited snapshot are indicated in the output with ``[|proto]'', where proto is the name of the protocol level at which the truncation has occurred. Note that taking larger snapshots both increases the amount of time it takes to process packets and, effectively, decreases the amount of packet buffering. This may cause packets to be lost. Note also that taking smaller snapshots will discard data from protocols above the transport layer, which loses information that may be important. NFS and AFS requests and replies, for example, are very large, and much of the detail won't be available if a too-short snapshot length is selected. If you need to reduce the snapshot size below the default, you should limit snaplen to the smallest number that will capture the protocol information you're interested in. Setting snaplen to 0 sets it to the default of 262144, for backwards compatibility with recent older versions of tcpdump. -T type Force packets selected by \u0026quot;expression\u0026quot; to be interpreted the specified type. Currently known types are aodv (Ad-hoc On-demand Distance Vector protocol), carp (Common Address Redundancy Protocol), cnfp (Cisco NetFlow protocol), domain (Domain Name System), lmp (Link Management Protocol), pgm (Pragmatic General Multicast), pgm_zmtp1 (ZMTP/1.0 inside PGM/EPGM), ptp (Pre‐ cision Time Protocol), radius (RADIUS), resp (REdis Serialization Protocol), rpc (Remote Procedure Call), rtcp (Real-Time Applications control protocol), rtp (Real-Time Applications protocol), snmp (Simple Network Management Protocol), someip (SOME/IP), tftp (Trivial File Transfer Protocol), vat (Visual Audio Tool), vxlan (Virtual eXtensible Local Area Network), wb (distributed White Board) and zmtp1 (ZeroMQ Message Transport Protocol 1.0). Note that the pgm type above affects UDP interpretation only, the native PGM is always recognised as IP protocol 113 regardless. UDP-encapsulated PGM is often called \u0026quot;EPGM\u0026quot; or \u0026quot;PGM/UDP\u0026quot;. Note that the pgm_zmtp1 type above affects interpretation of both native PGM and UDP at once. During the native PGM decoding the application data of an ODATA/RDATA packet would be de‐ coded as a ZeroMQ datagram with ZMTP/1.0 frames. During the UDP decoding in addition to that any UDP packet would be treated as an encapsulated PGM packet. -t Don't print a timestamp on each dump line. -tt Print the timestamp, as seconds since January 1, 1970, 00:00:00, UTC, and fractions of a second since that time, on each dump line. -ttt Print a delta (microsecond or nanosecond resolution depending on the --time-stamp-precision option) between current and previous line on each dump line. The default is microsecond res‐ olution. -tttt Print a timestamp, as hours, minutes, seconds, and fractions of a second since midnight, preceded by the date, on each dump line. -ttttt Print a delta (microsecond or nanosecond resolution depending on the --time-stamp-precision option) between current and first line on each dump line. The default is microsecond resolu‐ tion. -u Print undecoded NFS handles. -U --packet-buffered If the -w option is not specified, or if it is specified but the --print flag is also specified, make the printed packet output ``packet-buffered''; i.e., as the description of the con‐ tents of each packet is printed, it will be written to the standard output, rather than, when not writing to a terminal, being written only when the output buffer fills. If the -w option is specified, make the saved raw packet output ``packet-buffered''; i.e., as each packet is saved, it will be written to the output file, rather than being written only when the output buffer fills. The -U flag will not be supported if tcpdump was built with an older version of libpcap that lacks the pcap_dump_flush(3PCAP) function. -v When parsing and printing, produce (slightly more) verbose output. For example, the time to live, identification, total length and options in an IP packet are printed. Also enables additional packet integrity checks such as verifying the IP and ICMP header checksum. When writing to a file with the -w option and at the same time not reading from a file with the -r option, report to stderr, once per second, the number of packets captured. In Solaris, FreeBSD and possibly other operating systems this periodic update currently can cause loss of captured packets on their way from the kernel to tcpdump. -vv Even more verbose output. For example, additional fields are printed from NFS reply packets, and SMB packets are fully decoded. -vvv Even more verbose output. For example, telnet SB ... SE options are printed in full. With -X Telnet options are printed in hex as well. -V file Read a list of filenames from file. Standard input is used if file is ``-''. -w file Write the raw packets to file rather than parsing and printing them out. They can later be printed with the -r option. Standard output is used if file is ``-''. This output will be buffered if written to a file or pipe, so a program reading from the file or pipe may not see packets for an arbitrary amount of time after they are received. Use the -U flag to cause packets to be written as soon as they are received. The MIME type application/vnd.tcpdump.pcap has been registered with IANA for pcap files. The filename extension .pcap appears to be the most commonly used along with .cap and .dmp. Tcp‐ dump itself doesn't check the extension when reading capture files and doesn't add an extension when writing them (it uses magic numbers in the file header instead). However, many oper‐ ating systems and applications will use the extension if it is present and adding one (e.g. .pcap) is recommended. See pcap-savefile(5) for a description of the file format. -W filecount Used in conjunction with the -C option, this will limit the number of files created to the specified number, and begin overwriting files from the beginning, thus creating a 'rotating' buffer. In addition, it will name the files with enough leading 0s to support the maximum number of files, allowing them to sort correctly. Used in conjunction with the -G option, this will limit the number of rotated dump files that get created, exiting with status 0 when reaching the limit. If used in conjunction with both -C and -G, the -W option will currently be ignored, and will only affect the file name. -x When parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex. The smaller of the entire packet or snaplen bytes will be printed. Note that this is the entire link-layer packet, so for link layers that pad (e.g. Ethernet), the padding bytes will also be printed when the higher layer packet is shorter than the required padding. In the current implementation this flag may have the same effect as -xx if the packet is truncated. -xx When parsing and printing, in addition to printing the headers of each packet, print the data of each packet, including its link level header, in hex. -X When parsing and printing, in addition to printing the headers of each packet, print the data of each packet (minus its link level header) in hex and ASCII. This is very handy for analysing new protocols. In the current implementation this flag may have the same effect as -XX if the packet is truncated. -XX When parsing and printing, in addition to printing the headers of each packet, print the data of each packet, including its link level header, in hex and ASCII. -y datalinktype --linktype=datalinktype Set the data link type to use while capturing packets (see -L) or just compiling and dumping packet-matching code (see -d) to datalinktype. -z postrotate-command Used in conjunction with the -C or -G options, this will make tcpdump run \u0026quot; postrotate-command file \u0026quot; where file is the savefile being closed after each rotation. For example, specify‐ ing -z gzip or -z bzip2 will compress each savefile using gzip or bzip2. Note that tcpdump will run the command in parallel to the capture, using the lowest priority so that this doesn't disturb the capture process. And in case you would like to use a command that itself takes flags or different arguments, you can always write a shell script that will take the savefile name as the only argument, make the flags \u0026amp; arguments arrangements and execute the command that you want. -Z user --relinquish-privileges=user If tcpdump is running as root, after opening the capture device or input savefile, but before opening any savefiles for output, change the user ID to user and the group ID to the pri‐ mary group of user. This behavior is enabled by default (-Z tcpdump), and can be disabled by -Z root. expression selects which packets will be dumped. If no expression is given, all packets on the net will be dumped. Otherwise, only packets for which expression is `true' will be dumped. For the expression syntax, see pcap-filter(7). The expression argument can be passed to tcpdump as either a single Shell argument, or as multiple Shell arguments, whichever is more convenient. Generally, if the expression contains Shell metacharacters, such as backslashes used to escape protocol names, it is easier to pass it as a single, quoted argument rather than to escape the Shell metacharacters. Multiple arguments are concatenated with spaces before being parsed. EXAMPLES To print all packets arriving at or departing from sundown: tcpdump host sundown To print traffic between helios and either hot or ace: tcpdump host helios and \\( hot or ace \\) To print all IP packets between ace and any host except helios: tcpdump ip host ace and not helios To print all traffic between local hosts and hosts at Berkeley: tcpdump net ucb-ether To print all ftp traffic through internet gateway snup: (note that the expression is quoted to prevent the shell from (mis-)interpreting the parentheses): tcpdump 'gateway snup and (port ftp or ftp-data)' To print traffic neither sourced from nor destined for local hosts (if you gateway to one other net, this stuff should never make it onto your local net). tcpdump ip and not net localnet To print the start and end packets (the SYN and FIN packets) of each TCP conversation that involves a non-local host. tcpdump 'tcp[tcpflags] \u0026amp; (tcp-syn|tcp-fin) != 0 and not src and dst net localnet' To print the TCP packets with flags RST and ACK both set. (i.e. select only the RST and ACK flags in the flags field, and if the result is \u0026quot;RST and ACK both set\u0026quot;, match) tcpdump 'tcp[tcpflags] \u0026amp; (tcp-rst|tcp-ack) == (tcp-rst|tcp-ack)' To print all IPv4 HTTP packets to and from port 80, i.e. print only packets that contain data, not, for example, SYN and FIN packets and ACK-only packets. (IPv6 is left as an exercise for the reader.) tcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]\u0026amp;0xf)\u0026lt;\u0026lt;2)) - ((tcp[12]\u0026amp;0xf0)\u0026gt;\u0026gt;2)) != 0)' To print IP packets longer than 576 bytes sent through gateway snup: tcpdump 'gateway snup and ip[2:2] \u0026gt; 576' To print IP broadcast or multicast packets that were not sent via Ethernet broadcast or multicast: tcpdump 'ether[0] \u0026amp; 1 = 0 and ip[16] \u0026gt;= 224' To print all ICMP packets that are not echo requests/replies (i.e., not ping packets): tcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply' OUTPUT FORMAT The output of tcpdump is protocol dependent. The following gives a brief description and examples of most of the formats. Timestamps By default, all output lines are preceded by a timestamp. The timestamp is the current clock time in the form hh:mm:ss.frac and is as accurate as the kernel's clock. The timestamp reflects the time the kernel applied a time stamp to the packet. No attempt is made to account for the time lag between when the net‐ work interface finished receiving the packet from the network and when the kernel applied a time stamp to the packet; that time lag could include a delay between the time when the network in‐ terface finished receiving a packet from the network and the time when an interrupt was delivered to the kernel to get it to read the packet and a delay between the time when the kernel ser‐ viced the `new packet' interrupt and the time when it applied a time stamp to the packet. Link Level Headers If the '-e' option is given, the link level header is printed out. On Ethernets, the source and destination addresses, protocol, and packet length are printed. On FDDI networks, the '-e' option causes tcpdump to print the `frame control' field, the source and destination addresses, and the packet length. (The `frame control' field governs the in‐ terpretation of the rest of the packet. Normal packets (such as those containing IP datagrams) are `async' packets, with a priority value between 0 and 7; for example, `async4'. Such packets are assumed to contain an 802.2 Logical Link Control (LLC) packet; the LLC header is printed if it is not an ISO datagram or a so-called SNAP packet. On Token Ring networks, the '-e' option causes tcpdump to print the `access control' and `frame control' fields, the source and destination addresses, and the packet length. As on FDDI net‐ works, packets are assumed to contain an LLC packet. Regardless of whether the '-e' option is specified or not, the source routing information is printed for source-routed packets. On 802.11 networks, the '-e' option causes tcpdump to print the `frame control' fields, all of the addresses in the 802.11 header, and the packet length. As on FDDI networks, packets are as‐ sumed to contain an LLC packet. (N.B.: The following description assumes familiarity with the SLIP compression algorithm described in RFC-1144.) On SLIP links, a direction indicator (``I'' for inbound, ``O'' for outbound), packet type, and compression information are printed out. The packet type is printed first. The three types are ip, utcp, and ctcp. No further link information is printed for ip packets. For TCP packets, the connection identifier is printed following the type. If the packet is compressed, its encoded header is printed out. The special cases are printed out as *S+n and *SA+n, where n is the amount by which the sequence number (or sequence number and ack) has changed. If it is not a spe‐ cial case, zero or more changes are printed. A change is indicated by U (urgent pointer), W (window), A (ack), S (sequence number), and I (packet ID), followed by a delta (+n or -n), or a new value (=n). Finally, the amount of data in the packet and compressed header length are printed. For example, the following line shows an outbound compressed TCP packet, with an implicit connection identifier; the ack has changed by 6, the sequence number by 49, and the packet ID by 6; there are 3 bytes of data and 6 bytes of compressed header: O ctcp * A+6 S+49 I+6 3 (6) ARP/RARP Packets ARP/RARP output shows the type of request and its arguments. The format is intended to be self explanatory. Here is a short sample taken from the start of an `rlogin' from host rtsg to host csam: arp who-has csam tell rtsg arp reply csam is-at CSAM The first line says that rtsg sent an ARP packet asking for the Ethernet address of internet host csam. Csam replies with its Ethernet address (in this example, Ethernet addresses are in caps and internet addresses in lower case). This would look less redundant if we had done tcpdump -n: arp who-has 128.3.254.6 tell 128.3.254.68 arp reply 128.3.254.6 is-at 02:07:01:00:01:c4 If we had done tcpdump -e, the fact that the first packet is broadcast and the second is point-to-point would be visible: RTSG Broadcast 0806 64: arp who-has csam tell rtsg CSAM RTSG 0806 64: arp reply csam is-at CSAM For the first packet this says the Ethernet source address is RTSG, the destination is the Ethernet broadcast address, the type field contained hex 0806 (type ETHER_ARP) and the total length was 64 bytes. IPv4 Packets If the link-layer header is not being printed, for IPv4 packets, IP is printed after the time stamp. If the -v flag is specified, information from the IPv4 header is shown in parentheses after the IP or the link-layer header. The general format of this information is: tos tos, ttl ttl, id id, offset offset, flags [flags], proto proto, length length, options (options) tos is the type of service field; if the ECN bits are non-zero, those are reported as ECT(1), ECT(0), or CE. ttl is the time-to-live; it is not reported if it is zero. id is the IP identifi‐ cation field. offset is the fragment offset field; it is printed whether this is part of a fragmented datagram or not. flags are the MF and DF flags; + is reported if MF is set, and DF is reported if F is set. If neither are set, . is reported. proto is the protocol ID field. length is the total length field. options are the IP options, if any. Next, for TCP and UDP packets, the source and destination IP addresses and TCP or UDP ports, with a dot between each IP address and its corresponding port, will be printed, with a \u0026gt; separating the source and destination. For other protocols, the addresses will be printed, with a \u0026gt; separating the source and destination. Higher level protocol information, if any, will be printed af‐ ter that. For fragmented IP datagrams, the first fragment contains the higher level protocol header; fragments after the first contain no higher level protocol header. Fragmentation information will be printed only with the -v flag, in the IP header information, as described above. TCP Packets (N.B.:The following description assumes familiarity with the TCP protocol described in RFC-793. If you are not familiar with the protocol, this description will not be of much use to you.) The general format of a TCP protocol line is: src \u0026gt; dst: Flags [tcpflags], seq data-seqno, ack ackno, win window, urg urgent, options [opts], length len Src and dst are the source and destination IP addresses and ports. Tcpflags are some combination of S (SYN), F (FIN), P (PUSH), R (RST), U (URG), W (ECN CWR), E (ECN-Echo) or `.' (ACK), or `none' if no flags are set. Data-seqno describes the portion of sequence space covered by the data in this packet (see example below). Ackno is sequence number of the next data expected the other direction on this connection. Window is the number of bytes of receive buffer space available the other direction on this connection. Urg indicates there is `urgent' data in the packet. Opts are TCP options (e.g., mss 1024). Len is the length of payload data. Iptype, Src, dst, and flags are always present. The other fields depend on the contents of the packet's TCP protocol header and are output only if appropriate. Here is the opening portion of an rlogin from host rtsg to host csam. IP rtsg.1023 \u0026gt; csam.login: Flags [S], seq 768512:768512, win 4096, opts [mss 1024] IP csam.login \u0026gt; rtsg.1023: Flags [S.], seq, 947648:947648, ack 768513, win 4096, opts [mss 1024] IP rtsg.1023 \u0026gt; csam.login: Flags [.], ack 1, win 4096 IP rtsg.1023 \u0026gt; csam.login: Flags [P.], seq 1:2, ack 1, win 4096, length 1 IP csam.login \u0026gt; rtsg.1023: Flags [.], ack 2, win 4096 IP rtsg.1023 \u0026gt; csam.login: Flags [P.], seq 2:21, ack 1, win 4096, length 19 IP csam.login \u0026gt; rtsg.1023: Flags [P.], seq 1:2, ack 21, win 4077, length 1 IP csam.login \u0026gt; rtsg.1023: Flags [P.], seq 2:3, ack 21, win 4077, urg 1, length 1 IP csam.login \u0026gt; rtsg.1023: Flags [P.], seq 3:4, ack 21, win 4077, urg 1, length 1 The first line says that TCP port 1023 on rtsg sent a packet to port login on csam. The S indicates that the SYN flag was set. The packet sequence number was 768512 and it contained no data. (The notation is `first:last' which means `sequence numbers first up to but not including last'.) There was no piggy-backed ACK, the available receive window was 4096 bytes and there was a max-segment-size option requesting an MSS of 1024 bytes. Csam replies with a similar packet except it includes a piggy-backed ACK for rtsg's SYN. Rtsg then ACKs csam's SYN. The `.' means the ACK flag was set. The packet contained no data so there is no data sequence number or length. Note that the ACK sequence number is a small integer (1). The first time tcpdump sees a TCP `conversation', it prints the sequence number from the packet. On subsequent packets of the conversation, the difference between the current packet's sequence number and this initial sequence number is printed. This means that sequence numbers after the first can be interpreted as relative byte positions in the conversation's data stream (with the first data byte each direction being `1'). `-S' will override this feature, causing the original sequence numbers to be output. On the 6th line, rtsg sends csam 19 bytes of data (bytes 2 through 20 in the rtsg → csam side of the conversation). The PUSH flag is set in the packet. On the 7th line, csam says it's re‐ ceived data sent by rtsg up to but not including byte 21. Most of this data is apparently sitting in the socket buffer since csam's receive window has gotten 19 bytes smaller. Csam also sends one byte of data to rtsg in this packet. On the 8th and 9th lines, csam sends two bytes of urgent, pushed data to rtsg. If the snapshot was small enough that tcpdump didn't capture the full TCP header, it interprets as much of the header as it can and then reports ``[|tcp]'' to indicate the remainder could not be interpreted. If the header contains a bogus option (one with a length that's either too small or beyond the end of the header), tcpdump reports it as ``[bad opt]'' and does not interpret any further options (since it's impossible to tell where they start). If the header length indicates options are present but the IP datagram length is not long enough for the options to actu‐ ally be there, tcpdump reports it as ``[bad hdr length]''. Capturing TCP packets with particular flag combinations (SYN-ACK, URG-ACK, etc.) There are 8 bits in the control bits section of the TCP header: CWR | ECE | URG | ACK | PSH | RST | SYN | FIN Let's assume that we want to watch packets used in establishing a TCP connection. Recall that TCP uses a 3-way handshake protocol when it initializes a new connection; the connection sequence with regard to the TCP control bits is 1) Caller sends SYN 2) Recipient responds with SYN, ACK 3) Caller sends ACK Now we're interested in capturing packets that have only the SYN bit set (Step 1). Note that we don't want packets from step 2 (SYN-ACK), just a plain initial SYN. What we need is a correct filter expression for tcpdump. Recall the structure of a TCP header without options: 0 15 31 ----------------------------------------------------------------- | source port | destination port | ----------------------------------------------------------------- | sequence number | ----------------------------------------------------------------- | acknowledgment number | ----------------------------------------------------------------- | HL | rsvd |C|E|U|A|P|R|S|F| window size | ----------------------------------------------------------------- | TCP checksum | urgent pointer | ----------------------------------------------------------------- A TCP header usually holds 20 octets of data, unless options are present. The first line of the graph contains octets 0 - 3, the second line shows octets 4 - 7 etc. Starting to count with 0, the relevant TCP control bits are contained in octet 13: 0 7| 15| 23| 31 ----------------|---------------|---------------|---------------- | HL | rsvd |C|E|U|A|P|R|S|F| window size | ----------------|---------------|---------------|---------------- | | 13th octet | | | Let's have a closer look at octet no. 13: | | |---------------| |C|E|U|A|P|R|S|F| |---------------| |7 5 3 0| These are the TCP control bits we are interested in. We have numbered the bits in this octet from 0 to 7, right to left, so the PSH bit is bit number 3, while the URG bit is number 5. Recall that we want to capture packets with only SYN set. Let's see what happens to octet 13 if a TCP datagram arrives with the SYN bit set in its header: |C|E|U|A|P|R|S|F| |---------------| |0 0 0 0 0 0 1 0| |---------------| |7 6 5 4 3 2 1 0| Looking at the control bits section we see that only bit number 1 (SYN) is set. Assuming that octet number 13 is an 8-bit unsigned integer in network byte order, the binary value of this octet is 00000010 and its decimal representation is 7 6 5 4 3 2 1 0 0*2 + 0*2 + 0*2 + 0*2 + 0*2 + 0*2 + 1*2 + 0*2 = 2 We're almost done, because now we know that if only SYN is set, the value of the 13th octet in the TCP header, when interpreted as a 8-bit unsigned integer in network byte order, must be ex‐ actly 2. This relationship can be expressed as tcp[13] == 2 We can use this expression as the filter for tcpdump in order to watch packets which have only SYN set: tcpdump -i xl0 tcp[13] == 2 The expression says \u0026quot;let the 13th octet of a TCP datagram have the decimal value 2\u0026quot;, which is exactly what we want. Now, let's assume that we need to capture SYN packets, but we don't care if ACK or any other TCP control bit is set at the same time. Let's see what happens to octet 13 when a TCP datagram with SYN-ACK set arrives: |C|E|U|A|P|R|S|F| |---------------| |0 0 0 1 0 0 1 0| |---------------| |7 6 5 4 3 2 1 0| Now bits 1 and 4 are set in the 13th octet. The binary value of octet 13 is 00010010 which translates to decimal 7 6 5 4 3 2 1 0 0*2 + 0*2 + 0*2 + 1*2 + 0*2 + 0*2 + 1*2 + 0*2 = 18 Now we can't just use 'tcp[13] == 18' in the tcpdump filter expression, because that would select only those packets that have SYN-ACK set, but not those with only SYN set. Remember that we don't care if ACK or any other control bit is set as long as SYN is set. In order to achieve our goal, we need to logically AND the binary value of octet 13 with some other value to preserve the SYN bit. We know that we want SYN to be set in any case, so we'll logically AND the value in the 13th octet with the binary value of a SYN: 00010010 SYN-ACK 00000010 SYN AND 00000010 (we want SYN) AND 00000010 (we want SYN) -------- -------- = 00000010 = 00000010 We see that this AND operation delivers the same result regardless whether ACK or another TCP control bit is set. The decimal representation of the AND value as well as the result of this op‐ eration is 2 (binary 00000010), so we know that for packets with SYN set the following relation must hold true: ( ( value of octet 13 ) AND ( 2 ) ) == ( 2 ) This points us to the tcpdump filter expression tcpdump -i xl0 'tcp[13] \u0026amp; 2 == 2' Some offsets and field values may be expressed as names rather than as numeric values. For example tcp[13] may be replaced with tcp[tcpflags]. The following TCP flag field values are also available: tcp-fin, tcp-syn, tcp-rst, tcp-push, tcp-ack, tcp-urg. This can be demonstrated as: tcpdump -i xl0 'tcp[tcpflags] \u0026amp; tcp-push != 0' Note that you should use single quotes or a backslash in the expression to hide the AND ('\u0026amp;') special character from the shell. UDP Packets UDP format is illustrated by this rwho packet: actinide.who \u0026gt; broadcast.who: udp 84 This says that port who on host actinide sent a UDP datagram to port who on host broadcast, the Internet broadcast address. The packet contained 84 bytes of user data. Some UDP services are recognized (from the source or destination port number) and the higher level protocol information printed. In particular, Domain Name service requests (RFC-1034/1035) and Sun RPC calls (RFC-1050) to NFS. TCP or UDP Name Server Requests (N.B.:The following description assumes familiarity with the Domain Service protocol described in RFC-1035. If you are not familiar with the protocol, the following description will appear to be written in Greek.) Name server requests are formatted as src \u0026gt; dst: id op? flags qtype qclass name (len) h2opolo.1538 \u0026gt; helios.domain: 3+ A? ucbvax.berkeley.edu. (37) Host h2opolo asked the domain server on helios for an address record (qtype=A) associated with the name ucbvax.berkeley.edu. The query id was `3'. The `+' indicates the recursion desired flag was set. The query length was 37 bytes, excluding the TCP or UDP and IP protocol headers. The query operation was the normal one, Query, so the op field was omitted. If the op had been anything else, it would have been printed between the `3' and the `+'. Similarly, the qclass was the normal one, C_IN, and omitted. Any other qclass would have been printed immediately after the `A'. A few anomalies are checked and may result in extra fields enclosed in square brackets: If a query contains an answer, authority records or additional records section, ancount, nscount, or arcount are printed as `[na]', `[nn]' or `[nau]' where n is the appropriate count. If any of the response bits are set (AA, RA or rcode) or any of the `must be zero' bits are set in bytes two and three, `[b2\u0026amp;3=x]' is printed, where x is the hex value of header bytes two and three. TCP or UDP Name Server Responses Name server responses are formatted as src \u0026gt; dst: id op rcode flags a/n/au type class data (len) helios.domain \u0026gt; h2opolo.1538: 3 3/3/7 A 128.32.137.3 (273) helios.domain \u0026gt; h2opolo.1537: 2 NXDomain* 0/1/0 (97) In the first example, helios responds to query id 3 from h2opolo with 3 answer records, 3 name server records and 7 additional records. The first answer record is type A (address) and its data is internet address 128.32.137.3. The total size of the response was 273 bytes, excluding TCP or UDP and IP headers. The op (Query) and response code (NoError) were omitted, as was the class (C_IN) of the A record. In the second example, helios responds to query 2 with a response code of non-existent domain (NXDomain) with no answers, one name server and no authority records. The `*' indicates that the authoritative answer bit was set. Since there were no answers, no type, class or data were printed. Other flag characters that might appear are `-' (recursion available, RA, not set) and `|' (truncated message, TC, set). If the `question' section doesn't contain exactly one entry, `[nq]' is printed. SMB/CIFS decoding tcpdump now includes fairly extensive SMB/CIFS/NBT decoding for data on UDP/137, UDP/138 and TCP/139. Some primitive decoding of IPX and NetBEUI SMB data is also done. By default a fairly minimal decode is done, with a much more detailed decode done if -v is used. Be warned that with -v a single SMB packet may take up a page or more, so only use -v if you really want all the gory details. For information on SMB packet formats and what all the fields mean see https://download.samba.org/pub/samba/specs/ and other online resources. The SMB patches were written by Andrew Tridgell (tridge@samba.org). NFS Requests and Replies Sun NFS (Network File System) requests and replies are printed as: src.sport \u0026gt; dst.nfs: NFS request xid xid len op args src.nfs \u0026gt; dst.dport: NFS reply xid xid reply stat len op results sushi.1023 \u0026gt; wrl.nfs: NFS request xid 26377 112 readlink fh 21,24/10.73165 wrl.nfs \u0026gt; sushi.1023: NFS reply xid 26377 reply ok 40 readlink \u0026quot;../var\u0026quot; sushi.1022 \u0026gt; wrl.nfs: NFS request xid 8219 144 lookup fh 9,74/4096.6878 \u0026quot;xcolors\u0026quot; wrl.nfs \u0026gt; sushi.1022: NFS reply xid 8219 reply ok 128 lookup fh 9,74/4134.3150 In the first line, host sushi sends a transaction with id 26377 to wrl. The request was 112 bytes, excluding the UDP and IP headers. The operation was a readlink (read symbolic link) on file handle (fh) 21,24/10.731657119. (If one is lucky, as in this case, the file handle can be interpreted as a major,minor device number pair, followed by the inode number and generation number.) In the second line, wrl replies `ok' with the same transaction id and the contents of the link. In the third line, sushi asks (using a new transaction id) wrl to lookup the name `xcolors' in directory file 9,74/4096.6878. In the fourth line, wrl sends a reply with the respective transac‐ tion id. Note that the data printed depends on the operation type. The format is intended to be self explanatory if read in conjunction with an NFS protocol spec. Also note that older versions of tcpdump printed NFS packets in a slightly different format: the transaction id (xid) would be printed instead of the non-NFS port number of the packet. If the -v (verbose) flag is given, additional information is printed. For example: sushi.1023 \u0026gt; wrl.nfs: NFS request xid 79658 148 read fh 21,11/12.195 8192 bytes @ 24576 wrl.nfs \u0026gt; sushi.1023: NFS reply xid 79658 reply ok 1472 read REG 100664 ids 417/0 sz 29388 (-v also prints the IP header TTL, ID, length, and fragmentation fields, which have been omitted from this example.) In the first line, sushi asks wrl to read 8192 bytes from file 21,11/12.195, at byte offset 24576. Wrl replies `ok'; the packet shown on the second line is the first fragment of the reply, and hence is only 1472 bytes long (the other bytes will follow in subsequent fragments, but these fragments do not have NFS or even UDP headers and so might not be printed, depending on the filter expression used). Because the -v flag is given, some of the file attributes (which are returned in addition to the file data) are printed: the file type (``REG'', for regular file), the file mode (in octal), the UID and GID, and the file size. If the -v flag is given more than once, even more details are printed. NFS reply packets do not explicitly identify the RPC operation. Instead, tcpdump keeps track of ``recent'' requests, and matches them to the replies using the transaction ID. If a reply does not closely follow the corresponding request, it might not be parsable. AFS Requests and Replies Transarc AFS (Andrew File System) requests and replies are printed as: src.sport \u0026gt; dst.dport: rx packet-type src.sport \u0026gt; dst.dport: rx packet-type service call call-name args src.sport \u0026gt; dst.dport: rx packet-type service reply call-name args elvis.7001 \u0026gt; pike.afsfs: rx data fs call rename old fid 536876964/1/1 \u0026quot;.newsrc.new\u0026quot; new fid 536876964/1/1 \u0026quot;.newsrc\u0026quot; pike.afsfs \u0026gt; elvis.7001: rx data fs reply rename In the first line, host elvis sends a RX packet to pike. This was a RX data packet to the fs (fileserver) service, and is the start of an RPC call. The RPC call was a rename, with the old directory file id of 536876964/1/1 and an old filename of `.newsrc.new', and a new directory file id of 536876964/1/1 and a new filename of `.newsrc'. The host pike responds with a RPC reply to the rename call (which was successful, because it was a data packet and not an abort packet). In general, all AFS RPCs are decoded at least by RPC call name. Most AFS RPCs have at least some of the arguments decoded (generally only the `interesting' arguments, for some definition of interesting). The format is intended to be self-describing, but it will probably not be useful to people who are not familiar with the workings of AFS and RX. If the -v (verbose) flag is given twice, acknowledgement packets and additional header information is printed, such as the RX call ID, call number, sequence number, serial number, and the RX packet flags. If the -v flag is given twice, additional information is printed, such as the RX call ID, serial number, and the RX packet flags. The MTU negotiation information is also printed from RX ack packets. If the -v flag is given three times, the security index and service id are printed. Error codes are printed for abort packets, with the exception of Ubik beacon packets (because abort packets are used to signify a yes vote for the Ubik protocol). AFS reply packets do not explicitly identify the RPC operation. Instead, tcpdump keeps track of ``recent'' requests, and matches them to the replies using the call number and service ID. If a reply does not closely follow the corresponding request, it might not be parsable. KIP AppleTalk (DDP in UDP) AppleTalk DDP packets encapsulated in UDP datagrams are de-encapsulated and dumped as DDP packets (i.e., all the UDP header information is discarded). The file /etc/atalk.names is used to translate AppleTalk net and node numbers to names. Lines in this file have the form number name 1.254 ether 16.1 icsd-net 1.254.110 ace The first two lines give the names of AppleTalk networks. The third line gives the name of a particular host (a host is distinguished from a net by the 3rd octet in the number - a net number must have two octets and a host number must have three octets.) The number and name should be separated by whitespace (blanks or tabs). The /etc/atalk.names file may contain blank lines or comment lines (lines starting with a `#'). AppleTalk addresses are printed in the form net.host.port 144.1.209.2 \u0026gt; icsd-net.112.220 office.2 \u0026gt; icsd-net.112.220 jssmag.149.235 \u0026gt; icsd-net.2 (If the /etc/atalk.names doesn't exist or doesn't contain an entry for some AppleTalk host/net number, addresses are printed in numeric form.) In the first example, NBP (DDP port 2) on net 144.1 node 209 is sending to whatever is listening on port 220 of net icsd node 112. The second line is the same except the full name of the source node is known (`office'). The third line is a send from port 235 on net jssmag node 149 to broadcast on the icsd-net NBP port (note that the broadcast address (255) is indicated by a net name with no host number - for this reason it's a good idea to keep node names and net names distinct in /etc/atalk.names). NBP (name binding protocol) and ATP (AppleTalk transaction protocol) packets have their contents interpreted. Other protocols just dump the protocol name (or number if no name is registered for the protocol) and packet size. NBP packets are formatted like the following examples: icsd-net.112.220 \u0026gt; jssmag.2: nbp-lkup 190: \u0026quot;=:LaserWriter@*\u0026quot; jssmag.209.2 \u0026gt; icsd-net.112.220: nbp-reply 190: \u0026quot;RM1140:LaserWriter@*\u0026quot; 250 techpit.2 \u0026gt; icsd-net.112.220: nbp-reply 190: \u0026quot;techpit:LaserWriter@*\u0026quot; 186 The first line is a name lookup request for laserwriters sent by net icsd host 112 and broadcast on net jssmag. The nbp id for the lookup is 190. The second line shows a reply for this re‐ quest (note that it has the same id) from host jssmag.209 saying that it has a laserwriter resource named \u0026quot;RM1140\u0026quot; registered on port 250. The third line is another reply to the same request saying host techpit has laserwriter \u0026quot;techpit\u0026quot; registered on port 186. ATP packet formatting is demonstrated by the following example: jssmag.209.165 \u0026gt; helios.132: atp-req 12266\u0026lt;0-7\u0026gt; 0xae030001 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:0 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:1 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:2 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:3 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:4 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:5 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:6 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp*12266:7 (512) 0xae040000 jssmag.209.165 \u0026gt; helios.132: atp-req 12266\u0026lt;3,5\u0026gt; 0xae030001 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:3 (512) 0xae040000 helios.132 \u0026gt; jssmag.209.165: atp-resp 12266:5 (512) 0xae040000 jssmag.209.165 \u0026gt; helios.132: atp-rel 12266\u0026lt;0-7\u0026gt; 0xae030001 jssmag.209.133 \u0026gt; helios.132: atp-req* 12267\u0026lt;0-7\u0026gt; 0xae030002 Jssmag.209 initiates transaction id 12266 with host helios by requesting up to 8 packets (the `\u0026lt;0-7\u0026gt;'). The hex number at the end of the line is the value of the `userdata' field in the re‐ quest. Helios responds with 8 512-byte packets. The `:digit' following the transaction id gives the packet sequence number in the transaction and the number in parens is the amount of data in the packet, excluding the ATP header. The `*' on packet 7 indicates that the EOM bit was set. Jssmag.209 then requests that packets 3 \u0026amp; 5 be retransmitted. Helios resends them then jssmag.209 releases the transaction. Finally, jssmag.209 initiates the next request. The `*' on the request indicates that XO (`exactly once') was not set. SEE ALSO stty(1), pcap(3PCAP), bpf(4), nit(4P), pcap-savefile(5), pcap-filter(7), pcap-tstamp(7) https://www.iana.org/assignments/media-types/application/vnd.tcpdump.pcap AUTHORS The original authors are: Van Jacobson, Craig Leres and Steven McCanne, all of the Lawrence Berkeley National Laboratory, University of California, Berkeley, CA. It is currently being maintained by tcpdump.org. The current version is available via HTTPS: https://www.tcpdump.org/ The original distribution is available via anonymous ftp: ftp://ftp.ee.lbl.gov/old/tcpdump.tar.Z IPv6/IPsec support is added by WIDE/KAME project. This program uses OpenSSL/LibreSSL, under specific configurations. BUGS To report a security issue please send an e-mail to security@tcpdump.org. To report bugs and other problems, contribute patches, request a feature, provide generic feedback etc. please see the file CONTRIBUTING in the tcpdump source tree root. NIT doesn't let you watch your own outbound traffic, BPF will. We recommend that you use the latter. On Linux systems with 2.0[.x] kernels: packets on the loopback device will be seen twice; packet filtering cannot be done in the kernel, so that all packets must be copied from the kernel in order to be filtered in user mode; all of a packet, not just the part that's within the snapshot length, will be copied from the kernel (the 2.0[.x] packet capture mechanism, if asked to copy only part of a packet to userspace, will not report the true length of the packet; this would cause most IP packets to get an error from tcpdump); capturing on some PPP devices won't work correctly. We recommend that you upgrade to a 2.2 or later kernel. Some attempt should be made to reassemble IP fragments or, at least to compute the right length for the higher level protocol. Name server inverse queries are not dumped correctly: the (empty) question section is printed rather than real query in the answer section. Some believe that inverse queries are themselves a bug and prefer to fix the program generating them rather than tcpdump. A packet trace that crosses a daylight savings time change will give skewed time stamps (the time change is ignored). Filter expressions on fields other than those in Token Ring headers will not correctly handle source-routed Token Ring packets. Filter expressions on fields other than those in 802.11 headers will not correctly handle 802.11 data packets with both To DS and From DS set. ip6 proto should chase header chain, but at this moment it does not. ip6 protochain is supplied for this behavior. Arithmetic expression against transport layer headers, like tcp[0], does not work against IPv6 packets. It only looks at IPv4 packets. 21 December 2020 TCPDUMP(8) ```bash "}),e.add({id:51,href:"/docs/tools/know/tcpflow/",title:"Tcpflow",description:`Description # tcpflow is a tool for capturing network data and saving it to files based on the TCP stream. It is useful for capturing network traffic for later analysis, such as with Wireshark.
Download # brew install tcpflow Usage # tcpflow -i en0 -c -C -p -g -B -r 1000000 -l /tmp/tcpflow Options # -i - interface to listen on -c - capture data -C - capture data and print to stdout -p - print packet headers -g - print packet headers and data -B - print packet headers and data in hex -r - set the read buffer size -l - set the directory to save files to References # https://github.`,content:"Description # tcpflow is a tool for capturing network data and saving it to files based on the TCP stream. It is useful for capturing network traffic for later analysis, such as with Wireshark.\nDownload # brew install tcpflow Usage # tcpflow -i en0 -c -C -p -g -B -r 1000000 -l /tmp/tcpflow Options # -i - interface to listen on -c - capture data -C - capture data and print to stdout -p - print packet headers -g - print packet headers and data -B - print packet headers and data in hex -r - set the read buffer size -l - set the directory to save files to References # https://github.com/simsong/tcpflow help # tcpflow(1) tcpflow 1.6.1 tcpflow(1) NAME tcpflow - TCP flow recorder SYNOPSIS tcpflow [-aBcCDIpsZ] [-b max_bytes] [-d debug_level] [-[eE] scanner] [-f max_fds] [-F[ctTXMkmg]] [-h|--help] [-i iface] [-l file1.pcap file2.pcap...] [-L semlock] [-m min_bytes] [-o outdir] [-r file1.pcap] [-R file0.pcap] [-S name=value] [-T[filename template]] [-U|--relinquish-privileges username] [-v|--verbose] [-V|--version] [-w file] [-x scanner] [-X file.xml] [-z|--ch‐ root directory] [expression] DESCRIPTION tcpflow is a program that captures data transmitted as part of TCP connections (flows), and stores the data in a way that is convenient for protocol analysis or debugging. Rather than showing packet-by-packet information, tcpflow reconstructs the actual data streams and stores each flow in a separate file for later analysis. tcpflow understands TCP sequence numbers and will cor‐ rectly reconstruct data streams regardless of retransmissions or out-of-order delivery. tcpflow provides control over filenames for automatic binning of connections by protocol, IP address or connection number, and has a sophisticated plug-in system for decompressing compressed HTTP connections, undoing MIME encoding, or calling user-provided programs for post-processing. By default tcpflow stores all captured data in files that have names of the form: 192.168.101.102.02345-010.011.012.013.45103 ...where the contents of the above file would be data transmitted from host 192.168.101.102 port 2345, to host 10.11.12.13 port 45103. If you want to simply process a few hundred thousand packets and see what you have, try this: tcpflow -a -o outdir -Fk -r packets.pcap This will cause tcpflow to perform (-a) all processing, store the output in a directory called outdir, bin the output in directories of 1000 connections each, and read its input from the file packets.pcap. More sophisticated processing is possible, of course. OPTIONS -a Enable all processing. Same as -e all. -B Force binary output even when printing to console with -C or -c. -b max_bytes Specifies the maximum size of a captured flow. Any bytes beyond max_bytes from the first byte captured will be discarded. The default is to store an unlimited number of bytes per flow. Note: before version 1.4, tcpflow could only store a maximum of 4GiB per flow. -c Console print. Print the contents of packets to stdout as they are received, without storing any captured data to files (implies -s). -C Console print without the packet source and destination details being printed. Print the contents of packets to stdout as they are received, without storing any captured data to files (implies -s). -D Console output should be in hex. -d Debug level. Set the level of debugging messages printed to stderr to debug_level. Higher numbers produce more messages. -d 0 causes completely silent operation. -d 1 , the default, produces minimal status messages. -d 10 produces verbose output equivalent to -v . Numbers higher than 10 can produce a large amount of debugging information useful only to develop‐ ers. -E name Disable all scanners and then enable scanner name -e name Enable scanner name. -e all Enables all scanners. Same as -a -e http Perform HTTP post-processing (\u0026quot;After\u0026quot; processing). If the output file is 208.111.153.175.00080-192.168.001.064.37314, Then the post-processing will create the files: 208.111.153.175.00080-192.168.001.064.37314-HTTP 208.111.153.175.00080-192.168.001.064.37314-HTTPBODY If the HTTPBODY was compressed with GZIP, you may get a third file as well: 208.111.153.175.00080-192.168.001.064.37314-HTTPBODY-GZIP Additional information about these streams, such as their MD5 hash value, is also written to the DFXML report file. -e python -S py_path=path -S py_module=module -S py_function=foo Post-process TCP payload by an external python function. The python function must take a single string parameter. The python function can return a string (else the function does must not return). The returned string (if any) is written in the DFXML report file inside the XML tag \u0026lt;scan_python_result\u0026gt;...\u0026lt;/scan_python_result\u0026gt;. A sample python script is available within the tcpflow source code in directory python/plugins. Example: tcpflow -r my.cap -e python -S py_path=python/plugins -S py_module=samplePlugin -S py_function=sampleFunction -F[format] Specifies format for output filenames. Format specifiers: c Appends the connection counter to ALL filenames. t Prepends each filename with a Unix timestamp (seconds since epoch). T Prepends each filename with an ISO-8601 timestamp. X Do not output any files (other than the DFXML report file). -FM Include MD5 of each flow in the DFXML report file. -FX Suppresses file output entirely, DFXML report file is still produced. -Fk bin output in 1K directories -Fm bin output in 1M directories (2 levels) -Fg bin output in 1G directories (3 levels) -fmax_fds Max file descriptors used. Limit the number of file descriptors used by tcpflow to max_fds. Higher numbers use more system resources, but usually perform better. If the underlying operating system supports the setrlimit() system call, the OS will be asked to enforce the requested limit. The default is for tcpflow to use the maximum number of file descriptors al‐ lowed by the OS. The -v option will report how many file descriptors tcpflow is using. -g Output flow information to console in multiple colors. (Blue for client to server flows, red for server to client flows, green for undecided flows.) Note: This option was different from tcpflow 1.3 (-e) and 1.4.4 (-J). -h --help Help. Print usage information and exit. -hh More help. Print more usage information and exit. -i iface Interface name. Capture packets from the network interface named iface. If no interface is specified with -i , a reasonable default will be used by libpcap automatically. -I Store the reception timestamps (of TCP packets) in a companion file *.findx. Therefore each flow will have two files: (1) the usual file containing payload bytes and (2) the text file containing the corresponding timestamps. This last file *.findx has three columns using the pipe '|' as separator: byte-index|timestamp|length The byte-index column is the postion within the file containing the payload bytes. The timestamp column represents the number of seconds since epoch as a floating point number. The precision is the microsecond but may also be the nanosecond in a future tcpflow version. The length column is the number of successive bytes concerned by timestamp and can include sev‐ eral TCP frames (TCP packets). The extension findx may become from the fact that the timestamps are frame indexed. -L semlock_name Specifies that semlock_name should be used as a Unix semaphore to prevent two different copies of tcpflow running in two different processes but outputting to the same standard output from printing on top of each other. This is an application of Unix named semaphores; bet you have never seen one before. -l Treat the following arguments as filenames with an assumed -r command before each one. This allows you to read a lot of files at once with shell globbing. For example, to process all of the pcap files in the current directory, use this: tcpflow -o out -a -l *.pcap -m min_size Forces a new connection output file when there is a skip in the TCP session of min_size bytes or more. -o outdir Specifies the output directory where the transcript files will be written. -P No purge. Normally tcpflow removes connections from the hash table after the connection is closed with a FIN. This conserves memory but takes additional CPU time. Selecting this option causes the std::tr1:unordered_map to grow without bounds, as tcpflow did prior to version 1.1. That makes tcpflow run faster if there are less than 10 million connections, but can lead to out-of-memory errors. -p No promiscuous mode. Normally, tcpflow attempts to put the network interface into promiscuous mode before capturing packets. The -p option tells tcpflow not to put the interface into promiscuous mode. Note that it might already be in promiscuous mode for some other reason. -q Quiet mode --- don't print warnings. Currently the only warning that tcpflow prints is a warning when more than 10,000 files are created that the user should have provided the -Fk, -Fm, or -Fg options. We might have other warnings in the future. --relinquish-privileges=username When tcpflow is run as root, this option changes the user ID and group ID to write files owned by username. The group ID is the first one from the username groups list. This operation is performed just after opening the capture device or just after opening the first input PCAP file. This option does not support multi root-only readable input files as the root privi‐ leges are dropped after opening the first file (e.g. -r root-only-access.pcap -R root-only.pcap -l root-only*.pcap). This option has the same behaviour as the tcpdump(1) option having the same name --relinquish-privileges -r Read from file. Read packets from file, which was created using the -w option of tcpdump(1). This option may be repeated any number of times. Standard input is used if file is \u0026quot;-\u0026quot;. Note that for this option to be useful, tcpdump's -s option should be used to set the snaplen to the MTU of the interface (e.g., 1500) while capturing packets. -R Read from a file, but only to complete TCP flows. This option is used when tcpflow is used to process a series of files that are captured over time. For each time period n, file file(n).pcap should be processed with -R file(n).pcap, while file(n-1).pcap should be processed with -r file(n-1).pcap. -Sname=value Sets a name parameter to be equal to value for a plug-in. Use -hh to find out all of the settable parameters. -s Strip non-printables. Convert all non-printable characters to the \u0026quot;.\u0026quot; character before printing packets to the console or storing them to a file. -T[format] Specifies an arbitrary template for filenames. %A expands to source IP address. %a expands to source IP port. %B expands to destination IP address. %b expands to destination IP port. %T expands to timestamp in ISO8601 format. %t expands to timestamp in Unix time_t format. %V expands to \u0026quot;--\u0026quot; if a VLAN is present. %v expands to the VLAN number if a VLAN is present. %C expands to \u0026quot;c\u0026quot; if the connection count\u0026gt;0. %c expands to the connection count if the connection count\u0026gt;0. %# always expands to the connection count. %N (connection_number ) % 1000 %K (connection_number / 1000) % 1000 %M (connection_number / 1000000) % 1000 %G (connection_number / 1000000000) % 1000 %% prints a \u0026quot;%\u0026quot;. When the option -T is used, tcpflow ignores options -Fk, -Fm and -Fg. However, the option -T handles '/' within the filename template patern to create sub-directories. For example the following line will create a directory tree out/IP-src/port-src/IP- dst/port-dst. tcpflow -r packets.pcap -o out -T %A/%a/%B/%b/%c%N.flow -V --version Print the version number and exit. -v --verbose Verbose operation. Verbosely describe tcpflow's operation. Equivalent to -d 10. -w filename.pcap Write packets that were not processed to filename.pcap. Typically this will be UDP packets. -X filename.xml Write a DFXML report to filename.xml. The file contains a record of every tcp connection, how the tcpflow program was compiled, and the computer on which tcpflow was run. By default tcpflow writes the DFXML report in file report.xml. -Z Don't decompress gzip-compressed streams. -K Retain per flow isolated pcap structure. expression selects which packets will be captured. If no expression is given, all packets on the net will be captured. Otherwise, only packets for which expression is `true' will be captured. For the expression syntax, see pcap-filter(7). The expression argument can be passed to tcpflow as either a single Shell argument, or as multiple Shell arguments, whichever is more convenient. Generally, if the expression contains Shell metacharacters, such as backslashes used to escape protocol names, it is easier to pass it as a single, quoted argument rather than to escape the Shell metacharacters. Multiple arguments are concatenated with spaces before being parsed. DFXML report The DFXML report is the XML file written by tcpflow to provide tcpflow build details, command line arguments and information about processed flows. By default the DFXML file is named report.xml. But this filename can be changed using command line option -X. DFXML file respects the DFXML schema defined by project https://github.com/dfxml-working-group/dfxml_schema. Moreover tcpflow adds two extra XML tags, as illustrated by the following example: \u0026lt;tcpflow startime='2017-07-22T00:12:21.962782Z' endtime='2017-07-22T00:12:22.097591Z' family='2' mac_daddr='40:3d:78:57:ed:d4' mac_saddr='00:c5:42:d2:cb:f2' src_ipn='141.134.34.12' dst_ipn='192.168.0.40' srcport='80' dstport='38797' packets='4' len='677' caplen='611' /\u0026gt; \u0026lt;tcpflow:result scanner=\u0026quot;python\u0026quot; path=\u0026quot;python/plugins\u0026quot; module=\u0026quot;samplePlugin\u0026quot; function=\u0026quot;sampleFunction\u0026quot;\u0026gt;bla bla bla\u0026lt;/tcpflow:result\u0026gt; The first XML tag \u0026lt;tcpflow\u0026gt; provide information about the captured flow. This tag should be renamed \u0026lt;tcpflow:cap\u0026gt; in a future version in order to conform better to DFXML schema. The second XML tag \u0026lt;tcpflow:result\u0026gt; collects processing results. For the moment, only the scanner python uses this feature. The XML attributes of \u0026lt;tcpflow\u0026gt; are: • startime Reception time of first packet • endtime Reception time of last packet • family • mac_daddr Destination MAC address of first packet (printed if any) • mac_saddr Source MAC address of first packet (printed if any) • src_ipn IP source • dst_ipn IP destination • srcport TCP port source • dstport TCP port destination • packets Nummber of packets • out_of_order_count Number of times tcpflow has replaced missing payload by zeros in the flow file, for example when capture does not contain the TCP session begin (printed if any) • violations Number of protocol violations (printed if any) • len Sum of un-truncated length of all packet data (including headers, see https://stackoverflow.com/q/1491660) • caplen Sum of captured bytes of all packet data (including headers, printed if different from len) The XML attributes of \u0026lt;tcpflow:result\u0026gt; are: • scanner Name of the scanner • path Directory of the scanner module (printed if relevant) • module Module name (printed if relevant, used to indicate the python script) • function Function name (printed if relevant, used to indicate the function within the python module) EXAMPLES To record all packets arriving at or departing from sundown and extract all of the HTTP attachments: tcpflow -e http -o outdir host sundown To record traffic between helios and either hot or ace and bin the results into 1000 files per directory and calculate the MD5 of each flow: tcpflow -X report.xml -e md5 -o outdir -Fk host helios and \\( hot or ace \\) BUGS Please send bug reports to simsong@acm.org. tcpflow currently does not understand IP fragments. Flows containing IP fragments will not be recorded correctly. AUTHORS Originally by Jeremy Elson \u0026lt;jelson@circlemud.org\u0026gt;. Substantially modified and maintained by Simson L. Garfinkel \u0026lt;simsong@acm.org\u0026gt;. Network visualization code by Michael Shick \u0026lt;mike@shick.in\u0026gt; The current version of this software is available at http://digitalcorpora.org/downloads/tcpflow/ An announcement mailing list for this program is at: http://groups.google.com/group/tcpflow-users SEE ALSO tcpdump(1), nit(4P), bpf(4), pcap(3), pcap-savefile(5), pcap-filter(7) tcpflow 1.6.1 2013-04-13 tcpflow(1) ```bash "}),e.add({id:52,href:"/docs/tools/know/termshark/",title:"Termshark",description:`Description # Termshark is a terminal UI for tshark, inspired by Wireshark.
Installation # brew install termshark Usage # Capture ping packets on interface eth0:
termshark -i en0 Inspect a local pcap:
termshark -r test.pcap Resources # User Guide help # termshark v2.4.0 A wireshark-inspired terminal user interface for tshark. Analyze network traffic interactively from your terminal. See https://termshark.io for more information. Usage: termshark [FilterOrPcap] Application Options: -i=\u0026lt;interfaces\u0026gt; Interface(s) to read.`,content:"Description # Termshark is a terminal UI for tshark, inspired by Wireshark.\nInstallation # brew install termshark Usage # Capture ping packets on interface eth0:\ntermshark -i en0 Inspect a local pcap:\ntermshark -r test.pcap Resources # User Guide help # termshark v2.4.0 A wireshark-inspired terminal user interface for tshark. Analyze network traffic interactively from your terminal. See https://termshark.io for more information. Usage: termshark [FilterOrPcap] Application Options: -i=\u0026lt;interfaces\u0026gt; Interface(s) to read. -r=\u0026lt;infile/fifo\u0026gt; Pcap file/fifo to read. Use - for stdin. -w=\u0026lt;outfile\u0026gt; Write raw packet data to outfile. -d=\u0026lt;layer type\u0026gt;==\u0026lt;selector\u0026gt;,\u0026lt;decode-as protocol\u0026gt; Specify dissection of layer type. -D Print a list of the interfaces on which termshark can capture. -Y=\u0026lt;displaY filter\u0026gt; Apply display filter. -f=\u0026lt;capture filter\u0026gt; Apply capture filter. -t=\u0026lt;timestamp format\u0026gt;[a|ad|adoy|d|dd|e|r|u|ud|udoy] Set the format of the packet timestamp printed in summary lines. --tty=\u0026lt;tty\u0026gt; Display the UI on this terminal. -C, --profile=\u0026lt;profile\u0026gt; Start with this configuration profile. --pass-thru=[auto|true|false] Run tshark instead (auto =\u0026gt; if stdout is not a tty). (default: auto) --log-tty Log to the terminal. -h, --help Show this help message. -v, --version Show version information. Arguments: FilterOrPcap: Filter (capture for iface, display for pcap), or pcap to read. If --pass-thru is true (or auto, and stdout is not a tty), tshark will be executed with the supplied command-line flags. You can provide tshark-specific flags and they will be passed through to tshark (-n, -d, -T, etc). For example: $ termshark -r file.pcap -T psml -n | less ```bash "}),e.add({id:53,href:"/docs/tools/know/nmap/",title:"Nmap",description:`Description # Nmap is a free and open source utility for network discovery and security auditing. Many systems and network administrators also find it useful for tasks such as network inventory, managing service upgrade schedules, and monitoring host or service uptime.
Installation # brew install nmap Usage # nmap -sP 192.168.0.1/24 References # Nmap Nmap - Wikipedia help # NMAP(1) Nmap Reference Guide NMAP(1) NAME nmap - Network exploration tool and security / port scanner SYNOPSIS nmap [Scan Type.`,content:"Description # Nmap is a free and open source utility for network discovery and security auditing. Many systems and network administrators also find it useful for tasks such as network inventory, managing service upgrade schedules, and monitoring host or service uptime.\nInstallation # brew install nmap Usage # nmap -sP 192.168.0.1/24 References # Nmap Nmap - Wikipedia help # NMAP(1) Nmap Reference Guide NMAP(1) NAME nmap - Network exploration tool and security / port scanner SYNOPSIS nmap [Scan Type...] [Options] {target specification} DESCRIPTION Nmap (“Network Mapper”) is an open source tool for network exploration and security auditing. It was designed to rapidly scan large networks, although it works fine against single hosts. Nmap uses raw IP packets in novel ways to determine what hosts are available on the network, what services (application name and version) those hosts are offering, what operating systems (and OS versions) they are running, what type of packet filters/firewalls are in use, and dozens of other characteristics. While Nmap is commonly used for security audits, many systems and network administrators find it useful for routine tasks such as network inventory, managing service upgrade schedules, and monitoring host or service uptime. The output from Nmap is a list of scanned targets, with supplemental information on each depending on the options used. Key among that information is the “interesting ports table”. That table lists the port number and protocol, service name, and state. The state is either open, filtered, closed, or unfiltered. Open means that an application on the target machine is listening for connections/packets on that port. Filtered means that a firewall, filter, or other network obstacle is blocking the port so that Nmap cannot tell whether it is open or closed. Closed ports have no application listening on them, though they could open up at any time. Ports are classified as unfiltered when they are responsive to Nmap's probes, but Nmap cannot determine whether they are open or closed. Nmap reports the state combinations open|filtered and closed|filtered when it cannot determine which of the two states describe a port. The port table may also include software version details when version detection has been requested. When an IP protocol scan is requested (-sO), Nmap provides information on supported IP protocols rather than listening ports. In addition to the interesting ports table, Nmap can provide further information on targets, including reverse DNS names, operating system guesses, device types, and MAC addresses. A typical Nmap scan is shown in Example 1. The only Nmap arguments used in this example are -A, to enable OS and version detection, script scanning, and traceroute; -T4 for faster execution; and then the hostname. Example 1. A representative Nmap scan # nmap -A -T4 scanme.nmap.org Nmap scan report for scanme.nmap.org (74.207.244.221) Host is up (0.029s latency). rDNS record for 74.207.244.221: li86-221.members.linode.com Not shown: 995 closed ports PORT STATE SERVICE VERSION 22/tcp open ssh OpenSSH 5.3p1 Debian 3ubuntu7 (protocol 2.0) | ssh-hostkey: 1024 8d:60:f1:7c:ca:b7:3d:0a:d6:67:54:9d:69:d9:b9:dd (DSA) |_2048 79:f8:09:ac:d4:e2:32:42:10:49:d3:bd:20:82:85:ec (RSA) 80/tcp open http Apache httpd 2.2.14 ((Ubuntu)) |_http-title: Go ahead and ScanMe! 646/tcp filtered ldp 1720/tcp filtered H.323/Q.931 9929/tcp open nping-echo Nping echo Device type: general purpose Running: Linux 2.6.X OS CPE: cpe:/o:linux:linux_kernel:2.6.39 OS details: Linux 2.6.39 Network Distance: 11 hops Service Info: OS: Linux; CPE: cpe:/o:linux:kernel TRACEROUTE (using port 53/tcp) HOP RTT ADDRESS [Cut first 10 hops for brevity] 11 17.65 ms li86-221.members.linode.com (74.207.244.221) Nmap done: 1 IP address (1 host up) scanned in 14.40 seconds The newest version of Nmap can be obtained from https://nmap.org. The newest version of this help is available at https://nmap.org/book/man.html. It is also included as a chapter of Nmap Network Scanning: The Official Nmap Project Guide to Network Discovery and Security Scanning (see https://nmap.org/book/). OPTIONS SUMMARY This options summary is printed when Nmap is run with no arguments, and the latest version is always available at https://svn.nmap.org/nmap/docs/nmap.usage.txt. It helps people remember the most common options, but is no substitute for the in-depth documentation in the rest of this manual. Some obscure options aren't even included here. Nmap 7.93 ( https://nmap.org ) Usage: nmap [Scan Type(s)] [Options] {target specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, 192.168.0.1; 10.0.0-255.1-254 -iL \u0026lt;inputfilename\u0026gt;: Input from list of hosts/networks -iR \u0026lt;num hosts\u0026gt;: Choose random targets --exclude \u0026lt;host1[,host2][,host3],...\u0026gt;: Exclude hosts/networks --excludefile \u0026lt;exclude_file\u0026gt;: Exclude list from file HOST DISCOVERY: -sL: List Scan - simply list targets to scan -sn: Ping Scan - disable port scan -Pn: Treat all hosts as online -- skip host discovery -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes -PO[protocol list]: IP Protocol Ping -n/-R: Never do DNS resolution/Always resolve [default: sometimes] --dns-servers \u0026lt;serv1[,serv2],...\u0026gt;: Specify custom DNS servers --system-dns: Use OS's DNS resolver --traceroute: Trace hop path to each host SCAN TECHNIQUES: -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans -sU: UDP Scan -sN/sF/sX: TCP Null, FIN, and Xmas scans --scanflags \u0026lt;flags\u0026gt;: Customize TCP scan flags -sI \u0026lt;zombie host[:probeport]\u0026gt;: Idle scan -sY/sZ: SCTP INIT/COOKIE-ECHO scans -sO: IP protocol scan -b \u0026lt;FTP relay host\u0026gt;: FTP bounce scan PORT SPECIFICATION AND SCAN ORDER: -p \u0026lt;port ranges\u0026gt;: Only scan specified ports Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9 --exclude-ports \u0026lt;port ranges\u0026gt;: Exclude the specified ports from scanning -F: Fast mode - Scan fewer ports than the default scan -r: Scan ports sequentially - don't randomize --top-ports \u0026lt;number\u0026gt;: Scan \u0026lt;number\u0026gt; most common ports --port-ratio \u0026lt;ratio\u0026gt;: Scan ports more common than \u0026lt;ratio\u0026gt; SERVICE/VERSION DETECTION: -sV: Probe open ports to determine service/version info --version-intensity \u0026lt;level\u0026gt;: Set from 0 (light) to 9 (try all probes) --version-light: Limit to most likely probes (intensity 2) --version-all: Try every single probe (intensity 9) --version-trace: Show detailed version scan activity (for debugging) SCRIPT SCAN: -sC: equivalent to --script=default --script=\u0026lt;Lua scripts\u0026gt;: \u0026lt;Lua scripts\u0026gt; is a comma separated list of directories, script-files or script-categories --script-args=\u0026lt;n1=v1,[n2=v2,...]\u0026gt;: provide arguments to scripts --script-args-file=filename: provide NSE script args in a file --script-trace: Show all data sent and received --script-updatedb: Update the script database. --script-help=\u0026lt;Lua scripts\u0026gt;: Show help about scripts. \u0026lt;Lua scripts\u0026gt; is a comma-separated list of script-files or script-categories. OS DETECTION: -O: Enable OS detection --osscan-limit: Limit OS detection to promising targets --osscan-guess: Guess OS more aggressively TIMING AND PERFORMANCE: Options which take \u0026lt;time\u0026gt; are in seconds, or append 'ms' (milliseconds), 's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m). -T\u0026lt;0-5\u0026gt;: Set timing template (higher is faster) --min-hostgroup/max-hostgroup \u0026lt;size\u0026gt;: Parallel host scan group sizes --min-parallelism/max-parallelism \u0026lt;numprobes\u0026gt;: Probe parallelization --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout \u0026lt;time\u0026gt;: Specifies probe round trip time. --max-retries \u0026lt;tries\u0026gt;: Caps number of port scan probe retransmissions. --host-timeout \u0026lt;time\u0026gt;: Give up on target after this long --scan-delay/--max-scan-delay \u0026lt;time\u0026gt;: Adjust delay between probes --min-rate \u0026lt;number\u0026gt;: Send packets no slower than \u0026lt;number\u0026gt; per second --max-rate \u0026lt;number\u0026gt;: Send packets no faster than \u0026lt;number\u0026gt; per second FIREWALL/IDS EVASION AND SPOOFING: -f; --mtu \u0026lt;val\u0026gt;: fragment packets (optionally w/given MTU) -D \u0026lt;decoy1,decoy2[,ME],...\u0026gt;: Cloak a scan with decoys -S \u0026lt;IP_Address\u0026gt;: Spoof source address -e \u0026lt;iface\u0026gt;: Use specified interface -g/--source-port \u0026lt;portnum\u0026gt;: Use given port number --proxies \u0026lt;url1,[url2],...\u0026gt;: Relay connections through HTTP/SOCKS4 proxies --data \u0026lt;hex string\u0026gt;: Append a custom payload to sent packets --data-string \u0026lt;string\u0026gt;: Append a custom ASCII string to sent packets --data-length \u0026lt;num\u0026gt;: Append random data to sent packets --ip-options \u0026lt;options\u0026gt;: Send packets with specified ip options --ttl \u0026lt;val\u0026gt;: Set IP time-to-live field --spoof-mac \u0026lt;mac address/prefix/vendor name\u0026gt;: Spoof your MAC address --badsum: Send packets with a bogus TCP/UDP/SCTP checksum OUTPUT: -oN/-oX/-oS/-oG \u0026lt;file\u0026gt;: Output scan in normal, XML, s|\u0026lt;rIpt kIddi3, and Grepable format, respectively, to the given filename. -oA \u0026lt;basename\u0026gt;: Output in the three major formats at once -v: Increase verbosity level (use -vv or more for greater effect) -d: Increase debugging level (use -dd or more for greater effect) --reason: Display the reason a port is in a particular state --open: Only show open (or possibly open) ports --packet-trace: Show all packets sent and received --iflist: Print host interfaces and routes (for debugging) --append-output: Append to rather than clobber specified output files --resume \u0026lt;filename\u0026gt;: Resume an aborted scan --noninteractive: Disable runtime interactions via keyboard --stylesheet \u0026lt;path/URL\u0026gt;: XSL stylesheet to transform XML output to HTML --webxml: Reference stylesheet from Nmap.Org for more portable XML --no-stylesheet: Prevent associating of XSL stylesheet w/XML output MISC: -6: Enable IPv6 scanning -A: Enable OS detection, version detection, script scanning, and traceroute --datadir \u0026lt;dirname\u0026gt;: Specify custom Nmap data file location --send-eth/--send-ip: Send using raw ethernet frames or IP packets --privileged: Assume that the user is fully privileged --unprivileged: Assume the user lacks raw socket privileges -V: Print version number -h: Print this help summary page. EXAMPLES: nmap -v -A scanme.nmap.org nmap -v -sn 192.168.0.0/16 10.0.0.0/8 nmap -v -iR 10000 -Pn -p 80 SEE THE MAN PAGE (https://nmap.org/book/man.html) FOR MORE OPTIONS AND EXAMPLES TARGET SPECIFICATION Everything on the Nmap command-line that isn't an option (or option argument) is treated as a target host specification. The simplest case is to specify a target IP address or hostname for scanning. When a hostname is given as a target, it is resolved via the Domain Name System (DNS) to determine the IP address to scan. If the name resolves to more than one IP address, only the first one will be scanned. To make Nmap scan all the resolved addresses instead of only the first one, use the --resolve-all option. Sometimes you wish to scan a whole network of adjacent hosts. For this, Nmap supports CIDR-style addressing. You can append /numbits to an IP address or hostname and Nmap will scan every IP address for which the first numbits are the same as for the reference IP or hostname given. For example, 192.168.10.0/24 would scan the 256 hosts between 192.168.10.0 (binary: 11000000 10101000 00001010 00000000) and 192.168.10.255 (binary: 11000000 10101000 00001010 11111111), inclusive. 192.168.10.40/24 would scan exactly the same targets. Given that the host scanme.nmap.org is at the IP address 64.13.134.52, the specification scanme.nmap.org/16 would scan the 65,536 IP addresses between 64.13.0.0 and 64.13.255.255. The smallest allowed value is /0, which targets the whole Internet. The largest value for IPv4 is /32, which scans just the named host or IP address because all address bits are fixed. The largest value for IPv6 is /128, which does the same thing. CIDR notation is short but not always flexible enough. For example, you might want to scan 192.168.0.0/16 but skip any IPs ending with .0 or .255 because they may be used as subnet network and broadcast addresses. Nmap supports this through octet range addressing. Rather than specify a normal IP address, you can specify a comma-separated list of numbers or ranges for each octet. For example, 192.168.0-255.1-254 will skip all addresses in the range that end in .0 or .255, and 192.168.3-5,7.1 will scan the four addresses 192.168.3.1, 192.168.4.1, 192.168.5.1, and 192.168.7.1. Either side of a range may be omitted; the default values are 0 on the left and 255 on the right. Using - by itself is the same as 0-255, but remember to use 0- in the first octet so the target specification doesn't look like a command-line option. Ranges need not be limited to the final octets: the specifier 0-255.0-255.13.37 will perform an Internet-wide scan for all IP addresses ending in 13.37. This sort of broad sampling can be useful for Internet surveys and research. IPv6 addresses can be specified by their fully qualified IPv6 address or hostname or with CIDR notation for subnets. Octet ranges aren't yet supported for IPv6. IPv6 addresses with non-global scope need to have a zone ID suffix. On Unix systems, this is a percent sign followed by an interface name; a complete address might be fe80::a8bb:ccff:fedd:eeff%eth0. On Windows, use an interface index number in place of an interface name: fe80::a8bb:ccff:fedd:eeff%1. You can see a list of interface indexes by running the command netsh.exe interface ipv6 show interface. Nmap accepts multiple host specifications on the command line, and they don't need to be the same type. The command nmap scanme.nmap.org 192.168.0.0/8 10.0.0,1,3-7.- does what you would expect. While targets are usually specified on the command lines, the following options are also available to control target selection: -iL inputfilename (Input from list) Reads target specifications from inputfilename. Passing a huge list of hosts is often awkward on the command line, yet it is a common desire. For example, your DHCP server might export a list of 10,000 current leases that you wish to scan. Or maybe you want to scan all IP addresses except for those to locate hosts using unauthorized static IP addresses. Simply generate the list of hosts to scan and pass that filename to Nmap as an argument to the -iL option. Entries can be in any of the formats accepted by Nmap on the command line (IP address, hostname, CIDR, IPv6, or octet ranges). Each entry must be separated by one or more spaces, tabs, or newlines. You can specify a hyphen (-) as the filename if you want Nmap to read hosts from standard input rather than an actual file. The input file may contain comments that start with # and extend to the end of the line. -iR num hosts (Choose random targets) For Internet-wide surveys and other research, you may want to choose targets at random. The num hosts argument tells Nmap how many IPs to generate. Undesirable IPs such as those in certain private, multicast, or unallocated address ranges are automatically skipped. The argument 0 can be specified for a never-ending scan. Keep in mind that some network administrators bristle at unauthorized scans of their networks and may complain. Use this option at your own risk! If you find yourself really bored one rainy afternoon, try the command nmap -Pn -sS -p 80 -iR 0 --open to locate random web servers for browsing. --exclude host1[,host2[,...]] (Exclude hosts/networks) Specifies a comma-separated list of targets to be excluded from the scan even if they are part of the overall network range you specify. The list you pass in uses normal Nmap syntax, so it can include hostnames, CIDR netblocks, octet ranges, etc. This can be useful when the network you wish to scan includes untouchable mission-critical servers, systems that are known to react adversely to port scans, or subnets administered by other people. --excludefile exclude_file (Exclude list from file) This offers the same functionality as the --exclude option, except that the excluded targets are provided in a newline-, space-, or tab-delimited exclude_file rather than on the command line. The exclude file may contain comments that start with # and extend to the end of the line. -n (No DNS resolution) Tells Nmap to never do reverse DNS resolution on the active IP addresses it finds. Since DNS can be slow even with Nmap's built-in parallel stub resolver, this option can slash scanning times. -R (DNS resolution for all targets) Tells Nmap to always do reverse DNS resolution on the target IP addresses. Normally reverse DNS is only performed against responsive (online) hosts. --resolve-all (Scan each resolved address) If a hostname target resolves to more than one address, scan all of them. The default behavior is to only scan the first resolved address. Regardless, only addresses in the appropriate address family will be scanned: IPv4 by default, IPv6 with -6. --unique (Scan each address only once) Scan each IP address only once. The default behavior is to scan each address as many times as it is specified in the target list, such as when network ranges overlap or different hostnames resolve to the same address. --system-dns (Use system DNS resolver) By default, Nmap reverse-resolves IP addresses by sending queries directly to the name servers configured on your host and then listening for responses. Many requests (often dozens) are performed in parallel to improve performance. Specify this option to use your system resolver instead (one IP at a time via the getnameinfo call). This is slower and rarely useful unless you find a bug in the Nmap parallel resolver (please let us know if you do). The system resolver is always used for forward lookups (getting an IP address from a hostname). --dns-servers server1[,server2[,...]] (Servers to use for reverse DNS queries) By default, Nmap determines your DNS servers (for rDNS resolution) from your resolv.conf file (Unix) or the Registry (Win32). Alternatively, you may use this option to specify alternate servers. This option is not honored if you are using --system-dns. Using multiple DNS servers is often faster, especially if you choose authoritative servers for your target IP space. This option can also improve stealth, as your requests can be bounced off just about any recursive DNS server on the Internet. This option also comes in handy when scanning private networks. Sometimes only a few name servers provide proper rDNS information, and you may not even know where they are. You can scan the network for port 53 (perhaps with version detection), then try Nmap list scans (-sL) specifying each name server one at a time with --dns-servers until you find one which works. This option might not be honored if the DNS response exceeds the size of a UDP packet. In such a situation our DNS resolver will make the best effort to extract a response from the truncated packet, and if not successful it will fall back to using the system resolver. Also, responses that contain CNAME aliases will fall back to the system resolver. HOST DISCOVERY One of the very first steps in any network reconnaissance mission is to reduce a (sometimes huge) set of IP ranges into a list of active or interesting hosts. Scanning every port of every single IP address is slow and usually unnecessary. Of course what makes a host interesting depends greatly on the scan purposes. Network administrators may only be interested in hosts running a certain service, while security auditors may care about every single device with an IP address. An administrator may be comfortable using just an ICMP ping to locate hosts on his internal network, while an external penetration tester may use a diverse set of dozens of probes in an attempt to evade firewall restrictions. Because host discovery needs are so diverse, Nmap offers a wide variety of options for customizing the techniques used. Host discovery is sometimes called ping scan, but it goes well beyond the simple ICMP echo request packets associated with the ubiquitous ping tool. Users can skip the discovery step entirely with a list scan (-sL) or by disabling host discovery (-Pn), or engage the network with arbitrary combinations of multi-port TCP SYN/ACK, UDP, SCTP INIT and ICMP probes. The goal of these probes is to solicit responses which demonstrate that an IP address is actually active (is being used by a host or network device). On many networks, only a small percentage of IP addresses are active at any given time. This is particularly common with private address space such as 10.0.0.0/8. That network has 16 million IPs, but I have seen it used by companies with less than a thousand machines. Host discovery can find those machines in a sparsely allocated sea of IP addresses. If no host discovery options are given, Nmap sends an ICMP echo request, a TCP SYN packet to port 443, a TCP ACK packet to port 80, and an ICMP timestamp request. (For IPv6, the ICMP timestamp request is omitted because it is not part of ICMPv6.) These defaults are equivalent to the -PE -PS443 -PA80 -PP options. The exceptions to this are the ARP (for IPv4) and Neighbor Discovery (for IPv6) scans which are used for any targets on a local ethernet network. For unprivileged Unix shell users, the default probes are a SYN packet to ports 80 and 443 using the connect system call. This host discovery is often sufficient when scanning local networks, but a more comprehensive set of discovery probes is recommended for security auditing. The -P* options (which select ping types) can be combined. You can increase your odds of penetrating strict firewalls by sending many probe types using different TCP ports/flags and ICMP codes. Also note that ARP/Neighbor Discovery is done by default against targets on a local Ethernet network even if you specify other -P* options, because it is almost always faster and more effective. By default, Nmap does host discovery and then performs a port scan against each host it determines is online. This is true even if you specify non-default host discovery types such as UDP probes (-PU). Read about the -sn option to learn how to perform only host discovery, or use -Pn to skip host discovery and port scan all target addresses. The following options control host discovery: -sL (List Scan) The list scan is a degenerate form of host discovery that simply lists each host of the network(s) specified, without sending any packets to the target hosts. By default, Nmap still does reverse-DNS resolution on the hosts to learn their names. It is often surprising how much useful information simple hostnames give out. For example, fw.chi is the name of one company's Chicago firewall. Nmap also reports the total number of IP addresses at the end. The list scan is a good sanity check to ensure that you have proper IP addresses for your targets. If the hosts sport domain names you do not recognize, it is worth investigating further to prevent scanning the wrong company's network. Since the idea is to simply print a list of target hosts, options for higher level functionality such as port scanning, OS detection, or host discovery cannot be combined with this. If you wish to disable host discovery while still performing such higher level functionality, read up on the -Pn (skip host discovery) option. -sn (No port scan) This option tells Nmap not to do a port scan after host discovery, and only print out the available hosts that responded to the host discovery probes. This is often known as a “ping scan”, but you can also request that traceroute and NSE host scripts be run. This is by default one step more intrusive than the list scan, and can often be used for the same purposes. It allows light reconnaissance of a target network without attracting much attention. Knowing how many hosts are up is more valuable to attackers than the list provided by list scan of every single IP and host name. Systems administrators often find this option valuable as well. It can easily be used to count available machines on a network or monitor server availability. This is often called a ping sweep, and is more reliable than pinging the broadcast address because many hosts do not reply to broadcast queries. The default host discovery done with -sn consists of an ICMP echo request, TCP SYN to port 443, TCP ACK to port 80, and an ICMP timestamp request by default. When executed by an unprivileged user, only SYN packets are sent (using a connect call) to ports 80 and 443 on the target. When a privileged user tries to scan targets on a local ethernet network, ARP requests are used unless --send-ip was specified. The -sn option can be combined with any of the discovery probe types (the -P* options) for greater flexibility. If any of those probe type and port number options are used, the default probes are overridden. When strict firewalls are in place between the source host running Nmap and the target network, using those advanced techniques is recommended. Otherwise hosts could be missed when the firewall drops probes or their responses. In previous releases of Nmap, -sn was known as -sP. -Pn (No ping) This option skips the host discovery stage altogether. Normally, Nmap uses this stage to determine active machines for heavier scanning and to gauge the speed of the network. By default, Nmap only performs heavy probing such as port scans, version detection, or OS detection against hosts that are found to be up. Disabling host discovery with -Pn causes Nmap to attempt the requested scanning functions against every target IP address specified. So if a /16 sized network is specified on the command line, all 65,536 IP addresses are scanned. Proper host discovery is skipped as with the list scan, but instead of stopping and printing the target list, Nmap continues to perform requested functions as if each target IP is active. Default timing parameters are used, which may result in slower scans. To skip host discovery and port scan, while still allowing NSE to run, use the two options -Pn -sn together. For machines on a local ethernet network, ARP scanning will still be performed (unless --disable-arp-ping or --send-ip is specified) because Nmap needs MAC addresses to further scan target hosts. In previous versions of Nmap, -Pn was -P0 and -PN. -PS port list (TCP SYN Ping) This option sends an empty TCP packet with the SYN flag set. The default destination port is 80 (configurable at compile time by changing DEFAULT_TCP_PROBE_PORT_SPEC in nmap.h). Alternate ports can be specified as a parameter. The syntax is the same as for the -p except that port type specifiers like T: are not allowed. Examples are -PS22 and -PS22-25,80,113,1050,35000. Note that there can be no space between -PS and the port list. If multiple probes are specified they will be sent in parallel. The SYN flag suggests to the remote system that you are attempting to establish a connection. Normally the destination port will be closed, and a RST (reset) packet sent back. If the port happens to be open, the target will take the second step of a TCP three-way-handshake by responding with a SYN/ACK TCP packet. The machine running Nmap then tears down the nascent connection by responding with a RST rather than sending an ACK packet which would complete the three-way-handshake and establish a full connection. The RST packet is sent by the kernel of the machine running Nmap in response to the unexpected SYN/ACK, not by Nmap itself. Nmap does not care whether the port is open or closed. Either the RST or SYN/ACK response discussed previously tell Nmap that the host is available and responsive. On Unix boxes, only the privileged user root is generally able to send and receive raw TCP packets. For unprivileged users, a workaround is automatically employed whereby the connect system call is initiated against each target port. This has the effect of sending a SYN packet to the target host, in an attempt to establish a connection. If connect returns with a quick success or an ECONNREFUSED failure, the underlying TCP stack must have received a SYN/ACK or RST and the host is marked available. If the connection attempt is left hanging until a timeout is reached, the host is marked as down. -PA port list (TCP ACK Ping) The TCP ACK ping is quite similar to the just-discussed SYN ping. The difference, as you could likely guess, is that the TCP ACK flag is set instead of the SYN flag. Such an ACK packet purports to be acknowledging data over an established TCP connection, but no such connection exists. So remote hosts should always respond with a RST packet, disclosing their existence in the process. The -PA option uses the same default port as the SYN probe (80) and can also take a list of destination ports in the same format. If an unprivileged user tries this, the connect workaround discussed previously is used. This workaround is imperfect because connect is actually sending a SYN packet rather than an ACK. The reason for offering both SYN and ACK ping probes is to maximize the chances of bypassing firewalls. Many administrators configure routers and other simple firewalls to block incoming SYN packets except for those destined for public services like the company web site or mail server. This prevents other incoming connections to the organization, while allowing users to make unobstructed outgoing connections to the Internet. This non-stateful approach takes up few resources on the firewall/router and is widely supported by hardware and software filters. The Linux Netfilter/iptables firewall software offers the --syn convenience option to implement this stateless approach. When stateless firewall rules such as this are in place, SYN ping probes (-PS) are likely to be blocked when sent to closed target ports. In such cases, the ACK probe shines as it cuts right through these rules. Another common type of firewall uses stateful rules that drop unexpected packets. This feature was initially found mostly on high-end firewalls, though it has become much more common over the years. The Linux Netfilter/iptables system supports this through the --state option, which categorizes packets based on connection state. A SYN probe is more likely to work against such a system, as unexpected ACK packets are generally recognized as bogus and dropped. A solution to this quandary is to send both SYN and ACK probes by specifying -PS and -PA. -PU port list (UDP Ping) Another host discovery option is the UDP ping, which sends a UDP packet to the given ports. For most ports, the packet will be empty, though some use a protocol-specific payload that is more likely to elicit a response. The payload database is described at https://nmap.org/book/nmap-payloads.html. Packet content can also be affected with the --data, --data-string, and --data-length options. The port list takes the same format as with the previously discussed -PS and -PA options. If no ports are specified, the default is 40125. This default can be configured at compile-time by changing DEFAULT_UDP_PROBE_PORT_SPEC in nmap.h. A highly uncommon port is used by default because sending to open ports is often undesirable for this particular scan type. Upon hitting a closed port on the target machine, the UDP probe should elicit an ICMP port unreachable packet in return. This signifies to Nmap that the machine is up and available. Many other types of ICMP errors, such as host/network unreachables or TTL exceeded are indicative of a down or unreachable host. A lack of response is also interpreted this way. If an open port is reached, most services simply ignore the empty packet and fail to return any response. This is why the default probe port is 40125, which is highly unlikely to be in use. A few services, such as the Character Generator (chargen) protocol, will respond to an empty UDP packet, and thus disclose to Nmap that the machine is available. The primary advantage of this scan type is that it bypasses firewalls and filters that only screen TCP. For example, I once owned a Linksys BEFW11S4 wireless broadband router. The external interface of this device filtered all TCP ports by default, but UDP probes would still elicit port unreachable messages and thus give away the device. -PY port list (SCTP INIT Ping) This option sends an SCTP packet containing a minimal INIT chunk. The default destination port is 80 (configurable at compile time by changing DEFAULT_SCTP_PROBE_PORT_SPEC in nmap.h). Alternate ports can be specified as a parameter. The syntax is the same as for the -p except that port type specifiers like S: are not allowed. Examples are -PY22 and -PY22,80,179,5060. Note that there can be no space between -PY and the port list. If multiple probes are specified they will be sent in parallel. The INIT chunk suggests to the remote system that you are attempting to establish an association. Normally the destination port will be closed, and an ABORT chunk will be sent back. If the port happens to be open, the target will take the second step of an SCTP four-way-handshake by responding with an INIT-ACK chunk. If the machine running Nmap has a functional SCTP stack, then it tears down the nascent association by responding with an ABORT chunk rather than sending a COOKIE-ECHO chunk which would be the next step in the four-way-handshake. The ABORT packet is sent by the kernel of the machine running Nmap in response to the unexpected INIT-ACK, not by Nmap itself. Nmap does not care whether the port is open or closed. Either the ABORT or INIT-ACK response discussed previously tell Nmap that the host is available and responsive. On Unix boxes, only the privileged user root is generally able to send and receive raw SCTP packets. Using SCTP INIT Pings is currently not possible for unprivileged users. -PE; -PP; -PM (ICMP Ping Types) In addition to the unusual TCP, UDP and SCTP host discovery types discussed previously, Nmap can send the standard packets sent by the ubiquitous ping program. Nmap sends an ICMP type 8 (echo request) packet to the target IP addresses, expecting a type 0 (echo reply) in return from available hosts. Unfortunately for network explorers, many hosts and firewalls now block these packets, rather than responding as required by RFC 1122[2]. For this reason, ICMP-only scans are rarely reliable enough against unknown targets over the Internet. But for system administrators monitoring an internal network, they can be a practical and efficient approach. Use the -PE option to enable this echo request behavior. While echo request is the standard ICMP ping query, Nmap does not stop there. The ICMP standards (RFC 792[3] and RFC 950[4] ) also specify timestamp request, information request, and address mask request packets as codes 13, 15, and 17, respectively. While the ostensible purpose for these queries is to learn information such as address masks and current times, they can easily be used for host discovery. A system that replies is up and available. Nmap does not currently implement information request packets, as they are not widely supported. RFC 1122 insists that “a host SHOULD NOT implement these messages”. Timestamp and address mask queries can be sent with the -PP and -PM options, respectively. A timestamp reply (ICMP code 14) or address mask reply (code 18) discloses that the host is available. These two queries can be valuable when administrators specifically block echo request packets while forgetting that other ICMP queries can be used for the same purpose. -PO protocol list (IP Protocol Ping) One of the newer host discovery options is the IP protocol ping, which sends IP packets with the specified protocol number set in their IP header. The protocol list takes the same format as do port lists in the previously discussed TCP, UDP and SCTP host discovery options. If no protocols are specified, the default is to send multiple IP packets for ICMP (protocol 1), IGMP (protocol 2), and IP-in-IP (protocol 4). The default protocols can be configured at compile-time by changing DEFAULT_PROTO_PROBE_PORT_SPEC in nmap.h. Note that for the ICMP, IGMP, TCP (protocol 6), UDP (protocol 17) and SCTP (protocol 132), the packets are sent with the proper protocol headers while other protocols are sent with no additional data beyond the IP header (unless any of --data, --data-string, or --data-length options are specified). This host discovery method looks for either responses using the same protocol as a probe, or ICMP protocol unreachable messages which signify that the given protocol isn't supported on the destination host. Either type of response signifies that the target host is alive. --disable-arp-ping (No ARP or ND Ping) Nmap normally does ARP or IPv6 Neighbor Discovery (ND) discovery of locally connected ethernet hosts, even if other host discovery options such as -Pn or -PE are used. To disable this implicit behavior, use the --disable-arp-ping option. The default behavior is normally faster, but this option is useful on networks using proxy ARP, in which a router speculatively replies to all ARP requests, making every target appear to be up according to ARP scan. --discovery-ignore-rst In some cases, firewalls may spoof TCP reset (RST) replies in response to probes to unoccupied or disallowed addresses. Since Nmap ordinarily considers RST replies to be proof that the target is up, this can lead to wasted time scanning targets that aren't there. Using the --discovery-ignore-rst will prevent Nmap from considering these replies during host discovery. You may need to select extra host discovery options to ensure you don't miss targets in this case. --traceroute (Trace path to host) Traceroutes are performed post-scan using information from the scan results to determine the port and protocol most likely to reach the target. It works with all scan types except connect scans (-sT) and idle scans (-sI). All traces use Nmap's dynamic timing model and are performed in parallel. Traceroute works by sending packets with a low TTL (time-to-live) in an attempt to elicit ICMP Time Exceeded messages from intermediate hops between the scanner and the target host. Standard traceroute implementations start with a TTL of 1 and increment the TTL until the destination host is reached. Nmap's traceroute starts with a high TTL and then decrements the TTL until it reaches zero. Doing it backwards lets Nmap employ clever caching algorithms to speed up traces over multiple hosts. On average Nmap sends 5–10 fewer packets per host, depending on network conditions. If a single subnet is being scanned (i.e. 192.168.0.0/24) Nmap may only have to send two packets to most hosts. PORT SCANNING BASICS While Nmap has grown in functionality over the years, it began as an efficient port scanner, and that remains its core function. The simple command nmap target scans 1,000 TCP ports on the host target. While many port scanners have traditionally lumped all ports into the open or closed states, Nmap is much more granular. It divides ports into six states: open, closed, filtered, unfiltered, open|filtered, or closed|filtered. These states are not intrinsic properties of the port itself, but describe how Nmap sees them. For example, an Nmap scan from the same network as the target may show port 135/tcp as open, while a scan at the same time with the same options from across the Internet might show that port as filtered. The six port states recognized by Nmap open An application is actively accepting TCP connections, UDP datagrams or SCTP associations on this port. Finding these is often the primary goal of port scanning. Security-minded people know that each open port is an avenue for attack. Attackers and pen-testers want to exploit the open ports, while administrators try to close or protect them with firewalls without thwarting legitimate users. Open ports are also interesting for non-security scans because they show services available for use on the network. closed A closed port is accessible (it receives and responds to Nmap probe packets), but there is no application listening on it. They can be helpful in showing that a host is up on an IP address (host discovery, or ping scanning), and as part of OS detection. Because closed ports are reachable, it may be worth scanning later in case some open up. Administrators may want to consider blocking such ports with a firewall. Then they would appear in the filtered state, discussed next. filtered Nmap cannot determine whether the port is open because packet filtering prevents its probes from reaching the port. The filtering could be from a dedicated firewall device, router rules, or host-based firewall software. These ports frustrate attackers because they provide so little information. Sometimes they respond with ICMP error messages such as type 3 code 13 (destination unreachable: communication administratively prohibited), but filters that simply drop probes without responding are far more common. This forces Nmap to retry several times just in case the probe was dropped due to network congestion rather than filtering. This slows down the scan dramatically. unfiltered The unfiltered state means that a port is accessible, but Nmap is unable to determine whether it is open or closed. Only the ACK scan, which is used to map firewall rulesets, classifies ports into this state. Scanning unfiltered ports with other scan types such as Window scan, SYN scan, or FIN scan, may help resolve whether the port is open. open|filtered Nmap places ports in this state when it is unable to determine whether a port is open or filtered. This occurs for scan types in which open ports give no response. The lack of response could also mean that a packet filter dropped the probe or any response it elicited. So Nmap does not know for sure whether the port is open or being filtered. The UDP, IP protocol, FIN, NULL, and Xmas scans classify ports this way. closed|filtered This state is used when Nmap is unable to determine whether a port is closed or filtered. It is only used for the IP ID idle scan. PORT SCANNING TECHNIQUES As a novice performing automotive repair, I can struggle for hours trying to fit my rudimentary tools (hammer, duct tape, wrench, etc.) to the task at hand. When I fail miserably and tow my jalopy to a real mechanic, he invariably fishes around in a huge tool chest until pulling out the perfect gizmo which makes the job seem effortless. The art of port scanning is similar. Experts understand the dozens of scan techniques and choose the appropriate one (or combination) for a given task. Inexperienced users and script kiddies, on the other hand, try to solve every problem with the default SYN scan. Since Nmap is free, the only barrier to port scanning mastery is knowledge. That certainly beats the automotive world, where it may take great skill to determine that you need a strut spring compressor, then you still have to pay thousands of dollars for it. Most of the scan types are only available to privileged users. This is because they send and receive raw packets, which requires root access on Unix systems. Using an administrator account on Windows is recommended, though Nmap sometimes works for unprivileged users on that platform when Npcap has already been loaded into the OS. Requiring root privileges was a serious limitation when Nmap was released in 1997, as many users only had access to shared shell accounts. Now, the world is different. Computers are cheaper, far more people have always-on direct Internet access, and desktop Unix systems (including Linux and Mac OS X) are prevalent. A Windows version of Nmap is now available, allowing it to run on even more desktops. For all these reasons, users have less need to run Nmap from limited shared shell accounts. This is fortunate, as the privileged options make Nmap far more powerful and flexible. While Nmap attempts to produce accurate results, keep in mind that all of its insights are based on packets returned by the target machines (or firewalls in front of them). Such hosts may be untrustworthy and send responses intended to confuse or mislead Nmap. Much more common are non-RFC-compliant hosts that do not respond as they should to Nmap probes. FIN, NULL, and Xmas scans are particularly susceptible to this problem. Such issues are specific to certain scan types and so are discussed in the individual scan type entries. This section documents the dozen or so port scan techniques supported by Nmap. Only one method may be used at a time, except that UDP scan (-sU) and any one of the SCTP scan types (-sY, -sZ) may be combined with any one of the TCP scan types. As a memory aid, port scan type options are of the form -sC, where C is a prominent character in the scan name, usually the first. The one exception to this is the deprecated FTP bounce scan (-b). By default, Nmap performs a SYN Scan, though it substitutes a connect scan if the user does not have proper privileges to send raw packets (requires root access on Unix). Of the scans listed in this section, unprivileged users can only execute connect and FTP bounce scans. -sS (TCP SYN scan) SYN scan is the default and most popular scan option for good reasons. It can be performed quickly, scanning thousands of ports per second on a fast network not hampered by restrictive firewalls. It is also relatively unobtrusive and stealthy since it never completes TCP connections. SYN scan works against any compliant TCP stack rather than depending on idiosyncrasies of specific platforms as Nmap's FIN/NULL/Xmas, Maimon and idle scans do. It also allows clear, reliable differentiation between the open, closed, and filtered states. This technique is often referred to as half-open scanning, because you don't open a full TCP connection. You send a SYN packet, as if you are going to open a real connection and then wait for a response. A SYN/ACK indicates the port is listening (open), while a RST (reset) is indicative of a non-listener. If no response is received after several retransmissions, the port is marked as filtered. The port is also marked filtered if an ICMP unreachable error (type 3, code 0, 1, 2, 3, 9, 10, or 13) is received. The port is also considered open if a SYN packet (without the ACK flag) is received in response. This can be due to an extremely rare TCP feature known as a simultaneous open or split handshake connection (see https://nmap.org/misc/split-handshake.pdf). -sT (TCP connect scan) TCP connect scan is the default TCP scan type when SYN scan is not an option. This is the case when a user does not have raw packet privileges. Instead of writing raw packets as most other scan types do, Nmap asks the underlying operating system to establish a connection with the target machine and port by issuing the connect system call. This is the same high-level system call that web browsers, P2P clients, and most other network-enabled applications use to establish a connection. It is part of a programming interface known as the Berkeley Sockets API. Rather than read raw packet responses off the wire, Nmap uses this API to obtain status information on each connection attempt. When SYN scan is available, it is usually a better choice. Nmap has less control over the high level connect call than with raw packets, making it less efficient. The system call completes connections to open target ports rather than performing the half-open reset that SYN scan does. Not only does this take longer and require more packets to obtain the same information, but target machines are more likely to log the connection. A decent IDS will catch either, but most machines have no such alarm system. Many services on your average Unix system will add a note to syslog, and sometimes a cryptic error message, when Nmap connects and then closes the connection without sending data. Truly pathetic services crash when this happens, though that is uncommon. An administrator who sees a bunch of connection attempts in her logs from a single system should know that she has been connect scanned. -sU (UDP scans) While most popular services on the Internet run over the TCP protocol, UDP[5] services are widely deployed. DNS, SNMP, and DHCP (registered ports 53, 161/162, and 67/68) are three of the most common. Because UDP scanning is generally slower and more difficult than TCP, some security auditors ignore these ports. This is a mistake, as exploitable UDP services are quite common and attackers certainly don't ignore the whole protocol. Fortunately, Nmap can help inventory UDP ports. UDP scan is activated with the -sU option. It can be combined with a TCP scan type such as SYN scan (-sS) to check both protocols during the same run. UDP scan works by sending a UDP packet to every targeted port. For some common ports such as 53 and 161, a protocol-specific payload is sent to increase response rate, but for most ports the packet is empty unless the --data, --data-string, or --data-length options are specified. If an ICMP port unreachable error (type 3, code 3) is returned, the port is closed. Other ICMP unreachable errors (type 3, codes 0, 1, 2, 9, 10, or 13) mark the port as filtered. Occasionally, a service will respond with a UDP packet, proving that it is open. If no response is received after retransmissions, the port is classified as open|filtered. This means that the port could be open, or perhaps packet filters are blocking the communication. Version detection (-sV) can be used to help differentiate the truly open ports from the filtered ones. A big challenge with UDP scanning is doing it quickly. Open and filtered ports rarely send any response, leaving Nmap to time out and then conduct retransmissions just in case the probe or response were lost. Closed ports are often an even bigger problem. They usually send back an ICMP port unreachable error. But unlike the RST packets sent by closed TCP ports in response to a SYN or connect scan, many hosts rate limit ICMP port unreachable messages by default. Linux and Solaris are particularly strict about this. For example, the Linux 2.4.20 kernel limits destination unreachable messages to one per second (in net/ipv4/icmp.c). Nmap detects rate limiting and slows down accordingly to avoid flooding the network with useless packets that the target machine will drop. Unfortunately, a Linux-style limit of one packet per second makes a 65,536-port scan take more than 18 hours. Ideas for speeding your UDP scans up include scanning more hosts in parallel, doing a quick scan of just the popular ports first, scanning from behind the firewall, and using --host-timeout to skip slow hosts. -sY (SCTP INIT scan) SCTP[6] is a relatively new alternative to the TCP and UDP protocols, combining most characteristics of TCP and UDP, and also adding new features like multi-homing and multi-streaming. It is mostly being used for SS7/SIGTRAN related services but has the potential to be used for other applications as well. SCTP INIT scan is the SCTP equivalent of a TCP SYN scan. It can be performed quickly, scanning thousands of ports per second on a fast network not hampered by restrictive firewalls. Like SYN scan, INIT scan is relatively unobtrusive and stealthy, since it never completes SCTP associations. It also allows clear, reliable differentiation between the open, closed, and filtered states. This technique is often referred to as half-open scanning, because you don't open a full SCTP association. You send an INIT chunk, as if you are going to open a real association and then wait for a response. An INIT-ACK chunk indicates the port is listening (open), while an ABORT chunk is indicative of a non-listener. If no response is received after several retransmissions, the port is marked as filtered. The port is also marked filtered if an ICMP unreachable error (type 3, code 0, 1, 2, 3, 9, 10, or 13) is received. -sN; -sF; -sX (TCP NULL, FIN, and Xmas scans) These three scan types (even more are possible with the --scanflags option described in the next section) exploit a subtle loophole in the TCP RFC[7] to differentiate between open and closed ports. Page 65 of RFC 793 says that “if the [destination] port state is CLOSED .... an incoming segment not containing a RST causes a RST to be sent in response.” Then the next page discusses packets sent to open ports without the SYN, RST, or ACK bits set, stating that: “you are unlikely to get here, but if you do, drop the segment, and return.” When scanning systems compliant with this RFC text, any packet not containing SYN, RST, or ACK bits will result in a returned RST if the port is closed and no response at all if the port is open. As long as none of those three bits are included, any combination of the other three (FIN, PSH, and URG) are OK. Nmap exploits this with three scan types: Null scan (-sN) Does not set any bits (TCP flag header is 0) FIN scan (-sF) Sets just the TCP FIN bit. Xmas scan (-sX) Sets the FIN, PSH, and URG flags, lighting the packet up like a Christmas tree. These three scan types are exactly the same in behavior except for the TCP flags set in probe packets. If a RST packet is received, the port is considered closed, while no response means it is open|filtered. The port is marked filtered if an ICMP unreachable error (type 3, code 0, 1, 2, 3, 9, 10, or 13) is received. The key advantage to these scan types is that they can sneak through certain non-stateful firewalls and packet filtering routers. Another advantage is that these scan types are a little more stealthy than even a SYN scan. Don't count on this though—most modern IDS products can be configured to detect them. The big downside is that not all systems follow RFC 793 to the letter. A number of systems send RST responses to the probes regardless of whether the port is open or not. This causes all of the ports to be labeled closed. Major operating systems that do this are Microsoft Windows, many Cisco devices, BSDI, and IBM OS/400. This scan does work against most Unix-based systems though. Another downside of these scans is that they can't distinguish open ports from certain filtered ones, leaving you with the response open|filtered. -sA (TCP ACK scan) This scan is different than the others discussed so far in that it never determines open (or even open|filtered) ports. It is used to map out firewall rulesets, determining whether they are stateful or not and which ports are filtered. The ACK scan probe packet has only the ACK flag set (unless you use --scanflags). When scanning unfiltered systems, open and closed ports will both return a RST packet. Nmap then labels them as unfiltered, meaning that they are reachable by the ACK packet, but whether they are open or closed is undetermined. Ports that don't respond, or send certain ICMP error messages back (type 3, code 0, 1, 2, 3, 9, 10, or 13), are labeled filtered. -sW (TCP Window scan) Window scan is exactly the same as ACK scan except that it exploits an implementation detail of certain systems to differentiate open ports from closed ones, rather than always printing unfiltered when a RST is returned. It does this by examining the TCP Window field of the RST packets returned. On some systems, open ports use a positive window size (even for RST packets) while closed ones have a zero window. So instead of always listing a port as unfiltered when it receives a RST back, Window scan lists the port as open or closed if the TCP Window value in that reset is positive or zero, respectively. This scan relies on an implementation detail of a minority of systems out on the Internet, so you can't always trust it. Systems that don't support it will usually return all ports closed. Of course, it is possible that the machine really has no open ports. If most scanned ports are closed but a few common port numbers (such as 22, 25, 53) are filtered, the system is most likely susceptible. Occasionally, systems will even show the exact opposite behavior. If your scan shows 1,000 open ports and three closed or filtered ports, then those three may very well be the truly open ones. -sM (TCP Maimon scan) The Maimon scan is named after its discoverer, Uriel Maimon. He described the technique in Phrack Magazine issue #49 (November 1996). Nmap, which included this technique, was released two issues later. This technique is exactly the same as NULL, FIN, and Xmas scans, except that the probe is FIN/ACK. According to RFC 793[7] (TCP), a RST packet should be generated in response to such a probe whether the port is open or closed. However, Uriel noticed that many BSD-derived systems simply drop the packet if the port is open. --scanflags (Custom TCP scan) Truly advanced Nmap users need not limit themselves to the canned scan types offered. The --scanflags option allows you to design your own scan by specifying arbitrary TCP flags. Let your creative juices flow, while evading intrusion detection systems whose vendors simply paged through the Nmap help adding specific rules! The --scanflags argument can be a numerical flag value such as 9 (PSH and FIN), but using symbolic names is easier. Just mash together any combination of URG, ACK, PSH, RST, SYN, and FIN. For example, --scanflags URGACKPSHRSTSYNFIN sets everything, though it's not very useful for scanning. The order these are specified in is irrelevant. In addition to specifying the desired flags, you can specify a TCP scan type (such as -sA or -sF). That base type tells Nmap how to interpret responses. For example, a SYN scan considers no-response to indicate a filtered port, while a FIN scan treats the same as open|filtered. Nmap will behave the same way it does for the base scan type, except that it will use the TCP flags you specify instead. If you don't specify a base type, SYN scan is used. -sZ (SCTP COOKIE ECHO scan) SCTP COOKIE ECHO scan is a more advanced SCTP scan. It takes advantage of the fact that SCTP implementations should silently drop packets containing COOKIE ECHO chunks on open ports, but send an ABORT if the port is closed. The advantage of this scan type is that it is not as obvious a port scan than an INIT scan. Also, there may be non-stateful firewall rulesets blocking INIT chunks, but not COOKIE ECHO chunks. Don't be fooled into thinking that this will make a port scan invisible; a good IDS will be able to detect SCTP COOKIE ECHO scans too. The downside is that SCTP COOKIE ECHO scans cannot differentiate between open and filtered ports, leaving you with the state open|filtered in both cases. -sI zombie host[:probeport] (idle scan) This advanced scan method allows for a truly blind TCP port scan of the target (meaning no packets are sent to the target from your real IP address). Instead, a unique side-channel attack exploits predictable IP fragmentation ID sequence generation on the zombie host to glean information about the open ports on the target. IDS systems will display the scan as coming from the zombie machine you specify (which must be up and meet certain criteria). This fascinating scan type is too complex to fully describe in this reference guide, so I wrote and posted an informal paper with full details at https://nmap.org/book/idlescan.html. Besides being extraordinarily stealthy (due to its blind nature), this scan type permits mapping out IP-based trust relationships between machines. The port listing shows open ports from the perspective of the zombie host. So you can try scanning a target using various zombies that you think might be trusted (via router/packet filter rules). You can add a colon followed by a port number to the zombie host if you wish to probe a particular port on the zombie for IP ID changes. Otherwise Nmap will use the port it uses by default for TCP pings (80). -sO (IP protocol scan) IP protocol scan allows you to determine which IP protocols (TCP, ICMP, IGMP, etc.) are supported by target machines. This isn't technically a port scan, since it cycles through IP protocol numbers rather than TCP or UDP port numbers. Yet it still uses the -p option to select scanned protocol numbers, reports its results within the normal port table format, and even uses the same underlying scan engine as the true port scanning methods. So it is close enough to a port scan that it belongs here. Besides being useful in its own right, protocol scan demonstrates the power of open-source software. While the fundamental idea is pretty simple, I had not thought to add it nor received any requests for such functionality. Then in the summer of 2000, Gerhard Rieger conceived the idea, wrote an excellent patch implementing it, and sent it to the announce mailing list (then called nmap-hackers). I incorporated that patch into the Nmap tree and released a new version the next day. Few pieces of commercial software have users enthusiastic enough to design and contribute their own improvements! Protocol scan works in a similar fashion to UDP scan. Instead of iterating through the port number field of a UDP packet, it sends IP packet headers and iterates through the eight-bit IP protocol field. The headers are usually empty, containing no data and not even the proper header for the claimed protocol. The exceptions are TCP, UDP, ICMP, SCTP, and IGMP. A proper protocol header for those is included since some systems won't send them otherwise and because Nmap already has functions to create them. Instead of watching for ICMP port unreachable messages, protocol scan is on the lookout for ICMP protocol unreachable messages. If Nmap receives any response in any protocol from the target host, Nmap marks that protocol as open. An ICMP protocol unreachable error (type 3, code 2) causes the protocol to be marked as closed while port unreachable (type 3, code 3) marks the protocol open. Other ICMP unreachable errors (type 3, code 0, 1, 9, 10, or 13) cause the protocol to be marked filtered (though they prove that ICMP is open at the same time). If no response is received after retransmissions, the protocol is marked open|filtered -b FTP relay host (FTP bounce scan) An interesting feature of the FTP protocol (RFC 959[8]) is support for so-called proxy FTP connections. This allows a user to connect to one FTP server, then ask that files be sent to a third-party server. Such a feature is ripe for abuse on many levels, so most servers have ceased supporting it. One of the abuses this feature allows is causing the FTP server to port scan other hosts. Simply ask the FTP server to send a file to each interesting port of a target host in turn. The error message will describe whether the port is open or not. This is a good way to bypass firewalls because organizational FTP servers are often placed where they have more access to other internal hosts than any old Internet host would. Nmap supports FTP bounce scan with the -b option. It takes an argument of the form username:password@server:port. Server is the name or IP address of a vulnerable FTP server. As with a normal URL, you may omit username:password, in which case anonymous login credentials (user: anonymous password:-wwwuser@) are used. The port number (and preceding colon) may be omitted as well, in which case the default FTP port (21) on server is used. This vulnerability was widespread in 1997 when Nmap was released, but has largely been fixed. Vulnerable servers are still around, so it is worth trying when all else fails. If bypassing a firewall is your goal, scan the target network for port 21 (or even for any FTP services if you scan all ports with version detection) and use the ftp-bounce NSE script. Nmap will tell you whether the host is vulnerable or not. If you are just trying to cover your tracks, you don't need to (and, in fact, shouldn't) limit yourself to hosts on the target network. Before you go scanning random Internet addresses for vulnerable FTP servers, consider that sysadmins may not appreciate you abusing their servers in this way. PORT SPECIFICATION AND SCAN ORDER In addition to all of the scan methods discussed previously, Nmap offers options for specifying which ports are scanned and whether the scan order is randomized or sequential. By default, Nmap scans the most common 1,000 ports for each protocol. -p port ranges (Only scan specified ports) This option specifies which ports you want to scan and overrides the default. Individual port numbers are OK, as are ranges separated by a hyphen (e.g. 1-1023). The beginning and/or end values of a range may be omitted, causing Nmap to use 1 and 65535, respectively. So you can specify -p- to scan ports from 1 through 65535. Scanning port zero is allowed if you specify it explicitly. For IP protocol scanning (-sO), this option specifies the protocol numbers you wish to scan for (0–255). When scanning a combination of protocols (e.g. TCP and UDP), you can specify a particular protocol by preceding the port numbers by T: for TCP, U: for UDP, S: for SCTP, or P: for IP Protocol. The qualifier lasts until you specify another qualifier. For example, the argument -p U:53,111,137,T:21-25,80,139,8080 would scan UDP ports 53, 111,and 137, as well as the listed TCP ports. Note that to scan both UDP and TCP, you have to specify -sU and at least one TCP scan type (such as -sS, -sF, or -sT). If no protocol qualifier is given, the port numbers are added to all protocol lists. Ports can also be specified by name according to what the port is referred to in the nmap-services. You can even use the wildcards * and ? with the names. For example, to scan FTP and all ports whose names begin with “http”, use -p ftp,http*. Be careful about shell expansions and quote the argument to -p if unsure. Ranges of ports can be surrounded by square brackets to indicate ports inside that range that appear in nmap-services. For example, the following will scan all ports in nmap-services equal to or below 1024: -p [-1024]. Be careful with shell expansions and quote the argument to -p if unsure. --exclude-ports port ranges (Exclude the specified ports from scanning) This option specifies which ports you do want Nmap to exclude from scanning. The port ranges are specified similar to -p. For IP protocol scanning (-sO), this option specifies the protocol numbers you wish to exclude (0–255). When ports are asked to be excluded, they are excluded from all types of scans (i.e. they will not be scanned under any circumstances). This also includes the discovery phase. -F (Fast (limited port) scan) Specifies that you wish to scan fewer ports than the default. Normally Nmap scans the most common 1,000 ports for each scanned protocol. With -F, this is reduced to 100. Nmap needs an nmap-services file with frequency information in order to know which ports are the most common. If port frequency information isn't available, perhaps because of the use of a custom nmap-services file, Nmap scans all named ports plus ports 1-1024. In that case, -F means to scan only ports that are named in the services file. -r (Don't randomize ports) By default, Nmap randomizes the scanned port order (except that certain commonly accessible ports are moved near the beginning for efficiency reasons). This randomization is normally desirable, but you can specify -r for sequential (sorted from lowest to highest) port scanning instead. --port-ratio ratio\u0026lt;decimal number between 0 and 1\u0026gt; Scans all ports in nmap-services file with a ratio greater than the one given. ratio must be between 0.0 and 1.0. --top-ports n Scans the n highest-ratio ports found in nmap-services file after excluding all ports specified by --exclude-ports. n must be 1 or greater. SERVICE AND VERSION DETECTION Point Nmap at a remote machine and it might tell you that ports 25/tcp, 80/tcp, and 53/udp are open. Using its nmap-services database of about 2,200 well-known services, Nmap would report that those ports probably correspond to a mail server (SMTP), web server (HTTP), and name server (DNS) respectively. This lookup is usually accurate—the vast majority of daemons listening on TCP port 25 are, in fact, mail servers. However, you should not bet your security on this! People can and do run services on strange ports. Even if Nmap is right, and the hypothetical server above is running SMTP, HTTP, and DNS servers, that is not a lot of information. When doing vulnerability assessments (or even simple network inventories) of your companies or clients, you really want to know which mail and DNS servers and versions are running. Having an accurate version number helps dramatically in determining which exploits a server is vulnerable to. Version detection helps you obtain this information. After TCP and/or UDP ports are discovered using one of the other scan methods, version detection interrogates those ports to determine more about what is actually running. The nmap-service-probes database contains probes for querying various services and match expressions to recognize and parse responses. Nmap tries to determine the service protocol (e.g. FTP, SSH, Telnet, HTTP), the application name (e.g. ISC BIND, Apache httpd, Solaris telnetd), the version number, hostname, device type (e.g. printer, router), the OS family (e.g. Windows, Linux). When possible, Nmap also gets the Common Platform Enumeration (CPE) representation of this information. Sometimes miscellaneous details like whether an X server is open to connections, the SSH protocol version, or the KaZaA user name, are available. Of course, most services don't provide all of this information. If Nmap was compiled with OpenSSL support, it will connect to SSL servers to deduce the service listening behind that encryption layer. Some UDP ports are left in the open|filtered state after a UDP port scan is unable to determine whether the port is open or filtered. Version detection will try to elicit a response from these ports (just as it does with open ports), and change the state to open if it succeeds. open|filtered TCP ports are treated the same way. Note that the Nmap -A option enables version detection among other things. A paper documenting the workings, usage, and customization of version detection is available at https://nmap.org/book/vscan.html. When RPC services are discovered, the Nmap RPC grinder is automatically used to determine the RPC program and version numbers. It takes all the TCP/UDP ports detected as RPC and floods them with SunRPC program NULL commands in an attempt to determine whether they are RPC ports, and if so, what program and version number they serve up. Thus you can effectively obtain the same info as rpcinfo -p even if the target's portmapper is behind a firewall (or protected by TCP wrappers). Decoys do not currently work with RPC scan. When Nmap receives responses from a service but cannot match them to its database, it prints out a special fingerprint and a URL for you to submit it to if you know for sure what is running on the port. Please take a couple minutes to make the submission so that your find can benefit everyone. Thanks to these submissions, Nmap has about 6,500 pattern matches for more than 650 protocols such as SMTP, FTP, HTTP, etc. Version detection is enabled and controlled with the following options: -sV (Version detection) Enables version detection, as discussed above. Alternatively, you can use -A, which enables version detection among other things. -sR is an alias for -sV. Prior to March 2011, it was used to active the RPC grinder separately from version detection, but now these options are always combined. --allports (Don't exclude any ports from version detection) By default, Nmap version detection skips TCP port 9100 because some printers simply print anything sent to that port, leading to dozens of pages of HTTP GET requests, binary SSL session requests, etc. This behavior can be changed by modifying or removing the Exclude directive in nmap-service-probes, or you can specify --allports to scan all ports regardless of any Exclude directive. --version-intensity intensity (Set version scan intensity) When performing a version scan (-sV), Nmap sends a series of probes, each of which is assigned a rarity value between one and nine. The lower-numbered probes are effective against a wide variety of common services, while the higher-numbered ones are rarely useful. The intensity level specifies which probes should be applied. The higher the number, the more likely it is the service will be correctly identified. However, high intensity scans take longer. The intensity must be between 0 and 9. The default is 7. When a probe is registered to the target port via the nmap-service-probes ports directive, that probe is tried regardless of intensity level. This ensures that the DNS probes will always be attempted against any open port 53, the SSL probe will be done against 443, etc. --version-light (Enable light mode) This is a convenience alias for --version-intensity 2. This light mode makes version scanning much faster, but it is slightly less likely to identify services. --version-all (Try every single probe) An alias for --version-intensity 9, ensuring that every single probe is attempted against each port. --version-trace (Trace version scan activity) This causes Nmap to print out extensive debugging info about what version scanning is doing. It is a subset of what you get with --packet-trace. OS DETECTION One of Nmap's best-known features is remote OS detection using TCP/IP stack fingerprinting. Nmap sends a series of TCP and UDP packets to the remote host and examines practically every bit in the responses. After performing dozens of tests such as TCP ISN sampling, TCP options support and ordering, IP ID sampling, and the initial window size check, Nmap compares the results to its nmap-os-db database of more than 2,600 known OS fingerprints and prints out the OS details if there is a match. Each fingerprint includes a freeform textual description of the OS, and a classification which provides the vendor name (e.g. Sun), underlying OS (e.g. Solaris), OS generation (e.g. 10), and device type (general purpose, router, switch, game console, etc). Most fingerprints also have a Common Platform Enumeration (CPE) representation, like cpe:/o:linux:linux_kernel:2.6. If Nmap is unable to guess the OS of a machine, and conditions are good (e.g. at least one open port and one closed port were found), Nmap will provide a URL you can use to submit the fingerprint if you know (for sure) the OS running on the machine. By doing this you contribute to the pool of operating systems known to Nmap and thus it will be more accurate for everyone. OS detection enables some other tests which make use of information that is gathered during the process anyway. One of these is TCP Sequence Predictability Classification. This measures approximately how hard it is to establish a forged TCP connection against the remote host. It is useful for exploiting source-IP based trust relationships (rlogin, firewall filters, etc) or for hiding the source of an attack. This sort of spoofing is rarely performed any more, but many machines are still vulnerable to it. The actual difficulty number is based on statistical sampling and may fluctuate. It is generally better to use the English classification such as “worthy challenge” or “trivial joke”. This is only reported in normal output in verbose (-v) mode. When verbose mode is enabled along with -O, IP ID sequence generation is also reported. Most machines are in the “incremental” class, which means that they increment the ID field in the IP header for each packet they send. This makes them vulnerable to several advanced information gathering and spoofing attacks. Another bit of extra information enabled by OS detection is a guess at a target's uptime. This uses the TCP timestamp option (RFC 1323[9]) to guess when a machine was last rebooted. The guess can be inaccurate due to the timestamp counter not being initialized to zero or the counter overflowing and wrapping around, so it is printed only in verbose mode. A paper documenting the workings, usage, and customization of OS detection is available at https://nmap.org/book/osdetect.html. OS detection is enabled and controlled with the following options: -O (Enable OS detection) Enables OS detection, as discussed above. Alternatively, you can use -A to enable OS detection along with other things. --osscan-limit (Limit OS detection to promising targets) OS detection is far more effective if at least one open and one closed TCP port are found. Set this option and Nmap will not even try OS detection against hosts that do not meet this criteria. This can save substantial time, particularly on -Pn scans against many hosts. It only matters when OS detection is requested with -O or -A. --osscan-guess; --fuzzy (Guess OS detection results) When Nmap is unable to detect a perfect OS match, it sometimes offers up near-matches as possibilities. The match has to be very close for Nmap to do this by default. Either of these (equivalent) options make Nmap guess more aggressively. Nmap will still tell you when an imperfect match is printed and display its confidence level (percentage) for each guess. --max-os-tries (Set the maximum number of OS detection tries against a target) When Nmap performs OS detection against a target and fails to find a perfect match, it usually repeats the attempt. By default, Nmap tries five times if conditions are favorable for OS fingerprint submission, and twice when conditions aren't so good. Specifying a lower --max-os-tries value (such as 1) speeds Nmap up, though you miss out on retries which could potentially identify the OS. Alternatively, a high value may be set to allow even more retries when conditions are favorable. This is rarely done, except to generate better fingerprints for submission and integration into the Nmap OS database. NMAP SCRIPTING ENGINE (NSE) The Nmap Scripting Engine (NSE) is one of Nmap's most powerful and flexible features. It allows users to write (and share) simple scripts (using the Lua programming language[10] ) to automate a wide variety of networking tasks. Those scripts are executed in parallel with the speed and efficiency you expect from Nmap. Users can rely on the growing and diverse set of scripts distributed with Nmap, or write their own to meet custom needs. Tasks we had in mind when creating the system include network discovery, more sophisticated version detection, vulnerability detection. NSE can even be used for vulnerability exploitation. To reflect those different uses and to simplify the choice of which scripts to run, each script contains a field associating it with one or more categories. Currently defined categories are auth, broadcast, default. discovery, dos, exploit, external, fuzzer, intrusive, malware, safe, version, and vuln. These are all described at https://nmap.org/book/nse-usage.html#nse-categories. Scripts are not run in a sandbox and thus could accidentally or maliciously damage your system or invade your privacy. Never run scripts from third parties unless you trust the authors or have carefully audited the scripts yourself. The Nmap Scripting Engine is described in detail at https://nmap.org/book/nse.html and is controlled by the following options: -sC Performs a script scan using the default set of scripts. It is equivalent to --script=default. Some of the scripts in this category are considered intrusive and should not be run against a target network without permission. --script filename|category|directory/|expression[,...] Runs a script scan using the comma-separated list of filenames, script categories, and directories. Each element in the list may also be a Boolean expression describing a more complex set of scripts. Each element is interpreted first as an expression, then as a category, and finally as a file or directory name. There are two special features for advanced users only. One is to prefix script names and expressions with + to force them to run even if they normally wouldn't (e.g. the relevant service wasn't detected on the target port). The other is that the argument all may be used to specify every script in Nmap's database. Be cautious with this because NSE contains dangerous scripts such as exploits, brute force authentication crackers, and denial of service attacks. File and directory names may be relative or absolute. Absolute names are used directly. Relative paths are looked for in the scripts of each of the following places until found: --datadir $NMAPDIR ~/.nmap (not searched on Windows) APPDATA\\nmap (only on Windows) the directory containing the nmap executable the directory containing the nmap executable, followed by ../share/nmap (not searched on Windows) NMAPDATADIR (not searched on Windows) the current directory. When a directory name ending in / is given, Nmap loads every file in the directory whose name ends with .nse. All other files are ignored and directories are not searched recursively. When a filename is given, it does not have to have the .nse extension; it will be added automatically if necessary. Nmap scripts are stored in a scripts subdirectory of the Nmap data directory by default (see https://nmap.org/book/data-files.html). For efficiency, scripts are indexed in a database stored in scripts/script.db, which lists the category or categories in which each script belongs. When referring to scripts from script.db by name, you can use a shell-style ‘*’ wildcard. nmap --script \u0026quot;http-*\u0026quot; Loads all scripts whose name starts with http-, such as http-auth and http-open-proxy. The argument to --script had to be in quotes to protect the wildcard from the shell. More complicated script selection can be done using the and, or, and not operators to build Boolean expressions. The operators have the same precedence[11] as in Lua: not is the highest, followed by and and then or. You can alter precedence by using parentheses. Because expressions contain space characters it is necessary to quote them. nmap --script \u0026quot;not intrusive\u0026quot; Loads every script except for those in the intrusive category. nmap --script \u0026quot;default or safe\u0026quot; This is functionally equivalent to nmap --script \u0026quot;default,safe\u0026quot;. It loads all scripts that are in the default category or the safe category or both. nmap --script \u0026quot;default and safe\u0026quot; Loads those scripts that are in both the default and safe categories. nmap --script \u0026quot;(default or safe or intrusive) and not http-*\u0026quot; Loads scripts in the default, safe, or intrusive categories, except for those whose names start with http-. --script-args n1=v1,n2={n3=v3},n4={v4,v5} Lets you provide arguments to NSE scripts. Arguments are a comma-separated list of name=value pairs. Names and values may be strings not containing whitespace or the characters ‘{’, ‘}’, ‘=’, or ‘,’. To include one of these characters in a string, enclose the string in single or double quotes. Within a quoted string, ‘\\’ escapes a quote. A backslash is only used to escape quotation marks in this special case; in all other cases a backslash is interpreted literally. Values may also be tables enclosed in {}, just as in Lua. A table may contain simple string values or more name-value pairs, including nested tables. Many scripts qualify their arguments with the script name, as in xmpp-info.server_name. You may use that full qualified version to affect just the specified script, or you may pass the unqualified version (server_name in this case) to affect all scripts using that argument name. A script will first check for its fully qualified argument name (the name specified in its documentation) before it accepts an unqualified argument name. A complex example of script arguments is --script-args 'user=foo,pass=\u0026quot;,{}=bar\u0026quot;,whois={whodb=nofollow+ripe},xmpp-info.server_name=localhost'. The online NSE Documentation Portal at https://nmap.org/nsedoc/ lists the arguments that each script accepts. --script-args-file filename Lets you load arguments to NSE scripts from a file. Any arguments on the command line supersede ones in the file. The file can be an absolute path, or a path relative to Nmap's usual search path (NMAPDIR, etc.) Arguments can be comma-separated or newline-separated, but otherwise follow the same rules as for --script-args, without requiring special quoting and escaping, since they are not parsed by the shell. --script-help filename|category|directory|expression|all[,...] Shows help about scripts. For each script matching the given specification, Nmap prints the script name, its categories, and its description. The specifications are the same as those accepted by --script; so for example if you want help about the ftp-anon script, you would run nmap --script-help ftp-anon. In addition to getting help for individual scripts, you can use this as a preview of what scripts will be run for a specification, for example with nmap --script-help default. --script-trace This option does what --packet-trace does, just one ISO layer higher. If this option is specified all incoming and outgoing communication performed by a script is printed. The displayed information includes the communication protocol, the source, the target and the transmitted data. If more than 5% of all transmitted data is not printable, then the trace output is in a hex dump format. Specifying --packet-trace enables script tracing too. --script-updatedb This option updates the script database found in scripts/script.db which is used by Nmap to determine the available default scripts and categories. It is only necessary to update the database if you have added or removed NSE scripts from the default scripts directory or if you have changed the categories of any script. This option is generally used by itself: nmap --script-updatedb. TIMING AND PERFORMANCE One of my highest Nmap development priorities has always been performance. A default scan (nmap hostname) of a host on my local network takes a fifth of a second. That is barely enough time to blink, but adds up when you are scanning hundreds or thousands of hosts. Moreover, certain scan options such as UDP scanning and version detection can increase scan times substantially. So can certain firewall configurations, particularly response rate limiting. While Nmap utilizes parallelism and many advanced algorithms to accelerate these scans, the user has ultimate control over how Nmap runs. Expert users carefully craft Nmap commands to obtain only the information they care about while meeting their time constraints. Techniques for improving scan times include omitting non-critical tests, and upgrading to the latest version of Nmap (performance enhancements are made frequently). Optimizing timing parameters can also make a substantial difference. Those options are listed below. Some options accept a time parameter. This is specified in seconds by default, though you can append ‘ms’, ‘s’, ‘m’, or ‘h’ to the value to specify milliseconds, seconds, minutes, or hours. So the --host-timeout arguments 900000ms, 900, 900s, and 15m all do the same thing. --min-hostgroup numhosts; --max-hostgroup numhosts (Adjust parallel scan group sizes) Nmap has the ability to port scan or version scan multiple hosts in parallel. Nmap does this by dividing the target IP space into groups and then scanning one group at a time. In general, larger groups are more efficient. The downside is that host results can't be provided until the whole group is finished. So if Nmap started out with a group size of 50, the user would not receive any reports (except for the updates offered in verbose mode) until the first 50 hosts are completed. By default, Nmap takes a compromise approach to this conflict. It starts out with a group size as low as five so the first results come quickly and then increases the groupsize to as high as 1024. The exact default numbers depend on the options given. For efficiency reasons, Nmap uses larger group sizes for UDP or few-port TCP scans. When a maximum group size is specified with --max-hostgroup, Nmap will never exceed that size. Specify a minimum size with --min-hostgroup and Nmap will try to keep group sizes above that level. Nmap may have to use smaller groups than you specify if there are not enough target hosts left on a given interface to fulfill the specified minimum. Both may be set to keep the group size within a specific range, though this is rarely desired. These options do not have an effect during the host discovery phase of a scan. This includes plain ping scans (-sn). Host discovery always works in large groups of hosts to improve speed and accuracy. The primary use of these options is to specify a large minimum group size so that the full scan runs more quickly. A common choice is 256 to scan a network in /24 sized chunks. For a scan with many ports, exceeding that number is unlikely to help much. For scans of just a few port numbers, host group sizes of 2048 or more may be helpful. --min-parallelism numprobes; --max-parallelism numprobes (Adjust probe parallelization) These options control the total number of probes that may be outstanding for a host group. They are used for port scanning and host discovery. By default, Nmap calculates an ever-changing ideal parallelism based on network performance. If packets are being dropped, Nmap slows down and allows fewer outstanding probes. The ideal probe number slowly rises as the network proves itself worthy. These options place minimum or maximum bounds on that variable. By default, the ideal parallelism can drop to one if the network proves unreliable and rise to several hundred in perfect conditions. The most common usage is to set --min-parallelism to a number higher than one to speed up scans of poorly performing hosts or networks. This is a risky option to play with, as setting it too high may affect accuracy. Setting this also reduces Nmap's ability to control parallelism dynamically based on network conditions. A value of 10 might be reasonable, though I only adjust this value as a last resort. The --max-parallelism option is sometimes set to one to prevent Nmap from sending more than one probe at a time to hosts. The --scan-delay option, discussed later, is another way to do this. --min-rtt-timeout time, --max-rtt-timeout time, --initial-rtt-timeout time (Adjust probe timeouts) Nmap maintains a running timeout value for determining how long it will wait for a probe response before giving up or retransmitting the probe. This is calculated based on the response times of previous probes. If the network latency shows itself to be significant and variable, this timeout can grow to several seconds. It also starts at a conservative (high) level and may stay that way for a while when Nmap scans unresponsive hosts. Specifying a lower --max-rtt-timeout and --initial-rtt-timeout than the defaults can cut scan times significantly. This is particularly true for pingless (-Pn) scans, and those against heavily filtered networks. Don't get too aggressive though. The scan can end up taking longer if you specify such a low value that many probes are timing out and retransmitting while the response is in transit. If all the hosts are on a local network, 100 milliseconds (--max-rtt-timeout 100ms) is a reasonable aggressive value. If routing is involved, ping a host on the network first with the ICMP ping utility, or with a custom packet crafter such as Nping that is more likely to get through a firewall. Look at the maximum round trip time out of ten packets or so. You might want to double that for the --initial-rtt-timeout and triple or quadruple it for the --max-rtt-timeout. I generally do not set the maximum RTT below 100 ms, no matter what the ping times are. Nor do I exceed 1000 ms. --min-rtt-timeout is a rarely used option that could be useful when a network is so unreliable that even Nmap's default is too aggressive. Since Nmap only reduces the timeout down to the minimum when the network seems to be reliable, this need is unusual and should be reported as a bug to the nmap-dev mailing list. --max-retries numtries (Specify the maximum number of port scan probe retransmissions) When Nmap receives no response to a port scan probe, it could mean the port is filtered. Or maybe the probe or response was simply lost on the network. It is also possible that the target host has rate limiting enabled that temporarily blocked the response. So Nmap tries again by retransmitting the initial probe. If Nmap detects poor network reliability, it may try many more times before giving up on a port. While this benefits accuracy, it also lengthens scan times. When performance is critical, scans may be sped up by limiting the number of retransmissions allowed. You can even specify --max-retries 0 to prevent any retransmissions, though that is only recommended for situations such as informal surveys where occasional missed ports and hosts are acceptable. The default (with no -T template) is to allow ten retransmissions. If a network seems reliable and the target hosts aren't rate limiting, Nmap usually only does one retransmission. So most target scans aren't even affected by dropping --max-retries to a low value such as three. Such values can substantially speed scans of slow (rate limited) hosts. You usually lose some information when Nmap gives up on ports early, though that may be preferable to letting the --host-timeout expire and losing all information about the target. --host-timeout time (Give up on slow target hosts) Some hosts simply take a long time to scan. This may be due to poorly performing or unreliable networking hardware or software, packet rate limiting, or a restrictive firewall. The slowest few percent of the scanned hosts can eat up a majority of the scan time. Sometimes it is best to cut your losses and skip those hosts initially. Specify --host-timeout with the maximum amount of time you are willing to wait. For example, specify 30m to ensure that Nmap doesn't waste more than half an hour on a single host. Note that Nmap may be scanning other hosts at the same time during that half an hour, so it isn't a complete loss. A host that times out is skipped. No port table, OS detection, or version detection results are printed for that host. The special value 0 can be used to mean “no timeout”, which can be used to override the T5 timing template, which sets the host timeout to 15 minutes. --script-timeout time While some scripts complete in fractions of a second, others can take hours or more depending on the nature of the script, arguments passed in, network and application conditions, and more. The --script-timeout option sets a ceiling on script execution time. Any script instance which exceeds that time will be terminated and no output will be shown. If debugging (-d) is enabled, Nmap will report on each timeout. For host and service scripts, a script instance only scans a single target host or port and the timeout period will be reset for the next instance. The special value 0 can be used to mean “no timeout”, which can be used to override the T5 timing template, which sets the script timeout to 10 minutes. --scan-delay time; --max-scan-delay time (Adjust delay between probes) This option causes Nmap to wait at least the given amount of time between each probe it sends to a given host. This is particularly useful in the case of rate limiting. Solaris machines (among many others) will usually respond to UDP scan probe packets with only one ICMP message per second. Any more than that sent by Nmap will be wasteful. A --scan-delay of 1s will keep Nmap at that slow rate. Nmap tries to detect rate limiting and adjust the scan delay accordingly, but it doesn't hurt to specify it explicitly if you already know what rate works best. When Nmap adjusts the scan delay upward to cope with rate limiting, the scan slows down dramatically. The --max-scan-delay option specifies the largest delay that Nmap will allow. A low --max-scan-delay can speed up Nmap, but it is risky. Setting this value too low can lead to wasteful packet retransmissions and possible missed ports when the target implements strict rate limiting. Another use of --scan-delay is to evade threshold based intrusion detection and prevention systems (IDS/IPS). --min-rate number; --max-rate number (Directly control the scanning rate) Nmap's dynamic timing does a good job of finding an appropriate speed at which to scan. Sometimes, however, you may happen to know an appropriate scanning rate for a network, or you may have to guarantee that a scan will be finished by a certain time. Or perhaps you must keep Nmap from scanning too quickly. The --min-rate and --max-rate options are designed for these situations. When the --min-rate option is given Nmap will do its best to send packets as fast as or faster than the given rate. The argument is a positive real number representing a packet rate in packets per second. For example, specifying --min-rate 300 means that Nmap will try to keep the sending rate at or above 300 packets per second. Specifying a minimum rate does not keep Nmap from going faster if conditions warrant. Likewise, --max-rate limits a scan's sending rate to a given maximum. Use --max-rate 100, for example, to limit sending to 100 packets per second on a fast network. Use --max-rate 0.1 for a slow scan of one packet every ten seconds. Use --min-rate and --max-rate together to keep the rate inside a certain range. These two options are global, affecting an entire scan, not individual hosts. They only affect port scans and host discovery scans. Other features like OS detection implement their own timing. There are two conditions when the actual scanning rate may fall below the requested minimum. The first is if the minimum is faster than the fastest rate at which Nmap can send, which is dependent on hardware. In this case Nmap will simply send packets as fast as possible, but be aware that such high rates are likely to cause a loss of accuracy. The second case is when Nmap has nothing to send, for example at the end of a scan when the last probes have been sent and Nmap is waiting for them to time out or be responded to. It's normal to see the scanning rate drop at the end of a scan or in between hostgroups. The sending rate may temporarily exceed the maximum to make up for unpredictable delays, but on average the rate will stay at or below the maximum. Specifying a minimum rate should be done with care. Scanning faster than a network can support may lead to a loss of accuracy. In some cases, using a faster rate can make a scan take longer than it would with a slower rate. This is because Nmap's adaptive retransmission algorithms will detect the network congestion caused by an excessive scanning rate and increase the number of retransmissions in order to improve accuracy. So even though packets are sent at a higher rate, more packets are sent overall. Cap the number of retransmissions with the --max-retries option if you need to set an upper limit on total scan time. --defeat-rst-ratelimit Many hosts have long used rate limiting to reduce the number of ICMP error messages (such as port-unreachable errors) they send. Some systems now apply similar rate limits to the RST (reset) packets they generate. This can slow Nmap down dramatically as it adjusts its timing to reflect those rate limits. You can tell Nmap to ignore those rate limits (for port scans such as SYN scan which don't treat non-responsive ports as open) by specifying --defeat-rst-ratelimit. Using this option can reduce accuracy, as some ports will appear non-responsive because Nmap didn't wait long enough for a rate-limited RST response. With a SYN scan, the non-response results in the port being labeled filtered rather than the closed state we see when RST packets are received. This option is useful when you only care about open ports, and distinguishing between closed and filtered ports isn't worth the extra time. --defeat-icmp-ratelimit Similar to --defeat-rst-ratelimit, the --defeat-icmp-ratelimit option trades accuracy for speed, increasing UDP scanning speed against hosts that rate-limit ICMP error messages. Because this option causes Nmap to not delay in order to receive the port unreachable messages, a non-responsive port will be labeled closed|filtered instead of the default open|filtered. This has the effect of only treating ports which actually respond via UDP as open. Since many UDP services do not respond in this way, the chance for inaccuracy is greater with this option than with --defeat-rst-ratelimit. --nsock-engine iocp|epoll|kqueue|poll|select Enforce use of a given nsock IO multiplexing engine. Only the select(2)-based fallback engine is guaranteed to be available on your system. Engines are named after the name of the IO management facility they leverage. Engines currently implemented are epoll, kqueue, poll, and select, but not all will be present on any platform. By default, Nmap will use the \u0026quot;best\u0026quot; engine, i.e. the first one in this list that is supported. Use nmap -V to see which engines are supported on your platform. -T paranoid|sneaky|polite|normal|aggressive|insane (Set a timing template) While the fine-grained timing controls discussed in the previous section are powerful and effective, some people find them confusing. Moreover, choosing the appropriate values can sometimes take more time than the scan you are trying to optimize. Fortunately, Nmap offers a simpler approach, with six timing templates. You can specify them with the -T option and their number (0–5) or their name. The template names are paranoid (0), sneaky (1), polite (2), normal (3), aggressive (4), and insane (5). The first two are for IDS evasion. Polite mode slows down the scan to use less bandwidth and target machine resources. Normal mode is the default and so -T3 does nothing. Aggressive mode speeds scans up by making the assumption that you are on a reasonably fast and reliable network. Finally insane mode assumes that you are on an extraordinarily fast network or are willing to sacrifice some accuracy for speed. These templates allow the user to specify how aggressive they wish to be, while leaving Nmap to pick the exact timing values. The templates also make some minor speed adjustments for which fine-grained control options do not currently exist. For example, -T4 prohibits the dynamic scan delay from exceeding 10 ms for TCP ports and -T5 caps that value at 5 ms. Templates can be used in combination with fine-grained controls, and the fine-grained controls that you specify will take precedence over the timing template default for that parameter. I recommend using -T4 when scanning reasonably modern and reliable networks. Keep that option even when you add fine-grained controls so that you benefit from those extra minor optimizations that it enables. If you are on a decent broadband or ethernet connection, I would recommend always using -T4. Some people love -T5 though it is too aggressive for my taste. People sometimes specify -T2 because they think it is less likely to crash hosts or because they consider themselves to be polite in general. They often don't realize just how slow -T polite really is. Their scan may take ten times longer than a default scan. Machine crashes and bandwidth problems are rare with the default timing options (-T3) and so I normally recommend that for cautious scanners. Omitting version detection is far more effective than playing with timing values at reducing these problems. While -T0 and -T1 may be useful for avoiding IDS alerts, they will take an extraordinarily long time to scan thousands of machines or ports. For such a long scan, you may prefer to set the exact timing values you need rather than rely on the canned -T0 and -T1 values. The main effects of T0 are serializing the scan so only one port is scanned at a time, and waiting five minutes between sending each probe. T1 and T2 are similar but they only wait 15 seconds and 0.4 seconds, respectively, between probes. T3 is Nmap's default behavior, which includes parallelization. -T4 does the equivalent of --max-rtt-timeout 1250ms --min-rtt-timeout 100ms --initial-rtt-timeout 500ms --max-retries 6 and sets the maximum TCP and SCTP scan delay to 10ms. T5 does the equivalent of --max-rtt-timeout 300ms --min-rtt-timeout 50ms --initial-rtt-timeout 250ms --max-retries 2 --host-timeout 15m --script-timeout 10m --max-scan-delay as well as setting the maximum TCP and SCTP scan delay to 5ms. Maximum UDP scan delay is not set by T4 or T5, but it can be set with the --max-scan-delay option. FIREWALL/IDS EVASION AND SPOOFING Many Internet pioneers envisioned a global open network with a universal IP address space allowing virtual connections between any two nodes. This allows hosts to act as true peers, serving and retrieving information from each other. People could access all of their home systems from work, changing the climate control settings or unlocking the doors for early guests. This vision of universal connectivity has been stifled by address space shortages and security concerns. In the early 1990s, organizations began deploying firewalls for the express purpose of reducing connectivity. Huge networks were cordoned off from the unfiltered Internet by application proxies, network address translation, and packet filters. The unrestricted flow of information gave way to tight regulation of approved communication channels and the content that passes over them. Network obstructions such as firewalls can make mapping a network exceedingly difficult. It will not get any easier, as stifling casual reconnaissance is often a key goal of implementing the devices. Nevertheless, Nmap offers many features to help understand these complex networks, and to verify that filters are working as intended. It even supports mechanisms for bypassing poorly implemented defenses. One of the best methods of understanding your network security posture is to try to defeat it. Place yourself in the mind-set of an attacker, and deploy techniques from this section against your networks. Launch an FTP bounce scan, idle scan, fragmentation attack, or try to tunnel through one of your own proxies. In addition to restricting network activity, companies are increasingly monitoring traffic with intrusion detection systems (IDS). All of the major IDSs ship with rules designed to detect Nmap scans because scans are sometimes a precursor to attacks. Many of these products have recently morphed into intrusion prevention systems (IPS) that actively block traffic deemed malicious. Unfortunately for network administrators and IDS vendors, reliably detecting bad intentions by analyzing packet data is a tough problem. Attackers with patience, skill, and the help of certain Nmap options can usually pass by IDSs undetected. Meanwhile, administrators must cope with large numbers of false positive results where innocent activity is misdiagnosed and alerted on or blocked. Occasionally people suggest that Nmap should not offer features for evading firewall rules or sneaking past IDSs. They argue that these features are just as likely to be misused by attackers as used by administrators to enhance security. The problem with this logic is that these methods would still be used by attackers, who would just find other tools or patch the functionality into Nmap. Meanwhile, administrators would find it that much harder to do their jobs. Deploying only modern, patched FTP servers is a far more powerful defense than trying to prevent the distribution of tools implementing the FTP bounce attack. There is no magic bullet (or Nmap option) for detecting and subverting firewalls and IDS systems. It takes skill and experience. A tutorial is beyond the scope of this reference guide, which only lists the relevant options and describes what they do. -f (fragment packets); --mtu (using the specified MTU) The -f option causes the requested scan (including host discovery scans) to use tiny fragmented IP packets. The idea is to split up the TCP header over several packets to make it harder for packet filters, intrusion detection systems, and other annoyances to detect what you are doing. Be careful with this! Some programs have trouble handling these tiny packets. The old-school sniffer named Sniffit segmentation faulted immediately upon receiving the first fragment. Specify this option once, and Nmap splits the packets into eight bytes or less after the IP header. So a 20-byte TCP header would be split into three packets. Two with eight bytes of the TCP header, and one with the final four. Of course each fragment also has an IP header. Specify -f again to use 16 bytes per fragment (reducing the number of fragments). Or you can specify your own offset size with the --mtu option. Don't also specify -f if you use --mtu. The offset must be a multiple of eight. While fragmented packets won't get by packet filters and firewalls that queue all IP fragments, such as the CONFIG_IP_ALWAYS_DEFRAG option in the Linux kernel, some networks can't afford the performance hit this causes and thus leave it disabled. Others can't enable this because fragments may take different routes into their networks. Some source systems defragment outgoing packets in the kernel. Linux with the iptables connection tracking module is one such example. Do a scan while a sniffer such as Wireshark is running to ensure that sent packets are fragmented. If your host OS is causing problems, try the --send-eth option to bypass the IP layer and send raw ethernet frames. Fragmentation is only supported for Nmap's raw packet features, which includes TCP and UDP port scans (except connect scan and FTP bounce scan) and OS detection. Features such as version detection and the Nmap Scripting Engine generally don't support fragmentation because they rely on your host's TCP stack to communicate with target services. -D decoy1[,decoy2][,ME][,...] (Cloak a scan with decoys) Causes a decoy scan to be performed, which makes it appear to the remote host that the host(s) you specify as decoys are scanning the target network too. Thus their IDS might report 5–10 port scans from unique IP addresses, but they won't know which IP was scanning them and which were innocent decoys. While this can be defeated through router path tracing, response-dropping, and other active mechanisms, it is generally an effective technique for hiding your IP address. Separate each decoy host with commas, and you can optionally use ME as one of the decoys to represent the position for your real IP address. If you put ME in the sixth position or later, some common port scan detectors (such as Solar Designer's excellent Scanlogd) are unlikely to show your IP address at all. If you don't use ME, Nmap will put you in a random position. You can also use RND to generate a random, non-reserved IP address, or RND:number to generate number addresses. Note that the hosts you use as decoys should be up or you might accidentally SYN flood your targets. Also it will be pretty easy to determine which host is scanning if only one is actually up on the network. You might want to use IP addresses instead of names (so the decoy networks don't see you in their nameserver logs). Right now random IP address generation is only supported with IPv4 Decoys are used both in the initial host discovery scan (using ICMP, SYN, ACK, or whatever) and during the actual port scanning phase. Decoys are also used during remote OS detection (-O). Decoys do not work with version detection or TCP connect scan. When a scan delay is in effect, the delay is enforced between each batch of spoofed probes, not between each individual probe. Because decoys are sent as a batch all at once, they may temporarily violate congestion control limits. It is worth noting that using too many decoys may slow your scan and potentially even make it less accurate. Also, some ISPs will filter out your spoofed packets, but many do not restrict spoofed IP packets at all. -S IP_Address (Spoof source address) In some circumstances, Nmap may not be able to determine your source address (Nmap will tell you if this is the case). In this situation, use -S with the IP address of the interface you wish to send packets through. Another possible use of this flag is to spoof the scan to make the targets think that someone else is scanning them. Imagine a company being repeatedly port scanned by a competitor! The -e option and -Pn are generally required for this sort of usage. Note that you usually won't receive reply packets back (they will be addressed to the IP you are spoofing), so Nmap won't produce useful reports. -e interface (Use specified interface) Tells Nmap what interface to send and receive packets on. Nmap should be able to detect this automatically, but it will tell you if it cannot. --source-port portnumber; -g portnumber (Spoof source port number) One surprisingly common misconfiguration is to trust traffic based only on the source port number. It is easy to understand how this comes about. An administrator will set up a shiny new firewall, only to be flooded with complaints from ungrateful users whose applications stopped working. In particular, DNS may be broken because the UDP DNS replies from external servers can no longer enter the network. FTP is another common example. In active FTP transfers, the remote server tries to establish a connection back to the client to transfer the requested file. Secure solutions to these problems exist, often in the form of application-level proxies or protocol-parsing firewall modules. Unfortunately there are also easier, insecure solutions. Noting that DNS replies come from port 53 and active FTP from port 20, many administrators have fallen into the trap of simply allowing incoming traffic from those ports. They often assume that no attacker would notice and exploit such firewall holes. In other cases, administrators consider this a short-term stop-gap measure until they can implement a more secure solution. Then they forget the security upgrade. Overworked network administrators are not the only ones to fall into this trap. Numerous products have shipped with these insecure rules. Even Microsoft has been guilty. The IPsec filters that shipped with Windows 2000 and Windows XP contain an implicit rule that allows all TCP or UDP traffic from port 88 (Kerberos). In another well-known case, versions of the Zone Alarm personal firewall up to 2.1.25 allowed any incoming UDP packets with the source port 53 (DNS) or 67 (DHCP). Nmap offers the -g and --source-port options (they are equivalent) to exploit these weaknesses. Simply provide a port number and Nmap will send packets from that port where possible. Most scanning operations that use raw sockets, including SYN and UDP scans, support the option completely. The option notably doesn't have an effect for any operations that use normal operating system sockets, including DNS requests, TCP connect scan, version detection, and script scanning. Setting the source port also doesn't work for OS detection, because Nmap must use different port numbers for certain OS detection tests to work properly. --data hex string (Append custom binary data to sent packets) This option lets you include binary data as payload in sent packets. hex string may be specified in any of the following formats: 0xAABBCCDDEEFF..., AABBCCDDEEFF... or \\xAA\\xBB\\xCC\\xDD\\xEE\\xFF.... Examples of use are --data 0xdeadbeef and --data \\xCA\\xFE\\x09. Note that if you specify a number like 0x00ff no byte-order conversion is performed. Make sure you specify the information in the byte order expected by the receiver. --data-string string (Append custom string to sent packets) This option lets you include a regular string as payload in sent packets. string can contain any string. However, note that some characters may depend on your system's locale and the receiver may not see the same information. Also, make sure you enclose the string in double quotes and escape any special characters from the shell. Examples: --data-string \u0026quot;Scan conducted by Security Ops, extension 7192\u0026quot; or --data-string \u0026quot;Ph34r my l33t skills\u0026quot;. Keep in mind that nobody is likely to actually see any comments left by this option unless they are carefully monitoring the network with a sniffer or custom IDS rules. --data-length number (Append random data to sent packets) Normally Nmap sends minimalist packets containing only a header. So its TCP packets are generally 40 bytes and ICMP echo requests are just 28. Some UDP ports and IP protocols get a custom payload by default. This option tells Nmap to append the given number of random bytes to most of the packets it sends, and not to use any protocol-specific payloads. (Use --data-length 0 for no random or protocol-specific payloads. OS detection (-O) packets are not affected because accuracy there requires probe consistency, but most pinging and portscan packets support this. It slows things down a little, but can make a scan slightly less conspicuous. --ip-options S|R [route]|L [route]|T|U ... ; --ip-options hex string (Send packets with specified ip options) The IP protocol[12] offers several options which may be placed in packet headers. Unlike the ubiquitous TCP options, IP options are rarely seen due to practicality and security concerns. In fact, many Internet routers block the most dangerous options such as source routing. Yet options can still be useful in some cases for determining and manipulating the network route to target machines. For example, you may be able to use the record route option to determine a path to a target even when more traditional traceroute-style approaches fail. Or if your packets are being dropped by a certain firewall, you may be able to specify a different route with the strict or loose source routing options. The most powerful way to specify IP options is to simply pass in values as the argument to --ip-options. Precede each hex number with \\x then the two digits. You may repeat certain characters by following them with an asterisk and then the number of times you wish them to repeat. For example, \\x01\\x07\\x04\\x00*36\\x01 is a hex string containing 36 NUL bytes. Nmap also offers a shortcut mechanism for specifying options. Simply pass the letter R, T, or U to request record-route, record-timestamp, or both options together, respectively. Loose or strict source routing may be specified with an L or S followed by a space and then a space-separated list of IP addresses. If you wish to see the options in packets sent and received, specify --packet-trace. For more information and examples of using IP options with Nmap, see https://seclists.org/nmap-dev/2006/q3/52. --ttl value (Set IP time-to-live field) Sets the IPv4 time-to-live field in sent packets to the given value. --randomize-hosts (Randomize target host order) Tells Nmap to shuffle each group of up to 16384 hosts before it scans them. This can make the scans less obvious to various network monitoring systems, especially when you combine it with slow timing options. If you want to randomize over larger group sizes, increase PING_GROUP_SZ in nmap.h and recompile. An alternative solution is to generate the target IP list with a list scan (-sL -n -oN filename), randomize it with a Perl script, then provide the whole list to Nmap with -iL. --spoof-mac MAC address, prefix, or vendor name (Spoof MAC address) Asks Nmap to use the given MAC address for all of the raw ethernet frames it sends. This option implies --send-eth to ensure that Nmap actually sends ethernet-level packets. The MAC given can take several formats. If it is simply the number 0, Nmap chooses a completely random MAC address for the session. If the given string is an even number of hex digits (with the pairs optionally separated by a colon), Nmap will use those as the MAC. If fewer than 12 hex digits are provided, Nmap fills in the remainder of the six bytes with random values. If the argument isn't a zero or hex string, Nmap looks through nmap-mac-prefixes to find a vendor name containing the given string (it is case insensitive). If a match is found, Nmap uses the vendor's OUI (three-byte prefix) and fills out the remaining three bytes randomly. Valid --spoof-mac argument examples are Apple, 0, 01:02:03:04:05:06, deadbeefcafe, 0020F2, and Cisco. This option only affects raw packet scans such as SYN scan or OS detection, not connection-oriented features such as version detection or the Nmap Scripting Engine. --proxies Comma-separated list of proxy URLs (Relay TCP connections through a chain of proxies) Asks Nmap to establish TCP connections with a final target through supplied chain of one or more HTTP or SOCKS4 proxies. Proxies can help hide the true source of a scan or evade certain firewall restrictions, but they can hamper scan performance by increasing latency. Users may need to adjust Nmap timeouts and other scan parameters accordingly. In particular, a lower --max-parallelism may help because some proxies refuse to handle as many concurrent connections as Nmap opens by default. This option takes a list of proxies as argument, expressed as URLs in the format proto://host:port. Use commas to separate node URLs in a chain. No authentication is supported yet. Valid protocols are HTTP and SOCKS4. Warning: this feature is still under development and has limitations. It is implemented within the nsock library and thus has no effect on the ping, port scanning and OS discovery phases of a scan. Only NSE and version scan benefit from this option so far— other features may disclose your true address. SSL connections are not yet supported, nor is proxy-side DNS resolution (hostnames are always resolved by Nmap). --badsum (Send packets with bogus TCP/UDP checksums) Asks Nmap to use an invalid TCP, UDP or SCTP checksum for packets sent to target hosts. Since virtually all host IP stacks properly drop these packets, any responses received are likely coming from a firewall or IDS that didn't bother to verify the checksum. For more details on this technique, see https://nmap.org/p60-12.html --adler32 (Use deprecated Adler32 instead of CRC32C for SCTP checksums) Asks Nmap to use the deprecated Adler32 algorithm for calculating the SCTP checksum. If --adler32 is not given, CRC-32C (Castagnoli) is used. RFC 2960[13] originally defined Adler32 as checksum algorithm for SCTP; RFC 4960[6] later redefined the SCTP checksums to use CRC-32C. Current SCTP implementations should be using CRC-32C, but in order to elicit responses from old, legacy SCTP implementations, it may be preferable to use Adler32. OUTPUT Any security tool is only as useful as the output it generates. Complex tests and algorithms are of little value if they aren't presented in an organized and comprehensible fashion. Given the number of ways Nmap is used by people and other software, no single format can please everyone. So Nmap offers several formats, including the interactive mode for humans to read directly and XML for easy parsing by software. In addition to offering different output formats, Nmap provides options for controlling the verbosity of output as well as debugging messages. Output types may be sent to standard output or to named files, which Nmap can append to or clobber. Output files may also be used to resume aborted scans. Nmap makes output available in five different formats. The default is called interactive output, and it is sent to standard output (stdout). There is also normal output, which is similar to interactive except that it displays less runtime information and warnings since it is expected to be analyzed after the scan completes rather than interactively. XML output is one of the most important output types, as it can be converted to HTML, easily parsed by programs such as Nmap graphical user interfaces, or imported into databases. The two remaining output types are the simple grepable output which includes most information for a target host on a single line, and sCRiPt KiDDi3 0utPUt for users who consider themselves |\u0026lt;-r4d. While interactive output is the default and has no associated command-line options, the other four format options use the same syntax. They take one argument, which is the filename that results should be stored in. Multiple formats may be specified, but each format may only be specified once. For example, you may wish to save normal output for your own review while saving XML of the same scan for programmatic analysis. You might do this with the options -oX myscan.xml -oN myscan.nmap. While this chapter uses the simple names like myscan.xml for brevity, more descriptive names are generally recommended. The names chosen are a matter of personal preference, though I use long ones that incorporate the scan date and a word or two describing the scan, placed in a directory named after the company I'm scanning. While these options save results to files, Nmap still prints interactive output to stdout as usual. For example, the command nmap -oX myscan.xml target prints XML to myscan.xml and fills standard output with the same interactive results it would have printed if -oX wasn't specified at all. You can change this by passing a hyphen character as the argument to one of the format types. This causes Nmap to deactivate interactive output, and instead print results in the format you specified to the standard output stream. So the command nmap -oX - target will send only XML output to stdout. Serious errors may still be printed to the normal error stream, stderr. Unlike some Nmap arguments, the space between the logfile option flag (such as -oX) and the filename or hyphen is mandatory. If you omit the flags and give arguments such as -oG- or -oXscan.xml, a backwards compatibility feature of Nmap will cause the creation of normal format output files named G- and Xscan.xml respectively. All of these arguments support strftime-like conversions in the filename. %H, %M, %S, %m, %d, %y, and %Y are all exactly the same as in strftime. %T is the same as %H%M%S, %R is the same as %H%M, and %D is the same as %m%d%y. A % followed by any other character just yields that character (%% gives you a percent symbol). So -oX 'scan-%T-%D.xml' will use an XML file with a name in the form of scan-144840-121307.xml. Nmap also offers options to control scan verbosity and to append to output files rather than clobbering them. All of these options are described below. Nmap Output Formats -oN filespec (normal output) Requests that normal output be directed to the given filename. As discussed above, this differs slightly from interactive output. -oX filespec (XML output) Requests that XML output be directed to the given filename. Nmap includes a document type definition (DTD) which allows XML parsers to validate Nmap XML output. While it is primarily intended for programmatic use, it can also help humans interpret Nmap XML output. The DTD defines the legal elements of the format, and often enumerates the attributes and values they can take on. The latest version is always available from https://svn.nmap.org/nmap/docs/nmap.dtd. XML offers a stable format that is easily parsed by software. Free XML parsers are available for all major computer languages, including C/C++, Perl, Python, and Java. People have even written bindings for most of these languages to handle Nmap output and execution specifically. Examples are Nmap::Scanner[14] and Nmap::Parser[15] in Perl CPAN. In almost all cases that a non-trivial application interfaces with Nmap, XML is the preferred format. The XML output references an XSL stylesheet which can be used to format the results as HTML. The easiest way to use this is simply to load the XML output in a web browser such as Firefox or IE. By default, this will only work on the machine you ran Nmap on (or a similarly configured one) due to the hard-coded nmap.xsl filesystem path. Use the --webxml or --stylesheet options to create portable XML files that render as HTML on any web-connected machine. -oS filespec (ScRipT KIdd|3 oUTpuT) Script kiddie output is like interactive output, except that it is post-processed to better suit the l33t HaXXorZ who previously looked down on Nmap due to its consistent capitalization and spelling. Humor impaired people should note that this option is making fun of the script kiddies before flaming me for supposedly “helping them”. -oG filespec (grepable output) This output format is covered last because it is deprecated. The XML output format is far more powerful, and is nearly as convenient for experienced users. XML is a standard for which dozens of excellent parsers are available, while grepable output is my own simple hack. XML is extensible to support new Nmap features as they are released, while I often must omit those features from grepable output for lack of a place to put them. Nevertheless, grepable output is still quite popular. It is a simple format that lists each host on one line and can be trivially searched and parsed with standard Unix tools such as grep, awk, cut, sed, diff, and Perl. Even I usually use it for one-off tests done at the command line. Finding all the hosts with the SSH port open or that are running Solaris takes only a simple grep to identify the hosts, piped to an awk or cut command to print the desired fields. Grepable output consists of comments (lines starting with a pound (#)) and target lines. A target line includes a combination of six labeled fields, separated by tabs and followed with a colon. The fields are Host, Ports, Protocols, Ignored State, OS, Seq Index, IP ID, and Status. The most important of these fields is generally Ports, which gives details on each interesting port. It is a comma separated list of port entries. Each port entry represents one interesting port, and takes the form of seven slash (/) separated subfields. Those subfields are: Port number, State, Protocol, Owner, Service, SunRPC info, and Version info. As with XML output, this help does not allow for documenting the entire format. A more detailed look at the Nmap grepable output format is available from https://nmap.org/book/output-formats-grepable-output.html. -oA basename (Output to all formats) As a convenience, you may specify -oA basename to store scan results in normal, XML, and grepable formats at once. They are stored in basename.nmap, basename.xml, and basename.gnmap, respectively. As with most programs, you can prefix the filenames with a directory path, such as ~/nmaplogs/foocorp/ on Unix or c:\\hacking\\sco on Windows. Verbosity and debugging options -v (Increase verbosity level), -vlevel (Set verbosity level) Increases the verbosity level, causing Nmap to print more information about the scan in progress. Open ports are shown as they are found and completion time estimates are provided when Nmap thinks a scan will take more than a few minutes. Use it twice or more for even greater verbosity: -vv, or give a verbosity level directly, for example -v3. Most changes only affect interactive output, and some also affect normal and script kiddie output. The other output types are meant to be processed by machines, so Nmap can give substantial detail by default in those formats without fatiguing a human user. However, there are a few changes in other modes where output size can be reduced substantially by omitting some detail. For example, a comment line in the grepable output that provides a list of all ports scanned is only printed in verbose mode because it can be quite long. -d (Increase debugging level), -dlevel (Set debugging level) When even verbose mode doesn't provide sufficient data for you, debugging is available to flood you with much more! As with the verbosity option (-v), debugging is enabled with a command-line flag (-d) and the debug level can be increased by specifying it multiple times, as in -dd, or by setting a level directly. For example, -d9 sets level nine. That is the highest effective level and will produce thousands of lines unless you run a very simple scan with very few ports and targets. Debugging output is useful when a bug is suspected in Nmap, or if you are simply confused as to what Nmap is doing and why. As this feature is mostly intended for developers, debug lines aren't always self-explanatory. You may get something like: Timeout vals: srtt: -1 rttvar: -1 to: 1000000 delta 14987 ==\u0026gt; srtt: 14987 rttvar: 14987 to: 100000. If you don't understand a line, your only recourses are to ignore it, look it up in the source code, or request help from the development list (nmap-dev). Some lines are self explanatory, but the messages become more obscure as the debug level is increased. --reason (Host and port state reasons) Shows the reason each port is set to a specific state and the reason each host is up or down. This option displays the type of the packet that determined a port or hosts state. For example, A RST packet from a closed port or an echo reply from an alive host. The information Nmap can provide is determined by the type of scan or ping. The SYN scan and SYN ping (-sS and -PS) are very detailed, but the TCP connect scan (-sT) is limited by the implementation of the connect system call. This feature is automatically enabled by the debug option (-d) and the results are stored in XML log files even if this option is not specified. --stats-every time (Print periodic timing stats) Periodically prints a timing status message after each interval of time. The time is a specification of the kind described in the section called “TIMING AND PERFORMANCE”; so for example, use --stats-every 10s to get a status update every 10 seconds. Updates are printed to interactive output (the screen) and XML output. --packet-trace (Trace packets and data sent and received) Causes Nmap to print a summary of every packet sent or received. This is often used for debugging, but is also a valuable way for new users to understand exactly what Nmap is doing under the covers. To avoid printing thousands of lines, you may want to specify a limited number of ports to scan, such as -p20-30. If you only care about the goings on of the version detection subsystem, use --version-trace instead. If you only care about script tracing, specify --script-trace. With --packet-trace, you get all of the above. --open (Show only open (or possibly open) ports) Sometimes you only care about ports you can actually connect to (open ones), and don't want results cluttered with closed, filtered, and closed|filtered ports. Output customization is normally done after the scan using tools such as grep, awk, and Perl, but this feature was added due to overwhelming requests. Specify --open to only see hosts with at least one open, open|filtered, or unfiltered port, and only see ports in those states. These three states are treated just as they normally are, which means that open|filtered and unfiltered may be condensed into counts if there are an overwhelming number of them. Beginning with Nmap 7.40, the --open option implies --defeat-rst-ratelimit, because that option only affects closed and filtered ports, which are hidden by --open. --iflist (List interfaces and routes) Prints the interface list and system routes as detected by Nmap and quits. This is useful for debugging routing problems or device mischaracterization (such as Nmap treating a PPP connection as ethernet). Miscellaneous output options --append-output (Append to rather than clobber output files) When you specify a filename to an output format flag such as -oX or -oN, that file is overwritten by default. If you prefer to keep the existing content of the file and append the new results, specify the --append-output option. All output filenames specified in that Nmap execution will then be appended to rather than clobbered. This doesn't work well for XML (-oX) scan data as the resultant file generally won't parse properly until you fix it up by hand. --resume filename (Resume aborted scan) Some extensive Nmap runs take a very long time—on the order of days. Such scans don't always run to completion. Restrictions may prevent Nmap from being run during working hours, the network could go down, the machine Nmap is running on might suffer a planned or unplanned reboot, or Nmap itself could crash. The administrator running Nmap could cancel it for any other reason as well, by pressing ctrl-C. Restarting the whole scan from the beginning may be undesirable. Fortunately, if scan output files were kept, the user can ask Nmap to resume scanning with the target it was working on when execution ceased. Simply specify the --resume option and pass the output file as its argument. No other arguments are permitted, as Nmap parses the output file to use the same ones specified previously. Simply call Nmap as nmap --resume logfilename. Nmap will append new results to the data files specified in the previous execution. Scans can be resumed from any of the 3 major output formats: Normal, Grepable, or XML --noninteractive (Disable runtime interactions) At times, such as when running Nmap in a shell background, it might be undesirable for Nmap to monitor and respond to user keyboard input when running. (See the section called “RUNTIME INTERACTION” about how to control Nmap during a scan.) Use option --noninteractive to prevent Nmap taking control of the terminal. --stylesheet path or URL (Set XSL stylesheet to transform XML output) Nmap ships with an XSL stylesheet named nmap.xsl for viewing or translating XML output to HTML. The XML output includes an xml-stylesheet directive which points to nmap.xml where it was initially installed by Nmap. Run the XML file through an XSLT processor such as xsltproc[16] to produce an HTML file. Directly opening the XML file in a browser no longer works well because modern browsers limit the locations a stylesheet may be loaded from. If you wish to use a different stylesheet, specify it as the argument to --stylesheet. You must pass the full pathname or URL. One common invocation is --stylesheet https://nmap.org/svn/docs/nmap.xsl. This tells an XSLT processor to load the latest version of the stylesheet from Nmap.Org. The --webxml option does the same thing with less typing and memorization. Loading the XSL from Nmap.Org makes it easier to view results on a machine that doesn't have Nmap (and thus nmap.xsl) installed. So the URL is often more useful, but the local filesystem location of nmap.xsl is used by default for privacy reasons. --webxml (Load stylesheet from Nmap.Org) This is a convenience option, nothing more than an alias for --stylesheet https://nmap.org/svn/docs/nmap.xsl. --no-stylesheet (Omit XSL stylesheet declaration from XML) Specify this option to prevent Nmap from associating any XSL stylesheet with its XML output. The xml-stylesheet directive is omitted. MISCELLANEOUS OPTIONS This section describes some important (and not-so-important) options that don't really fit anywhere else. -6 (Enable IPv6 scanning) Nmap has IPv6 support for its most popular features. Ping scanning, port scanning, version detection, and the Nmap Scripting Engine all support IPv6. The command syntax is the same as usual except that you also add the -6 option. Of course, you must use IPv6 syntax if you specify an address rather than a hostname. An address might look like 3ffe:7501:4819:2000:210:f3ff:fe03:14d0, so hostnames are recommended. The output looks the same as usual, with the IPv6 address on the “interesting ports” line being the only IPv6 giveaway. While IPv6 hasn't exactly taken the world by storm, it gets significant use in some (usually Asian) countries and most modern operating systems support it. To use Nmap with IPv6, both the source and target of your scan must be configured for IPv6. If your ISP (like most of them) does not allocate IPv6 addresses to you, free tunnel brokers are widely available and work fine with Nmap. I use the free IPv6 tunnel broker service at http://www.tunnelbroker.net. Other tunnel brokers are listed at Wikipedia[17]. 6to4 tunnels are another popular, free approach. On Windows, raw-socket IPv6 scans are supported only on ethernet devices (not tunnels), and only on Windows Vista and later. Use the --unprivileged option in other situations. -A (Aggressive scan options) This option enables additional advanced and aggressive options. Presently this enables OS detection (-O), version scanning (-sV), script scanning (-sC) and traceroute (--traceroute). More features may be added in the future. The point is to enable a comprehensive set of scan options without people having to remember a large set of flags. However, because script scanning with the default set is considered intrusive, you should not use -A against target networks without permission. This option only enables features, and not timing options (such as -T4) or verbosity options (-v) that you might want as well. Options which require privileges (e.g. root access) such as OS detection and traceroute will only be enabled if those privileges are available. --datadir directoryname (Specify custom Nmap data file location) Nmap obtains some special data at runtime in files named nmap-service-probes, nmap-services, nmap-protocols, nmap-rpc, nmap-mac-prefixes, and nmap-os-db. If the location of any of these files has been specified (using the --servicedb or --versiondb options), that location is used for that file. After that, Nmap searches these files in the directory specified with the --datadir option (if any). Any files not found there, are searched for in the directory specified by the NMAPDIR environment variable. Next comes ~/.nmap for real and effective UIDs; or on Windows, HOME\\AppData\\Roaming\\nmap (where HOME is the user's home directory, like C:\\Users\\user). This is followed by the location of the nmap executable and the same location with ../share/nmap appended. Then a compiled-in location such as /usr/local/share/nmap or /usr/share/nmap. --servicedb services file (Specify custom services file) Asks Nmap to use the specified services file rather than the nmap-services data file that comes with Nmap. Using this option also causes a fast scan (-F) to be used. See the description for --datadir for more information on Nmap's data files. --versiondb service probes file (Specify custom service probes file) Asks Nmap to use the specified service probes file rather than the nmap-service-probes data file that comes with Nmap. See the description for --datadir for more information on Nmap's data files. --send-eth (Use raw ethernet sending) Asks Nmap to send packets at the raw ethernet (data link) layer rather than the higher IP (network) layer. By default, Nmap chooses the one which is generally best for the platform it is running on. Raw sockets (IP layer) are generally most efficient for Unix machines, while ethernet frames are required for Windows operation since Microsoft disabled raw socket support. Nmap still uses raw IP packets on Unix despite this option when there is no other choice (such as non-ethernet connections). --send-ip (Send at raw IP level) Asks Nmap to send packets via raw IP sockets rather than sending lower level ethernet frames. It is the complement to the --send-eth option discussed previously. --privileged (Assume that the user is fully privileged) Tells Nmap to simply assume that it is privileged enough to perform raw socket sends, packet sniffing, and similar operations that usually require root privileges on Unix systems. By default Nmap quits if such operations are requested but geteuid is not zero. --privileged is useful with Linux kernel capabilities and similar systems that may be configured to allow unprivileged users to perform raw-packet scans. Be sure to provide this option flag before any flags for options that require privileges (SYN scan, OS detection, etc.). The NMAP_PRIVILEGED environment variable may be set as an equivalent alternative to --privileged. --unprivileged (Assume that the user lacks raw socket privileges) This option is the opposite of --privileged. It tells Nmap to treat the user as lacking network raw socket and sniffing privileges. This is useful for testing, debugging, or when the raw network functionality of your operating system is somehow broken. The NMAP_UNPRIVILEGED environment variable may be set as an equivalent alternative to --unprivileged. --release-memory (Release memory before quitting) This option is only useful for memory-leak debugging. It causes Nmap to release allocated memory just before it quits so that actual memory leaks are easier to spot. Normally Nmap skips this as the OS does this anyway upon process termination. -V; --version (Print version number) Prints the Nmap version number and exits. -h; --help (Print help summary page) Prints a short help screen with the most common command flags. Running Nmap without any arguments does the same thing. RUNTIME INTERACTION During the execution of Nmap, all key presses are captured. This allows you to interact with the program without aborting and restarting it. Certain special keys will change options, while any other keys will print out a status message telling you about the scan. The convention is that lowercase letters increase the amount of printing, and uppercase letters decrease the printing. You may also press ‘?’ for help. v / V Increase / decrease the verbosity level d / D Increase / decrease the debugging Level p / P Turn on / off packet tracing ? Print a runtime interaction help screen Anything else Print out a status message like this: Stats: 0:00:07 elapsed; 20 hosts completed (1 up), 1 undergoing Service Scan Service scan Timing: About 33.33% done; ETC: 20:57 (0:00:12 remaining) EXAMPLES Here are some Nmap usage examples, from the simple and routine to a little more complex and esoteric. Some actual IP addresses and domain names are used to make things more concrete. In their place you should substitute addresses/names from your own network. While I don't think port scanning other networks is or should be illegal, some network administrators don't appreciate unsolicited scanning of their networks and may complain. Getting permission first is the best approach. For testing purposes, you have permission to scan the host scanme.nmap.org. This permission only includes scanning via Nmap and not testing exploits or denial of service attacks. To conserve bandwidth, please do not initiate more than a dozen scans against that host per day. If this free scanning target service is abused, it will be taken down and Nmap will report Failed to resolve given hostname/IP: scanme.nmap.org. These permissions also apply to the hosts scanme2.nmap.org, scanme3.nmap.org, and so on, though those hosts do not currently exist. nmap -v scanme.nmap.org This option scans all reserved TCP ports on the machine scanme.nmap.org . The -v option enables verbose mode. nmap -sS -O scanme.nmap.org/24 Launches a stealth SYN scan against each machine that is up out of the 256 IPs on the /24 sized network where Scanme resides. It also tries to determine what operating system is running on each host that is up and running. This requires root privileges because of the SYN scan and OS detection. nmap -sV -p 22,53,110,143,4564 198.116.0-255.1-127 Launches host enumeration and a TCP scan at the first half of each of the 255 possible eight-bit subnets in the 198.116.0.0/16 address space. This tests whether the systems run SSH, DNS, POP3, or IMAP on their standard ports, or anything on port 4564. For any of these ports found open, version detection is used to determine what application is running. nmap -v -iR 100000 -Pn -p 80 Asks Nmap to choose 100,000 hosts at random and scan them for web servers (port 80). Host enumeration is disabled with -Pn since first sending a couple probes to determine whether a host is up is wasteful when you are only probing one port on each target host anyway. nmap -Pn -p80 -oX logs/pb-port80scan.xml -oG logs/pb-port80scan.gnmap 216.163.128.20/20 This scans 4096 IPs for any web servers (without pinging them) and saves the output in grepable and XML formats. NMAP BOOK While this reference guide details all material Nmap options, it can't fully demonstrate how to apply those features to quickly solve real-world tasks. For that, we released Nmap Network Scanning: The Official Nmap Project Guide to Network Discovery and Security Scanning. Topics include subverting firewalls and intrusion detection systems, optimizing Nmap performance, and automating common networking tasks with the Nmap Scripting Engine. Hints and instructions are provided for common Nmap tasks such as taking network inventory, penetration testing, detecting rogue wireless access points, and quashing network worm outbreaks. Examples and diagrams show actual communication on the wire. More than half of the book is available free online. See https://nmap.org/book for more information. BUGS Like its author, Nmap isn't perfect. But you can help make it better by sending bug reports or even writing patches. If Nmap doesn't behave the way you expect, first upgrade to the latest version available from https://nmap.org. If the problem persists, do some research to determine whether it has already been discovered and addressed. Try searching for the problem or error message on Google since that aggregates so many forums. If nothing comes of this, create an Issue on our tracker (http://issues.nmap.org) and/or mail a bug report to \u0026lt;dev@nmap.org\u0026gt;. If you subscribe to the nmap-dev list before posting, your message will bypass moderation and get through more quickly. Subscribe at https://nmap.org/mailman/listinfo/dev. Please include everything you have learned about the problem, as well as what version of Nmap you are using and what operating system version it is running on. Other suggestions for improving Nmap may be sent to the Nmap dev mailing list as well. If you are able to write a patch improving Nmap or fixing a bug, that is even better! Instructions for submitting patches or git pull requests are available from https://github.com/nmap/nmap/blob/master/CONTRIBUTING.md Particularly sensitive issues such as a security reports may be sent directly to Nmap's author Fyodor directly at \u0026lt;fyodor@nmap.org\u0026gt;. All other reports and comments should use the dev list or issue tracker instead because more people read, follow, and respond to those. AUTHORS Gordon “Fyodor” Lyon \u0026lt;fyodor@nmap.org\u0026gt; wrote and released Nmap in 1997. Since then, hundreds of people have made valuable contributions, as detailed in the CHANGELOG file distributed with Nmap and also available from https://nmap.org/changelog.html. David Fifield and Daniel Miller deserve special recognition for their enormous multi-year contributions! LEGAL NOTICES Nmap Copyright and Licensing The Nmap Security Scanner is (C) 1996–2022 Nmap Software LLC (\u0026quot;The Nmap Project\u0026quot;). Nmap is also a registered trademark of the Nmap Project. It is published under the Nmap Public Source License[18]. This generally allows end users to download and use Nmap for free. It doesn't allow Nmap to be used and redistributed within commercial software or hardware products (including appliances, virtual machines, and traditional applications). We fund the project by selling a special Nmap OEM Edition for this purpose, as described at https://nmap.org/oem. Hundreds of large and small software vendors have already purchased OEM licenses to embed Nmap technology such as host discovery, port scanning, OS detection, version detection, and the Nmap Scripting Engine within their products. The Nmap Project has permission to redistribute Npcap, a packet capturing driver and library for the Microsoft Windows platform. Npcap is a separate work with it's own license rather than this Nmap license. Since the Npcap license does not permit redistribution without special permission, our Nmap Windows binary packages which contain Npcap may not be redistributed without special permission. Even though the NPSL is based on GPLv2, it contains different provisions and is not directly compatible. It is incompatible with some other open source licenses as well. In some cases we can relicense portions of Nmap or grant special permissions to use it in other open source software. Please contact fyodor@nmap.org with any such requests. Similarly, we don't incorporate incompatible open source software into Nmap without special permission from the copyright holders. If you have received a written license agreement or contract for Nmap (such as an Nmap OEM license[19]) stating terms other than these, you may choose to use and redistribute Nmap under those terms instead. Creative Commons License for this Nmap Guide This Nmap Reference Guide is (C) 2005–2022 Nmap Software LLC. It is hereby placed under version 3.0 of the Creative Commons Attribution License[20]. This allows you redistribute and modify the work as you desire, as long as you credit the original source. Alternatively, you may choose to treat this document as falling under the same license as Nmap itself (discussed previously). Source Code Availability and Community Contributions Source is provided to this software because we believe users have a right to know exactly what a program is going to do before they run it. This also allows you to audit the software for security holes. Source code also allows you to port Nmap to new platforms, fix bugs, and add new features. You are highly encouraged to submit your changes as Github Pull Requests (PR) or send them to \u0026lt;dev@nmap.org\u0026gt; for possible incorporation into the main distribution. By submitting such changes, it is assumed that you are offering the Nmap Project the unlimited, non-exclusive right to reuse, modify, and relicense the code. This is important because the inability to relicense code has caused devastating problems for other Free Software projects (such as KDE and NASM). We also sell commercial licenses to Nmap OEM[21]. If you wish to specify special license conditions of your contributions, just say so when you send them. No Warranty This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. It should also be noted that Nmap has occasionally been known to crash poorly written applications, TCP/IP stacks, and even operating systems. While this is extremely rare, it is important to keep in mind. Nmap should never be run against mission critical systems unless you are prepared to suffer downtime. We acknowledge here that Nmap may crash your systems or networks and we disclaim all liability for any damage or problems Nmap could cause. Inappropriate Usage Because of the slight risk of crashes and because a few black hats like to use Nmap for reconnaissance prior to attacking systems, there are administrators who become upset and may complain when their system is scanned. Thus, it is often advisable to request permission before doing even a light scan of a network. Nmap should never be installed with special privileges (e.g. suid root). That would open up a major security vulnerability as other users on the system (or attackers) could use it for privilege escalation. Nmap is not designed, manufactured, or intended for use in hazardous environments requiring fail- safe performance where the failure of the software could lead directly to death, personal injury, or significant physical or environmental damage. Third-Party Software and Funding Notices This product includes software developed by the Apache Software Foundation[22]. A modified version of the Libpcap portable packet capture library[23] is distributed along with Nmap. The Windows version of Nmap utilizes the Libpcap-derived Ncap library[24] instead. Regular expression support is provided by the PCRE library[25], which is open-source software, written by Philip Hazel. Certain raw networking functions use the Libdnet[26] networking library, which was written by Dug Song. A modified version is distributed with Nmap. Nmap can optionally link with the OpenSSL cryptography toolkit[27] for SSL version detection support. The Nmap Scripting Engine uses an embedded version of the Lua programming language[28]. The Liblinear linear classification library[29] is used for our IPv6 OS detection machine learning techniques[30]. All of the third-party software described in this paragraph is freely redistributable under BSD-style software licenses. Binary packages for Windows and Mac OS X include support libraries necessary to run Zenmap and Ndiff with Python and PyGTK. (Unix platforms commonly make these libraries easy to install, so they are not part of the packages.) A listing of these support libraries and their licenses is included in the LICENSES files. This software was supported in part through the Google Summer of Code[31] and the DARPA CINDER program[32] (DARPA-BAA-10-84). United States Export Control Nmap only uses encryption when compiled with the optional OpenSSL support and linked with OpenSSL. When compiled without OpenSSL support, the Nmap Project believes that Nmap is not subject to U.S. Export Administration Regulations (EAR)[33] export control. As such, there is no applicable ECCN (export control classification number) and exportation does not require any special license, permit, or other governmental authorization. When compiled with OpenSSL support or distributed as source code, the Nmap Project believes that Nmap falls under U.S. ECCN 5D002[34] (“Information Security Software”). We distribute Nmap under the TSU exception for publicly available encryption software defined in EAR 740.13(e)[35]. NOTES 1. Nmap Network Scanning: The Official Nmap Project Guide to Network Discovery and Security Scanning https://nmap.org/book/ 2. RFC 1122 http://www.rfc-editor.org/rfc/rfc1122.txt 3. RFC 792 http://www.rfc-editor.org/rfc/rfc792.txt 4. RFC 950 http://www.rfc-editor.org/rfc/rfc950.txt 5. UDP http://www.rfc-editor.org/rfc/rfc768.txt 6. SCTP http://www.rfc-editor.org/rfc/rfc4960.txt 7. TCP RFC http://www.rfc-editor.org/rfc/rfc793.txt 8. RFC 959 http://www.rfc-editor.org/rfc/rfc959.txt 9. RFC 1323 http://www.rfc-editor.org/rfc/rfc1323.txt 10. Lua programming language http://lua.org 11. precedence http://www.lua.org/manual/5.1/manual.html#2.5.3 12. IP protocol http://www.rfc-editor.org/rfc/rfc791.txt 13. RFC 2960 http://www.rfc-editor.org/rfc/rfc2960.txt 14. Nmap::Scanner http://sourceforge.net/projects/nmap-scanner/ 15. Nmap::Parser http://nmapparser.wordpress.com/ 16. xsltproc http://xmlsoft.org/XSLT/ 17. listed at Wikipedia http://en.wikipedia.org/wiki/List_of_IPv6_tunnel_brokers 18. Nmap Public Source License https://nmap.org/npsl 19. Nmap OEM license https://nmap.org/oem/ 20. Creative Commons Attribution License http://creativecommons.org/licenses/by/3.0/ 21. Nmap OEM https://nmap.org/oem 22. Apache Software Foundation https://www.apache.org 23. Libpcap portable packet capture library https://www.tcpdump.org 24. Ncap library https://npcap.com 25. PCRE library https://pcre.org 26. Libdnet http://libdnet.sourceforge.net 27. OpenSSL cryptography toolkit https://openssl.org 28. Lua programming language https://lua.org 29. Liblinear linear classification library https://www.csie.ntu.edu.tw/~cjlin/liblinear/ 30. IPv6 OS detection machine learning techniques https://nmap.org/book/osdetect-guess.html#osdetect-guess-ipv6 31. Google Summer of Code https://nmap.org/soc/ 32. DARPA CINDER program https://www.fbo.gov/index?s=opportunity\u0026amp;mode=form\u0026amp;id=585e02a51f77af5cb3c9e06b9cc82c48\u0026amp;tab=core\u0026amp;_cview=1 33. Export Administration Regulations (EAR) https://www.bis.doc.gov/index.php/regulations/export-administration-regulations-ear 34. 5D002 https://www.bis.doc.gov/index.php/documents/regulations-docs/federal-register-notices/federal-register-2014/951-ccl5-pt2/file 35. EAR 740.13(e) https://www.bis.doc.gov/index.php/documents/regulations-docs/2341-740-2/file Nmap 08/31/2022 NMAP(1) ```bash "}),e.add({id:54,href:"/docs/tools/know/nuclei/",title:"Nuclei",description:`Description # Nuclei is a fast tool for configurable targeted scanning based on templates offering massive extensibility and ease of use.
Installation # brew install nuclei Usage # nuclei -u https://example.com Resources # Nuclei Getting Started Nuclei Templates Guide Nuclei Templates help # Nuclei is a fast, template based vulnerability scanner focusing on extensive configurability, massive extensibility and ease of use. Usage: nuclei [flags] Flags: TARGET: -u, -target string[] target URLs/hosts to scan -l, -list string path to file containing a list of target URLs/hosts to scan (one per line) -resume string resume scan using resume.`,content:"Description # Nuclei is a fast tool for configurable targeted scanning based on templates offering massive extensibility and ease of use.\nInstallation # brew install nuclei Usage # nuclei -u https://example.com Resources # Nuclei Getting Started Nuclei Templates Guide Nuclei Templates help # Nuclei is a fast, template based vulnerability scanner focusing on extensive configurability, massive extensibility and ease of use. Usage: nuclei [flags] Flags: TARGET: -u, -target string[] target URLs/hosts to scan -l, -list string path to file containing a list of target URLs/hosts to scan (one per line) -resume string resume scan using resume.cfg (clustering will be disabled) -sa, -scan-all-ips scan all the IP's associated with dns record -iv, -ip-version string[] IP version to scan of hostname (4,6) - (default 4) TEMPLATES: -nt, -new-templates run only new templates added in latest nuclei-templates release -ntv, -new-templates-version string[] run new templates added in specific version -as, -automatic-scan automatic web scan using wappalyzer technology detection to tags mapping -t, -templates string[] list of template or template directory to run (comma-separated, file) -tu, -template-url string[] list of template urls to run (comma-separated, file) -w, -workflows string[] list of workflow or workflow directory to run (comma-separated, file) -wu, -workflow-url string[] list of workflow urls to run (comma-separated, file) -validate validate the passed templates to nuclei -nss, -no-strict-syntax disable strict syntax check on templates -td, -template-display displays the templates content -tl list all available templates FILTERING: -a, -author string[] templates to run based on authors (comma-separated, file) -tags string[] templates to run based on tags (comma-separated, file) -etags, -exclude-tags string[] templates to exclude based on tags (comma-separated, file) -itags, -include-tags string[] tags to be executed even if they are excluded either by default or configuration -id, -template-id string[] templates to run based on template ids (comma-separated, file) -eid, -exclude-id string[] templates to exclude based on template ids (comma-separated, file) -it, -include-templates string[] templates to be executed even if they are excluded either by default or configuration -et, -exclude-templates string[] template or template directory to exclude (comma-separated, file) -em, -exclude-matchers string[] template matchers to exclude in result -s, -severity value[] templates to run based on severity. Possible values: info, low, medium, high, critical, unknown -es, -exclude-severity value[] templates to exclude based on severity. Possible values: info, low, medium, high, critical, unknown -pt, -type value[] templates to run based on protocol type. Possible values: dns, file, http, headless, network, workflow, ssl, websocket, whois -ept, -exclude-type value[] templates to exclude based on protocol type. Possible values: dns, file, http, headless, network, workflow, ssl, websocket, whois -tc, -template-condition string[] templates to run based on expression condition OUTPUT: -o, -output string output file to write found issues/vulnerabilities -sresp, -store-resp store all request/response passed through nuclei to output directory -srd, -store-resp-dir string store all request/response passed through nuclei to custom directory (default \u0026quot;output\u0026quot;) -silent display findings only -nc, -no-color disable output content coloring (ANSI escape codes) -json write output in JSONL(ines) format -irr, -include-rr include request/response pairs in the JSONL output (for findings only) -nm, -no-meta disable printing result metadata in cli output -ts, -timestamp enables printing timestamp in cli output -rdb, -report-db string nuclei reporting database (always use this to persist report data) -ms, -matcher-status display match failure status -me, -markdown-export string directory to export results in markdown format -se, -sarif-export string file to export results in SARIF format CONFIGURATIONS: -config string path to the nuclei configuration file -fr, -follow-redirects enable following redirects for http templates -fhr, -follow-host-redirects follow redirects on the same host -mr, -max-redirects int max number of redirects to follow for http templates (default 10) -dr, -disable-redirects disable redirects for http templates -rc, -report-config string nuclei reporting module configuration file -H, -header string[] custom header/cookie to include in all http request in header:value format (cli, file) -V, -var value custom vars in key=value format -r, -resolvers string file containing resolver list for nuclei -sr, -system-resolvers use system DNS resolving as error fallback -dc, -disable-clustering disable clustering of requests -passive enable passive HTTP response processing mode -fh2, -force-http2 force http2 connection on requests -ev, -env-vars enable environment variables to be used in template -cc, -client-cert string client certificate file (PEM-encoded) used for authenticating against scanned hosts -ck, -client-key string client key file (PEM-encoded) used for authenticating against scanned hosts -ca, -client-ca string client certificate authority file (PEM-encoded) used for authenticating against scanned hosts -sml, -show-match-line show match lines for file templates, works with extractors only -ztls use ztls library with autofallback to standard one for tls13 -sni string tls sni hostname to use (default: input domain name) -sandbox sandbox nuclei for safe templates execution -i, -interface string network interface to use for network scan -at, -attack-type string type of payload combinations to perform (batteringram,pitchfork,clusterbomb) -sip, -source-ip string source ip address to use for network scan -config-directory string override the default config path ($home/.config) -rsr, -response-size-read int max response size to read in bytes (default 10485760) -rss, -response-size-save int max response size to read in bytes (default 1048576) INTERACTSH: -iserver, -interactsh-server string interactsh server url for self-hosted instance (default: oast.pro,oast.live,oast.site,oast.online,oast.fun,oast.me) -itoken, -interactsh-token string authentication token for self-hosted interactsh server -interactions-cache-size int number of requests to keep in the interactions cache (default 5000) -interactions-eviction int number of seconds to wait before evicting requests from cache (default 60) -interactions-poll-duration int number of seconds to wait before each interaction poll request (default 5) -interactions-cooldown-period int extra time for interaction polling before exiting (default 5) -ni, -no-interactsh disable interactsh server for OAST testing, exclude OAST based templates UNCOVER: -uc, -uncover enable uncover engine -uq, -uncover-query string[] uncover search query -ue, -uncover-engine string[] uncover search engine (shodan,shodan-idb,fofa,censys,quake,hunter,zoomeye,netlas,criminalip) (default shodan) -uf, -uncover-field string uncover fields to return (ip,port,host) (default \u0026quot;ip:port\u0026quot;) -ul, -uncover-limit int uncover results to return (default 100) -ucd, -uncover-delay int delay between uncover query requests in seconds (0 to disable) (default 1) RATE-LIMIT: -rl, -rate-limit int maximum number of requests to send per second (default 150) -rlm, -rate-limit-minute int maximum number of requests to send per minute -bs, -bulk-size int maximum number of hosts to be analyzed in parallel per template (default 25) -c, -concurrency int maximum number of templates to be executed in parallel (default 25) -hbs, -headless-bulk-size int maximum number of headless hosts to be analyzed in parallel per template (default 10) -headc, -headless-concurrency int maximum number of headless templates to be executed in parallel (default 10) OPTIMIZATIONS: -timeout int time to wait in seconds before timeout (default 10) -retries int number of times to retry a failed request (default 1) -ldp, -leave-default-ports leave default HTTP/HTTPS ports (eg. host:80,host:443) -mhe, -max-host-error int max errors for a host before skipping from scan (default 30) -project use a project folder to avoid sending same request multiple times -project-path string set a specific project path -spm, -stop-at-first-match stop processing HTTP requests after the first match (may break template/workflow logic) -stream stream mode - start elaborating without sorting the input -ss, -scan-strategy value strategy to use while scanning(auto/host-spray/template-spray) (default 0) -irt, -input-read-timeout duration timeout on input read (default 3m0s) -nh, -no-httpx disable httpx probing for non-url input -no-stdin disable stdin processing HEADLESS: -headless enable templates that require headless browser support (root user on Linux will disable sandbox) -page-timeout int seconds to wait for each page in headless mode (default 20) -sb, -show-browser show the browser on the screen when running templates with headless mode -sc, -system-chrome use local installed Chrome browser instead of nuclei installed -lha, -list-headless-action list available headless actions DEBUG: -debug show all requests and responses -dreq, -debug-req show all sent requests -dresp, -debug-resp show all received responses -p, -proxy string[] list of http/socks5 proxy to use (comma separated or file input) -pi, -proxy-internal proxy all internal requests -ldf, -list-dsl-function list all supported DSL function signatures -tlog, -trace-log string file to write sent requests trace log -elog, -error-log string file to write sent requests error log -version show nuclei version -hm, -hang-monitor enable nuclei hang monitoring -v, -verbose show verbose output -profile-mem string optional nuclei memory profile dump file -vv display templates loaded for scan -svd, -show-var-dump show variables dump for debugging -ep, -enable-pprof enable pprof debugging server -tv, -templates-version shows the version of the installed nuclei-templates -hc, -health-check run diagnostic check up UPDATE: -un, -update update nuclei engine to the latest released version -ut, -update-templates update nuclei-templates to latest released version -ud, -update-template-dir string custom directory to install / update nuclei-templates -duc, -disable-update-check disable automatic nuclei/templates update check STATISTICS: -stats display statistics about the running scan -sj, -stats-json write statistics data to an output file in JSONL(ines) format -si, -stats-interval int number of seconds to wait between showing a statistics update (default 5) -m, -metrics expose nuclei metrics on a port -mp, -metrics-port int port to expose nuclei metrics on (default 9092) ```bash "}),e.add({id:55,href:"/docs/tools/know/p0f/",title:"P0f",description:"Description # What\u0026rsquo;s this? P0f is a tool that utilizes an array of sophisticated, purely passive traffic fingerprinting mechanisms to identify the players behind any incidental TCP/IP communications (often as little as a single normal SYN) without interfering in any way. Version 3 is a complete rewrite of the original codebase, incorporating a significant number of improvements to network-level fingerprinting, and introducing the ability to reason about application-level payloads (e.g., HTTP).",content:`Description # What\u0026rsquo;s this? P0f is a tool that utilizes an array of sophisticated, purely passive traffic fingerprinting mechanisms to identify the players behind any incidental TCP/IP communications (often as little as a single normal SYN) without interfering in any way. Version 3 is a complete rewrite of the original codebase, incorporating a significant number of improvements to network-level fingerprinting, and introducing the ability to reason about application-level payloads (e.g., HTTP).
Some of p0f\u0026rsquo;s capabilities include:
Highly scalable and extremely fast identification of the operating system and software on both endpoints of a vanilla TCP connection - especially in settings where NMap probes are blocked, too slow, unreliable, or would simply set off alarms.
Measurement of system uptime and network hookup, distance (including topology behind NAT or packet filters), user language preferences, and so on.
Automated detection of connection sharing / NAT, load balancing, and application-level proxying setups.
Detection of clients and servers that forge declarative statements such as X-Mailer or User-Agent.
The tool can be operated in the foreground or as a daemon, and offers a simple real-time API for third-party components that wish to obtain additional information about the actors they are talking to.
Common uses for p0f include reconnaissance during penetration tests; routine network monitoring; detection of unauthorized network interconnects in corporate environments; providing signals for abuse-prevention tools; and miscellanous forensics.
You can read more about its design and operation in this document. In one form or another, earlier versions of p0f are used in a wide variety of projects, including pfsense, Ettercap, PRADS, amavisd, milter, postgrey, fwknop, Satori, the OpenBSD firewall, and an assortment of commercial tools.
Fun fact: The idea for p0f dates back to June 10, 2000. Today, almost all applications that do passive OS fingerprinting either simply reuse p0f for TCP-level checks (Ettercap, Disco, PRADS, Satori), or use inferior approaches that, for example, pay no attention to the intricate relationship between host\u0026rsquo;s window size and MTU (SinFP).
install # brew install p0f package info # Name : p0f Version : 3.09b Release : 14.fc37 Architecture : x86_64 Size : 286 k Source : p0f-3.09b-14.fc37.src.rpm Repository : @System From repo : fedora Summary : Versatile passive OS fingerprinting tool URL : http://lcamtuf.coredump.cx/p0f.shtml License : LGPLv2+ Description : P0f is a versatile passive OS fingerprinting tool. P0f can identify the : system on machines that talk thru or near your box. p0f will also check : masquerading and firewall presence, the distance to the remote system and its : uptime, other guy's network hookup (DSL, OC3, avian carriers) and his ISP. sample usage # sudo p0f -i eth0 readme # Usage: p0f [ ...options... ] [ 'filter rule' ] Network interface options: -i iface - listen on the specified network interface -r file - read offline pcap data from a given file -p - put the listening interface in promiscuous mode -L - list all available interfaces Operating mode and output settings: -f file - read fingerprint database from 'file' (/etc/p0f/p0f.fp) -o file - write information to the specified log file -s name - answer to API queries at a named unix socket -u user - switch to the specified unprivileged account and chroot -d - fork into background (requires -o or -s) Performance-related options: -S limit - limit number of parallel API connections (20) -t c,h - set connection / host cache age limits (30s,120m) -m c,h - cap the number of active connections / hosts (1000,10000) Optional filter expressions (man tcpdump) can be specified in the command line to prevent p0f from looking at incidental network traffic. Problems? You can reach the author at \u0026lt;lcamtuf@coredump.cx\u0026gt;. \`\`\`bash `}),e.add({id:56,href:"/docs/tools/know/rustscan/",title:"Rustscan",description:`Description # RustScan is a modern port scanner written in Rust. It is designed to be fast and easy to use. I
install # brew install rustscan Usage # rustscan - References # Wiki GitHub See also # nmap masscan p0f help # rustscan 2.1.1 Fast Port Scanner built in Rust. WARNING Do not use this program against sensitive infrastructure since the specified server may not be able to handle this many socket connections at once.`,content:"Description # RustScan is a modern port scanner written in Rust. It is designed to be fast and easy to use. I\ninstall # brew install rustscan Usage # rustscan - References # Wiki GitHub See also # nmap masscan p0f help # rustscan 2.1.1 Fast Port Scanner built in Rust. WARNING Do not use this program against sensitive infrastructure since the specified server may not be able to handle this many socket connections at once. - Discord https://discord.gg/GFrQsGy - GitHub https://github.com/RustScan/RustScan USAGE: rustscan [FLAGS] [OPTIONS] [-- \u0026lt;command\u0026gt;...] FLAGS: --accessible Accessible mode. Turns off features which negatively affect screen readers -g, --greppable Greppable mode. Only output the ports. No Nmap. Useful for grep or outputting to a file -h, --help Prints help information -n, --no-config Whether to ignore the configuration file or not --top Use the top 1000 ports -V, --version Prints version information OPTIONS: -a, --addresses \u0026lt;addresses\u0026gt;... A comma-delimited list or newline-delimited file of separated CIDRs, IPs, or hosts to be scanned -b, --batch-size \u0026lt;batch-size\u0026gt; The batch size for port scanning, it increases or slows the speed of scanning. Depends on the open file limit of your OS. If you do 65535 it will do every port at the same time. Although, your OS may not support this [default: 4500] -c, --config-path \u0026lt;config-path\u0026gt; Custom path to config file -p, --ports \u0026lt;ports\u0026gt;... A list of comma separed ports to be scanned. Example: 80,443,8080 -r, --range \u0026lt;range\u0026gt; A range of ports with format start-end. Example: 1-1000 --scan-order \u0026lt;scan-order\u0026gt; The order of scanning to be performed. The \u0026quot;serial\u0026quot; option will scan ports in ascending order while the \u0026quot;random\u0026quot; option will scan ports randomly [default: serial] [possible values: Serial, Random] --scripts \u0026lt;scripts\u0026gt; Level of scripting required for the run [default: default] [possible values: None, Default, Custom] -t, --timeout \u0026lt;timeout\u0026gt; The timeout in milliseconds before a port is assumed to be closed [default: 1500] --tries \u0026lt;tries\u0026gt; The number of tries before a port is assumed to be closed. If set to 0, rustscan will correct it to 1 [default: 1] -u, --ulimit \u0026lt;ulimit\u0026gt; Automatically ups the ULIMIT with the value you provided ARGS: \u0026lt;command\u0026gt;... The Script arguments to run. To use the argument -A, end RustScan's args with '-- -A'. Example: 'rustscan -T 1500 -a 127.0.0.1 -- -A -sC'. This command adds -Pn -vvv -p $PORTS automatically to nmap. For things like --script '(safe and vuln)' enclose it in quotations marks \\\u0026quot;'(safe and vuln)'\\\u0026quot;\u0026quot;) ```bash "}),e.add({id:57,href:"/docs/tools/know/masscan/",title:"Masscan",description:`Description # masscan is a fast port scanner, originally developed by Robert \u0026ldquo;Rob\u0026rdquo; Fuller. It is capable of scanning the entire Internet in under 6 minutes, transmitting 10 million packets per second. It can scan the ent
Installation # brew install masscan sample usage # sudo masscan -p1-10000 192.168.0.1-192.168.0.32 --rate 1000000 help # MASSCAN(8) MASSCAN(8) NAME masscan - Fast scan of the Internet SYNOPSIS masscan \u0026lt;ip addresses/ranges\u0026gt; -p ports options DESCRIPTION masscan is an Internet-scale port scanner, useful for large scale surveys of the Internet, or of internal networks.`,content:"Description # masscan is a fast port scanner, originally developed by Robert \u0026ldquo;Rob\u0026rdquo; Fuller. It is capable of scanning the entire Internet in under 6 minutes, transmitting 10 million packets per second. It can scan the ent\nInstallation # brew install masscan sample usage # sudo masscan -p1-10000 192.168.0.1-192.168.0.32 --rate 1000000 help # MASSCAN(8) MASSCAN(8) NAME masscan - Fast scan of the Internet SYNOPSIS masscan \u0026lt;ip addresses/ranges\u0026gt; -p ports options DESCRIPTION masscan is an Internet-scale port scanner, useful for large scale surveys of the Internet, or of internal networks. While the default transmit rate is only 100 packets/second, it can optional go as fast as 25 million packets/second, a rate sufficient to scan the Internet in 3 minutes for one port. OPTIONS • \u0026lt;ip/range\u0026gt;: anything on the command-line not prefixed with a ´-´ is assumed to be an IP address or range. There are three valid formats. The first is a single IPv4 address like \u0026quot;192.168.0.1\u0026quot;. The second is a range like \u0026quot;10.0.0.1-10.0.0.100\u0026quot;. The third is a CIDR address, like \u0026quot;0.0.0.0/0\u0026quot;. At least one target must be specified. Multiple targets can be specified. This can be specified as multiple options separated by space, or can be separated by a comma as a single option, such as 10.0.0.0/8,192.168.0.1. • --range \u0026lt;ip/range\u0026gt;: the same as target range spec described above, except as a named parameter instead of an unnamed one. • -p \u0026lt;ports, --ports \u0026lt;ports\u0026gt;: specifies the port(s) to be scanned. A single port can be specified, like -p80. A range of ports can be specified, like -p 20-25. A list of ports/ranges can be specified, like -p80,20-25. UDP ports can also be specified, like --ports U:161,U:1024-1100. • --banners: specifies that banners should be grabbed, like HTTP server versions, HTML title fields, and so forth. Only a few protocols are supported. • --rate \u0026lt;packets-per-second\u0026gt;: specifies the desired rate for transmitting packets. This can be very small numbers, like 0.1 for transmitting packets at rates of one every 10 seconds, for very large numbers like 10000000, which attempts to transmit at 10 million packets/second. In my experience, Windows and can do 250 thousand packets per second, and latest versions of Linux can do 2.5 million packets per second. The PF_RING driver is needed to get to 25 million packets/second. • -c \u0026lt;filename\u0026gt;, --conf \u0026lt;filename\u0026gt;: reads in a configuration file. The format of the configuration file is described below. • --resume \u0026lt;filename\u0026gt;: the same as --conf, except that a few options are automatically set, such as --append-output. The format of the configuration file is described below. • --echo: don´t run, but instead dump the current configuration to a file. This file can then be used with the -c option. The format of this output is described below under ´CONFIGURATION FILE´. • -e \u0026lt;ifname\u0026gt;, --adapter \u0026lt;ifname\u0026gt;: use the named raw network interface, such as \u0026quot;eth0\u0026quot; or \u0026quot;dna1\u0026quot;. If not specified, the first network interface found with a default gateway will be used. • --adapter-ip \u0026lt;ip-address\u0026gt;: send packets using this IP address. If not specified, then the first IP address bound to the network interface will be used. Instead of a single IP address, a range may be specified. NOTE: The size of the range must be an even power of 2, such as 1, 2, 4, 8, 16, 1024 etc. addresses. • --adapter-port \u0026lt;port\u0026gt;: send packets using this port number as the source. If not specified, a random port will be chosen in the range 40000 through 60000. This port should be filtered by the host firewall (like iptables) to prevent the host network stack from interfering with arriving packets. Instead of a single port, a range can be specified, like 40000-40003. NOTE: The size of the range must be an even power of 2, such as the example above that has a total of 4 addresses. • --adapter-mac \u0026lt;mac-address\u0026gt;: send packets using this as the source MAC address. If not specified, then the first MAC address bound to the network interface will be used. • --router-mac \u0026lt;mac address\u0026gt;: send packets to this MAC address as the destination. If not specified, then the gateway address of the network interface will be ARPed. • --ping: indicates that the scan should include an ICMP echo request. This may be included with TCP and UDP scanning. • --exclude \u0026lt;ip/range\u0026gt;: blacklist an IP address or range, preventing it from being scanned. This overrides any target specification, guaranteeing that this address/range won´t be scanned. This has the same format as the normal target specification. • --excludefile \u0026lt;filename\u0026gt;: reads in a list of exclude ranges, in the same target format described above. These ranges override any targets, preventing them from being scanned. • --append-output: causes output to append to file, rather than overwriting the file. • --iflist: list the available network interfaces, and then exits. • --retries: the number of retries to send, at 1 second intervals. Note that since this scanner is stateless, retries are sent regardless if replies have already been received. • --nmap: print help about nmap-compatibility alternatives for these options. • --pcap-payloads: read packets from a libpcap file containing packets and extract the UDP payloads, and associate those payloads with the destination port. These payloads will then be used when sending UDP packets with the matching destination port. Only one payload will be remembered per port. Similar to --nmap-payloads. • --nmap-payloads \u0026lt;filename\u0026gt;: read in a file in the same format as the nmap file nmap-payloads. This contains UDP payload, so that we can send useful UDP packets instead of empty ones. Simi‐ lar to --pcap-payloads. • --http-user-agent \u0026lt;user-agent\u0026gt;: replaces the existing user-agent field with the indicated value when doing HTTP requests. • --open-only: report only open ports, not closed ports. • --pcap \u0026lt;filename\u0026gt;: saves received packets (but not transmitted packets) to the libpcap-format file. • --packet-trace: prints a summary of those packets sent and received. This is useful at low rates, like a few packets per second, but will overwhelm the terminal at high rates. • --pfring: force the use of the PF_RING driver. The program will exit if PF_RING DNA drvers are not available. • --resume-index: the point in the scan at when it was paused. • --resume-count: the maximum number of probes to send before exiting. This is useful with the --resume-index to chop up a scan and split it among multiple instances, though the --shards op‐ tion might be better. • --shards \u0026lt;x\u0026gt;/\u0026lt;y\u0026gt;: splits the scan among instances. x is the id for this scan, while y is the total number of instances. For example, --shards 1/2 tells an instance to send every other packet, starting with index 0. Likewise, --shards 2/2 sends every other packet, but starting with index 1, so that it doesn´t overlap with the first example. • --rotate \u0026lt;time\u0026gt;: rotates the output file, renaming it with the current timestamp, moving it to a separate directory. The time is specified in number of seconds, like \u0026quot;3600\u0026quot; for an hour. Or, units of time can be specified, such as \u0026quot;hourly\u0026quot;, or \u0026quot;6hours\u0026quot;, or \u0026quot;10min\u0026quot;. Times are aligned on an even boundary, so if \u0026quot;daily\u0026quot; is specified, then the file will be rotated every day at midnight. • --rotate-offset \u0026lt;time\u0026gt;: an offset in the time. This is to accommodate timezones. • --rotate-dir \u0026lt;directory\u0026gt;: when rotating the file, this specifies which directory to move the file to. A useful directory is /var/log/masscan. • --seed \u0026lt;integer\u0026gt;: an integer that seeds the random number generator. Using a different seed will cause packets to be sent in a different random order. Instead of an integer, the string time can be specified, which seeds using the local timestamp, automatically generating a differnet random order of scans. If no seed specified, time is the default. • --regress: run a regression test, returns ´0´ on success and ´1´ on failure. • --ttl \u0026lt;num\u0026gt;: specifies the TTL of outgoing packets, defaults to 255. • --wait \u0026lt;seconds\u0026gt;: specifies the number of seconds after transmit is done to wait for receiving packets before exiting the program. The default is 10 seconds. The string forever can be specified to never terminate. • --offline: don´t actually transmit packets. This is useful with a low rate and --packet-trace to look at what packets might´ve been transmitted. Or, it´s useful with --rate 100000000 in order to benchmark how fast transmit would work (assuming a zero-overhead driver). PF_RING is about 20% slower than the benchmark result from offline mode. • -sL: this doesn´t do a scan, but instead creates a list of random addresses. This is useful for importing into other tools. The options --shard, --resume-index, and --resume-count can be useful with this feature. • --interactive: show the results in realtime on the console. It has no effect if used with --output-format or --output-filename. • --output-format \u0026lt;fmt\u0026gt;: indicates the format of the output file, which can be xml, binary, grepable, list, or JSON. The option --output-filename must be specified. • --output-filename \u0026lt;filename\u0026gt;: the file which to save results to. If the parameter --output-format is not specified, then the default of xml will be used. • -oB \u0026lt;filename\u0026gt;: sets the output format to binary and saves the output in the given filename. This is equivelent to using the --output-format and --output-filename parameters. The option --readscan can then be used to read the binary file. Binary files are much smaller than their XML equivelents, but require a separate step to convert back into XML or another readable for‐ mat. • -oX \u0026lt;filename\u0026gt;: sets the output format to XML and saves the output in the given filename. This is equivelent to using the --output-format xml and --output-filename parameters. • -oG \u0026lt;filename\u0026gt;: sets the output format to grepable and saves the output in the given filename. This is equivelent to using the --output-format grepable and --output-filename parameters. • -oJ \u0026lt;filename\u0026gt;: sets the output format to JSON and saves the output in the given filename. This is equivelent to using the --output-format json and --output-filename parameters. • -oL \u0026lt;filename\u0026gt;: sets the output format to a simple list format and saves the output in the given filename. This is equivelent to using the --output-format list and --output-filename param‐ eters. • --readscan \u0026lt;binary-files\u0026gt;: reads the files created by the -oB option from a scan, then outputs them in one of the other formats, depending on command-line parameters. In other words, it can take the binary version of the output and convert it to an XML or JSON format. CONFIGURATION FILE FORMAT The configuration file uses the same parameter names as on the commandline, but without the -- prefix, and with an = sign between the name and the value. An example configuration file might be: # targets range = 10.0.0.0/8,192.168.0.0/16 range = 172.16.0.0/14 ports = 20-25,80,U:53 ping = true # adapter adapter = eth0 adapter-ip = 192.168.0.1 router-mac = 66-55-44-33-22-11 # other exclude-file = /etc/masscan/exludes.txt By default, the program will read default configuration from the file /etc/masscan/masscan.conf. This is useful for system-specific settings, such as the --adapter-xxx options. This is also useful for excluded IP addresses, so that you can scan the entire Internet, while skipping dangerous addresses, like those owned by the DoD, and not make an accidental mistake. CONTROL-C BEHAVIOR When the user presses ctrl-c, the scan will stop, and the current state of the scan will be saved in the file ´paused.conf´. The scan can be resumed with the --resume option: # masscan --resume paused.conf The program will not exit immediately, but will wait a default of 10 seconds to receive results from the Internet and save the results before exiting completely. This time can be changed with the --wait option. SIMPLE EXAMPLES The following example scans all private networks for webservers, and prints all open ports that were found. # masscan 10.0.0.0/8 192.168.0.0/16 172.16.0.0/12 -p80 --open-only The following example scans the entire Internet for DNS servers, grabbing their versions, then saves the results in an XML file. # masscan 0.0.0.0/0 --excludefile no-dod.txt -pU:53 --banners --output-filename dns.xml You should be able to import the XML into databases and such. The following example reads a binary scan results file called bin-test.scan and prints results to console. # masscan --readscan bin-test.scan The following example reads a binary scan results file called bin-test.scan and creates an XML output file called bin-test.xml. # masscan --readscan bin-test.scan -oX bin-test.xml ADVANCED EXAMPLES Let´s say that you want to scan the entire Internet and spread the scan across three machines. Masscan would be launched on all three machines using the following command-lines: # masscan 0.0.0.0/0 -p0-65535 --shard 1/3 # masscan 0.0.0.0/0 -p0-65535 --shard 2/3 # masscan 0.0.0.0/0 -p0-65535 --shard 3/3 An alternative is with the \u0026quot;resume\u0026quot; feature. A scan has an internal index that goes from zero to the number of ports times then number of IP addresses. The following example shows splitting up a scan into chunks of a 1000 items each: # masscan 0.0.0.0/0 -p0-65535 --resume-index 0 --resume-count 1000 # masscan 0.0.0.0/0 -p0-65535 --resume-index 1000 --resume-count 1000 # masscan 0.0.0.0/0 -p0-65535 --resume-index 2000 --resume-count 1000 # masscan 0.0.0.0/0 -p0-65535 --resume-index 3000 --resume-count 1000 A script can use this to split smaller tasks across many other machines, such as Amazon EC2 instances. As each instance completes a job, the script might send a request to a central coordinat‐ ing server for more work. SPURIOUS RESETS When scanning TCP using the default IP address of your adapter, the built-in stack will generate RST packets. This will prevent banner grabbing. There are are two ways to solve this. The first way is to create a firewall rule to block that port from being seen by the stack. How this works is dependent on the operating system, but on Linux this looks something like: # iptables -A INPUT -p tcp -i eth0 --dport 61234 -j DROP Then, when scanning, that same port must be used as the source: # masscan 10.0.0.0/8 -p80 --banners --adapter-port 61234 An alternative is to \u0026quot;spoof\u0026quot; a different IP address. This IP address must be within the range of the local network, but must not otherwise be in use by either your own computer or another com‐ puter on the network. An example of this would look like: # masscan 10.0.0.0/8 -p80 --banners --adapter-ip 192.168.1.101 Setting your source IP address this way is the preferred way of running this scanner. ABUSE COMPLAINTS This scanner is designed for large-scale surveys, of either an organization, or of the Internet as a whole. This scanning will be noticed by those monitoring their logs, which will generate complaints. If you are scanning your own organization, this may lead to you being fired. Never scan outside your local subnet without getting permission from your boss, with a clear written declaration of why you are scanning. The same applies to scanning the Internet from your employer. This is another good way to get fired, as your IT department gets flooded with complaints as to why your organization is hacking them. When scanning on your own, such as your home Internet or ISP, this will likely cause them to cancel your account due to the abuse complaints. One solution is to work with your ISP, to be clear about precisely what we are doing, to prove to them that we are researching the Internet, not \u0026quot;hacking\u0026quot; it. We have our ISP send the abuse complaints directly to us. For anyone that asks, we add them to our \u0026quot;--excludefile\u0026quot;, blacklisting them so that we won´t scan them again. While interacting with such people, some instead add us to their whitelist, so that their firewalls won´t log us anymore (they´ll still block us, of course, they just won´t log that fact to avoid filling up their logs with our scans). Ultimately, I don´t know if it´s possible to completely solve this problem. Despite the Internet being a public, end-to-end network, you are still \u0026quot;guilty until proven innocent\u0026quot; when you do a scan. COMPATIBILITY While not listed in this document, a lot of parameters compatible with nmap will also work. SEE ALSO nmap(8), pcap(3) AUTHORS This tool was written by Robert Graham. The source code is available at https://github.com/robertdavidgraham/masscan. January 2014 MASSCAN(8) ```bash "}),e.add({id:58,href:"/docs/tools/know/mtr/",title:"Mtr",description:`Description # mtr combines the functionality of the \u0026rsquo;traceroute\u0026rsquo; and \u0026lsquo;ping\u0026rsquo; programs in a single network diagnostic tool. It is useful for diagnosing network problems, especially when the problem is not with the local host.
install # brew install mtr sample usage # mtr nutek.neosb.net help # MTR(8) System Administration MTR(8) NAME mtr - a network diagnostic tool SYNOPSIS mtr [-4|-6] [-F FILENAME] [--report] [--report-wide] [--xml] [--gtk] [--curses] [--displaymode MODE] [--raw] [--csv] [--json] [--split] [--no-dns] [--show-ips] [-o FIELDS] [-y IPINFO] [--aslookup] [-i INTERVAL] [-c COUNT] [-s PACKETSIZE] [-B BITPATTERN] [-G GRACEPERIOD] [-Q TOS] [--mpls] [-I NAME] [-a ADDRESS] [-f FIRST-TTL] [-m MAX-TTL] [-U MAX-UNKNOWN] [--udp] [--tcp] [--sctp] [-P PORT] [-L LOCALPORT] [-Z TIMEOUT] [-M MARK] HOSTNAME DESCRIPTION mtr combines the functionality of the traceroute and ping programs in a single network diagnostic tool.`,content:"Description # mtr combines the functionality of the \u0026rsquo;traceroute\u0026rsquo; and \u0026lsquo;ping\u0026rsquo; programs in a single network diagnostic tool. It is useful for diagnosing network problems, especially when the problem is not with the local host.\ninstall # brew install mtr sample usage # mtr nutek.neosb.net help # MTR(8) System Administration MTR(8) NAME mtr - a network diagnostic tool SYNOPSIS mtr [-4|-6] [-F FILENAME] [--report] [--report-wide] [--xml] [--gtk] [--curses] [--displaymode MODE] [--raw] [--csv] [--json] [--split] [--no-dns] [--show-ips] [-o FIELDS] [-y IPINFO] [--aslookup] [-i INTERVAL] [-c COUNT] [-s PACKETSIZE] [-B BITPATTERN] [-G GRACEPERIOD] [-Q TOS] [--mpls] [-I NAME] [-a ADDRESS] [-f FIRST-TTL] [-m MAX-TTL] [-U MAX-UNKNOWN] [--udp] [--tcp] [--sctp] [-P PORT] [-L LOCALPORT] [-Z TIMEOUT] [-M MARK] HOSTNAME DESCRIPTION mtr combines the functionality of the traceroute and ping programs in a single network diagnostic tool. As mtr starts, it investigates the network connection between the host mtr runs on and HOSTNAME by sending packets with purposely low TTLs. It continues to send packets with low TTL, noting the response time of the intervening routers. This allows mtr to print the response percentage and response times of the internet route to HOSTNAME. A sudden increase in packet loss or re‐ sponse time is often an indication of a bad (or simply overloaded) link. The results are usually reported as round-trip-response times in milliseconds and the percentage of packet loss. OPTIONS -h, --help Print the summary of command line argument options. -v, --version Print the installed version of mtr. -4 Use IPv4 only. -6 Use IPv6 only. (IPV4 may be used for DNS lookups.) -F FILENAME, --filename FILENAME Reads the list of hostnames from the specified file. -r, --report This option puts mtr into report mode. When in this mode, mtr will run for the number of cycles specified by the -c option, and then print statistics and exit. This mode is useful for generating statistics about network quality. Note that each running instance of mtr generates a significant amount of network traffic. Using mtr to measure the quality of your network may result in decreased network performance. -w, --report-wide This option puts mtr into wide report mode. When in this mode, mtr will not cut hostnames in the report. -x, --xml Use this option to tell mtr to use the xml output format. This format is better suited for automated processing of the measurement results. -t, --curses Use this option to force mtr to use the curses based terminal interface (if available). In case the list of hops exceeds the height of your terminal, you can use the + and - keys to scroll up and down half a page. Ctrl-L clears spurious error messages that may overwrite other parts of the display. --displaymode MODE Use this option to select the initial display mode: 0 (default) selects statistics, 1 selects the stripchart without latency information, and 2 selects the stripchart with latency in‐ formation. -g, --gtk Use this option to force mtr to use the GTK+ based X11 window interface (if available). GTK+ must have been available on the system when mtr was built for this to work. See the GTK+ web page at ⟨http://www.gtk.org/⟩ for more information about GTK+. -l, --raw Use the raw output format. This format is better suited for archival of the measurement results. It could be parsed to be presented into any of the other display methods. Example of the raw output format: h 0 10.1.1.1 p 0 339 h 1 46.149.16.4 p 1 530 h 2 172.31.1.16 p 2 531 h 3 82.221.168.236 p 3 1523 h 5 195.130.211.8 p 5 1603 h 6 193.4.58.17 p 6 1127 h 7 193.4.58.17 d 7 www.isnic.is -C, --csv Use the Comma-Separated-Value (CSV) output format. (Note: The separator is actually a semi-colon ';'.) Example of the CSV output format: MTR.0.86+git:16e39fc0;1435562787;OK;nic.is;1;r-76520-PROD.greenqloud.internal;288 MTR.0.86+git:16e39fc0;1435562787;OK;nic.is;2;46.149.16.4;2086 MTR.0.86+git:16e39fc0;1435562787;OK;nic.is;3;172.31.1.16;600 MTR.0.86+git:16e39fc0;1435562787;OK;nic.is;4;82.221.168.236;1163 MTR.0.86+git:16e39fc0;1435562787;OK;nic.is;5;???;0 MTR.0.86+git:16e39fc0;1435562787;OK;nic.is;6;rix-k2-gw.isnic.is;1654 MTR.0.86+git:16e39fc0;1435562787;OK;nic.is;7;www.isnic.is;1036 -j, --json Use this option to tell mtr to use the JSON output format. This format is better suited for automated processing of the measurement results. Jansson library must have been available on the system when mtr was built for this to work. -p, --split Use this option to set mtr to spit out a format that is suitable for a split-user interface. -n, --no-dns Use this option to force mtr to display numeric IP numbers and not try to resolve the host names. -b, --show-ips Use this option to tell mtr to display both the host names and numeric IP numbers. In split mode this adds an extra field to the output. In report mode, there is usually too little space to add the IPs, and they will be truncated. Use the wide report (-w) mode to see the IPs in report mode. -o FIELDS, --order FIELDS Use this option to specify which fields to display and in which order. You may use one or more space characters to separate fields. Available fields: ┌──┬─────────────────────┐ │L │ Loss ratio │ ├──┼─────────────────────┤ │D │ Dropped packets │ ├──┼─────────────────────┤ │R │ Received packets │ ├──┼─────────────────────┤ │S │ Sent Packets │ ├──┼─────────────────────┤ │N │ Newest RTT(ms) │ ├──┼─────────────────────┤ │B │ Min/Best RTT(ms) │ ├──┼─────────────────────┤ │A │ Average RTT(ms) │ ├──┼─────────────────────┤ │W │ Max/Worst RTT(ms) │ ├──┼─────────────────────┤ │V │ Standard Deviation │ ├──┼─────────────────────┤ │G │ Geometric Mean │ ├──┼─────────────────────┤ │J │ Current Jitter │ ├──┼─────────────────────┤ │M │ Jitter Mean/Avg. │ ├──┼─────────────────────┤ │X │ Worst Jitter │ ├──┼─────────────────────┤ │I │ Interarrival Jitter │ └──┴─────────────────────┘ Example: -o \u0026quot;LSD NBAW X\u0026quot; -y n, --ipinfo n Displays information about each IP hop. Valid values for n are: 0 Display AS number (equivalent to -z) 1 Display IP prefix 2 Display country code of the origin AS 3 Display RIR (ripencc, arin, ...) 4 Display the allocation date of the IP prefix It is possible to cycle between these fields at runtime (using the y key). -z, --aslookup Displays the Autonomous System (AS) number alongside each hop. Equivalent to --ipinfo 0. Example (columns to the right not shown for clarity): 1. AS??? r-76520-PROD.greenqloud.internal 2. AS51969 46.149.16.4 3. AS??? 172.31.1.16 4. AS30818 82.221.168.236 5. ??? 6. AS??? rix-k2-gw.isnic.is 7. AS1850 www.isnic.is -i SECONDS, --interval SECONDS Use this option to specify the positive number of seconds between ICMP ECHO requests. The default value for this parameter is one second. The root user may choose values between zero and one. -c COUNT, --report-cycles COUNT Use this option to set the number of pings sent to determine both the machines on the network and the reliability of those machines. Each cycle lasts one second. -s PACKETSIZE, --psize PACKETSIZE This option sets the packet size used for probing. It is in bytes, inclusive IP and ICMP headers. If set to a negative number, every iteration will use a different, random packet size up to that number. -B NUM, --bitpattern NUM Specifies bit pattern to use in payload. Should be within range 0 - 255. If NUM is greater than 255, a random pattern is used. -G SECONDS, --gracetime SECONDS Use this option to specify the positive number of seconds to wait for responses after the final request. The default value is five seconds. -Q NUM, --tos NUM Specifies value for type of service field in IP header. Should be within range 0 - 255. -e, --mpls Use this option to tell mtr to display information from ICMP extensions for MPLS (RFC 4950) that are encoded in the response packets. -I NAME, --interface NAME Use the network interface with a specific name for sending network probes. This can be useful when you have multiple network interfaces with routes to your destination, for example both wired Ethernet and WiFi, and wish to test a particular interface. -a ADDRESS, --address ADDRESS Use this option to bind the outgoing socket to ADDRESS, so that all packets will be sent with ADDRESS as source address. NOTE that this option doesn't apply to DNS requests (which could be and could not be what you want). -f NUM, --first-ttl NUM Specifies with what TTL to start. Defaults to 1. -m NUM, --max-ttl NUM Specifies the maximum number of hops (max time-to-live value) traceroute will probe. Default is 30. -U NUM, --max-unknown NUM Specifies the maximum unknown host. Default is 5. -u, --udp Use UDP datagrams instead of ICMP ECHO. -T, --tcp Use TCP SYN packets instead of ICMP ECHO. PACKETSIZE is ignored, since SYN packets can not contain data. -S, --sctp Use Stream Control Transmission Protocol packets instead of ICMP ECHO. -P PORT, --port PORT The target port number for TCP/SCTP/UDP traces. -L LOCALPORT, --localport LOCALPORT The source port number for UDP traces. -Z SECONDS, --timeout SECONDS The number of seconds to keep probe sockets open before giving up on the connection. Using large values for this, especially combined with a short interval, will use up a lot of file descriptors. -M MARK, --mark MARK Set the mark for each packet sent through this socket similar to the netfilter MARK target but socket-based. MARK is 32 unsigned integer. See socket(7) for full description of this socket option. ENVIRONMENT mtr recognizes a few environment variables. MTR_OPTIONS This environment variable allows one to specify options, as if they were passed on the command line. It is parsed before reading the actual command line options, so that options speci‐ fied in MTR_OPTIONS are overridden by command-line options. Example: MTR_OPTIONS=\u0026quot;-4 -c 1\u0026quot; mtr -6 localhost would send one probe (because of -c 1) towards ::1 (because of -6, which overrides the -4 passed in MTR_OPTIONS). MTR_PACKET A path to the mtr-packet executable, to be used for sending and receiving network probes. If MTR_PACKET is unset, the PATH will be used to search for an mtr-packet executable. DISPLAY Specifies an X11 server for the GTK+ frontend. INTERACTIVE CONTROL mtr can be controlled while it is running with the following keys: ?|h help p pause (SPACE to resume) d switching display mode e toggle MPLS information on/off n toggle DNS on/off r reset all counters o str set the columns to display, default str='LRS N BAWV' j toggle latency(LS NABWV)/jitter(DR AGJMXI) stats c \u0026lt;n\u0026gt; report cycle n, default n=infinite i \u0026lt;n\u0026gt; set the ping interval to n seconds, default n=1 f \u0026lt;n\u0026gt; set the initial time-to-live(ttl), default n=1 m \u0026lt;n\u0026gt; set the max time-to-live, default n= # of hops s \u0026lt;n\u0026gt; set the packet size to n or random(n\u0026lt;0) b \u0026lt;c\u0026gt; set ping bit pattern to c(0..255) or random(c\u0026lt;0) Q \u0026lt;t\u0026gt; set ping packet's TOS to t u switch between ICMP ECHO and UDP datagrams y switching IP info z toggle ASN info on/off q exit BUGS Some modern routers give a lower priority to ICMP ECHO packets than to other network traffic. Consequently, the reliability of these routers reported by mtr will be significantly lower than the actual reliability of these routers. CONTACT INFORMATION For the latest version, see the mtr web page at ⟨http://www.bitwizard.nl/mtr/⟩ For patches, bug reports, or feature requests, please open an issue on GitHub at: ⟨https://github.com/traviscross/mtr⟩. SEE ALSO mtr-packet(8), traceroute(8), ping(8), socket(7), TCP/IP Illustrated (Stevens, ISBN 0201633469). mtr 0.95 MTR(8) ```bash "}),e.add({id:59,href:"/docs/tools/know/nethogs/",title:"Nethogs",description:`Description # NetHogs is a small \u0026rsquo;net top\u0026rsquo; tool. Instead of breaking the traffic down per protocol or per subnet, like most tools do, it groups bandwidth by process.
NetHogs does not rely on a special kernel module to be loaded. If there\u0026rsquo;s suddenly a lot of network traffic, you can fire up NetHogs and immediately see which PID is causing this. This makes it easy to identify programs that have gone wild and are suddenly taking up your bandwidth.`,content:"Description # NetHogs is a small \u0026rsquo;net top\u0026rsquo; tool. Instead of breaking the traffic down per protocol or per subnet, like most tools do, it groups bandwidth by process.\nNetHogs does not rely on a special kernel module to be loaded. If there\u0026rsquo;s suddenly a lot of network traffic, you can fire up NetHogs and immediately see which PID is causing this. This makes it easy to identify programs that have gone wild and are suddenly taking up your bandwidth.\nSince NetHogs heavily relies on /proc, most features are only available on Linux. NetHogs can be built on Mac OS X and FreeBSD, but it will only show connections, not processes.\ninstall # brew install nethogs sample usage # sudo nethogs help # NETHOGS(8) System Manager's Manual NETHOGS(8) NAME nethogs - Net top tool grouping bandwidth per process SYNOPSIS nethogs [-V] [-h] [-x] [-d seconds] [-v mode] [-c count] [-t] [-p] [-s] [-a] [-l] [-f filter] [-C] [-b] [-g period] [-P pid] [device(s)] DESCRIPTION NetHogs is a small 'net top' tool. Instead of breaking the traffic down per protocol or per subnet, like most such tools do, it groups bandwidth by process - and does not rely on a special kernel module to be loaded. So if there's suddenly a lot of network traffic, you can fire up NetHogs and immediately see which PID is causing this, and if it's some kind of spinning process, kill it. Options -V prints version. -h prints available commands usage. -x bughunt mode - implies tracemode. -d delay for update refresh rate in seconds. default is 1. -v view mode (0 = KB/s, 1 = total KB, 2 = total B, 3 = total MB, 4 = MB/s, 5 = GB/s). default is 0. -c number of updates. default is 0 (unlimited). -t tracemode. -p sniff in promiscuous mode (not recommended). -s sort output by sent column. -l display command line. -a monitor all devices, even loopback/stopped ones. -C capture TCP and UDP. -b Display the program basename. -g garbage collection period in number of refresh. default is 50. -P Show only processes with the specified pid(s). -f EXPERIMENTAL: specify string pcap filter (like tcpdump). This may be removed or changed in a future version. device(s) to monitor. default is all interfaces up and running excluding loopback INTERACTIVE CONTROL q quit s sort by SENT traffic r sort by RECEIVED traffic l display command line b display the program basename m switch between total (KB, B, MB) and throughput (KB/s, MB/s, GB/s) mode RUNNING WITHOUT ROOT In order to be run by an unprivileged user, nethogs needs the cap_net_admin and cap_net_raw capabilities. These can be set on the executable by using the setcap(8) command, as follows: sudo setcap \u0026quot;cap_net_admin,cap_net_raw+pe\u0026quot; /usr/local/sbin/nethogs Notes 1. When using the -P \u0026lt;pid\u0026gt; option, in a case where a process exited (normally or abruptly), Nethogs does not track that it exited. So, the operating system might create a new process (for an‐ other program) with the same pid. In this case, this new process will be shown by Nethogs. SEE ALSO netstat(8) tcpdump(1) pcap(3) AUTHOR Written by Arnout Engelen \u0026lt;arnouten@bzzt.net\u0026gt;. 14 February 2004 NETHOGS(8) ```bash "}),e.add({id:60,href:"/docs/tools/know/ngrep/",title:"Ngrep",description:"Description # ngrep is like GNU grep applied to the network layer. It\u0026rsquo;s a PCAP-based tool that allows you to specify an extended regular or hexadecimal expression to match against data payloads of packets. It understands many kinds of protocols, including IPv4/6, TCP, UDP, ICMPv4/6, IGMP and Raw, across a wide variety of interface types, and understands BPF filter logic in the same fashion as more common packet sniffing tools, such as tcpdump and snoop.",content:"Description # ngrep is like GNU grep applied to the network layer. It\u0026rsquo;s a PCAP-based tool that allows you to specify an extended regular or hexadecimal expression to match against data payloads of packets. It understands many kinds of protocols, including IPv4/6, TCP, UDP, ICMPv4/6, IGMP and Raw, across a wide variety of interface types, and understands BPF filter logic in the same fashion as more common packet sniffing tools, such as tcpdump and snoop.\nInstallation # brew install ngrep sample usage # sudo ngrep -d any -W byline port 80 help # NGREP(8) User Manuals NGREP(8) NAME ngrep - network grep SYNOPSIS ngrep \u0026lt;-hNXViwqpevxlDtTRM\u0026gt; \u0026lt;-IO pcap_dump \u0026gt; \u0026lt; -n num \u0026gt; \u0026lt; -d dev \u0026gt; \u0026lt; -A num \u0026gt; \u0026lt; -s snaplen \u0026gt; \u0026lt; -S limitlen \u0026gt; \u0026lt; -W normal|byline|single|none \u0026gt; \u0026lt; -c cols \u0026gt; \u0026lt; -P char \u0026gt; \u0026lt; -F file \u0026gt; \u0026lt; match expres‐ sion \u0026gt; \u0026lt; bpf filter \u0026gt; DESCRIPTION ngrep strives to provide most of GNU grep's common features, applying them to the network layer. ngrep is a pcap-aware tool that will allow you to specify extended regular expressions to match against data payloads of packets. It currently recognizes TCP, UDP and ICMP across Ethernet, PPP, SLIP, FDDI and null interfaces, and understands bpf filter logic in the same fashion as more common packet sniffing tools, such as tcpdump(8) and snoop(1). OPTIONS -h Display help/usage information. -N Show sub-protocol number along with single-character identifier (useful when observing raw or unknown protocols). -X Treat the match expression as a hexadecimal string. See the explanation of match expression below. -V Display version information. -i Ignore case for the regex expression. -w Match the regex expression as a word. -q Be quiet; don't output any information other than packet headers and their payloads (if relevant). -p Don't put the interface into promiscuous mode. -e Show empty packets. Normally empty packets are discarded because they have no payload to search. If specified, empty packets will be shown, regardless of the specified regex expres‐ sion. -v Invert the match; only display packets that don't match. -x Dump packet contents as hexadecimal as well as ASCII. -l Make stdout line buffered. -D When reading pcap_dump files, replay them at their recorded time intervals (mimic realtime). -t Print a timestamp in the form of YYYY/MM/DD HH:MM:SS.UUUUUU everytime a packet is matched. -T Print a timestamp in the form of +S.UUUUUU, indicating the delta between packet matches. Specify a second time to indicate the delta since the first packet match. -R Do not try to drop privileges to the DROPPRIVS_USER. ngrep makes no effort to validate input from live or offline sources as it is focused more on performance and handling large amounts of data than protocol correctness, which is most of‐ ten a fair assumption to make. However, sometimes it matters and thus as a rule ngrep will try to be defensive and drop any root privileges it might have. There exist scenarios where this behaviour can become an obstacle, so this option is provided to end-users who want to disable this feature, but must do so with an understanding of the risks. Packets can be randomly malformed or even specifically designed to overflow sniffers and take control of them, and revoking root privileges is currently the only risk mitigation ngrep employs against such an attack. Use this option and turn it off at your own risk. -c cols Explicitly set the console width to ``cols''. Note that this is the console width, and not the full width of what ngrep prints out as payloads; depending on the output mode ngrep may print less than ``cols'' bytes per line (indentation). -F file Read in the bpf filter from the specified filename. This is a compatibility option for users familiar with tcpdump. Please note that specifying ``-F'' will override any bpf filter specified on the command-line. -P char Specify an alternate character to signify non-printable characters when displayed. The default is ``.''. -K num Kill matching TCP connections (like tcpkill). The numeric argument controls how many RST segments are sent. -W normal|byline|single|none Specify an alternate manner for displaying packets, when not in hexadecimal mode. The ``byline'' mode honors embedded linefeeds, wrapping text only when a linefeed is encountered (use‐ ful for observing HTTP transactions, for instance). The ``none'' mode doesn't wrap under any circumstance (entire payload is displayed on one line). The ``single'' mode is conceptu‐ ally the same as ``none'', except that everything including IP and source/destination header information is all on one line. ``normal'' is the default mode and is only included for completeness. This option is incompatible with ``-x''. -s snaplen Set the bpf caplen to snaplen (default 65536). -S limitlen Set the upper limit on the size of packets that ngrep will look at. Useful for looking at only the first N bytes of packets without changing the BPF snaplen. -I pcap_dump Input file pcap_dump into ngrep. Works with any pcap-compatible dump file format. This option is useful for searching for a wide range of different patterns over the same packet stream. -O pcap_dump Output matched packets to a pcap-compatible dump file. This feature does not interfere with normal output to stdout. -n num Match only num packets total, then exit. -d dev By default ngrep will select a default interface to listen on. Use this option to force ngrep to listen on interface dev. -A num Dump num packets of trailing context after matching a packet. match expression A match expression is either an extended regular expression, or if the -X option is specified, a string signifying a hexadecimal value. An extended regular expression follows the rules as implemented by the GNU regex library. Hexadecimal expressions can optionally be preceded by `0x'. E.g., `DEADBEEF', `0xDEADBEEF'. bpf filter Selects a filter that specifies what packets will be dumped. If no bpf filter is given, all IP packets seen on the selected interface will be dumped. Otherwise, only packets for which bpf filter is `true' will be dumped. The bpf filter consists of one or more primitives. Primitives usually consist of an id (name or number) preceded by one or more qualifiers. There are three different kinds of qualifier: type qualifiers say what kind of thing the id name or number refers to. Possible types are host, net and port. E.g., `host blort', `net 1.2.3', `port 80'. If there is no type qualifier, host is assumed. dir qualifiers specify a particular transfer direction to and/or from id. Possible directions are src, dst, src or dst and src and dst. E.g., `src foo', `dst net 1.2.3', `src or dst port ftp-data'. If there is no dir qualifier, src or dst is assumed. For `null' link layers (i.e. point to point protocols such as slip) the inbound and outbound qualifiers can be used to specify a desired direction. proto qualifiers are restricted to ip-only protocols. Possible protos are: tcp , udp and icmp. e.g., `udp src foo' or `tcp port 21'. If there is no proto qualifier, all protocols consis‐ tent with the type are assumed. E.g., `src foo' means `ip and ((tcp or udp) src foo)', `net bar' means `ip and (net bar)', and `port 53' means `ip and ((tcp or udp) port 53)'. In addition to the above, there are some special `primitive' keywords that don't follow the pattern: gateway, broadcast, less, greater and arithmetic expressions. All of these are described below. More complex filter expressions are built up by using the words and, or and not to combine primitives. E.g., `host blort and not port ftp and not port ftp-data'. To save typing, identical qualifier lists can be omitted. E.g., `tcp dst port ftp or ftp-data or domain' is exactly the same as `tcp dst port ftp or tcp dst port ftp-data or tcp dst port domain'. Allowable primitives are: dst host host True if the IP destination field of the packet is host, which may be either an address or a name. src host host True if the IP source field of the packet is host. host host True if either the IP source or destination of the packet is host. Any of the above host expressions can be prepended with the keywords, ip, arp, or rarp as in: ip host host which is equivalent to: ether dst ehost True if the ethernet destination address is ehost. Ehost may be either a name from /etc/ethers or a number (see ethers(3N) for numeric format). ether src ehost True if the ethernet source address is ehost. ether host ehost True if either the ethernet source or destination address is ehost. gateway host True if the packet used host as a gateway. I.e., the ethernet source or destination address was host but neither the IP source nor the IP destination was host. Host must be a name and must be found in both /etc/hosts and /etc/ethers. (An equivalent expression is ether host ehost and not host host which can be used with either names or numbers for host / ehost.) dst net net True if the IP destination address of the packet has a network number of net. Net may be either a name from /etc/networks or a network number (see networks(4) for details). src net net True if the IP source address of the packet has a network number of net. net net True if either the IP source or destination address of the packet has a network number of net. net net mask mask True if the IP address matches net with the specific netmask. May be qualified with src or dst. net net/len True if the IP address matches net a netmask len bits wide. May be qualified with src or dst. dst port port True if the packet is ip/tcp or ip/udp and has a destination port value of port. The port can be a number or a name used in /etc/services (see tcp(4P) and udp(4P)). If a name is used, both the port number and protocol are checked. If a number or ambiguous name is used, only the port number is checked (e.g., dst port 513 will print both tcp/login traffic and udp/who traffic, and port domain will print both tcp/domain and udp/domain traffic). src port port True if the packet has a source port value of port. port port True if either the source or destination port of the packet is port. Any of the above port expressions can be prepended with the keywords, tcp or udp, as in: tcp src port port which matches only tcp packets whose source port is port. less length True if the packet has a length less than or equal to length. This is equivalent to: len \u0026lt;= length. greater length True if the packet has a length greater than or equal to length. This is equivalent to: len \u0026gt;= length. ip proto protocol True if the packet is an ip packet (see ip(4P)) of protocol type protocol. Protocol can be a number or one of the names tcp, udp or icmp. Note that the identifiers tcp and udp are also keywords and must be escaped via backslash (\\), which is \\\\ in the C-shell. ip broadcast True if the packet is an IP broadcast packet. It checks for both the all-zeroes and all-ones broadcast conventions, and looks up the local subnet mask. ip multicast True if the packet is an IP multicast packet. ip Abbreviation for: ether proto ip tcp, udp, icmp Abbreviations for: ip proto p where p is one of the above protocols. expr relop expr True if the relation holds, where relop is one of \u0026gt;, \u0026lt;, \u0026gt;=, \u0026lt;=, =, !=, and expr is an arithmetic expression composed of integer constants (expressed in standard C syntax), the normal binary operators [+, -, *, /, \u0026amp;, |], a length operator, and special packet data accessors. To access data inside the packet, use the following syntax: proto [ expr : size ] Proto is one of ip, tcp, udp or icmp, and indicates the protocol layer for the index operation. The byte offset, relative to the indicated protocol layer, is given by expr. Size is optional and indicates the number of bytes in the field of interest; it can be either one, two, or four, and defaults to one. The length operator, indicated by the keyword len, gives the length of the packet. For example, `ether[0] \u0026amp; 1 != 0' catches all multicast traffic. The expression `ip[0] \u0026amp; 0xf != 5' catches all IP packets with options. The expression `ip[6:2] \u0026amp; 0x1fff = 0' catches only unfragmented datagrams and frag zero of fragmented datagrams. This check is implicitly applied to the tcp and udp index operations. For instance, tcp[0] always means the first byte of the TCP header, and never means the first byte of an intervening fragment. Primitives may be combined using: A parenthesized group of primitives and operators (parentheses are special to the Shell and must be escaped). Negation (`!' or `not'). Concatenation (`\u0026amp;\u0026amp;' or `and'). Alternation (`||' or `or'). Negation has highest precedence. Alternation and concatenation have equal precedence and associate left to right. Note that explicit and tokens, not juxtaposition, are now required for con‐ catenation. If an identifier is given without a keyword, the most recent keyword is assumed. For example, not host vs and ace is short for not host vs and host ace which should not be confused with not ( host vs or ace ) Expression arguments can be passed to ngrep as either a single argument or as multiple arguments, whichever is more convenient. Generally, if the expression contains Shell metacharacters, it is easier to pass it as a single, quoted argument. Multiple arguments are concatenated with spaces before being parsed. DIAGNOSTICS Errors from ngrep, libpcap, and the GNU regex library are all output to stderr. EXIT STATUS The ngrep utility exits with one of the following values: 0 One or more frames were matched. 1 No frames were matched. 2 An error occurred. 3+ Hell is freezing over, run! AUTHOR Written by Jordan Ritter \u0026lt;jpr5@darkridge.com\u0026gt;. REPORTING BUGS Please report bugs to the ngrep's GitHub Issue Tracker, located at http://github.com/jpr5/ngrep/issues Non-bug, non-feature-request general feedback should be sent to the author directly by email. NOTES ALL YOUR BASE ARE BELONG TO US. *nux September 2017 NGREP(8) ```bash "}),e.add({id:61,href:"/docs/tools/know/nikto/",title:"Nikto",description:"Description # Nikto is an Open Source (GPL) web server scanner which performs comprehensive tests against web servers for multiple items, including over 6700 potentially dangerous files/programs, checks for outdated versions of over 1250 servers, and version specific problems on over 270 servers. It also checks for server configuration items such as the presence of multiple index files, HTTP server options, and will attempt to identify installed web servers and software.",content:"Description # Nikto is an Open Source (GPL) web server scanner which performs comprehensive tests against web servers for multiple items, including over 6700 potentially dangerous files/programs, checks for outdated versions of over 1250 servers, and version specific problems on over 270 servers. It also checks for server configuration items such as the presence of multiple index files, HTTP server options, and will attempt to identify installed web servers and software. Nikto has been used to find hundreds of web server problems, including missing patches, mis-configurations and default installs.\nNikto is an Open Source (GPL) web server scanner which performs comprehensive tests against web servers for multiple items, including over 6700 potentially dangerous files/programs, checks for outdated versions of over 1250 servers, and version specific problems on over 270 servers. It also checks for server configuration items such as the presence of multiple index files, HTTP server options, and will attempt to identify installed web servers and software. Scan items and plugins are frequently updated and can be automatically updated.\nNikto is not designed as a stealthy tool. It will test a web server in the quickest time possible, and is obvious in log files or to an IPS/IDS. However, there is support for LibWhisker\u0026rsquo;s anti-IDS methods in case you want to give it a try (or test your IDS system).\nNot every check is a security problem, though most are. There are some items that are \u0026ldquo;info only\u0026rdquo; type checks that look for things that may not have a security flaw, but the webmaster or security engineer may not know are present on the server. These items are usually marked appropriately in the information printed. There are also some checks for unknown items which have been seen scanned for in log files.\nFeatures\nHere are some of the major features of Nikto. See the documentation for a full list of features and how to use them. SSL Support (Unix with OpenSSL or maybe Windows with ActiveState\u0026rsquo;s Perl/NetSSL) Full HTTP proxy support Checks for outdated server components Save reports in plain text, XML, HTML, NBE or CSV Template engine to easily customize reports Scan multiple ports on a server, or multiple servers via input file (including nmap output) LibWhisker\u0026rsquo;s IDS encoding techniques Easily updated via command line Identifies installed software via headers, favicons and files Host authentication with Basic and NTLM Subdomain guessing Apache and cgiwrap username enumeration Mutation techniques to \u0026ldquo;fish\u0026rdquo; for content on web servers Scan tuning to include or exclude entire classes of vulnerability checks Guess credentials for authorization realms (including many default id/pw combos) Authorization guessing handles any directory, not just the root directory Enhanced false positive reduction via multiple methods: headers, page content, and content hashing Reports \u0026ldquo;unusual\u0026rdquo; headers seen Interactive status, pause and changes to verbosity settings Save full request/response for positive tests Replay saved positive requests Maximum execution time per target Auto-pause at a specified time Checks for common \u0026ldquo;parking\u0026rdquo; sites install # brew install nikto sample usage # nikto -h https://nutek.neosb.net -p 443 -o nikto.txt -Format txt -Tuning 123bde -ask no -C all -Display 1234 -evasion 1 -F html links # Nikto help # NIKTO(1) NIKTO(1) NAME nikto - Scan web server for known vulnerabilities SYNOPSIS /usr/local/bin/nikto [options...] DESCRIPTION Examine a web server to find potential problems and security vulnerabilities, including: • Server and software misconfigurations • Default files and programs • Insecure files and programs • Outdated servers and programs Nikto is built on LibWhisker (by RFP) and can run on any platform which has a Perl environment. It supports SSL, proxies, host authentication, IDS evasion and more. It can be updated automatically from the command-line, and supports the optional submission of updated version data back to the maintainers. OPTIONS Below are all of the Nikto command line options and explanations. A brief version of this text is available by running Nikto with the -h (-help) option. -Cgidirs Scan these CGI directories. Special words \u0026quot;none\u0026quot; or \u0026quot;all\u0026quot; may be used to scan all CGI directories or none, (respectively). A literal value for a CGI directory such as \u0026quot;/cgi-test/\u0026quot; may be specified (must include trailing slash). If this is option is not specified, all CGI directories listed in config.txt will be tested. -config Specify an alternative config file to use instead of the config.txt located in the install directory. -dbcheck Check the scan databases for syntax errors. -Display Control the output that Nikto shows. See Chapter 5 for detailed information on these options. Use the reference number or letter to specify the type, multiple may be used: 1 - Show redirects 2 - Show cookies received 3 - Show all 200/OK responses 4 - Show URLs which require authentication D - Debug Output V - Verbose Output -evasion Specify the LibWhisker IDS evasion technique to use (see the LibWhisker docs for detailed information on these). Use the reference number to specify the type, multiple may be used: 1 - Random URI encoding (non-UTF8) 2 - Directory self-reference (/./) 3 - Premature URL ending 4 - Prepend long random string 5 - Fake parameter 6 - TAB as request spacer 7 - Change the case of the URL 8 - Use Windows directory separator (\\) -findonly Only discover the HTTP(S) ports, do not perform a security scan. This will attempt to connect with HTTP or HTTPS, and report the Server header. -Format Save the output file specified with -o (-output) option in this format. If not specified, the default will be taken from the file extension specified in the -output option. Valid formats are: csv - a comma-seperated list htm - an HTML report txt - a text report xml - an XML report -host Host(s) to target. Can be an IP address, hostname or text file of hosts. A single dash (-) maybe used for stdout. Can also parse nmap -oG style output -Help Display extended help information. -id ID and password to use for host Basic host authentication. Format is \u0026quot;id:password\u0026quot;. -list-plugins Will list all plugins that Nikto can run against targets and then will exit without performing a scan. These can be tuned for a session using the -plugins option. The output format is: Plugin name full name - description Written by author, Copyright (C) copyright -mutate Specify mutation technique. A mutation will cause Nikto to combine tests or attempt to guess values. These techniques may cause a tremendous amount of tests to be launched against the target. Use the reference number to specify the type, multiple may be used: 1 - Test all files with all root directories 2 - Guess for password file names 3 - Enumerate user names via Apache (/~user type requests) 4 - Enumerate user names via cgiwrap (/cgi-bin/cgiwrap/~user type requests) 5 - Attempt to brute force sub-domain names, assume that the host name is the parent domain 6 - Attempt to guess directory names from the supplied dictionary file -mutate-options Provide extra information for mutates, e.g. a dictionary file -nolookup Do not perform name lookups on IP addresses. -nossl Do not use SSL to connect to the server. -no404 Disable 404 (file not found) checking. This will reduce the total number of requests made to the webserver and may be preferable when checking a server over a slow link, or an embedded device. This will generally lead to more false positives being discovered. -output Write output to the file specified. The format used will be taken from the file extension. This can be over-riden by using the -Format option (e.g. to write text files with a different extenstion. Existing files will have new information appended. -plugins Select which plugins will be run on the specified targets. A comma separated list should be provided which lists the names of the plugins. The names can be found by using -list-plugins. There are two special entries: ALL, which specifies all plugins shall be run and NONE, which specifies no plugins shall be run. The default is ALL -port TCP port(s) to target. To test more than one port on the same host, specify the list of ports in the -p (-port) option. Ports can be specified as a range (i.e., 80-90), or as a comma-delimited list, (i.e., 80,88,90). If not specified, port 80 is used. -Pause Seconds to delay between each test. -root Prepend the value specified to the beginning of every request. This is useful to test applications or web servers which have all of their files under a certain directory. -ssl Only test SSL on the ports specified. Using this option will dramatically speed up requests to HTTPS ports, since otherwise the HTTP request will have to timeout first. -Single Perform a single request to a target server. Nikto will prompt for all options which can be specified, and then report the detailed output. See Chapter 5 for detailed information. -timeout Seconds to wait before timing out a request. Default timeout is 10 seconds. -Tuning Tuning options will control the test that Nikto will use against a target. By default, if any options are specified, only those tests will be performed. If the \u0026quot;x\u0026quot; option is used, it will reverse the logic and exclude only those tests. Use the reference number or letter to specify the type, multiple may be used: 0 - File Upload 1 - Interesting File / Seen in logs 2 - Misconfiguration / Default File 3 - Information Disclosure 4 - Injection (XSS/Script/HTML) 5 - Remote File Retrieval - Inside Web Root 6 - Denial of Service 7 - Remote File Retrieval - Server Wide 8 - Command Execution / Remote Shell 9 - SQL Injection a - Authentication Bypass b - Software Identification c - Remote Source Inclusion x - Reverse Tuning Options (i.e., include all except specified) The given string will be parsed from left to right, any x characters will apply to all characters to the right of the character. -useproxy Use the HTTP proxy defined in the configuration file. -update Update the plugins and databases directly from cirt.net. -Version Display the Nikto software, plugin and database versions. -vhost Specify the Host header to be sent to the target. FILES nikto.conf The Nikto configuration file. This sets Nikto´s global options. Several nikto.conf files may exist and are parsed in the below order. As each configuration file is loaded is supersedes any previously set configuration: • System wide (e.g. /etc/nikto.conf) • Home directory (e.g. $HOME/nikto.conf) • Current directory (e.g. ./nikto.conf) ${NIKTO_DIR}/plugins/db* db files are the databases that nikto uses to check for vulnerabilities and issues within the web server. ${NIKTO_DIR}/plugins/*.plugin All nikto´s plugins exist here. Nikto itself is just a wrapper script to manage CLI and pass through to the plugins. ${NIKTO_DIR}/templates Contains the templates for nikto´s output formats. BUGS The current features are not supported: • SOCKS Proxies AUTHORS Nikto was originally written and maintained by Sullo, CIRT, Inc. It is currently maintained by David Lodge. See the main documentation for other contributors. All code is (C) CIRT, Inc., except LibWhisker which is (C) rfp.labs (wiretrip.net). Other portions of code may be (C) as specified. SEE ALSO Nikto Homepage[1] NOTES 1. Nikto Homepage http://www.cirt.net/ 01/19/2010 NIKTO(1) ```bash ```bash nikto -H Options: -ask+ Whether to ask about submitting updates yes Ask about each (default) no Don't ask, don't send auto Don't ask, just send -Cgidirs+ Scan these CGI dirs: \u0026quot;none\u0026quot;, \u0026quot;all\u0026quot;, or values like \u0026quot;/cgi/ /cgi-a/\u0026quot; -config+ Use this config file -Display+ Turn on/off display outputs: 1 Show redirects 2 Show cookies received 3 Show all 200/OK responses 4 Show URLs which require authentication D Debug output E Display all HTTP errors P Print progress to STDOUT S Scrub output of IPs and hostnames V Verbose output -dbcheck Check database and other key files for syntax errors -evasion+ Encoding technique: 1 Random URI encoding (non-UTF8) 2 Directory self-reference (/./) 3 Premature URL ending 4 Prepend long random string 5 Fake parameter 6 TAB as request spacer 7 Change the case of the URL 8 Use Windows directory separator (\\) A Use a carriage return (0x0d) as a request spacer B Use binary value 0x0b as a request spacer -Format+ Save file (-o) format: csv Comma-separated-value htm HTML Format nbe Nessus NBE format sql Generic SQL (see docs for schema) txt Plain text xml XML Format (if not specified the format will be taken from the file extension passed to -output) -Help Extended help information -host+ Target host -404code Ignore these HTTP codes as negative responses (always). Format is \u0026quot;302,301\u0026quot;. -404string Ignore this string in response body content as negative response (always). Can be a regular expression. -id+ Host authentication to use, format is id:pass or id:pass:realm -key+ Client certificate key file -list-plugins List all available plugins, perform no testing -maxtime+ Maximum testing time per host (e.g., 1h, 60m, 3600s) -mutate+ Guess additional file names: 1 Test all files with all root directories 2 Guess for password file names 3 Enumerate user names via Apache (/~user type requests) 4 Enumerate user names via cgiwrap (/cgi-bin/cgiwrap/~user type requests) 5 Attempt to brute force sub-domain names, assume that the host name is the parent domain 6 Attempt to guess directory names from the supplied dictionary file -mutate-options Provide information for mutates -nointeractive Disables interactive features -nolookup Disables DNS lookups -nossl Disables the use of SSL -no404 Disables nikto attempting to guess a 404 page -Option Over-ride an option in nikto.conf, can be issued multiple times -output+ Write output to this file ('.' for auto-name) -Pause+ Pause between tests (seconds, integer or float) -Plugins+ List of plugins to run (default: ALL) -port+ Port to use (default 80) -RSAcert+ Client certificate file -root+ Prepend root value to all requests, format is /directory -Save Save positive responses to this directory ('.' for auto-name) -ssl Force ssl mode on port -Tuning+ Scan tuning: 1 Interesting File / Seen in logs 2 Misconfiguration / Default File 3 Information Disclosure 4 Injection (XSS/Script/HTML) 5 Remote File Retrieval - Inside Web Root 6 Denial of Service 7 Remote File Retrieval - Server Wide 8 Command Execution / Remote Shell 9 SQL Injection 0 File Upload a Authentication Bypass b Software Identification c Remote Source Inclusion d WebService e Administrative Console x Reverse Tuning Options (i.e., include all except specified) -timeout+ Timeout for requests (default 10 seconds) -Userdbs Load only user databases, not the standard databases all Disable standard dbs and load only user dbs tests Disable only db_tests and load udb_tests -useragent Over-rides the default useragent -until Run until the specified time or duration -update Update databases and plugins from CIRT.net -useproxy Use the proxy defined in nikto.conf, or argument http://server:port -Version Print plugin and database versions -vhost+ Virtual host (for Host header) + requires a value ```bash "}),e.add({id:62,href:"/docs/tools/know/fping/",title:"Fping",description:`Description # fping is a program to send ICMP echo requests to network hosts and to measure the round-trip times for the replies.
install # brew install fping sample usage # fping -q -a -g 192.168.0.0/24 help # FPING(8) FPING(8) NAME fping - send ICMP ECHO_REQUEST packets to network hosts SYNOPSIS fping [ options ] [ systems... ] DESCRIPTION fping is a program like ping which uses the Internet Control Message Protocol (ICMP) echo request to determine if a target host is responding.`,content:"Description # fping is a program to send ICMP echo requests to network hosts and to measure the round-trip times for the replies.\ninstall # brew install fping sample usage # fping -q -a -g 192.168.0.0/24 help # FPING(8) FPING(8) NAME fping - send ICMP ECHO_REQUEST packets to network hosts SYNOPSIS fping [ options ] [ systems... ] DESCRIPTION fping is a program like ping which uses the Internet Control Message Protocol (ICMP) echo request to determine if a target host is responding. fping differs from ping in that you can specify any number of targets on the command line, or specify a file containing the lists of targets to ping. Instead of sending to one target until it times out or replies, fping will send out a ping packet and move on to the next target in a round-robin fashion. In the default mode, if a target replies, it is noted and removed from the list of targets to check; if a target does not respond within a certain time limit and/or retry limit it is designated as unreachable. fping also supports sending a specified number of pings to a target, or looping indefinitely (as in ping ). Unlike ping, fping is meant to be used in scripts, so its output is designed to be easy to parse. Current statistics can be obtained without termination of process with signal SIGQUIT (^\\ from the keyboard on most systems). OPTIONS -4, --ipv4 Restrict name resolution and IPs to IPv4 addresses. -6, --ipv6 Restrict name resolution and IPs to IPv6 addresses. -a, --alive Show systems that are alive. -A, --addr Display targets by address rather than DNS name. Combined with -d, the output will be both the ip and (if available) the hostname. -b, --size=BYTES Number of bytes of ping data to send. The minimum size (normally 12) allows room for the data that fping needs to do its work (sequence number, timestamp). The reported received data size includes the IP header (normally 20 bytes) and ICMP header (8 bytes), so the minimum total size is 40 bytes. Default is 56, as in ping. Maximum is the theoretical maximum IP datagram size (64K), though most systems limit this to a smaller, system-dependent number. -B, --backoff=N Backoff factor. In the default mode, fping sends several requests to a target before giving up, waiting longer for a reply on each successive request. This parameter is the value by which the wait time (-t) is multiplied on each successive request; it must be entered as a floating-point number (x.y). The default is 1.5. -c, --count=N Number of request packets to send to each target. In this mode, a line is displayed for each received response (this can suppressed with -q or -Q). Also, statistics about responses for each target are displayed when all requests have been sent (or when interrupted). -C, --vcount=N Similar to -c, but the per-target statistics are displayed in a format designed for automated response-time statistics gathering. For example: $ fping -C 5 -q somehost somehost : 91.7 37.0 29.2 - 36.8 shows the response time in milliseconds for each of the five requests, with the \u0026quot;-\u0026quot; indicating that no response was received to the fourth request. -d, --rdns Use DNS to lookup address of ping target. This allows you to give fping a list of IP addresses as input and print hostnames in the output. This is similar to option -n/--name, but will force a reverse-DNS lookup even if you give hostnames as target (NAME-\u0026gt;IP-\u0026gt;NAME). -D, --timestamp Add Unix timestamps in front of output lines generated with in looping or counting modes (-l, -c, or -C). -e, --elapsed Show elapsed (round-trip) time of packets. -f, --file Read list of targets from a file. This option can only be used by the root user. Regular users should pipe in the file via stdin: $ fping \u0026lt; targets_file -g, --generate addr/mask Generate a target list from a supplied IP netmask, or a starting and ending IP. Specify the netmask or start/end in the targets portion of the command line. If a network with netmask is given, the network and broadcast addresses will be excluded. ex. To ping the network 192.168.1.0/24, the specified command line could look like either: $ fping -g 192.168.1.0/24 or $ fping -g 192.168.1.1 192.168.1.254 -h, --help Print usage message. -H, --ttl=N Set the IP TTL field (time to live hops). -i, --interval=MSEC The minimum amount of time (in milliseconds) between sending a ping packet to any target (default is 10, minimum is 1). -I, --iface=IFACE Set the interface (requires SO_BINDTODEVICE support). -l, --loop Loop sending packets to each target indefinitely. Can be interrupted with Ctrl-C; statistics about responses for each target are then displayed. -m, --all Send pings to each of a target host's multiple IP addresses (use of option '-A' is recommended). -M, --dontfrag Set the \u0026quot;Don't Fragment\u0026quot; bit in the IP header (used to determine/test the MTU). -n, --name If targets are specified as IP addresses, do a reverse-DNS lookup on them to print hostnames in the output. -N, --netdata Format output for netdata (-l -Q are required). See: \u0026lt;http://my-netdata.io/\u0026gt; -o, --outage Calculate \u0026quot;outage time\u0026quot; based on the number of lost pings and the interval used (useful for network convergence tests). -O, --tos=N Set the typ of service flag (TOS). N can be either decimal or hexadecimal (0xh) format. -p, --period=MSEC In looping or counting modes (-l, -c, or -C), this parameter sets the time in milliseconds that fping waits between successive packets to an individual target. Default is 1000 and minimum is 10. -q, --quiet Quiet. Don't show per-probe results, but only the final summary. Also don't show ICMP error messages. -Q, --squiet=SECS Like -q, but additionally show interval summary results every SECS seconds. -r, --retry=N Retry limit (default 3). This is the number of times an attempt at pinging a target will be made, not including the first try. -R, --random Instead of using all-zeros as the packet data, generate random bytes. Use to defeat, e.g., link data compression. -s, --stats Print cumulative statistics upon exit. -S, --src=addr Set source address. -t, --timeout=MSEC Initial target timeout in milliseconds. In the default, non-loop mode, the default timeout is 500ms, and it represents the amount of time that fping waits for a response to its first request. Successive timeouts are multiplied by the backoff factor specified with -B. In loop/count mode, the default timeout is automatically adjusted to match the \u0026quot;period\u0026quot; value (but not more than 2000ms). You can still adjust the timeout value with this option, if you wish to, but note that setting a value larger than \u0026quot;period\u0026quot; produces inconsistent results, because the timeout value can be respected only for the last ping. Also note that any received replies that are larger than the timeout value, will be discarded. -T n Ignored (for compatibility with fping 2.4). -u, --unreach Show targets that are unreachable. -v, --version Print fping version information. -x, --reachable=N Given a list of hosts, this mode checks if number of reachable hosts is \u0026gt;= N and exits true in that case. EXAMPLES Generate 20 pings to two hosts in ca. 1 second (i.e. one ping every 50 ms to each host), and report every ping RTT at the end: $ fping --quiet --interval=1 --vcount=20 --period=50 127.0.0.1 127.0.0.2 AUTHORS • Roland J. Schemers III, Stanford University, concept and versions 1.x • RL \u0026quot;Bob\u0026quot; Morgan, Stanford University, versions 2.x • David Papp, versions 2.3x and up • David Schweikert, versions 3.0 and up fping website: \u0026lt;http://www.fping.org\u0026gt; DIAGNOSTICS Exit status is 0 if all the hosts are reachable, 1 if some hosts were unreachable, 2 if any IP addresses were not found, 3 for invalid command line arguments, and 4 for a system call failure. RESTRICTIONS If fping was configured with \u0026quot;--enable-safe-limits\u0026quot;, the following values are not allowed for non-root users: • -i n, where n \u0026lt; 1 msec • -p n, where n \u0026lt; 10 msec SEE ALSO ping(8) fping 2022-02-06 FPING(8) ```bash "}),e.add({id:63,href:"/docs/tools/know/gau/",title:"Gau",description:"Description # gau is a simple tool for scraping URLs from a given domain. It is a wrapper around Wayback Machine and Common Crawl.\nInstallation # brew install gau Usage # gau example.com Resources # gau help # Usage of gau: --blacklist strings list of extensions to skip --fc strings list of status codes to filter --fp remove different parameters of the same endpoint --from string fetch urls from date (format: YYYYMM) --ft strings list of mime-types to filter --json output as json --mc strings list of status codes to match --mt strings list of mime-types to match --o string filename to write results to --providers strings list of providers to use (wayback,commoncrawl,otx,urlscan) --proxy string http proxy to use --retries uint retries for HTTP client --subs include subdomains of target domain --threads uint number of workers to spawn (default 1) --timeout uint timeout (in seconds) for HTTP client (default 45) --to string fetch urls to date (format: YYYYMM) --verbose show verbose output --version show gau version ```bash ",content:"Description # gau is a simple tool for scraping URLs from a given domain. It is a wrapper around Wayback Machine and Common Crawl.\nInstallation # brew install gau Usage # gau example.com Resources # gau help # Usage of gau: --blacklist strings list of extensions to skip --fc strings list of status codes to filter --fp remove different parameters of the same endpoint --from string fetch urls from date (format: YYYYMM) --ft strings list of mime-types to filter --json output as json --mc strings list of status codes to match --mt strings list of mime-types to match --o string filename to write results to --providers strings list of providers to use (wayback,commoncrawl,otx,urlscan) --proxy string http proxy to use --retries uint retries for HTTP client --subs include subdomains of target domain --threads uint number of workers to spawn (default 1) --timeout uint timeout (in seconds) for HTTP client (default 45) --to string fetch urls to date (format: YYYYMM) --verbose show verbose output --version show gau version ```bash "}),e.add({id:64,href:"/docs/tools/know/gobuster/",title:"Gobuster",description:`Description # Gobuster is a tool used to brute-force URIs (directories and files) in web sites, DNS subdomains (with wildcard support), Virtual Host names on target web servers and Virtual Host names on target web servers.
install # brew install gobuster sample usage # gobuster dir -u https://example.com -w /usr/share/wordlists/dirb/common.txt website # https://github.com/OJ/gobuster
help # Usage: gobuster [command] Available Commands: completion Generate the autocompletion script for the specified shell dir Uses directory/file enumeration mode dns Uses DNS subdomain enumeration mode fuzz Uses fuzzing mode help Help about any command s3 Uses aws bucket enumeration mode version shows the current version vhost Uses VHOST enumeration mode Flags: --delay duration Time each thread waits between requests (e.`,content:"Description # Gobuster is a tool used to brute-force URIs (directories and files) in web sites, DNS subdomains (with wildcard support), Virtual Host names on target web servers and Virtual Host names on target web servers.\ninstall # brew install gobuster sample usage # gobuster dir -u https://example.com -w /usr/share/wordlists/dirb/common.txt website # https://github.com/OJ/gobuster\nhelp # Usage: gobuster [command] Available Commands: completion Generate the autocompletion script for the specified shell dir Uses directory/file enumeration mode dns Uses DNS subdomain enumeration mode fuzz Uses fuzzing mode help Help about any command s3 Uses aws bucket enumeration mode version shows the current version vhost Uses VHOST enumeration mode Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) -h, --help help for gobuster --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ## Available Modes - dir - the classic directory brute-forcing mode - dns - DNS subdomain brute-forcing mode - s3 - Enumerate open S3 buckets and look for existence and bucket listings - gcs - Enumerate open google cloud buckets - vhost - virtual host brute-forcing mode (not the same as DNS!) - fuzz - some basic fuzzing, replaces the `FUZZ` keyword - tftp - bruteforce tftp files ## Easy Installation ### Binary Releases We are now shipping binaries for each of the releases so that you don't even have to build them yourself! How wonderful is that! If you're stupid enough to trust binaries that I've put together, you can download them from the [releases](https://github.com/OJ/gobuster/releases) page. ### Using `go install` If you have a [Go](https://golang.org/) environment ready to go (at least go 1.19), it's as easy as: ```bash go install github.com/OJ/gobuster/v3@latest ```bash PS: You need at least go 1.19 to compile gobuster. ### Building From Source Since this tool is written in [Go](https://golang.org/) you need to install the Go language/compiler/etc. Full details of installation and set up can be found [on the Go language website](https://golang.org/doc/install). Once installed you have two options. You need at least go 1.19 to compile gobuster. ### Compiling `gobuster` has external dependencies, and so they need to be pulled in first: ```bash go get \u0026amp;\u0026amp; go build ```bash This will create a `gobuster` binary for you. If you want to install it in the `$GOPATH/bin` folder you can run: ```bash go install ```bash ## Modes Help is built-in! - `gobuster help` - outputs the top-level help. - `gobuster help \u0026lt;mode\u0026gt;` - outputs the help specific to that mode. ## `dns` Mode ### Options ```bashtext Uses DNS subdomain enumeration mode Usage: gobuster dns [flags] Flags: -d, --domain string The target domain -h, --help help for dns -r, --resolver string Use custom DNS server (format server.com or server.com:port) -c, --show-cname Show CNAME records (cannot be used with '-i' option) -i, --show-ips Show IP addresses --timeout duration DNS resolver timeout (default 1s) --wildcard Force continued operation when wildcard found Global Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) --no-color Disable color output --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ### Examples ```bashtext gobuster dns -d mysite.com -t 50 -w common-names.txt ```bash Normal sample run goes like this: ```bashtext gobuster dns -d google.com -w ~/wordlists/subdomains.txt =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dns [+] Url/Domain : google.com [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/subdomains.txt =============================================================== 2019/06/21 11:54:20 Starting gobuster =============================================================== Found: chrome.google.com Found: ns1.google.com Found: admin.google.com Found: www.google.com Found: m.google.com Found: support.google.com Found: translate.google.com Found: cse.google.com Found: news.google.com Found: music.google.com Found: mail.google.com Found: store.google.com Found: mobile.google.com Found: search.google.com Found: wap.google.com Found: directory.google.com Found: local.google.com Found: blog.google.com =============================================================== 2019/06/21 11:54:20 Finished =============================================================== ```bash Show IP sample run goes like this: ```bashtext gobuster dns -d google.com -w ~/wordlists/subdomains.txt -i =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dns [+] Url/Domain : google.com [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/subdomains.txt =============================================================== 2019/06/21 11:54:54 Starting gobuster =============================================================== Found: www.google.com [172.217.25.36, 2404:6800:4006:802::2004] Found: admin.google.com [172.217.25.46, 2404:6800:4006:806::200e] Found: store.google.com [172.217.167.78, 2404:6800:4006:802::200e] Found: mobile.google.com [172.217.25.43, 2404:6800:4006:802::200b] Found: ns1.google.com [216.239.32.10, 2001:4860:4802:32::a] Found: m.google.com [172.217.25.43, 2404:6800:4006:802::200b] Found: cse.google.com [172.217.25.46, 2404:6800:4006:80a::200e] Found: chrome.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: search.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: local.google.com [172.217.25.46, 2404:6800:4006:80a::200e] Found: news.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: blog.google.com [216.58.199.73, 2404:6800:4006:806::2009] Found: support.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: wap.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: directory.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: translate.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: music.google.com [172.217.25.46, 2404:6800:4006:802::200e] Found: mail.google.com [172.217.25.37, 2404:6800:4006:802::2005] =============================================================== 2019/06/21 11:54:55 Finished =============================================================== ```bash Base domain validation warning when the base domain fails to resolve. This is a warning rather than a failure in case the user fat-fingers while typing the domain. ```bashtext gobuster dns -d yp.to -w ~/wordlists/subdomains.txt -i =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dns [+] Url/Domain : yp.to [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/subdomains.txt =============================================================== 2019/06/21 11:56:43 Starting gobuster =============================================================== 2019/06/21 11:56:53 [-] Unable to validate base domain: yp.to Found: cr.yp.to [131.193.32.108, 131.193.32.109] =============================================================== 2019/06/21 11:56:53 Finished =============================================================== ```bash Wildcard DNS is also detected properly: ```bashtext gobuster dns -d 0.0.1.xip.io -w ~/wordlists/subdomains.txt =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dns [+] Url/Domain : 0.0.1.xip.io [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/subdomains.txt =============================================================== 2019/06/21 12:13:48 Starting gobuster =============================================================== 2019/06/21 12:13:48 [-] Wildcard DNS found. IP address(es): 1.0.0.0 2019/06/21 12:13:48 [!] To force processing of Wildcard DNS, specify the '--wildcard' switch. =============================================================== 2019/06/21 12:13:48 Finished =============================================================== ```bash If the user wants to force processing of a domain that has wildcard entries, use `--wildcard`: ```bashtext gobuster dns -d 0.0.1.xip.io -w ~/wordlists/subdomains.txt --wildcard =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dns [+] Url/Domain : 0.0.1.xip.io [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/subdomains.txt =============================================================== 2019/06/21 12:13:51 Starting gobuster =============================================================== 2019/06/21 12:13:51 [-] Wildcard DNS found. IP address(es): 1.0.0.0 Found: 127.0.0.1.xip.io Found: test.127.0.0.1.xip.io =============================================================== 2019/06/21 12:13:53 Finished =============================================================== ```bash ## `dir` Mode ### Options ```bashtext Uses directory/file enumeration mode Usage: gobuster dir [flags] Flags: -f, --add-slash Append / to each request -c, --cookies string Cookies to use for the requests -d, --discover-backup Also search for backup files by appending multiple backup extensions --exclude-length ints exclude the following content length (completely ignores the status). Supply multiple times to exclude multiple sizes. -e, --expanded Expanded mode, print full URLs -x, --extensions string File extension(s) to search for -r, --follow-redirect Follow redirects -H, --headers stringArray Specify HTTP headers, -H 'Header1: val1' -H 'Header2: val2' -h, --help help for dir --hide-length Hide the length of the body in the output -m, --method string Use the following HTTP method (default \u0026quot;GET\u0026quot;) -n, --no-status Don't print status codes -k, --no-tls-validation Skip TLS certificate verification -P, --password string Password for Basic Auth --proxy string Proxy to use for requests [http(s)://host:port] --random-agent Use a random User-Agent string --retry Should retry on request timeout --retry-attempts int Times to retry on request timeout (default 3) -s, --status-codes string Positive status codes (will be overwritten with status-codes-blacklist if set) -b, --status-codes-blacklist string Negative status codes (will override status-codes if set) (default \u0026quot;404\u0026quot;) --timeout duration HTTP Timeout (default 10s) -u, --url string The target URL -a, --useragent string Set the User-Agent string (default \u0026quot;gobuster/3.2.0\u0026quot;) -U, --username string Username for Basic Auth Global Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) --no-color Disable color output --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ### Examples ```bashtext gobuster dir -u https://mysite.com/path/to/folder -c 'session=123456' -t 50 -w common-files.txt -x .php,.html ```bash Default options looks like this: ```bashtext gobuster dir -u https://buffered.io -w ~/wordlists/shortlist.txt =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dir [+] Url/Domain : https://buffered.io/ [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/shortlist.txt [+] Status codes : 200,204,301,302,307,401,403 [+] User Agent : gobuster/3.2.0 [+] Timeout : 10s =============================================================== 2019/06/21 11:49:43 Starting gobuster =============================================================== /categories (Status: 301) /contact (Status: 301) /posts (Status: 301) /index (Status: 200) =============================================================== 2019/06/21 11:49:44 Finished =============================================================== ```bash Default options with status codes disabled looks like this: ```bashtext gobuster dir -u https://buffered.io -w ~/wordlists/shortlist.txt -n =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dir [+] Url/Domain : https://buffered.io/ [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/shortlist.txt [+] Status codes : 200,204,301,302,307,401,403 [+] User Agent : gobuster/3.2.0 [+] No status : true [+] Timeout : 10s =============================================================== 2019/06/21 11:50:18 Starting gobuster =============================================================== /categories /contact /index /posts =============================================================== 2019/06/21 11:50:18 Finished =============================================================== ```bash Verbose output looks like this: ```bashtext gobuster dir -u https://buffered.io -w ~/wordlists/shortlist.txt -v =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dir [+] Url/Domain : https://buffered.io/ [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/shortlist.txt [+] Status codes : 200,204,301,302,307,401,403 [+] User Agent : gobuster/3.2.0 [+] Verbose : true [+] Timeout : 10s =============================================================== 2019/06/21 11:50:51 Starting gobuster =============================================================== Missed: /alsodoesnotexist (Status: 404) Found: /index (Status: 200) Missed: /doesnotexist (Status: 404) Found: /categories (Status: 301) Found: /posts (Status: 301) Found: /contact (Status: 301) =============================================================== 2019/06/21 11:50:51 Finished =============================================================== ```bash Example showing content length: ```bashtext gobuster dir -u https://buffered.io -w ~/wordlists/shortlist.txt -l =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Mode : dir [+] Url/Domain : https://buffered.io/ [+] Threads : 10 [+] Wordlist : /home/oj/wordlists/shortlist.txt [+] Status codes : 200,204,301,302,307,401,403 [+] User Agent : gobuster/3.2.0 [+] Show length : true [+] Timeout : 10s =============================================================== 2019/06/21 11:51:16 Starting gobuster =============================================================== /categories (Status: 301) [Size: 178] /posts (Status: 301) [Size: 178] /contact (Status: 301) [Size: 178] /index (Status: 200) [Size: 51759] =============================================================== 2019/06/21 11:51:17 Finished =============================================================== ```bash Quiet output, with status disabled and expanded mode looks like this (\u0026quot;grep mode\u0026quot;): ```bashtext gobuster dir -u https://buffered.io -w ~/wordlists/shortlist.txt -q -n -e https://buffered.io/index https://buffered.io/contact https://buffered.io/posts https://buffered.io/categories ```bash ## `vhost` Mode ### Options ```bashtext Uses VHOST enumeration mode (you most probably want to use the IP address as the URL parameter) Usage: gobuster vhost [flags] Flags: --append-domain Append main domain from URL to words from wordlist. Otherwise the fully qualified domains need to be specified in the wordlist. -c, --cookies string Cookies to use for the requests --domain string the domain to append when using an IP address as URL. If left empty and you specify a domain based URL the hostname from the URL is extracted --exclude-length ints exclude the following content length (completely ignores the status). Supply multiple times to exclude multiple sizes. -r, --follow-redirect Follow redirects -H, --headers stringArray Specify HTTP headers, -H 'Header1: val1' -H 'Header2: val2' -h, --help help for vhost -m, --method string Use the following HTTP method (default \u0026quot;GET\u0026quot;) -k, --no-tls-validation Skip TLS certificate verification -P, --password string Password for Basic Auth --proxy string Proxy to use for requests [http(s)://host:port] --random-agent Use a random User-Agent string --retry Should retry on request timeout --retry-attempts int Times to retry on request timeout (default 3) --timeout duration HTTP Timeout (default 10s) -u, --url string The target URL -a, --useragent string Set the User-Agent string (default \u0026quot;gobuster/3.2.0\u0026quot;) -U, --username string Username for Basic Auth Global Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) --no-color Disable color output --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ### Examples ```bashtext gobuster vhost -u https://mysite.com -w common-vhosts.txt ```bash Normal sample run goes like this: ```bashtext gobuster vhost -u https://mysite.com -w common-vhosts.txt =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Url: https://mysite.com [+] Threads: 10 [+] Wordlist: common-vhosts.txt [+] User Agent: gobuster/3.2.0 [+] Timeout: 10s =============================================================== 2019/06/21 08:36:00 Starting gobuster =============================================================== Found: www.mysite.com Found: piwik.mysite.com Found: mail.mysite.com =============================================================== 2019/06/21 08:36:05 Finished =============================================================== ```bash ## `fuzz` Mode ### Options ```bashtext Uses fuzzing mode Usage: gobuster fuzz [flags] Flags: -c, --cookies string Cookies to use for the requests --exclude-length ints exclude the following content length (completely ignores the status). Supply multiple times to exclude multiple sizes. -b, --excludestatuscodes string Negative status codes (will override statuscodes if set) -r, --follow-redirect Follow redirects -H, --headers stringArray Specify HTTP headers, -H 'Header1: val1' -H 'Header2: val2' -h, --help help for fuzz -m, --method string Use the following HTTP method (default \u0026quot;GET\u0026quot;) -k, --no-tls-validation Skip TLS certificate verification -P, --password string Password for Basic Auth --proxy string Proxy to use for requests [http(s)://host:port] --random-agent Use a random User-Agent string --retry Should retry on request timeout --retry-attempts int Times to retry on request timeout (default 3) --timeout duration HTTP Timeout (default 10s) -u, --url string The target URL -a, --useragent string Set the User-Agent string (default \u0026quot;gobuster/3.2.0\u0026quot;) -U, --username string Username for Basic Auth Global Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) --no-color Disable color output --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ### Examples ```bashtext gobuster fuzz -u https://example.com?FUZZ=test -w parameter-names.txt ```bash ## `s3` Mode ### Options ```bashtext Uses aws bucket enumeration mode Usage: gobuster s3 [flags] Flags: -h, --help help for s3 -m, --maxfiles int max files to list when listing buckets (only shown in verbose mode) (default 5) -k, --no-tls-validation Skip TLS certificate verification --proxy string Proxy to use for requests [http(s)://host:port] --random-agent Use a random User-Agent string --retry Should retry on request timeout --retry-attempts int Times to retry on request timeout (default 3) --timeout duration HTTP Timeout (default 10s) -a, --useragent string Set the User-Agent string (default \u0026quot;gobuster/3.2.0\u0026quot;) Global Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) --no-color Disable color output --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ### Examples ```bashtext gobuster s3 -w bucket-names.txt ```bash ## `gcs` Mode ### Options ```bashtext Uses gcs bucket enumeration mode Usage: gobuster gcs [flags] Flags: -h, --help help for gcs -m, --maxfiles int max files to list when listing buckets (only shown in verbose mode) (default 5) -k, --no-tls-validation Skip TLS certificate verification --proxy string Proxy to use for requests [http(s)://host:port] --random-agent Use a random User-Agent string --retry Should retry on request timeout --retry-attempts int Times to retry on request timeout (default 3) --timeout duration HTTP Timeout (default 10s) -a, --useragent string Set the User-Agent string (default \u0026quot;gobuster/3.2.0\u0026quot;) Global Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) --no-color Disable color output --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ### Examples ```bashtext gobuster gcs -w bucket-names.txt ```bash ## `tftp` Mode ### Options ```bashtext Uses TFTP enumeration mode Usage: gobuster tftp [flags] Flags: -h, --help help for tftp -s, --server string The target TFTP server --timeout duration TFTP timeout (default 1s) Global Flags: --delay duration Time each thread waits between requests (e.g. 1500ms) --no-color Disable color output --no-error Don't display errors -z, --no-progress Don't display progress -o, --output string Output file to write results to (defaults to stdout) -p, --pattern string File containing replacement patterns -q, --quiet Don't print the banner and other noise -t, --threads int Number of concurrent threads (default 10) -v, --verbose Verbose output (errors) -w, --wordlist string Path to the wordlist ```bash ### Examples ```bashtext gobuster tftp -s tftp.example.com -w common-filenames.txt ```bash ## Wordlists via STDIN Wordlists can be piped into `gobuster` via stdin by providing a `-` to the `-w` option: ```bash hashcat -a 3 --stdout ?l | gobuster dir -u https://mysite.com -w - ```bash Note: If the `-w` option is specified at the same time as piping from STDIN, an error will be shown and the program will terminate. ## Patterns You can supply pattern files that will be applied to every word from the wordlist. Just place the string `{GOBUSTER}` in it and this will be replaced with the word. This feature is also handy in s3 mode to pre- or postfix certain patterns. **Caution:** Using a big pattern file can cause a lot of request as every pattern is applied to every word in the wordlist. ### Example file ```bashtext {GOBUSTER}Partial {GOBUSTER}Service PRE{GOBUSTER}POST {GOBUSTER}-prod {GOBUSTER}-dev ```bash #### Use case in combination with patterns - Create a custom wordlist for the target containing company names and so on - Create a pattern file to use for common bucket names. ```bash curl -s --output - https://raw.githubusercontent.com/eth0izzle/bucket-stream/master/permutations/extended.txt | sed -s 's/%s/{GOBUSTER}/' \u0026gt; patterns.txt ```bash - Run gobuster with the custom input. Be sure to turn verbose mode on to see the bucket details ```bashtext gobuster s3 --wordlist my.custom.wordlist -p patterns.txt -v ```bash Normal sample run goes like this: ```bashtext PS C:\\Users\\firefart\\Documents\\code\\gobuster\u0026gt; .\\gobuster.exe s3 --wordlist .\\wordlist.txt =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Threads: 10 [+] Wordlist: .\\wordlist.txt [+] User Agent: gobuster/3.2.0 [+] Timeout: 10s [+] Maximum files to list: 5 =============================================================== 2019/08/12 21:48:16 Starting gobuster in S3 bucket enumeration mode =============================================================== webmail hacking css img www dav web localhost =============================================================== 2019/08/12 21:48:17 Finished =============================================================== ```bash Verbose and sample run ```bashtext PS C:\\Users\\firefart\\Documents\\code\\gobuster\u0026gt; .\\gobuster.exe s3 --wordlist .\\wordlist.txt -v =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Threads: 10 [+] Wordlist: .\\wordlist.txt [+] User Agent: gobuster/3.2.0 [+] Verbose: true [+] Timeout: 10s [+] Maximum files to list: 5 =============================================================== 2019/08/12 21:49:00 Starting gobuster in S3 bucket enumeration mode =============================================================== www [Error: All access to this object has been disabled (AllAccessDisabled)] hacking [Error: Access Denied (AccessDenied)] css [Error: All access to this object has been disabled (AllAccessDisabled)] webmail [Error: All access to this object has been disabled (AllAccessDisabled)] img [Bucket Listing enabled: GodBlessPotomac1.jpg (1236807b), HOMEWORKOUTAUDIO.zip (203908818b), ProductionInfo.xml (11946b), Start of Perpetual Motion Logo-1.mp3 (621821b), addressbook.gif (3115b)] web [Error: Access Denied (AccessDenied)] dav [Error: All access to this object has been disabled (AllAccessDisabled)] localhost [Error: Access Denied (AccessDenied)] =============================================================== 2019/08/12 21:49:01 Finished =============================================================== ```bash Extended sample run ```bashtext PS C:\\Users\\firefart\\Documents\\code\\gobuster\u0026gt; .\\gobuster.exe s3 --wordlist .\\wordlist.txt -e =============================================================== Gobuster v3.2.0 by OJ Reeves (@TheColonial) \u0026amp; Christian Mehlmauer (@firefart) =============================================================== [+] Threads: 10 [+] Wordlist: .\\wordlist.txt [+] User Agent: gobuster/3.2.0 [+] Timeout: 10s [+] Expanded: true [+] Maximum files to list: 5 =============================================================== 2019/08/12 21:48:38 Starting gobuster in S3 bucket enumeration mode =============================================================== http://css.s3.amazonaws.com/ http://www.s3.amazonaws.com/ http://webmail.s3.amazonaws.com/ http://hacking.s3.amazonaws.com/ http://img.s3.amazonaws.com/ http://web.s3.amazonaws.com/ http://dav.s3.amazonaws.com/ http://localhost.s3.amazonaws.com/ =============================================================== 2019/08/12 21:48:38 Finished =============================================================== ```bash "}),e.add({id:65,href:"/docs/tools/know/httpx/",title:"Httpx",description:`Description # httpx is a fast and multi-purpose HTTP toolkit.
Installation # brew install httpx Usage # httpx -list hosts.txt -silent -probe echo 173.0.84.0/24 | httpx -silent Resources # httpx GitHub Similar # curl wget httpie httpstat httpstat.us httpbin help # Usage: ./httpx [flags] Flags: INPUT: -l, -list string input file containing list of hosts to process -rr, -request string file containing raw request -u, -target string[] input target host(s) to probe PROBES: -sc, -status-code display response status-code -cl, -content-length display response content-length -ct, -content-type display response content-type -location display response redirect location -favicon display mmh3 hash for '/favicon.`,content:"Description # httpx is a fast and multi-purpose HTTP toolkit.\nInstallation # brew install httpx Usage # httpx -list hosts.txt -silent -probe echo 173.0.84.0/24 | httpx -silent Resources # httpx GitHub Similar # curl wget httpie httpstat httpstat.us httpbin help # Usage: ./httpx [flags] Flags: INPUT: -l, -list string input file containing list of hosts to process -rr, -request string file containing raw request -u, -target string[] input target host(s) to probe PROBES: -sc, -status-code display response status-code -cl, -content-length display response content-length -ct, -content-type display response content-type -location display response redirect location -favicon display mmh3 hash for '/favicon.ico' file -hash string display response body hash (supported: md5,mmh3,simhash,sha1,sha256,sha512) -jarm display jarm fingerprint hash -rt, -response-time display response time -lc, -line-count display response body line count -wc, -word-count display response body word count -title display page title -server, -web-server display server name -td, -tech-detect display technology in use based on wappalyzer dataset -method display http request method -websocket display server using websocket -ip display host ip -cname display host cname -asn display host asn information -cdn display cdn in use -probe display probe status MATCHERS: -mc, -match-code string match response with specified status code (-mc 200,302) -ml, -match-length string match response with specified content length (-ml 100,102) -mlc, -match-line-count string match response body with specified line count (-mlc 423,532) -mwc, -match-word-count string match response body with specified word count (-mwc 43,55) -mfc, -match-favicon string[] match response with specified favicon hash (-mfc 1494302000) -ms, -match-string string match response with specified string (-ms admin) -mr, -match-regex string match response with specified regex (-mr admin) -mcdn, -match-cdn string[] match host with specified cdn provider (oracle, google, azure, cloudflare, cloudfront, fastly, incapsula, leaseweb, akamai, sucuri) -mrt, -match-response-time string match response with specified response time in seconds (-mrt '\u0026lt; 1') -mdc, -match-condition string match response with dsl expression condition EXTRACTOR: -er, -extract-regex string[] display response content with matched regex -ep, -extract-preset string[] display response content matched by a pre-defined regex (url,ipv4,mail) FILTERS: -fc, -filter-code string filter response with specified status code (-fc 403,401) -fl, -filter-length string filter response with specified content length (-fl 23,33) -flc, -filter-line-count string filter response body with specified line count (-flc 423,532) -fwc, -filter-word-count string filter response body with specified word count (-fwc 423,532) -ffc, -filter-favicon string[] filter response with specified favicon hash (-mfc 1494302000) -fs, -filter-string string filter response with specified string (-fs admin) -fe, -filter-regex string filter response with specified regex (-fe admin) -fcdn, -filter-cdn string[] filter host with specified cdn provider (oracle, google, azure, cloudflare, cloudfront, fastly, incapsula, leaseweb, akamai, sucuri) -frt, -filter-response-time string filter response with specified response time in seconds (-frt '\u0026gt; 1') -fdc, -filter-condition string filter response with dsl expression condition RATE-LIMIT: -t, -threads int number of threads to use (default 50) -rl, -rate-limit int maximum requests to send per second (default 150) -rlm, -rate-limit-minute int maximum number of requests to send per minute MISCELLANEOUS: -pa, -probe-all-ips probe all the ips associated with same host -p, -ports string[] ports to probe (nmap syntax: eg http:1,2-10,11,https:80) -path string path or list of paths to probe (comma-separated, file) -tls-probe send http probes on the extracted TLS domains (dns_name) -csp-probe send http probes on the extracted CSP domains -tls-grab perform TLS(SSL) data grabbing -pipeline probe and display server supporting HTTP1.1 pipeline -http2 probe and display server supporting HTTP2 -vhost probe and display server supporting VHOST -ldv, -list-dsl-variables list json output field keys name that support dsl matcher/filter OUTPUT: -o, -output string file to write output results -sr, -store-response store http response to output directory -srd, -store-response-dir string store http response to custom directory -csv store output in csv format -csvo, -csv-output-encoding string define output encoding -json store output in JSONL(ines) format -irr, -include-response include http request/response in JSON output (-json only) -irrb, -include-response-base64 include base64 encoded http request/response in JSON output (-json only) -include-chain include redirect http chain in JSON output (-json only) -store-chain include http redirect chain in responses (-sr only) CONFIGURATIONS: -r, -resolvers string[] list of custom resolver (file or comma separated) -allow string[] allowed list of IP/CIDR's to process (file or comma separated) -deny string[] denied list of IP/CIDR's to process (file or comma separated) -sni, -sni-name string custom TLS SNI name -random-agent enable Random User-Agent to use (default true) -H, -header string[] custom http headers to send with request -http-proxy, -proxy string http proxy to use (eg http://127.0.0.1:8080) -unsafe send raw requests skipping golang normalization -resume resume scan using resume.cfg -fr, -follow-redirects follow http redirects -maxr, -max-redirects int max number of redirects to follow per host (default 10) -fhr, -follow-host-redirects follow redirects on the same host -vhost-input get a list of vhosts as input -x string request methods to probe, use 'all' to probe all HTTP methods -body string post body to include in http request -s, -stream stream mode - start elaborating input targets without sorting -sd, -skip-dedupe disable dedupe input items (only used with stream mode) -ldp, -leave-default-ports leave default http/https ports in host header (eg. http://host:80 - https//host:443 -ztls use ztls library with autofallback to standard one for tls13 DEBUG: -health-check, -hc run diagnostic check up -debug display request/response content in cli -debug-req display request content in cli -debug-resp display response content in cli -version display httpx version -stats display scan statistic -profile-mem string optional httpx memory profile dump file -silent silent mode -v, -verbose verbose mode -si, -stats-interval int number of seconds to wait between showing a statistics update (default: 5) -nc, -no-color disable colors in cli output OPTIMIZATIONS: -nf, -no-fallback display both probed protocol (HTTPS and HTTP) -nfs, -no-fallback-scheme probe with protocol scheme specified in input -maxhr, -max-host-error int max error count per host before skipping remaining path/s (default 30) -ec, -exclude-cdn skip full port scans for CDNs (only checks for 80,443) -retries int number of retries -timeout int timeout in seconds (default 5) -delay duration duration between each http request (eg: 200ms, 1s) (default -1ns) -rsts, -response-size-to-save int max response size to save in bytes (default 2147483647) -rstr, -response-size-to-read int max response size to read in bytes (default 2147483647) ```bash "}),e.add({id:66,href:"/docs/tools/know/httrack/",title:"Httrack",description:"Description # httrack is a website copier. It allows you to download a website from the Internet to a local directory, building recursively all directories, getting html, images, and other files from the server to your computer. HTTrack arranges the original site\u0026rsquo;s relative link-structure. Simply open a page of the \u0026ldquo;mirrored\u0026rdquo; website in your browser, and you can browse the site from link to link, as if you were viewing it online.",content:`Description # httrack is a website copier. It allows you to download a website from the Internet to a local directory, building recursively all directories, getting html, images, and other files from the server to your computer. HTTrack arranges the original site\u0026rsquo;s relative link-structure. Simply open a page of the \u0026ldquo;mirrored\u0026rdquo; website in your browser, and you can browse the site from link to link, as if you were viewing it online. HTTrack can also update an existing mirrored site, and resume interrupted downloads. HTTrack is fully configurable, and has an integrated help system.
install # brew install httrack sample usage # httrack https://www.example.com help (from gist) # `}),e.add({id:67,href:"/docs/tools/know/arp-scan/",title:"Arp Scan",description:`-scan
Description # arp-scan is a tool for sending ARP requests to hosts on a local network and reporting the responses. It can be used to discover hosts that are up, and to identify their MAC addresses.
install # brew install arp-scan sample usage # arp-scan --localnet help # ARP-SCAN(1) General Commands Manual ARP-SCAN(1) NAME arp-scan - The ARP scanner SYNOPSIS arp-scan [options] [hosts...] Target hosts must be specified on the command line unless the --file option is given, in which case the targets are read from the specified file instead, or the --localnet option is used, in which case the targets are generated from the network interface IP address and netmask.`,content:"-scan\nDescription # arp-scan is a tool for sending ARP requests to hosts on a local network and reporting the responses. It can be used to discover hosts that are up, and to identify their MAC addresses.\ninstall # brew install arp-scan sample usage # arp-scan --localnet help # ARP-SCAN(1) General Commands Manual ARP-SCAN(1) NAME arp-scan - The ARP scanner SYNOPSIS arp-scan [options] [hosts...] Target hosts must be specified on the command line unless the --file option is given, in which case the targets are read from the specified file instead, or the --localnet option is used, in which case the targets are generated from the network interface IP address and netmask. You will need to be root, or arp-scan must be SUID root, in order to run arp-scan, because the functions that it uses to read and write packets require root privilege. The target hosts can be specified as IP addresses or hostnames. You can also specify the target as IPnetwork/bits (e.g. 192.168.1.0/24) to specify all hosts in the given network (network and broadcast addresses included), IPstart-IPend (e.g. 192.168.1.3-192.168.1.27) to specify all hosts in the inclusive range, or IPnetwork:NetMask (e.g. 192.168.1.0:255.255.255.0) to specify all hosts in the given network and mask. DESCRIPTION arp-scan sends ARP packets to hosts on the local network and displays any responses that are received. The network interface to use can be specified with the --interface option. If this option is not present, arp-scan will search the system interface list for the lowest numbered, configured up interface (excluding loopback). By default, the ARP packets are sent to the Ethernet broadcast address, ff:ff:ff:ff:ff:ff, but that can be changed with the --destaddr option. The target hosts to scan may be specified in one of three ways: by specifying the targets on the command line; by specifying a file containing the targets with the --file option; or by speci‐ fying the --localnet option which causes all possible hosts on the network attached to the interface (as defined by the interface address and mask) to be scanned. For hosts specified on the command line, or with the --file option, you can use either IP addresses or hostnames. You can also use network specifications IPnetwork/bits, IPstart-IPend, or IPnetwork:NetMask. The list of target hosts is stored in memory. Each host in this list uses 28 bytes of memory, so scanning a Class-B network (65,536 hosts) requires about 1.75MB of memory for the list, and scanning a Class-A (16,777,216 hosts) requires about 448MB. arp-scan supports Ethernet and 802.11 wireless networks. It could also support token ring and FDDI, but they have not been tested. It does not support serial links such as PPP or SLIP, because ARP is not supported on them. The ARP protocol is a layer-2 (datalink layer) protocol that is used to determine a host's layer-2 address given its layer-3 (network layer) address. ARP was designed to work with any layer-2 and layer-3 address format, but the most common use is to map IP addresses to Ethernet hardware addresses, and this is what arp-scan supports. ARP only operates on the local network, and can‐ not be routed. Although the ARP protocol makes use of IP addresses, it is not an IP-based protocol and arp-scan can be used on an interface that is not configured for IP. ARP is only used by IPv4 hosts. IPv6 uses NDP (neighbour discovery protocol) instead, which is a different protocol and is not supported by arp-scan. One ARP packet is sent for each for each target host, with the target protocol address (the ar$tpa field) set to the IP address of this host. If a host does not respond, then the ARP packet will be re-sent once more. The maximum number of retries can be changed with the --retry option. Reducing the number of retries will reduce the scanning time at the possible risk of missing some results due to packet loss. You can specify the bandwidth that arp-scan will use for the outgoing ARP packets with the --bandwidth option. By default, it uses a bandwidth of 256000 bits per second. Increasing the band‐ width will reduce the scanning time, but setting the bandwidth too high may result in an ARP storm which can disrupt network operation. Also, setting the bandwidth too high can send packets faster than the network interface can transmit them, which will eventually fill the kernel's transmit buffer resulting in the error message: No buffer space available. Another way to specify the outgoing ARP packet rate is with the --interval option, which is an alternative way to modify the same underlying parameter. The time taken to perform a single-pass scan (i.e. with --retry=1) is given by: time = n*i + t + o Where n is the number of hosts in the list, i is the time interval between packets (specified with --interval, or calculated from --bandwidth), t is the timeout value (specified with --time‐ out) and o is the overhead time taken to load the targets into the list and read the MAC/Vendor mapping files. For small lists of hosts, the timeout value will dominate, but for large lists the packet interval is the most important value. With 65,536 hosts, the default bandwidth of 256,000 bits/second (which results in a packet interval of 2ms), the default timeout of 500ms, and a single pass ( --retry=1), and assuming an over‐ head of 1 second, the scan would take 65536*0.002 + 0.5 + 1 = 132.57 seconds, or about 2 minutes 13 seconds. Any part of the outgoing ARP packet may be modified through the use of the various --arpXXX options. The use of some of these options may make the outgoing ARP packet non RFC compliant. Dif‐ ferent operating systems handle the various non standard ARP packets in different ways, and this may be used to fingerprint these systems. See arp-fingerprint(1) for information about a script which uses these options to fingerprint the target operating system. The table below summarises the options that change the outgoing ARP packet. In this table, the Field column gives the ARP packet field name from RFC 826, Bits specifies the number of bits in the field, Option shows the arp-scan option to modify this field, and Notes gives the default value and any other notes. ┌───────────────────────────────────────────────────────────────┐ │ Outgoing ARP Packet Options │ ├───────┬──────┬──────────┬─────────────────────────────────────┤ │Field │ Bits │ Option │ Notes │ ├───────┼──────┼──────────┼─────────────────────────────────────┤ │ar$hrd │ 16 │ --arphrd │ Default is 1 (ARPHRD_ETHER) │ │ar$pro │ 16 │ --arppro │ Default is 0x0800 │ │ar$hln │ 8 │ --arphln │ Default is 6 (ETH_ALEN) │ │ar$pln │ 8 │ --arppln │ Default is 4 (IPv4) │ │ar$op │ 16 │ --arpop │ Default is 1 (ARPOP_REQUEST) │ │ar$sha │ 48 │ --arpsha │ Default is interface h/w address │ │ar$spa │ 32 │ --arpspa │ Default is interface IP address │ │ar$tha │ 48 │ --arptha │ Default is zero (00:00:00:00:00:00) │ │ar$tpa │ 32 │ None │ Set to the target host IP address │ └───────┴──────┴──────────┴─────────────────────────────────────┘ The most commonly used outgoing ARP packet option is --arpspa, which sets the source IP address in the ARP packet. This option allows the outgoing ARP packet to use a different source IP ad‐ dress from the outgoing interface address. With this option it is possible to use arp-scan on an interface with no IP address configured, which can be useful if you want to ensure that the testing host does not interact with the network being tested. Warning: Setting ar$spa to the destination IP address can disrupt some operating systems, as they assume there is an IP address clash if they receive an ARP request for their own address. It is also possible to change the values in the Ethernet frame header that precedes the ARP packet in the outgoing packets. The table below summarises the options that change values in the Ethernet frame header. ┌───────────────────────────────────────────────────────────────────┐ │ Outgoing Ethernet Frame Options │ ├───────────────┬──────┬─────────────┬──────────────────────────────┤ │Field │ Bits │ Option │ Notes │ ├───────────────┼──────┼─────────────┼──────────────────────────────┤ │Dest Address │ 48 │ --destaddr │ Default is ff:ff:ff:ff:ff:ff │ │Source Address │ 48 │ --srcaddr │ Default is interface address │ │Protocol Type │ 16 │ --prototype │ Default is 0x0806 │ └───────────────┴──────┴─────────────┴──────────────────────────────┘ The most commonly used outgoing Ethernet frame option is --destaddr, which sets the destination Ethernet address for the ARP packet. --prototype is not often used, because it will cause the packet to be interpreted as a different Ethernet protocol. Any ARP responses that are received are displayed in the following format: \u0026lt;IP Address\u0026gt; \u0026lt;Hardware Address\u0026gt; \u0026lt;Vendor Details\u0026gt; Where IP Address is the IP address of the responding target, Hardware Address is its Ethernet hardware address (also known as the MAC address) and Vendor Details are the vendor details, de‐ coded from the hardware address. The output fields are separated by a single tab character. The responses are displayed in the order they are received, which is not always the same order as the requests were sent because some hosts may respond faster than others. The vendor decoding uses the files ieee-oui.txt, ieee-iab.txt and mac-vendor.txt, which are supplied with arp-scan. The ieee-oui.txt and ieee-iab.txt files are generated from the OUI and IAB data on the IEEE website at http://standards-oui.ieee.org/oui/oui.txt and http://standards.ieee.org/regauth/oui/iab.txt. The Perl scripts get-oui and get-iab, which are included in the arp- scan package, can be used to update these files with the latest data from the IEEE website. The mac-vendor.txt file contains other MAC to Vendor mappings that are not covered by the IEEE OUI and IAB files, and can be used to add custom mappings. Almost all hosts that support IP will respond to arp-scan if they receive an ARP packet with the target protocol address (ar$tpa) set to their IP address. This includes firewalls and other hosts with IP filtering that drop all IP traffic from the testing system. For this reason, arp-scan is a useful tool to quickly determine all the active IP hosts on a given Ethernet network segment. OPTIONS Where an option takes a value, that value is specified as a letter in angle brackets. The letter indicates the type of data that is expected: \u0026lt;s\u0026gt; A character string, e.g. --file=hostlist.txt. \u0026lt;i\u0026gt; An integer, which can be specified as a decimal number or as a hexadecimal number if preceeded with 0x, e.g. --arppro=2048 or --arpro=0x0800. \u0026lt;f\u0026gt; A floating point decimal number, e.g. --backoff=1.5. \u0026lt;m\u0026gt; An Ethernet MAC address, which can be specified either in the format 01:23:45:67:89:ab, or as 01-23-45-67-89-ab. The alphabetic hex characters may be either upper or lower case. E.g. --arpsha=01:23:45:67:89:ab. \u0026lt;a\u0026gt; An IPv4 address, e.g. --arpspa=10.0.0.1 \u0026lt;h\u0026gt; Binary data specified as a hexadecimal string, which should not include a leading 0x. The alphabetic hex characters may be either upper or lower case. E.g. --padding=aaaaaaaaaaaa \u0026lt;x\u0026gt; Something else. See the description of the option for details. --help or -h Display this usage message and exit. --file=\u0026lt;s\u0026gt; or -f \u0026lt;s\u0026gt; Read hostnames or addresses from the specified file instead of from the command line. One name or IP address per line. Use \u0026quot;-\u0026quot; for standard input. --localnet or -l Generate addresses from network interface configuration. Use the network interface IP address and network mask to generate the list of target host addresses. The list will include the network and broadcast addresses, so an interface address of 10.0.0.1 with netmask 255.255.255.0 would generate 256 target hosts from 10.0.0.0 to 10.0.0.255 inclusive. If you use this option, you cannot specify the --file option or specify any target hosts on the command line. The interface specifications are taken from the interface that arp-scan will use, which can be changed with the --interface option. --retry=\u0026lt;i\u0026gt; or -r \u0026lt;i\u0026gt; Set total number of attempts per host to \u0026lt;i\u0026gt;, default=2. --timeout=\u0026lt;i\u0026gt; or -t \u0026lt;i\u0026gt; Set initial per host timeout to \u0026lt;i\u0026gt; ms, default=500. This timeout is for the first packet sent to each host. subsequent timeouts are multiplied by the backoff factor which is set with --backoff. --interval=\u0026lt;x\u0026gt; or -i \u0026lt;x\u0026gt; Set minimum packet interval to \u0026lt;x\u0026gt;. This controls the outgoing bandwidth usage by limiting the rate at which packets can be sent. The packet interval will be no smaller than this num‐ ber. If you want to use up to a given bandwidth, then it is easier to use the --bandwidth option instead. The interval specified is in milliseconds by default, or in microseconds if \u0026quot;u\u0026quot; is appended to the value. --bandwidth=\u0026lt;x\u0026gt; or -B \u0026lt;x\u0026gt; Set desired outbound bandwidth to \u0026lt;x\u0026gt;, default=256000. The value is in bits per second by default. If you append \u0026quot;K\u0026quot; to the value, then the units are kilobits per sec; and if you ap‐ pend \u0026quot;M\u0026quot; to the value, the units are megabits per second. The \u0026quot;K\u0026quot; and \u0026quot;M\u0026quot; suffixes represent the decimal, not binary, multiples. So 64K is 64000, not 65536. You cannot specify both --interval and --bandwidth because they are just different ways to change the same underlying parameter. --backoff=\u0026lt;f\u0026gt; or -b \u0026lt;f\u0026gt; Set timeout backoff factor to \u0026lt;f\u0026gt;, default=1.50. The per-host timeout is multiplied by this factor after each timeout. So, if the number of retries is 3, the initial per-host timeout is 500ms and the backoff factor is 1.5, then the first timeout will be 500ms, the second 750ms and the third 1125ms. --verbose or -v Display verbose progress messages. Use more than once for greater effect: 1 - Display the network address and mask used when the --localnet option is specified, display any nonzero packet padding, display packets received from unknown hosts, and show when each pass through the list completes. 2 - Show each packet sent and received, when entries are removed from the list, the pcap filter string, and counts of MAC/Vendor mapping entries. 3 - Display the host list before scanning starts. --version or -V Display program version and exit. --random or -R Randomise the host list. This option randomises the order of the hosts in the host list, so the ARP packets are sent to the hosts in a random order. It uses the Knuth shuffle algo‐ rithm. --randomseed=\u0026lt;i\u0026gt; Use \u0026lt;i\u0026gt; to seed the pseudo random number generator. This option seeds the PRNG with the specified number, which can be useful if you want to ensure that the random host list is reprod‐ ucable. By default, the PRNG is seeded with an unpredictable value. This option is only effective in conjunction with the --random (-R) option. --numeric or -N IP addresses only, no hostnames. With this option, all hosts must be specified as IP addresses. Hostnames are not permitted. No DNS lookups will be performed. --snap=\u0026lt;i\u0026gt; or -n \u0026lt;i\u0026gt; Set the pcap snap length to \u0026lt;i\u0026gt;. Default=64. This specifies the frame capture length. This length includes the data-link header. The default is normally sufficient. --interface=\u0026lt;s\u0026gt; or -I \u0026lt;s\u0026gt; Use network interface \u0026lt;s\u0026gt;. If this option is not specified, arp-scan will search the system interface list for the lowest numbered, configured up interface (excluding loopback). The interface specified must support ARP. --quiet or -q Only display minimal output. No protocol decoding. If this option is specified, then only the IP address and MAC address are displayed for each responding host. No protocol decoding is performed and the OUI mapping files are not used. --plain or -x Display plain output showing only responding hosts. This option supresses the printing of the header and footer text, and only displays one line for each responding host. Useful if the output will be parsed by a script. --ignoredups or -g Don't display duplicate packets. By default, duplicate packets are displayed and are flagged with \u0026quot;(DUP: n)\u0026quot;. --ouifile=\u0026lt;s\u0026gt; or -O \u0026lt;s\u0026gt; Use IEEE Ethernet OUI to vendor mapping file \u0026lt;s\u0026gt;. If this option is not specified, the default filename is ieee-oui.txt in the current directory. If that is not found, then the file /usr/local/share/arp-scan/ieee-oui.txt is used. --iabfile=\u0026lt;s\u0026gt; or -O \u0026lt;s\u0026gt; Use IEEE Ethernet IAB to vendor mapping file \u0026lt;s\u0026gt;. If this option is not specified, the default filename is ieee-iab.txt in the current directory. If that is not found, then the file /usr/local/share/arp-scan/ieee-iab.txt is used. --macfile=\u0026lt;s\u0026gt; or -O \u0026lt;s\u0026gt; Use custom Ethernet MAC to vendor mapping file \u0026lt;s\u0026gt;. If this option is not specified, the default filename is mac-vendor.txt in the current directory. If that is not found, then the file /usr/local/share/arp-scan/mac-vendor.txt is used. --srcaddr=\u0026lt;m\u0026gt; or -S \u0026lt;m\u0026gt; Set the source Ethernet MAC address to \u0026lt;m\u0026gt;. This sets the 48-bit hardware address in the Ethernet frame header for outgoing ARP packets. It does not change the hardware address in the ARP packet, see --arpsha for details on how to change that address. The default is the Ethernet address of the outgoing interface. --destaddr=\u0026lt;m\u0026gt; or -T \u0026lt;m\u0026gt; Send the packets to Ethernet MAC address \u0026lt;m\u0026gt; This sets the 48-bit destination address in the Ethernet frame header. The default is the broadcast address ff:ff:ff:ff:ff:ff. Most oper‐ ating systems will also respond if the ARP request is sent to their MAC address, or to a multicast address that they are listening on. --arpsha=\u0026lt;m\u0026gt; or -u \u0026lt;m\u0026gt; Use \u0026lt;m\u0026gt; as the ARP source Ethernet address This sets the 48-bit ar$sha field in the ARP packet It does not change the hardware address in the frame header, see --srcaddr for details on how to change that address. The default is the Ethernet address of the outgoing interface. --arptha=\u0026lt;m\u0026gt; or -w \u0026lt;m\u0026gt; Use \u0026lt;m\u0026gt; as the ARP target Ethernet address This sets the 48-bit ar$tha field in the ARP packet The default is zero, because this field is not used for ARP request packets. --prototype=\u0026lt;i\u0026gt; or -y \u0026lt;i\u0026gt; Set the Ethernet protocol type to \u0026lt;i\u0026gt;, default=0x0806. This sets the 16-bit protocol type field in the Ethernet frame header. Setting this to a non-default value will result in the packet being ignored by the target, or sent to the wrong protocol stack. --arphrd=\u0026lt;i\u0026gt; or -H \u0026lt;i\u0026gt; Use \u0026lt;i\u0026gt; for the ARP hardware type, default=1. This sets the 16-bit ar$hrd field in the ARP packet. The normal value is 1 (ARPHRD_ETHER). Most, but not all, operating systems will also respond to 6 (ARPHRD_IEEE802). A few systems respond to any value. --arppro=\u0026lt;i\u0026gt; or -p \u0026lt;i\u0026gt; Use \u0026lt;i\u0026gt; for the ARP protocol type, default=0x0800. This sets the 16-bit ar$pro field in the ARP packet. Most operating systems only respond to 0x0800 (IPv4) but some will respond to other values as well. --arphln=\u0026lt;i\u0026gt; or -a \u0026lt;i\u0026gt; Set the hardware address length to \u0026lt;i\u0026gt;, default=6. This sets the 8-bit ar$hln field in the ARP packet. It sets the claimed length of the hardware address in the ARP packet. Setting it to any value other than the default will make the packet non RFC compliant. Some operating systems may still respond to it though. Note that the actual lengths of the ar$sha and ar$tha fields in the ARP packet are not changed by this option; it only changes the ar$hln field. --arppln=\u0026lt;i\u0026gt; or -P \u0026lt;i\u0026gt; Set the protocol address length to \u0026lt;i\u0026gt;, default=4. This sets the 8-bit ar$pln field in the ARP packet. It sets the claimed length of the protocol address in the ARP packet. Setting it to any value other than the default will make the packet non RFC compliant. Some operating systems may still respond to it though. Note that the actual lengths of the ar$spa and ar$tpa fields in the ARP packet are not changed by this option; it only changes the ar$pln field. --arpop=\u0026lt;i\u0026gt; or -o \u0026lt;i\u0026gt; Use \u0026lt;i\u0026gt; for the ARP operation, default=1. This sets the 16-bit ar$op field in the ARP packet. Most operating systems will only respond to the value 1 (ARPOP_REQUEST). However, some systems will respond to other values as well. --arpspa=\u0026lt;a\u0026gt; or -s \u0026lt;a\u0026gt; Use \u0026lt;a\u0026gt; as the source IP address. The address should be specified in dotted quad format; or the literal string \u0026quot;dest\u0026quot;, which sets the source address to be the same as the target host address. This sets the 32-bit ar$spa field in the ARP packet. Some operating systems check this, and will only respond if the source address is within the network of the receiving in‐ terface. Others don't care, and will respond to any source address. By default, the outgoing interface address is used. WARNING: Setting ar$spa to the destination IP address can disrupt some operating systems, as they assume there is an IP address clash if they receive an ARP request for their own ad‐ dress. --padding=\u0026lt;h\u0026gt; or -A \u0026lt;h\u0026gt; Specify padding after packet data. Set the padding data to hex value \u0026lt;h\u0026gt;. This data is appended to the end of the ARP packet, after the data. Most, if not all, operating systems will ignore any padding. The default is no padding, although the Ethernet driver on the sending system may pad the packet to the minimum Ethernet frame length. --llc or -L Use RFC 1042 LLC framing with SNAP. This option causes the outgoing ARP packets to use IEEE 802.2 framing with a SNAP header as described in RFC 1042. The default is to use Ethernet-II framing. arp-scan will decode and display received ARP packets in either Ethernet-II or IEEE 802.2 formats irrespective of this option. --vlan=\u0026lt;i\u0026gt; or -Q \u0026lt;i\u0026gt; Use 802.1Q tagging with VLAN id \u0026lt;i\u0026gt;. This option causes the outgoing ARP packets to use 802.1Q VLAN tagging with a VLAN ID of \u0026lt;i\u0026gt;, which should be in the range 0 to 4095 inclusive. arp-scan will always decode and display received ARP packets in 802.1Q format irrespective of this option. --pcapsavefile=\u0026lt;s\u0026gt; or -W \u0026lt;s\u0026gt; Write received packets to pcap savefile \u0026lt;s\u0026gt;. This option causes received ARP responses to be written to the specified pcap savefile as well as being decoded and displayed. This save‐ file can be analysed with programs that understand the pcap file format, such as \u0026quot;tcpdump\u0026quot; and \u0026quot;wireshark\u0026quot;. --rtt or -D Display the packet round-trip time. FILES /usr/local/share/arp-scan/ieee-oui.txt List of IEEE OUI (Organisationally Unique Identifier) to vendor mappings. /usr/local/share/arp-scan/ieee-iab.txt List of IEEE IAB (Individual Address Block) to vendor mappings. /usr/local/share/arp-scan/mac-vendor.txt List of other Ethernet MAC to vendor mappings. EXAMPLES The example below shows arp-scan being used to scan the network 192.168.0.0/24 using the network interface eth0. $ arp-scan --interface=eth0 192.168.0.0/24 Interface: eth0, datalink type: EN10MB (Ethernet) Starting arp-scan 1.4 with 256 hosts (http://www.nta-monitor.com/tools-resources/security-tools/arp-scan/) 192.168.0.1 00:c0:9f:09:b8:db QUANTA COMPUTER, INC. 192.168.0.3 00:02:b3:bb:66:98 Intel Corporation 192.168.0.5 00:02:a5:90:c3:e6 Compaq Computer Corporation 192.168.0.6 00:c0:9f:0b:91:d1 QUANTA COMPUTER, INC. 192.168.0.12 00:02:b3:46:0d:4c Intel Corporation 192.168.0.13 00:02:a5🇩🇪c2:17 Compaq Computer Corporation 192.168.0.87 00:0b:db:b2:fa:60 Dell ESG PCBA Test 192.168.0.90 00:02:b3:06:d7:9b Intel Corporation 192.168.0.105 00:13:72:09:ad:76 Dell Inc. 192.168.0.153 00:10:db:26:4d:52 Juniper Networks, Inc. 192.168.0.191 00:01:e6:57:8b:68 Hewlett-Packard Company 192.168.0.251 00:04:27:6a:5d:a1 Cisco Systems, Inc. 192.168.0.196 00:30:c1:5e:58:7d HEWLETT-PACKARD 13 packets received by filter, 0 packets dropped by kernel Ending arp-scan: 256 hosts scanned in 3.386 seconds (75.61 hosts/sec). 13 responded This next example shows arp-scan being used to scan the local network after configuring the network interface with DHCP using pump. # pump # ifconfig eth0 eth0 Link encap:Ethernet HWaddr 00:D0:B7:0B:DD:C7 inet addr:10.0.84.178 Bcast:10.0.84.183 Mask:255.255.255.248 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:46335 errors:0 dropped:0 overruns:0 frame:0 TX packets:1542776 errors:0 dropped:0 overruns:0 carrier:0 collisions:1644 txqueuelen:1000 RX bytes:6184146 (5.8 MiB) TX bytes:348887835 (332.7 MiB) # arp-scan --localnet Interface: eth0, datalink type: EN10MB (Ethernet) Starting arp-scan 1.4 with 8 hosts (http://www.nta-monitor.com/tools-resources/security-tools/arp-scan/) 10.0.84.179 00:02:b3:63:c7:57 Intel Corporation 10.0.84.177 00:d0:41:08:be:e8 AMIGO TECHNOLOGY CO., LTD. 10.0.84.180 00:02:b3:bd:82:9b Intel Corporation 10.0.84.181 00:02:b3:1f:73:da Intel Corporation 4 packets received by filter, 0 packets dropped by kernel Ending arp-scan 1.4: 8 hosts scanned in 0.820 seconds (9.76 hosts/sec). 4 responded AUTHOR Roy Hills \u0026lt;Roy.Hills@nta-monitor.com\u0026gt; SEE ALSO get-oui(1) get-iab(1) arp-fingerprint(1) RFC 826 - An Ethernet Address Resolution Protocol http://www.nta-monitor.com/wiki/ The arp-scan wiki page. https://github.com/royhills/arp-scan The arp-scan homepage. August 13, 2016 ARP-SCAN(1) ```bash "}),e.add({id:68,href:"/docs/tools/know/bmon/",title:"Bmon",description:`Description # bmon is a tool for monitoring network interface bandwidth, discards, errors, and more.
install # brew install bmon sample usage # bmon website # https://github.com/tgraf/bmon
help # bmon(8) bmon bmon(8) NAME bmon - bandwidth monitor and rate estimator SYNOPSIS bmon [--show-all] [--use-si] [--input=MODULE] [--output=MODULE] [OPTIONS...] DESCRIPTION bmon is a monitoring and debugging tool to capture networking related statistics and prepare them visually in a human friendly way. It features various output methods including an interactive curses user interface and a programmable text output for scripting.`,content:"Description # bmon is a tool for monitoring network interface bandwidth, discards, errors, and more.\ninstall # brew install bmon sample usage # bmon website # https://github.com/tgraf/bmon\nhelp # bmon(8) bmon bmon(8) NAME bmon - bandwidth monitor and rate estimator SYNOPSIS bmon [--show-all] [--use-si] [--input=MODULE] [--output=MODULE] [OPTIONS...] DESCRIPTION bmon is a monitoring and debugging tool to capture networking related statistics and prepare them visually in a human friendly way. It features various output methods including an interactive curses user interface and a programmable text output for scripting. OPTIONS -h, --help Prints a short help text and exits. -V, --version Prints the versioning identifier and exits. -i, --input=MODULE[:OPTIONS][,MODULE...] Set list of input modules to load and use. Multiple modules can be used in parallel. bmon automatically loads a useful and working input module by default. See INPUT MODULES for more de‐ tails. -o, --outputMODULE[:OPTIONS][,MODULE...] Set list of output modules to load and use. Multiple modules can be used in parallel. By default, bmon will use the curses output mode, if that is not available due to an incompatible con‐ sole it will fall back to a simple text mode. See OUTPUT MODULES for more details. -U, --use-si Use SI unit system (1KB = 1'000 bytes) instead of 1KB = 1'024 bytes. -f, --configfile=FILE Set alternative path to configuration file. -p, --policy=POLICY Set policy defining which network interfaces to display. See INTERFACE SELECTION for more details. -a, --show-all= Display all interfaces, even interface that are administratively down. -r, --read-interval=FLOAT Set interval in seconds in which input modules read statistics from their source. The default is 1.0 seconds. -R, --rate-interval=FLOAT Set interval in seconds in which the rate per counter is calculated. The default is 1.0 seconds. -b, --use-bit Show rates in bits per second instead of bytes per second. -L, --lifetime=FLOAT Set lifetime of an element in seconds before it is no longer displayed without receiving any statistical updates. The default is 30 seconds. INPUT MODULES Input modules provide statistical data about elements. Each element consists of attributes which represents a counter, a rate, or a percentage. Elements may carry additional child elements to represent a hierarchy. Each element is assigned to a group defined by the input module. Input modules are polled in the frequence of the configured read interval. The following input modules are available: netlink Uses the Netlink protocol to collect interface and traffic control statistics from the kernel. This is the default input module. proc Reads interface statistics from the /proc/net/dev file. This is considered a legacy interface and provided for backwards compatibily reasons. This is a fallback module if the Netlink interface is not available. dummy Programmable input module for debugging and testing purposes. null No data collected. To receive additional information about a module, run the module with the \u0026quot;help\u0026quot; option set like this: bmon -i netlink:help See MODULE CONFIGURATION for more details. OUTPUT MODULES Output modules display or export the statistical data collected by input modules. Multiple output modules can be run at the same time. bmon will not prevent possible conflicts such as multiple output modules writing to the console. The following output modules exist: curses Interactive curses based text user interface providing real time rate estimations and a graphical representatio nof each attribute. Press '?' to display the quick reference guide. This is the default output mode. ascii Simple programmable text output intended for human consumption. Capable of printing list of interfaces, detailed counters and graphs to the console. This is the default fallback output mode if curses is not available. format Fully scriptable output mode inteded for consumption by other programs. See the module help text for additional information. null Disable output. To receive additional information about a module, run the module with the \u0026quot;help\u0026quot; option set like this: bmon -o curses:help See MODULE CONFIGURATION for more details. MODULE CONFIGURATION The syntax to configure modules is as follows: ARGUMENT ::= mod1[:OPTS][,mod2[:OPTS]...] OPTS ::= OPTION[;OPTION...] OPTION ::= option[=value] Run the module with option \u0026quot;help\u0026quot; to receive the list of options for each module: bmon -i module:help INTERFACE SELECTION The following syntax is used to define the interface selection policy: SELECTION ::= NAME[,NAME[,...]] NAME ::= [!]interface The interface name may contain the character '*' which will act as a wildcard and represents any number of any character type, e.g. eth*, h*0, ... Examples: lo,eth0,eth1 eth*,!eth0 EXAMPLES To run bmon in curses mode monitoring the interfaces eth0 and eth1: bmon -p eth0,eth1 -o curses To run bmon in format mode, monitoring any eth* interfaces, with a specified format string: bmon -p 'eth*' -o format:fmt='$(element:name) $(attr:rxrate:packets)\\n' FILES /etc/bmon.conf $HOME/.bmonrc SEE ALSO ip(8), netstat(8), ifconfig(8), netlink(7), AUTHOR Thomas Graf \u0026lt;tgraf@suug.ch\u0026gt; among others Bandwidth Monitor bmon(8) ```bash "}),e.add({id:69,href:"/docs/tools/know/dnsx/",title:"Dnsx",description:`Description # dnsx is a fast and multi-purpose DNS toolkit designed for running various probes through the retryabledns library. It supports multiple DNS queries, user supplied resolvers, DNS wildcard filtering like shuffledns etc.
install # brew install dnsx sample usage # echo 69.52.0.0/16 | dnsx -silent -resp-only -ptr sample output # www.origina.blackrock.com e-confirm.blackrock.com www.blackrocksolutions.com ftp.blackrock.com help # dnsx is a fast and multi-purpose DNS toolkit allow to run multiple probes using retryabledns library.`,content:"Description # dnsx is a fast and multi-purpose DNS toolkit designed for running various probes through the retryabledns library. It supports multiple DNS queries, user supplied resolvers, DNS wildcard filtering like shuffledns etc.\ninstall # brew install dnsx sample usage # echo 69.52.0.0/16 | dnsx -silent -resp-only -ptr sample output # www.origina.blackrock.com e-confirm.blackrock.com www.blackrocksolutions.com ftp.blackrock.com help # dnsx is a fast and multi-purpose DNS toolkit allow to run multiple probes using retryabledns library. Usage: dnsx [flags] Flags: INPUT: -stream stream mode (wordlist, wildcard, stats and stop/resume will be disabled) -l, -list string list of sub(domains)/hosts to resolve (file or stdin) -d, -domain string list of domain to bruteforce (file or comma separated or stdin) -w, -wordlist string list of words to bruteforce (file or comma separated or stdin) QUERY: -a query A record (default) -aaaa query AAAA record -cname query CNAME record -ns query NS record -txt query TXT record -ptr query PTR record -mx query MX record -soa query SOA record FILTERS: -resp display dns response -resp-only display dns response only -rcode, -rc string filter result by dns status code (eg. -rcode noerror,servfail,refused) RATE-LIMIT: -t, -c int number of concurrent threads to use (default 100) -rl, -rate-limit int number of dns request/second to make (disabled as default) (default -1) OUTPUT: -o, -output string file to write output -json write output in JSONL(ines) format DEBUG: -silent display only results in the output -v, -verbose display verbose output -raw, -debug display raw dns response -stats display stats of the running scan -version display version of dnsx OPTIMIZATION: -retry int number of dns retries to make (default 2) -hf, -hostsfile use system host file -trace perform dns tracing -trace-max-recursion int Max recursion for dns trace (default 32767) -flush-interval int flush interval of output file (default 10) -resume resume existing scan CONFIGURATIONS: -r, -resolver string list of resolvers to use (file or comma separated) -wt, -wildcard-threshold int wildcard filter threshold (default 5) -wd, -wildcard-domain string domain name for wildcard filtering (other flags will be ignored) ```bash "}),e.add({id:70,href:"/docs/tools/know/feroxbuster/",title:"Feroxbuster",description:`Description # Feroxbuster is a fast, simple, recursive content discovery tool written in Rust. It is a modern replacement for dirb, dirbuster, and gobuster.
install # brew install feroxbuster sample usage # feroxbuster -u https://example.com webpage # https://epi052.github.io/feroxbuster
help # A fast, simple, recursive content discovery tool. Usage: feroxbuster [OPTIONS] Options: -h, --help Print help (see a summary with '-h') -V, --version Print version Target selection: -u, --url \u0026lt;URL\u0026gt; The target URL (required, unless [--stdin || --resume-from] used) --stdin Read url(s) from STDIN --resume-from \u0026lt;STATE_FILE\u0026gt; State file from which to resume a partially complete scan (ex.`,content:"Description # Feroxbuster is a fast, simple, recursive content discovery tool written in Rust. It is a modern replacement for dirb, dirbuster, and gobuster.\ninstall # brew install feroxbuster sample usage # feroxbuster -u https://example.com webpage # https://epi052.github.io/feroxbuster\nhelp # A fast, simple, recursive content discovery tool. Usage: feroxbuster [OPTIONS] Options: -h, --help Print help (see a summary with '-h') -V, --version Print version Target selection: -u, --url \u0026lt;URL\u0026gt; The target URL (required, unless [--stdin || --resume-from] used) --stdin Read url(s) from STDIN --resume-from \u0026lt;STATE_FILE\u0026gt; State file from which to resume a partially complete scan (ex. --resume-from ferox-1606586780.state) Composite settings: --burp Set --proxy to http://127.0.0.1:8080 and set --insecure to true --burp-replay Set --replay-proxy to http://127.0.0.1:8080 and set --insecure to true --smart Set --extract-links, --auto-tune, --collect-words, and --collect-backups to true --thorough Use the same settings as --smart and set --collect-extensions to true Proxy settings: -p, --proxy \u0026lt;PROXY\u0026gt; Proxy to use for requests (ex: http(s)://host:port, socks5(h)://host:port) -P, --replay-proxy \u0026lt;REPLAY_PROXY\u0026gt; Send only unfiltered requests through a Replay Proxy, instead of all requests -R, --replay-codes \u0026lt;REPLAY_CODE\u0026gt;... Status Codes to send through a Replay Proxy when found (default: --status-codes value) Request settings: -a, --user-agent \u0026lt;USER_AGENT\u0026gt; Sets the User-Agent (default: feroxbuster/2.7.3) -A, --random-agent Use a random User-Agent -x, --extensions \u0026lt;FILE_EXTENSION\u0026gt;... File extension(s) to search for (ex: -x php -x pdf js) -m, --methods \u0026lt;HTTP_METHODS\u0026gt;... Which HTTP request method(s) should be sent (default: GET) --data \u0026lt;DATA\u0026gt; Request's Body; can read data from a file if input starts with an @ (ex: @post.bin) -H, --headers \u0026lt;HEADER\u0026gt;... Specify HTTP headers to be used in each request (ex: -H Header:val -H 'stuff: things') -b, --cookies \u0026lt;COOKIE\u0026gt;... Specify HTTP cookies to be used in each request (ex: -b stuff=things) -Q, --query \u0026lt;QUERY\u0026gt;... Request's URL query parameters (ex: -Q token=stuff -Q secret=key) -f, --add-slash Append / to each request's URL Request filters: --dont-scan \u0026lt;URL\u0026gt;... URL(s) or Regex Pattern(s) to exclude from recursion/scans Response filters: -S, --filter-size \u0026lt;SIZE\u0026gt;... Filter out messages of a particular size (ex: -S 5120 -S 4927,1970) -X, --filter-regex \u0026lt;REGEX\u0026gt;... Filter out messages via regular expression matching on the response's body (ex: -X '^ignore me$') -W, --filter-words \u0026lt;WORDS\u0026gt;... Filter out messages of a particular word count (ex: -W 312 -W 91,82) -N, --filter-lines \u0026lt;LINES\u0026gt;... Filter out messages of a particular line count (ex: -N 20 -N 31,30) -C, --filter-status \u0026lt;STATUS_CODE\u0026gt;... Filter out status codes (deny list) (ex: -C 200 -C 401) --filter-similar-to \u0026lt;UNWANTED_PAGE\u0026gt;... Filter out pages that are similar to the given page (ex. --filter-similar-to http://site.xyz/soft404) -s, --status-codes \u0026lt;STATUS_CODE\u0026gt;... Status Codes to include (allow list) (default: 200 204 301 302 307 308 401 403 405) Client settings: -T, --timeout \u0026lt;SECONDS\u0026gt; Number of seconds before a client's request times out (default: 7) -r, --redirects Allow client to follow redirects -k, --insecure Disables TLS certificate validation in the client Scan settings: -t, --threads \u0026lt;THREADS\u0026gt; Number of concurrent threads (default: 50) -n, --no-recursion Do not scan recursively -d, --depth \u0026lt;RECURSION_DEPTH\u0026gt; Maximum recursion depth, a depth of 0 is infinite recursion (default: 4) --force-recursion Force recursion attempts on all 'found' endpoints (still respects recursion depth) -e, --extract-links Extract links from response body (html, javascript, etc...); make new requests based on findings -L, --scan-limit \u0026lt;SCAN_LIMIT\u0026gt; Limit total number of concurrent scans (default: 0, i.e. no limit) --parallel \u0026lt;PARALLEL_SCANS\u0026gt; Run parallel feroxbuster instances (one child process per url passed via stdin) --rate-limit \u0026lt;RATE_LIMIT\u0026gt; Limit number of requests per second (per directory) (default: 0, i.e. no limit) --time-limit \u0026lt;TIME_SPEC\u0026gt; Limit total run time of all scans (ex: --time-limit 10m) -w, --wordlist \u0026lt;FILE\u0026gt; Path to the wordlist --auto-tune Automatically lower scan rate when an excessive amount of errors are encountered --auto-bail Automatically stop scanning when an excessive amount of errors are encountered -D, --dont-filter Don't auto-filter wildcard responses Dynamic collection settings: -E, --collect-extensions Automatically discover extensions and add them to --extensions (unless they're in --dont-collect) -B, --collect-backups Automatically request likely backup extensions for \u0026quot;found\u0026quot; urls -g, --collect-words Automatically discover important words from within responses and add them to the wordlist -I, --dont-collect \u0026lt;FILE_EXTENSION\u0026gt;... File extension(s) to Ignore while collecting extensions (only used with --collect-extensions) Output settings: -v, --verbosity... Increase verbosity level (use -vv or more for greater effect. [CAUTION] 4 -v's is probably too much) --silent Only print URLs + turn off logging (good for piping a list of urls to other commands) -q, --quiet Hide progress bars and banner (good for tmux windows w/ notifications) --json Emit JSON logs to --output and --debug-log instead of normal text -o, --output \u0026lt;FILE\u0026gt; Output file to write results to (use w/ --json for JSON entries) --debug-log \u0026lt;FILE\u0026gt; Output file to write log entries (use w/ --json for JSON entries) --no-state Disable state output file (*.state) NOTE: Options that take multiple values are very flexible. Consider the following ways of specifying extensions: ./feroxbuster -u http://127.1 -x pdf -x js,html -x php txt json,docx The command above adds .pdf, .js, .html, .php, .txt, .json, and .docx to each url All of the methods above (multiple flags, space separated, comma separated, etc...) are valid and interchangeable. The same goes for urls, headers, status codes, queries, and size filters. EXAMPLES: Multiple headers: ./feroxbuster -u http://127.1 -H Accept:application/json \u0026quot;Authorization: Bearer {token}\u0026quot; IPv6, non-recursive scan with INFO-level logging enabled: ./feroxbuster -u http://[::1] --no-recursion -vv Read urls from STDIN; pipe only resulting urls out to another tool cat targets | ./feroxbuster --stdin --silent -s 200 301 302 --redirects -x js | fff -s 200 -o js-files Proxy traffic through Burp ./feroxbuster -u http://127.1 --burp Proxy traffic through a SOCKS proxy ./feroxbuster -u http://127.1 --proxy socks5://127.0.0.1:9050 Pass auth token via query parameter ./feroxbuster -u http://127.1 --query token=0123456789ABCDEF Find links in javascript/html and make additional requests based on results ./feroxbuster -u http://127.1 --extract-links Ludicrous speed... go! ./feroxbuster -u http://127.1 --threads 200 Limit to a total of 60 active requests at any given time (threads * scan limit) ./feroxbuster -u http://127.1 --threads 30 --scan-limit 2 Send all 200/302 responses to a proxy (only proxy requests/responses you care about) ./feroxbuster -u http://127.1 --replay-proxy http://localhost:8080 --replay-codes 200 302 --insecure Abort or reduce scan speed to individual directory scans when too many errors have occurred ./feroxbuster -u http://127.1 --auto-bail ./feroxbuster -u http://127.1 --auto-tune Examples and demonstrations of all features https://epi052.github.io/feroxbuster-docs/docs/examples/ ```bash "}),e.add({id:71,href:"/docs/tools/know/ffuf/",title:"Ffuf",description:"Description # ffuf is a fast web fuzzer written in Go.\nInstall # brew install ffuf Sample Usage # ffuf -w /usr/share/wordlists/dirb/common.txt -u http://example.com/FUZZ website # https://github.com/ffuf/ffuf\nhelp # Fuzz Faster U Fool - v1.0.2 HTTP OPTIONS: -H Header `\u0026quot;Name: Value\u0026quot;`, separated by colon. Multiple -H flags are accepted. -X HTTP method to use (default: GET) -b Cookie data `\u0026quot;NAME1=VALUE1; NAME2=VALUE2\u0026quot;` for copy as curl functionality. -d POST data -r Follow redirects (default: false) -recursion Scan recursively.",content:"Description # ffuf is a fast web fuzzer written in Go.\nInstall # brew install ffuf Sample Usage # ffuf -w /usr/share/wordlists/dirb/common.txt -u http://example.com/FUZZ website # https://github.com/ffuf/ffuf\nhelp # Fuzz Faster U Fool - v1.0.2 HTTP OPTIONS: -H Header `\u0026quot;Name: Value\u0026quot;`, separated by colon. Multiple -H flags are accepted. -X HTTP method to use (default: GET) -b Cookie data `\u0026quot;NAME1=VALUE1; NAME2=VALUE2\u0026quot;` for copy as curl functionality. -d POST data -r Follow redirects (default: false) -recursion Scan recursively. Only FUZZ keyword is supported, and URL (-u) has to end in it. (default: false) -recursion-depth Maximum recursion depth. (default: 0) -replay-proxy Replay matched requests using this proxy. -timeout HTTP request timeout in seconds. (default: 10) -u Target URL -x HTTP Proxy URL GENERAL OPTIONS: -V Show version information. (default: false) -ac Automatically calibrate filtering options (default: false) -acc Custom auto-calibration string. Can be used multiple times. Implies -ac -c Colorize output. (default: false) -maxtime Maximum running time in seconds. (default: 0) -p Seconds of `delay` between requests, or a range of random delay. For example \u0026quot;0.1\u0026quot; or \u0026quot;0.1-2.0\u0026quot; -s Do not print additional information (silent mode) (default: false) -sa Stop on all error cases. Implies -sf and -se. (default: false) -se Stop on spurious errors (default: false) -sf Stop when \u0026gt; 95% of responses return 403 Forbidden (default: false) -t Number of concurrent threads. (default: 40) -v Verbose output, printing full URL and redirect location (if any) with the results. (default: false) MATCHER OPTIONS: -mc Match HTTP status codes, or \u0026quot;all\u0026quot; for everything. (default: 200,204,301,302,307,401,403) -ml Match amount of lines in response -mr Match regexp -ms Match HTTP response size -mw Match amount of words in response FILTER OPTIONS: -fc Filter HTTP status codes from response. Comma separated list of codes and ranges -fl Filter by amount of lines in response. Comma separated list of line counts and ranges -fr Filter regexp -fs Filter HTTP response size. Comma separated list of sizes and ranges -fw Filter by amount of words in response. Comma separated list of word counts and ranges INPUT OPTIONS: -D DirSearch wordlist compatibility mode. Used in conjunction with -e flag. (default: false) -e Comma separated list of extensions. Extends FUZZ keyword. -ic Ignore wordlist comments (default: false) -input-cmd Command producing the input. --input-num is required when using this input method. Overrides -w. -input-num Number of inputs to test. Used in conjunction with --input-cmd. (default: 100) -mode Multi-wordlist operation mode. Available modes: clusterbomb, pitchfork (default: clusterbomb) -request File containing the raw http request -request-proto Protocol to use along with raw request (default: https) -w Wordlist file path and (optional) keyword separated by colon. eg. '/path/to/wordlist:KEYWORD' OUTPUT OPTIONS: -debug-log Write all of the internal logging to the specified file. -o Write output to file -od Directory path to store matched results to. -of Output file format. Available formats: json, ejson, html, md, csv, ecsv (default: json) EXAMPLE USAGE: Fuzz file paths from wordlist.txt, match all responses but filter out those with content-size 42. Colored, verbose output. ffuf -w wordlist.txt -u https://example.org/FUZZ -mc all -fs 42 -c -v Fuzz Host-header, match HTTP 200 responses. ffuf -w hosts.txt -u https://example.org/ -H \u0026quot;Host: FUZZ\u0026quot; -mc 200 Fuzz POST JSON data. Match all responses not containing text \u0026quot;error\u0026quot;. ffuf -w entries.txt -u https://example.org/ -X POST -H \u0026quot;Content-Type: application/json\u0026quot; \\ -d '{\u0026quot;name\u0026quot;: \u0026quot;FUZZ\u0026quot;, \u0026quot;anotherkey\u0026quot;: \u0026quot;anothervalue\u0026quot;}' -fr \u0026quot;error\u0026quot; Fuzz multiple locations. Match only responses reflecting the value of \u0026quot;VAL\u0026quot; keyword. Colored. ffuf -w params.txt:PARAM -w values.txt:VAL -u https://example.org/?PARAM=VAL -mr \u0026quot;VAL\u0026quot; -c More information and examples: https://github.com/ffuf/ffuf ```bash "}),e.add({id:72,href:"/docs/tools/know/amass/",title:"Amass",description:`Description # Amass is a tool used to enumerate subdomains of domains. It is a passive network mapper that discovers valid subdomains for any target domain by leveraging data sources such as the Certificate Transparency logs, DNS records, and reverse DNS records.
install # brew tap caffix/amass brew install amass sample usage # amass enum -d example.com sample output # example.com www.example.com mail.example.com help # amass --help .+++:. : .+++. +W@@@@@@8 \u0026amp;+W@# o8W8: +W@@@@@@#.`,content:"Description # Amass is a tool used to enumerate subdomains of domains. It is a passive network mapper that discovers valid subdomains for any target domain by leveraging data sources such as the Certificate Transparency logs, DNS records, and reverse DNS records.\ninstall # brew tap caffix/amass brew install amass sample usage # amass enum -d example.com sample output # example.com www.example.com mail.example.com help # amass --help .+++:. : .+++. +W@@@@@@8 \u0026amp;+W@# o8W8: +W@@@@@@#. oW@@@W#+ \u0026amp;@#+ .o@##. .@@@o@W.o@@o :@@#\u0026amp;W8o .@#: .:oW+ .@#+++\u0026amp;#\u0026amp; +@\u0026amp; \u0026amp;@\u0026amp; #@8 +@W@\u0026amp;8@+ :@W. +@8 +@: .@8 8@ @@ 8@o 8@8 WW .@W W@+ .@W. o@#: WW \u0026amp;@o \u0026amp;@: o@+ o@+ #@. 8@o +W@#+. +W@8: #@ :@W \u0026amp;@+ \u0026amp;@+ @8 :@o o@o oW@@W+ oW@8 o@+ @@\u0026amp; \u0026amp;@+ \u0026amp;@+ #@ \u0026amp;@. .W@W .+#@\u0026amp; o@W. WW +@W@8. \u0026amp;@+ :\u0026amp; o@+ #@ :@W\u0026amp;@\u0026amp; \u0026amp;@: .. :@o :@W: o@# +Wo \u0026amp;@+ :W: +@W\u0026amp;o++o@W. \u0026amp;@\u0026amp; 8@#o+\u0026amp;@W. #@: o@+ :W@@WWWW@@8 + :\u0026amp;W@@@@\u0026amp; \u0026amp;W .o#@@W\u0026amp;. :W@WWW@@\u0026amp; +o\u0026amp;\u0026amp;\u0026amp;\u0026amp;+. +oooo. v3.21.2 OWASP Amass Project - @owaspamass In-depth Attack Surface Mapping and Asset Discovery Usage: amass intel|enum|viz|track|db [options] -h Show the program usage message -help Show the program usage message -version Print the version number of this Amass binary Subcommands: amass intel - Discover targets for enumerations amass enum - Perform enumerations and network mapping amass viz - Visualize enumeration results amass track - Track differences between enumerations amass db - Manipulate the Amass graph database The user's guide can be found here: https://github.com/OWASP/Amass/blob/master/doc/user_guide.md An example configuration file can be found here: https://github.com/OWASP/Amass/blob/master/examples/config.ini The Amass tutorial can be found here: https://github.com/OWASP/Amass/blob/master/doc/tutorial.md ```bash "}),e.add({id:73,href:"/docs/tools/defend/fwknop/",title:"Fwknop",description:`description # fwknop is a tool for implementing a single packet authorization scheme for network services. It is designed to be used in situations where a network service needs to be protected from unauthorized access, but the client is not able to use a more secure authentication scheme such as SSH public key authentication or SSL client certificates.
install # brew install fwknop website # https://www.cipherdyne.org/fwknop/`,content:`description # fwknop is a tool for implementing a single packet authorization scheme for network services. It is designed to be used in situations where a network service needs to be protected from unauthorized access, but the client is not able to use a more secure authentication scheme such as SSH public key authentication or SSL client certificates.
install # brew install fwknop website # https://www.cipherdyne.org/fwknop/
`}),e.add({id:74,href:"/docs/tools/defend/gnupg/",title:"Gnupg",description:`Description # GnuPG is a complete and free implementation of the OpenPGP standard as defined by RFC4880 (also known as PGP).
Installation # brew install gnupg Usage # gpg --version Resources # GnuPG GnuPG Manual help # gpg (GnuPG) 2.3.7 libgcrypt 1.10.1-unknown Copyright (C) 2021 Free Software Foundation, Inc. License GNU GPL-3.0-or-later \u0026lt;https://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law.`,content:"Description # GnuPG is a complete and free implementation of the OpenPGP standard as defined by RFC4880 (also known as PGP).\nInstallation # brew install gnupg Usage # gpg --version Resources # GnuPG GnuPG Manual help # gpg (GnuPG) 2.3.7 libgcrypt 1.10.1-unknown Copyright (C) 2021 Free Software Foundation, Inc. License GNU GPL-3.0-or-later \u0026lt;https://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Home: /home/neosb/.gnupg Supported algorithms: Pubkey: RSA, ELG, DSA, ECDH, ECDSA, EDDSA Cipher: IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH, CAMELLIA128, CAMELLIA192, CAMELLIA256 AEAD: EAX, OCB Hash: SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224 Compression: Uncompressed, ZIP, ZLIB, BZIP2 Syntax: gpg [options] [files] Sign, check, encrypt or decrypt Default operation depends on the input data Commands: -s, --sign make a signature --clear-sign make a clear text signature -b, --detach-sign make a detached signature -e, --encrypt encrypt data -c, --symmetric encryption only with symmetric cipher -d, --decrypt decrypt data (default) --verify verify a signature -k, --list-keys list keys --list-signatures list keys and signatures --check-signatures list and check key signatures --fingerprint list keys and fingerprints -K, --list-secret-keys list secret keys --generate-key generate a new key pair --quick-generate-key quickly generate a new key pair --quick-add-uid quickly add a new user-id --quick-revoke-uid quickly revoke a user-id --quick-set-expire quickly set a new expiration date --full-generate-key full featured key pair generation --generate-revocation generate a revocation certificate --delete-keys remove keys from the public keyring --delete-secret-keys remove keys from the secret keyring --quick-sign-key quickly sign a key --quick-lsign-key quickly sign a key locally --quick-revoke-sig quickly revoke a key signature --sign-key sign a key --lsign-key sign a key locally --edit-key sign or edit a key --change-passphrase change a passphrase --export export keys --send-keys export keys to a keyserver --receive-keys import keys from a keyserver --search-keys search for keys on a keyserver --refresh-keys update all keys from a keyserver --import import/merge keys --card-status print the card status --edit-card change data on a card --change-pin change a card's PIN --update-trustdb update the trust database --print-md print message digests --server run in server mode --tofu-policy VALUE set the TOFU policy for a key Options controlling the diagnostic output: -v, --verbose verbose -q, --quiet be somewhat more quiet --options FILE read options from FILE --log-file FILE write server mode logs to FILE Options controlling the configuration: --default-key NAME use NAME as default secret key --encrypt-to NAME encrypt to user ID NAME as well --group SPEC set up email aliases --openpgp use strict OpenPGP behavior -n, --dry-run do not make any changes -i, --interactive prompt before overwriting Options controlling the output: -a, --armor create ascii armored output -o, --output FILE write output to FILE --textmode use canonical text mode -z N set compress level to N (0 disables) Options controlling key import and export: --auto-key-locate MECHANISMS use MECHANISMS to locate keys by mail address --auto-key-import import missing key from a signature --include-key-block include the public key in signatures --disable-dirmngr disable all access to the dirmngr Options to specify keys: -r, --recipient USER-ID encrypt for USER-ID -u, --local-user USER-ID use USER-ID to sign or decrypt (See the help for a complete listing of all commands and options) Examples: -se -r Bob [file] sign and encrypt for user Bob --clear-sign [file] make a clear text signature --detach-sign [file] make a detached signature --list-keys [names] show keys --fingerprint [names] show fingerprints Please report bugs to \u0026lt;https://bugs.gnupg.org\u0026gt;. ```bash ```bash GPG(1) GNU Privacy Guard 2.3 GPG(1) NAME gpg - OpenPGP encryption and signing tool SYNOPSIS gpg [--homedir dir] [--options file] [options] command [args] DESCRIPTION gpg is the OpenPGP part of the GNU Privacy Guard (GnuPG). It is a tool to provide digital encryption and signing services using the OpenPGP standard. gpg features complete key management and all the bells and whistles you would expect from a full OpenPGP implementation. There are two main versions of GnuPG: GnuPG 1.x and GnuPG 2.x. GnuPG 2.x supports modern encryption algorithms and thus should be preferred over GnuPG 1.x. You only need to use GnuPG 1.x if your platform doesn't support GnuPG 2.x, or you need support for some features that GnuPG 2.x has deprecated, e.g., decrypting data created with PGP-2 keys. If you are looking for version 1 of GnuPG, you may find that version installed under the name gpg1. RETURN VALUE The program returns 0 if there are no severe errors, 1 if at least a signature was bad, and other error codes for fatal errors. Note that signature verification requires exact knowledge of what has been signed and by whom it has been signed. Using only the return code is thus not an appropriate way to verify a signa‐ ture by a script. Either make proper use or the status codes or use the gpgv tool which has been designed to make signature verification easy for scripts. WARNINGS Use a good password for your user account and make sure that all security issues are always fixed on your machine. Also employ diligent physical protection to your machine. Consider to use a good passphrase as a last resort protection to your secret key in the case your machine gets stolen. It is important that your secret key is never leaked. Using an easy to carry around token or smartcard with the secret key is often a advisable. If you are going to verify detached signatures, make sure that the program knows about it; either give both filenames on the command line or use ‘-’ to specify STDIN. For scripted or other unattended use of gpg make sure to use the machine-parseable interface and not the default interface which is intended for direct use by humans. The machine-parseable interface provides a stable and well documented API independent of the locale or future changes of gpg. To enable this interface use the options --with-colons and --status-fd. For certain operations the option --command-fd may come handy too. See this help and the file ‘DETAILS’ for the specification of the interface. Note that the GnuPG ``info'' pages as well as the PDF version of the GnuPG manual features a chapter on unattended use of GnuPG. As an alternative the library GPGME can be used as a high-level abstraction on top of that interface. INTEROPERABILITY GnuPG tries to be a very flexible implementation of the OpenPGP standard. In particular, GnuPG implements many of the optional parts of the standard, such as the SHA-512 hash, and the ZLIB and BZIP2 compression algorithms. It is important to be aware that not all OpenPGP programs implement these optional algorithms and that by forcing their use via the --cipher-algo, --digest-algo, --cert-digest-algo, or --compress-algo options in GnuPG, it is possible to create a perfectly valid OpenPGP message, but one that cannot be read by the intended recipient. There are dozens of variations of OpenPGP programs available, and each supports a slightly different subset of these optional algorithms. For example, until recently, no (unhacked) version of PGP supported the BLOWFISH cipher algorithm. A message using BLOWFISH simply could not be read by a PGP user. By default, GnuPG uses the standard OpenPGP preferences system that will always do the right thing and create messages that are usable by all recipients, regardless of which OpenPGP program they use. Only override this safe default if you really know what you are doing. If you absolutely must override the safe default, or if the preferences on a given key are invalid for some reason, you are far better off using the --pgp6, --pgp7, or --pgp8 options. These options are safe as they do not force any particular algorithms in violation of OpenPGP, but rather reduce the available algorithms to a \u0026quot;PGP-safe\u0026quot; list. COMMANDS Commands are not distinguished from options except for the fact that only one command is allowed. Generally speaking, irrelevant options are silently ignored, and may not be checked for cor‐ rectness. gpg may be run with no commands. In this case it will print a warning perform a reasonable action depending on the type of file it is given as input (an encrypted message is decrypted, a sig‐ nature is verified, a file containing keys is listed, etc.). If you run into any problems, please add the option --verbose to the invocation to see more diagnostics. Commands not specific to the function --version Print the program version and licensing information. Note that you cannot abbreviate this command. --help -h Print a usage message summarizing the most useful command-line options. Note that you cannot arbitrarily abbreviate this command (though you can use its short form -h). --warranty Print warranty information. --dump-options Print a list of all available options and commands. Note that you cannot abbreviate this command. Commands to select the type of operation --sign -s Sign a message. This command may be combined with --encrypt (to sign and encrypt a message), --symmetric (to sign and symmetrically encrypt a message), or both --encrypt and --symmetric (to sign and encrypt a message that can be decrypted using a secret key or a passphrase). The signing key is chosen by default or can be set explicitly using the --local-user and --de‐ fault-key options. --clear-sign --clearsign Make a cleartext signature. The content in a cleartext signature is readable without any special software. OpenPGP software is only needed to verify the signature. cleartext signa‐ tures may modify end-of-line whitespace for platform independence and are not intended to be reversible. The signing key is chosen by default or can be set explicitly using the --lo‐ cal-user and --default-key options. --detach-sign -b Make a detached signature. --encrypt -e Encrypt data to one or more public keys. This command may be combined with --sign (to sign and encrypt a message), --symmetric (to encrypt a message that can be decrypted using a secret key or a passphrase), or --sign and --symmetric together (for a signed message that can be decrypted using a secret key or a passphrase). --recipient and related options specify which public keys to use for encryption. --symmetric -c Encrypt with a symmetric cipher using a passphrase. The default symmetric cipher used is AES-128, but may be chosen with the --cipher-algo option. This command may be combined with --sign (for a signed and symmetrically encrypted message), --encrypt (for a message that may be decrypted via a secret key or a passphrase), or --sign and --encrypt together (for a signed message that may be decrypted via a secret key or a passphrase). gpg caches the passphrase used for symmetric encryption so that a decrypt operation may not require that the user needs to enter the passphrase. The option --no-symkey-cache can be used to disable this feature. --store Store only (make a simple literal data packet). --decrypt -d Decrypt the file given on the command line (or STDIN if no file is specified) and write it to STDOUT (or the file specified with --output). If the decrypted file is signed, the signa‐ ture is also verified. This command differs from the default operation, as it never writes to the filename which is included in the file and it rejects files that don't begin with an encrypted message. --verify Assume that the first argument is a signed file and verify it without generating any output. With no arguments, the signature packet is read from STDIN. If only one argument is given, the specified file is expected to include a complete signature. With more than one argument, the first argument should specify a file with a detached signature and the remaining files should contain the signed data. To read the signed data from STDIN, use ‘-’ as the second filename. For security reasons, a detached signature will not read the signed material from STDIN if not explicitly specified. Note: If the option --batch is not used, gpg may assume that a single argument is a file with a detached signature, and it will try to find a matching data file by stripping certain suffixes. Using this historical feature to verify a detached signature is strongly discouraged; you should always specify the data file explicitly. Note: When verifying a cleartext signature, gpg verifies only what makes up the cleartext signed data and not any extra data outside of the cleartext signature or the header lines di‐ rectly following the dash marker line. The option --output may be used to write out the actual signed data, but there are other pitfalls with this format as well. It is suggested to avoid cleartext signatures in favor of detached signatures. Note: Sometimes the use of the gpgv tool is easier than using the full-fledged gpg with this option. gpgv is designed to compare signed data against a list of trusted keys and returns with success only for a good signature. It has its own manual page. --multifile This modifies certain other commands to accept multiple files for processing on the command line or read from STDIN with each filename on a separate line. This allows for many files to be processed at once. --multifile may currently be used along with --verify, --encrypt, and --decrypt. Note that --multifile --verify may not be used with detached signatures. --verify-files Identical to --multifile --verify. --encrypt-files Identical to --multifile --encrypt. --decrypt-files Identical to --multifile --decrypt. --list-keys -k --list-public-keys List the specified keys. If no keys are specified, then all keys from the configured public keyrings are listed. Never use the output of this command in scripts or other programs. The output is intended only for humans and its format is likely to change. The --with-colons option emits the output in a stable, machine-parseable format, which is intended for use by scripts and other programs. --list-secret-keys -K List the specified secret keys. If no keys are specified, then all known secret keys are listed. A # after the initial tags sec or ssb means that the secret key or subkey is currently not usable. We also say that this key has been taken offline (for example, a primary key can be taken offline by exporting the key using the command --export-secret-subkeys). A \u0026gt; af‐ ter these tags indicate that the key is stored on a smartcard. See also --list-keys. --check-signatures --check-sigs Same as --list-keys, but the key signatures are verified and listed too. Note that for performance reasons the revocation status of a signing key is not shown. This command has the same effect as using --list-keys with --with-sig-check. The status of the verification is indicated by a flag directly following the \u0026quot;sig\u0026quot; tag (and thus before the flags described below. A \u0026quot;!\u0026quot; indicates that the signature has been success‐ fully verified, a \u0026quot;-\u0026quot; denotes a bad signature and a \u0026quot;%\u0026quot; is used if an error occurred while checking the signature (e.g. a non supported algorithm). Signatures where the public key is not available are not listed; to see their keyids the command --list-sigs can be used. For each signature listed, there are several flags in between the signature status flag and keyid. These flags give additional information about each key signature. From left to right, they are the numbers 1-3 for certificate check level (see --ask-cert-level), \u0026quot;L\u0026quot; for a local or non-exportable signature (see --lsign-key), \u0026quot;R\u0026quot; for a nonRevocable signature (see the --edit-key command \u0026quot;nrsign\u0026quot;), \u0026quot;P\u0026quot; for a signature that contains a policy URL (see --cert-policy-url), \u0026quot;N\u0026quot; for a signature that contains a notation (see --cert-notation), \u0026quot;X\u0026quot; for an eXpired signature (see --ask-cert-expire), and the numbers 1-9 or \u0026quot;T\u0026quot; for 10 and above to indicate trust signature levels (see the --edit-key command \u0026quot;tsign\u0026quot;). --locate-keys --locate-external-keys Locate the keys given as arguments. This command basically uses the same algorithm as used when locating keys for encryption and may thus be used to see what keys gpg might use. In particular external methods as defined by --auto-key-locate are used to locate a key if the arguments comain valid mail addresses. Only public keys are listed. The variant --locate-external-keys does not consider a locally existing key and can thus be used to force the refresh of a key via the defined external methods. If a fingerprint is given and and the methods defined by --auto-key-locate define LDAP servers, the key is fetched from these resources; defined non-LDAP keyservers are skipped. --show-keys This commands takes OpenPGP keys as input and prints information about them in the same way the command --list-keys does for locally stored key. In addition the list options show-unus‐ able-uids, show-unusable-subkeys, show-notations and show-policy-urls are also enabled. As usual for automated processing, this command should be combined with the option --with- colons. --fingerprint List all keys (or the specified ones) along with their fingerprints. This is the same output as --list-keys but with the additional output of a line with the fingerprint. May also be combined with --check-signatures. If this command is given twice, the fingerprints of all secondary keys are listed too. This command also forces pretty printing of fingerprints if the keyid format has been set to \u0026quot;none\u0026quot;. --list-packets List only the sequence of packets. This command is only useful for debugging. When used with option --verbose the actual MPI values are dumped and not only their lengths. Note that the output of this command may change with new releases. --edit-card --card-edit Present a menu to work with a smartcard. The subcommand \u0026quot;help\u0026quot; provides an overview on available commands. For a detailed description, please see the Card HOWTO at https://gnupg.org/documentation/howtos.html#GnuPG-cardHOWTO . --card-status Show the content of the smart card. --change-pin Present a menu to allow changing the PIN of a smartcard. This functionality is also available as the subcommand \u0026quot;passwd\u0026quot; with the --edit-card command. --delete-keys name Remove key from the public keyring. In batch mode either --yes is required or the key must be specified by fingerprint. This is a safeguard against accidental deletion of multiple keys. If the exclamation mark syntax is used with the fingerprint of a subkey only that subkey is deleted; if the exclamation mark is used with the fingerprint of the primary key the entire public key is deleted. --delete-secret-keys name Remove key from the secret keyring. In batch mode the key must be specified by fingerprint. The option --yes can be used to advise gpg-agent not to request a confirmation. This extra pre-caution is done because gpg can't be sure that the secret key (as controlled by gpg-agent) is only used for the given OpenPGP public key. If the exclamation mark syntax is used with the fingerprint of a subkey only the secret part of that subkey is deleted; if the exclamation mark is used with the fingerprint of the primary key only the secret part of the pri‐ mary key is deleted. --delete-secret-and-public-key name Same as --delete-key, but if a secret key exists, it will be removed first. In batch mode the key must be specified by fingerprint. The option --yes can be used to advise gpg-agent not to request a confirmation. --export Either export all keys from all keyrings (default keyring and those registered via option --keyring), or if at least one name is given, those of the given name. The exported keys are written to STDOUT or to the file given with option --output. Use together with --armor to mail those keys. --send-keys keyIDs Similar to --export but sends the keys to a keyserver. Fingerprints may be used instead of key IDs. Don't send your complete keyring to a keyserver --- select only those keys which are new or changed by you. If no keyIDs are given, gpg does nothing. Take care: Keyservers are by design write only systems and thus it is not possible to ever delete keys once they have been send to a keyserver. --export-secret-keys --export-secret-subkeys Same as --export, but exports the secret keys instead. The exported keys are written to STDOUT or to the file given with option --output. This command is often used along with the op‐ tion --armor to allow for easy printing of the key for paper backup; however the external tool paperkey does a better job of creating backups on paper. Note that exporting a secret key can be a security risk if the exported keys are sent over an insecure channel. The second form of the command has the special property to render the secret part of the primary key useless; this is a GNU extension to OpenPGP and other implementations can not be ex‐ pected to successfully import such a key. Its intended use is in generating a full key with an additional signing subkey on a dedicated machine. This command then exports the key without the primary key to the main machine. GnuPG may ask you to enter the passphrase for the key. This is required, because the internal protection method of the secret key is different from the one specified by the OpenPGP protocol. --export-ssh-key This command is used to export a key in the OpenSSH public key format. It requires the specification of one key by the usual means and exports the latest valid subkey which has an au‐ thentication capability to STDOUT or to the file given with option --output. That output can directly be added to ssh's ‘authorized_key’ file. By specifying the key to export using a key ID or a fingerprint suffixed with an exclamation mark (!), a specific subkey or the primary key can be exported. This does not even require that the key has the authentication capability flag set. --import --fast-import Import/merge keys. This adds the given keys to the keyring. The fast version is currently just a synonym. There are a few other options which control how this command works. Most notable here is the --import-options merge-only option which does not insert new keys but does only the merging of new signatures, user-IDs and subkeys. --receive-keys keyIDs --recv-keys keyIDs Import the keys with the given keyIDs from a keyserver. --refresh-keys Request updates from a keyserver for keys that already exist on the local keyring. This is useful for updating a key with the latest signatures, user IDs, etc. Calling this with no ar‐ guments will refresh the entire keyring. --search-keys names Search the keyserver for the given names. Multiple names given here will be joined together to create the search string for the keyserver. Note that keyservers search for names in a different and simpler way than gpg does. The best choice is to use a mail address. Due to data privacy reasons keyservers may even not even allow searching by user id or mail address and thus may only return results when being used with the --recv-key command to search by key fingerprint or keyid. --fetch-keys URIs Retrieve keys located at the specified URIs. Note that different installations of GnuPG may support different protocols (HTTP, FTP, LDAP, etc.). When using HTTPS the system provided root certificates are used by this command. --update-trustdb Do trust database maintenance. This command iterates over all keys and builds the Web of Trust. This is an interactive command because it may have to ask for the \u0026quot;ownertrust\u0026quot; values for keys. The user has to give an estimation of how far she trusts the owner of the displayed key to correctly certify (sign) other keys. GnuPG only asks for the ownertrust value if it has not yet been assigned to a key. Using the --edit-key menu, the assigned value can be changed at any time. --check-trustdb Do trust database maintenance without user interaction. From time to time the trust database must be updated so that expired keys or signatures and the resulting changes in the Web of Trust can be tracked. Normally, GnuPG will calculate when this is required and do it automatically unless --no-auto-check-trustdb is set. This command can be used to force a trust data‐ base check at any time. The processing is identical to that of --update-trustdb but it skips keys with a not yet defined \u0026quot;ownertrust\u0026quot;. For use with cron jobs, this command can be used together with --batch in which case the trust database check is done only if a check is needed. To force a run even in batch mode add the option --yes. --export-ownertrust Send the ownertrust values to STDOUT. This is useful for backup purposes as these values are the only ones which can't be re-created from a corrupted trustdb. Example: gpg --export-ownertrust \u0026gt; otrust.txt --import-ownertrust Update the trustdb with the ownertrust values stored in files (or STDIN if not given); existing values will be overwritten. In case of a severely damaged trustdb and if you have a re‐ cent backup of the ownertrust values (e.g. in the file ‘otrust.txt’), you may re-create the trustdb using these commands: cd ~/.gnupg rm trustdb.gpg gpg --import-ownertrust \u0026lt; otrust.txt --rebuild-keydb-caches When updating from version 1.0.6 to 1.0.7 this command should be used to create signature caches in the keyring. It might be handy in other situations too. --print-md algo --print-mds Print message digest of algorithm algo for all given files or STDIN. With the second form (or a deprecated \u0026quot;*\u0026quot; for algo) digests for all available algorithms are printed. --gen-random 0|1|2|16|30 count Emit count random bytes of the given quality level 0, 1 or 2. If count is not given or zero, an endless sequence of random bytes will be emitted. If used with --armor the output will be base64 encoded. The special level 16 uses a quality level of 1 and outpust end endless stream of hex-encoded octets. The special level 30 outputs random as 30 zBase-32 characters. --gen-prime mode bits Use the source, Luke :-). The output format is subject to change with ant release. --enarmor --dearmor Pack or unpack an arbitrary input into/from an OpenPGP ASCII armor. This is a GnuPG extension to OpenPGP and in general not very useful. The --dearmor command can also be used to dearmor PEM armors. --unwrap This command is similar to --decrypt with the change that the output is not the usual plaintext but the original message with the decryption layer removed. Thus the output will be an OpenPGP data structure which often means a signed OpenPGP message. Note that this command may or may not remove a compression layer which is often found beneath the encryption layer. --tofu-policy {auto|good|unknown|bad|ask} keys Set the TOFU policy for all the bindings associated with the specified keys. For more information about the meaning of the policies, see: [trust-model-tofu]. The keys may be specified either by their fingerprint (preferred) or their keyid. How to manage your keys This section explains the main commands for key management. --quick-generate-key user-id [algo [usage [expire]]] --quick-gen-key This is a simple command to generate a standard key with one user id. In contrast to --generate-key the key is generated directly without the need to answer a bunch of prompts. Unless the option --yes is given, the key creation will be canceled if the given user id already exists in the keyring. If invoked directly on the console without any special options an answer to a ``Continue?'' style confirmation prompt is required. In case the user id already exists in the keyring a second prompt to force the creation of the key will show up. If algo or usage are given, only the primary key is created and no prompts are shown. To specify an expiration date but still create a primary and subkey use ``default'' or ``future- default'' for algo and ``default'' for usage. For a description of these optional arguments see the command --quick-add-key. The usage accepts also the value ``cert'' which can be used to create a certification only primary key; the default is to a create certification and signing key. The expire argument can be used to specify an expiration date for the key. Several formats are supported; commonly the ISO formats ``YYYY-MM-DD'' or ``YYYYMMDDThhmmss'' are used. To make the key expire in N seconds, N days, N weeks, N months, or N years use ``seconds=N'', ``Nd'', ``Nw'', ``Nm'', or ``Ny'' respectively. Not specifying a value, or using ``-'' re‐ sults in a key expiring in a reasonable default interval. The values ``never'', ``none'' can be used for no expiration date. If this command is used with --batch, --pinentry-mode has been set to loopback, and one of the passphrase options (--passphrase, --passphrase-fd, or --passphrase-file) is used, the sup‐ plied passphrase is used for the new key and the agent does not ask for it. To create a key without any protection --passphrase '' may be used. To create an OpenPGP key from the keys available on the currently inserted smartcard, the special string ``card'' can be used for algo. If the card features an encryption and a signing key, gpg will figure them out and creates an OpenPGP key consisting of the usual primary key and one subkey. This works only with certain smartcards. Note that the interactive --full- gen-key command allows to do the same but with greater flexibility in the selection of the smartcard keys. Note that it is possible to create a primary key and a subkey using non-default algorithms by using ``default'' and changing the default parameters using the option --default-new-key- algo. --quick-set-expire fpr expire [*|subfprs] With two arguments given, directly set the expiration time of the primary key identified by fpr to expire. To remove the expiration time 0 can be used. With three arguments and the third given as an asterisk, the expiration time of all non-revoked and not yet expired subkeys are set to expire. With more than two arguments and a list of fingerprints given for subfprs, all non-revoked subkeys matching these fingerprints are set to expire. --quick-add-key fpr [algo [usage [expire]]] Directly add a subkey to the key identified by the fingerprint fpr. Without the optional arguments an encryption subkey is added. If any of the arguments are given a more specific subkey is added. algo may be any of the supported algorithms or curve names given in the format as used by key listings. To use the default algorithm the string ``default'' or ``-'' can be used. Sup‐ ported algorithms are ``rsa'', ``dsa'', ``elg'', ``ed25519'', ``cv25519'', and other ECC curves. For example the string ``rsa'' adds an RSA key with the default key length; a string ``rsa4096'' requests that the key length is 4096 bits. The string ``future-default'' is an alias for the algorithm which will likely be used as default algorithm in future versions of gpg. To list the supported ECC curves the command gpg --with-colons --list-config curve can be used. Depending on the given algo the subkey may either be an encryption subkey or a signing subkey. If an algorithm is capable of signing and encryption and such a subkey is desired, a us‐ age string must be given. This string is either ``default'' or ``-'' to keep the default or a comma delimited list (or space delimited list) of keywords: ``sign'' for a signing subkey, ``auth'' for an authentication subkey, and ``encr'' for an encryption subkey (``encrypt'' can be used as alias for ``encr''). The valid combinations depend on the algorithm. The expire argument can be used to specify an expiration date for the key. Several formats are supported; commonly the ISO formats ``YYYY-MM-DD'' or ``YYYYMMDDThhmmss'' are used. To make the key expire in N seconds, N days, N weeks, N months, or N years use ``seconds=N'', ``Nd'', ``Nw'', ``Nm'', or ``Ny'' respectively. Not specifying a value, or using ``-'' re‐ sults in a key expiring in a reasonable default interval. The values ``never'', ``none'' can be used for no expiration date. --generate-key --gen-key Generate a new key pair using the current default parameters. This is the standard command to create a new key. In addition to the key a revocation certificate is created and stored in the ‘openpgp-revocs.d’ directory below the GnuPG home directory. --full-generate-key --full-gen-key Generate a new key pair with dialogs for all options. This is an extended version of --generate-key. There is also a feature which allows you to create keys in batch mode. See the manual section ``Unattended key generation'' on how to use this. --generate-revocation name --gen-revoke name Generate a revocation certificate for the complete key. To only revoke a subkey or a key signature, use the --edit command. This command merely creates the revocation certificate so that it can be used to revoke the key if that is ever needed. To actually revoke a key the created revocation certificate needs to be merged with the key to revoke. This is done by importing the revocation certificate using the --import command. Then the revoked key needs to be published, which is best done by sending the key to a keyserver (command --send-key) and by exporting (--export) it to a file which is then send to frequent communication partners. --generate-designated-revocation name --desig-revoke name Generate a designated revocation certificate for a key. This allows a user (with the permission of the keyholder) to revoke someone else's key. --edit-key Present a menu which enables you to do most of the key management related tasks. It expects the specification of a key on the command line. uid n Toggle selection of user ID or photographic user ID with index n. Use * to select all and 0 to deselect all. key n Toggle selection of subkey with index n or key ID n. Use * to select all and 0 to deselect all. sign Make a signature on key of user name. If the key is not yet signed by the default user (or the users given with -u), the program displays the information of the key again, to‐ gether with its fingerprint and asks whether it should be signed. This question is repeated for all users specified with -u. lsign Same as \u0026quot;sign\u0026quot; but the signature is marked as non-exportable and will therefore never be used by others. This may be used to make keys valid only in the local environment. nrsign Same as \u0026quot;sign\u0026quot; but the signature is marked as non-revocable and can therefore never be revoked. tsign Make a trust signature. This is a signature that combines the notions of certification (like a regular signature), and trust (like the \u0026quot;trust\u0026quot; command). It is generally only use‐ ful in distinct communities or groups. For more information please read the sections ``Trust Signature'' and ``Regular Expression'' in RFC-4880. Note that \u0026quot;l\u0026quot; (for local / non-exportable), \u0026quot;nr\u0026quot; (for non-revocable, and \u0026quot;t\u0026quot; (for trust) may be freely mixed and prefixed to \u0026quot;sign\u0026quot; to create a signature of any type desired. If the option --only-sign-text-ids is specified, then any non-text based user ids (e.g., photo IDs) will not be selected for signing. delsig Delete a signature. Note that it is not possible to retract a signature, once it has been send to the public (i.e. to a keyserver). In that case you better use revsig. revsig Revoke a signature. For every signature which has been generated by one of the secret keys, GnuPG asks whether a revocation certificate should be generated. check Check the signatures on all selected user IDs. With the extra option selfsig only self-signatures are shown. adduid Create an additional user ID. addphoto Create a photographic user ID. This will prompt for a JPEG file that will be embedded into the user ID. Note that a very large JPEG will make for a very large key. Also note that some programs will display your JPEG unchanged (GnuPG), and some programs will scale it to fit in a dialog box (PGP). showphoto Display the selected photographic user ID. deluid Delete a user ID or photographic user ID. Note that it is not possible to retract a user id, once it has been send to the public (i.e. to a keyserver). In that case you better use revuid. revuid Revoke a user ID or photographic user ID. primary Flag the current user id as the primary one, removes the primary user id flag from all other user ids and sets the timestamp of all affected self-signatures one second ahead. Note that setting a photo user ID as primary makes it primary over other photo user IDs, and setting a regular user ID as primary makes it primary over other regular user IDs. keyserver Set a preferred keyserver for the specified user ID(s). This allows other users to know where you prefer they get your key from. See --keyserver-options honor-keyserver-url for more on how this works. Setting a value of \u0026quot;none\u0026quot; removes an existing preferred keyserver. notation Set a name=value notation for the specified user ID(s). See --cert-notation for more on how this works. Setting a value of \u0026quot;none\u0026quot; removes all notations, setting a notation pre‐ fixed with a minus sign (-) removes that notation, and setting a notation name (without the =value) prefixed with a minus sign removes all notations with that name. pref List preferences from the selected user ID. This shows the actual preferences, without including any implied preferences. showpref More verbose preferences listing for the selected user ID. This shows the preferences in effect by including the implied preferences of 3DES (cipher), SHA-1 (digest), and Uncom‐ pressed (compression) if they are not already included in the preference list. In addition, the preferred keyserver and signature notations (if any) are shown. setpref string Set the list of user ID preferences to string for all (or just the selected) user IDs. Calling setpref with no arguments sets the preference list to the default (either built-in or set via --default-preference-list), and calling setpref with \u0026quot;none\u0026quot; as the argument sets an empty preference list. Use gpg --version to get a list of available algorithms. Note that while you can change the preferences on an attribute user ID (aka \u0026quot;photo ID\u0026quot;), GnuPG does not select keys via attribute user IDs so these preferences will not be used by GnuPG. When setting preferences, you should list the algorithms in the order which you'd like to see them used by someone else when encrypting a message to your key. If you don't in‐ clude 3DES, it will be automatically added at the end. Note that there are many factors that go into choosing an algorithm (for example, your key may not be the only recipient), and so the remote OpenPGP application being used to send to you may or may not follow your exact chosen order for a given message. It will, however, only choose an algorithm that is present on the preference list of every recipient key. See also the INTEROPERABILITY WITH OTHER OPENPGP PROGRAMS section below. addkey Add a subkey to this key. addcardkey Generate a subkey on a card and add it to this key. keytocard Transfer the selected secret subkey (or the primary key if no subkey has been selected) to a smartcard. The secret key in the keyring will be replaced by a stub if the key could be stored successfully on the card and you use the save command later. Only certain key types may be transferred to the card. A sub menu allows you to select on what card to store the key. Note that it is not possible to get that key back from the card - if the card gets broken your secret key will be lost unless you have a backup somewhere. bkuptocard file Restore the given file to a card. This command may be used to restore a backup key (as generated during card initialization) to a new card. In almost all cases this will be the encryption key. You should use this command only with the corresponding public key and make sure that the file given as argument is indeed the backup to restore. You should then select 2 to restore as encryption key. You will first be asked to enter the passphrase of the backup key and then for the Admin PIN of the card. keytotpm Transfer the selected secret subkey (or the primary key if no subkey has been selected) to TPM form. The secret key in the keyring will be replaced by the TPM representation of that key, which can only be read by the particular TPM that created it (so the keyfile now becomes locked to the laptop containing the TPM). Only certain key types may be trans‐ ferred to the TPM (all TPM 2.0 systems are mandated to have the rsa2048 and nistp256 algorithms but newer TPMs may have more). Note that the key itself is not transferred into the TPM, merely encrypted by the TPM in-place, so if the keyfile is deleted, the key will be lost. Once transferred to TPM representation, the key file can never be converted back to non-TPM form and the key will die when the TPM does, so you should first have a backup on secure offline storage of the actual secret key file before conversion. It is essential to use the physical system TPM that you have rw permission on the TPM resource manager device (/dev/tpmrm0). Usually this means you must be a member of the tss group. delkey Remove a subkey (secondary key). Note that it is not possible to retract a subkey, once it has been send to the public (i.e. to a keyserver). In that case you better use revkey. Also note that this only deletes the public part of a key. revkey Revoke a subkey. expire Change the key or subkey expiration time. If a subkey is selected, the expiration time of this subkey will be changed. With no selection, the key expiration of the primary key is changed. trust Change the owner trust value for the key. This updates the trust-db immediately and no save is required. disable enable Disable or enable an entire key. A disabled key can not normally be used for encryption. addrevoker Add a designated revoker to the key. This takes one optional argument: \u0026quot;sensitive\u0026quot;. If a designated revoker is marked as sensitive, it will not be exported by default (see ex‐ port-options). passwd Change the passphrase of the secret key. toggle This is dummy command which exists only for backward compatibility. clean Compact (by removing all signatures except the selfsig) any user ID that is no longer usable (e.g. revoked, or expired). Then, remove any signatures that are not usable by the trust calculations. Specifically, this removes any signature that does not validate, any signature that is superseded by a later signature, revoked signatures, and signatures issued by keys that are not present on the keyring. minimize Make the key as small as possible. This removes all signatures from each user ID except for the most recent self-signature. change-usage Change the usage flags (capabilities) of the primary key or of subkeys. These usage flags (e.g. Certify, Sign, Authenticate, Encrypt) are set during key creation. Sometimes it is useful to have the opportunity to change them (for example to add Authenticate) after they have been created. Please take care when doing this; the allowed usage flags depend on the key algorithm. cross-certify Add cross-certification signatures to signing subkeys that may not currently have them. Cross-certification signatures protect against a subtle attack against signing subkeys. See --require-cross-certification. All new keys generated have this signature by default, so this command is only useful to bring older keys up to date. save Save all changes to the keyring and quit. quit Quit the program without updating the keyring. The listing shows you the key with its secondary keys and all user IDs. The primary user ID is indicated by a dot, and selected keys or user IDs are indicated by an asterisk. The trust value is displayed with the primary key: \u0026quot;trust\u0026quot; is the assigned owner trust and \u0026quot;validity\u0026quot; is the calculated validity of the key. Validity values are also displayed for all user IDs. For possible values of trust, see: [trust-values]. --sign-key name Signs a public key with your secret key. This is a shortcut version of the subcommand \u0026quot;sign\u0026quot; from --edit-key. --lsign-key name Signs a public key with your secret key but marks it as non-exportable. This is a shortcut version of the subcommand \u0026quot;lsign\u0026quot; from --edit-key. --quick-sign-key fpr [names] --quick-lsign-key fpr [names] Directly sign a key from the passphrase without any further user interaction. The fpr must be the verified primary fingerprint of a key in the local keyring. If no names are given, all useful user ids are signed; with given [names] only useful user ids matching one of these names are signed. By default, or if a name is prefixed with a '*', a case insensitive sub‐ string match is used. If a name is prefixed with a '=' a case sensitive exact match is done. The command --quick-lsign-key marks the signatures as non-exportable. If such a non-exportable signature already exists the --quick-sign-key turns it into a exportable signature. If you need to update an existing signature, for example to add or change notation data, you need to use the option --force-sign-key. This command uses reasonable defaults and thus does not provide the full flexibility of the \u0026quot;sign\u0026quot; subcommand from --edit-key. Its intended use is to help unattended key signing by utilizing a list of verified fingerprints. --quick-add-uid user-id new-user-id This command adds a new user id to an existing key. In contrast to the interactive sub-command adduid of --edit-key the new-user-id is added verbatim with only leading and trailing white space removed, it is expected to be UTF-8 encoded, and no checks on its form are applied. --quick-revoke-uid user-id user-id-to-revoke This command revokes a user ID on an existing key. It cannot be used to revoke the last user ID on key (some non-revoked user ID must remain), with revocation reason ``User ID is no longer valid''. If you want to specify a different revocation reason, or to supply supplementary revocation text, you should use the interactive sub-command revuid of --edit-key. --quick-revoke-sig fpr signing-fpr [names] This command revokes the key signatures made by signing-fpr from the key specified by the fingerprint fpr. With names given only the signatures on user ids of the key matching any of the given names are affected (see --quick-sign-key). If a revocation already exists a notice is printed instead of creating a new revocation; no error is returned in this case. Note that key signature revocations may be superseded by a newer key signature and in turn again revoked. --quick-set-primary-uid user-id primary-user-id This command sets or updates the primary user ID flag on an existing key. user-id specifies the key and primary-user-id the user ID which shall be flagged as the primary user ID. The primary user ID flag is removed from all other user ids and the timestamp of all affected self-signatures is set one second ahead. --change-passphrase user-id --passwd user-id Change the passphrase of the secret key belonging to the certificate specified as user-id. This is a shortcut for the sub-command passwd of the --edit-key menu. When using together with the option --dry-run this will not actually change the passphrase but check that the current passphrase is correct. OPTIONS gpg features a bunch of options to control the exact behaviour and to change the default configuration. Long options can be put in an options file (default \u0026quot;~/.gnupg/gpg.conf\u0026quot;). Short option names will not work - for example, \u0026quot;armor\u0026quot; is a valid option for the options file, while \u0026quot;a\u0026quot; is not. Do not write the 2 dashes, but simply the name of the option and any required arguments. Lines with a hash ('#') as the first non-white-space character are ignored. Commands may be put in this file too, but that is not generally useful as the command will execute automatically with every execution of gpg. Please remember that option parsing stops as soon as a non-option is encountered, you can explicitly stop parsing by using the special option --. How to change the configuration These options are used to change the configuration and most of them are usually found in the option file. --default-key name Use name as the default key to sign with. If this option is not used, the default key is the first key found in the secret keyring. Note that -u or --local-user overrides this option. This option may be given multiple times. In this case, the last key for which a secret key is available is used. If there is no secret key available for any of the specified values, GnuPG will not emit an error message but continue as if this option wasn't given. --default-recipient name Use name as default recipient if option --recipient is not used and don't ask if this is a valid one. name must be non-empty. --default-recipient-self Use the default key as default recipient if option --recipient is not used and don't ask if this is a valid one. The default key is the first one from the secret keyring or the one set with --default-key. --no-default-recipient Reset --default-recipient and --default-recipient-self. Should not be used in an option file. -v, --verbose Give more information during processing. If used twice, the input data is listed in detail. --no-verbose Reset verbose level to 0. Should not be used in an option file. -q, --quiet Try to be as quiet as possible. Should not be used in an option file. --batch --no-batch Use batch mode. Never ask, do not allow interactive commands. --no-batch disables this option. Note that even with a filename given on the command line, gpg might still need to read from STDIN (in particular if gpg figures that the input is a detached signature and no data file has been specified). Thus if you do not want to feed data via STDIN, you should connect STDIN to ‘/dev/null’. It is highly recommended to use this option along with the options --status-fd and --with-colons for any unattended use of gpg. Should not be used in an option file. --no-tty Make sure that the TTY (terminal) is never used for any output. This option is needed in some cases because GnuPG sometimes prints warnings to the TTY even if --batch is used. --yes Assume \u0026quot;yes\u0026quot; on most questions. Should not be used in an option file. --no Assume \u0026quot;no\u0026quot; on most questions. Should not be used in an option file. --list-options parameters This is a space or comma delimited string that gives options used when listing keys and signatures (that is, --list-keys, --check-signatures, --list-public-keys, --list-secret-keys, and the --edit-key functions). Options can be prepended with a no- (after the two dashes) to give the opposite meaning. The options are: show-photos Causes --list-keys, --check-signatures, --list-public-keys, and --list-secret-keys to display any photo IDs attached to the key. Defaults to no. See also --photo-viewer. Does not work with --with-colons: see --attribute-fd for the appropriate way to get photo data for scripts and other frontends. show-usage Show usage information for keys and subkeys in the standard key listing. This is a list of letters indicating the allowed usage for a key (E=encryption, S=signing, C=certifica‐ tion, A=authentication). Defaults to yes. show-policy-urls Show policy URLs in the --check-signatures listings. Defaults to no. show-notations show-std-notations show-user-notations Show all, IETF standard, or user-defined signature notations in the --check-signatures listings. Defaults to no. show-keyserver-urls Show any preferred keyserver URL in the --check-signatures listings. Defaults to no. show-uid-validity Display the calculated validity of user IDs during key listings. Defaults to yes. show-unusable-uids Show revoked and expired user IDs in key listings. Defaults to no. show-unusable-subkeys Show revoked and expired subkeys in key listings. Defaults to no. show-keyring Display the keyring name at the head of key listings to show which keyring a given key resides on. Defaults to no. show-sig-expire Show signature expiration dates (if any) during --check-signatures listings. Defaults to no. show-sig-subpackets Include signature subpackets in the key listing. This option can take an optional argument list of the subpackets to list. If no argument is passed, list all subpackets. Defaults to no. This option is only meaningful when using --with-colons along with --check-signatures. show-only-fpr-mbox For each user-id which has a valid mail address print only the fingerprint followed by the mail address. sort-sigs With --list-sigs and --check-sigs sort the signatures by keyID and creation time to make it easier to view the history of these signatures. The self-signature is also listed be‐ fore other signatures. Defaults to yes. --verify-options parameters This is a space or comma delimited string that gives options used when verifying signatures. Options can be prepended with a `no-' to give the opposite meaning. The options are: show-photos Display any photo IDs present on the key that issued the signature. Defaults to no. See also --photo-viewer. show-policy-urls Show policy URLs in the signature being verified. Defaults to yes. show-notations show-std-notations show-user-notations Show all, IETF standard, or user-defined signature notations in the signature being verified. Defaults to IETF standard. show-keyserver-urls Show any preferred keyserver URL in the signature being verified. Defaults to yes. show-uid-validity Display the calculated validity of the user IDs on the key that issued the signature. Defaults to yes. show-unusable-uids Show revoked and expired user IDs during signature verification. Defaults to no. show-primary-uid-only Show only the primary user ID during signature verification. That is all the AKA lines as well as photo Ids are not shown with the signature verification status. --enable-large-rsa --disable-large-rsa With --generate-key and --batch, enable the creation of RSA secret keys as large as 8192 bit. Note: 8192 bit is more than is generally recommended. These large keys don't signifi‐ cantly improve security, but they are more expensive to use, and their signatures and certifications are larger. This option is only available if the binary was build with large-secmem support. --enable-dsa2 --disable-dsa2 Enable hash truncation for all DSA keys even for old DSA Keys up to 1024 bit. This is also the default with --openpgp. Note that older versions of GnuPG also required this flag to al‐ low the generation of DSA larger than 1024 bit. --photo-viewer string This is the command line that should be run to view a photo ID. \u0026quot;%i\u0026quot; will be expanded to a filename containing the photo. \u0026quot;%I\u0026quot; does the same, except the file will not be deleted once the viewer exits. Other flags are \u0026quot;%k\u0026quot; for the key ID, \u0026quot;%K\u0026quot; for the long key ID, \u0026quot;%f\u0026quot; for the key fingerprint, \u0026quot;%t\u0026quot; for the extension of the image type (e.g. \u0026quot;jpg\u0026quot;), \u0026quot;%T\u0026quot; for the MIME type of the image (e.g. \u0026quot;image/jpeg\u0026quot;), \u0026quot;%v\u0026quot; for the single-character calculated validity of the image being viewed (e.g. \u0026quot;f\u0026quot;), \u0026quot;%V\u0026quot; for the calculated validity as a string (e.g. \u0026quot;full\u0026quot;), \u0026quot;%U\u0026quot; for a base32 encoded hash of the user ID, and \u0026quot;%%\u0026quot; for an actual percent sign. If neither %i or %I are present, then the photo will be supplied to the viewer on standard input. On Unix the default viewer is xloadimage -fork -quiet -title 'KeyID 0x%k' STDIN with a fallback to display -title 'KeyID 0x%k' %i and finally to xdg-open %i. On Windows !ShellExecute 400 %i is used; here the command is a meta command to use that API call followed by a wait time in milliseconds which is used to give the viewer time to read the temporary image file before gpg deletes it again. Note that if your image viewer program is not secure, then executing it from gpg does not make it secure. --exec-path string Sets a list of directories to search for photo viewers If not provided photo viewers use the PATH environment variable. --keyring file Add file to the current list of keyrings. If file begins with a tilde and a slash, these are replaced by the $HOME directory. If the filename does not contain a slash, it is assumed to be in the GnuPG home directory (\u0026quot;~/.gnupg\u0026quot; unless --homedir or $GNUPGHOME is used). Note that this adds a keyring to the current list. If the intent is to use the specified keyring alone, use --keyring along with --no-default-keyring. If the option --no-keyring has been used no keyrings will be used at all. Note that if the option use-keyboxd is enabled in ‘common.conf’, no keyrings are used at all and keys are all maintained by the keyboxd process in its own database. --primary-keyring file This is a varian of --keyring and designates file as the primary public keyring. This means that newly imported keys (via --import or keyserver --recv-from) will go to this keyring. --secret-keyring file This is an obsolete option and ignored. All secret keys are stored in the ‘private-keys-v1.d’ directory below the GnuPG home directory. --trustdb-name file Use file instead of the default trustdb. If file begins with a tilde and a slash, these are replaced by the $HOME directory. If the filename does not contain a slash, it is assumed to be in the GnuPG home directory (‘~/.gnupg’ if --homedir or $GNUPGHOME is not used). --homedir dir Set the name of the home directory to dir. If this option is not used, the home directory defaults to ‘~/.gnupg’. It is only recognized when given on the command line. It also over‐ rides any home directory stated through the environment variable ‘GNUPGHOME’ or (on Windows systems) by means of the Registry entry HKCU\\Software\\GNU\\GnuPG:HomeDir. On Windows systems it is possible to install GnuPG as a portable application. In this case only this command line option is considered, all other ways to set a home directory are ig‐ nored. To install GnuPG as a portable application under Windows, create an empty file named ‘gpgconf.ctl’ in the same directory as the tool ‘gpgconf.exe’. The root of the installation is then that directory; or, if ‘gpgconf.exe’ has been installed directly below a directory named ‘bin’, its parent directory. You also need to make sure that the following directories exist and are writable: ‘ROOT/home’ for the GnuPG home and ‘ROOT/var/cache/gnupg’ for internal cache files. --display-charset name Set the name of the native character set. This is used to convert some informational strings like user IDs to the proper UTF-8 encoding. Note that this has nothing to do with the char‐ acter set of data to be encrypted or signed; GnuPG does not recode user-supplied data. If this option is not used, the default character set is determined from the current locale. A verbosity level of 3 shows the chosen set. This option should not be used on Windows. Valid values for name are: iso-8859-1 This is the Latin 1 set. iso-8859-2 The Latin 2 set. iso-8859-15 This is currently an alias for the Latin 1 set. koi8-r The usual Russian set (RFC-1489). utf-8 Bypass all translations and assume that the OS uses native UTF-8 encoding. --utf8-strings --no-utf8-strings Assume that command line arguments are given as UTF-8 strings. The default (--no-utf8-strings) is to assume that arguments are encoded in the character set as specified by --display- charset. These options affect all following arguments. Both options may be used multiple times. This option should not be used in an option file. This option has no effect on Windows. There the internal used UTF-8 encoding is translated for console input and output. The command line arguments are expected as Unicode and trans‐ lated to UTF-8. Thus when calling this program from another, make sure to use the Unicode version of CreateProcess. --options file Read options from file and do not try to read them from the default options file in the homedir (see --homedir). This option is ignored if used in an options file. --no-options Shortcut for --options /dev/null. This option is detected before an attempt to open an option file. Using this option will also prevent the creation of a ‘~/.gnupg’ homedir. -z n --compress-level n --bzip2-compress-level n Set compression level to n for the ZIP and ZLIB compression algorithms. The default is to use the default compression level of zlib (normally 6). --bzip2-compress-level sets the com‐ pression level for the BZIP2 compression algorithm (defaulting to 6 as well). This is a different option from --compress-level since BZIP2 uses a significant amount of memory for each additional compression level. -z sets both. A value of 0 for n disables compression. --bzip2-decompress-lowmem Use a different decompression method for BZIP2 compressed files. This alternate method uses a bit more than half the memory, but also runs at half the speed. This is useful under ex‐ treme low memory circumstances when the file was originally compressed at a high --bzip2-compress-level. --mangle-dos-filenames --no-mangle-dos-filenames Older version of Windows cannot handle filenames with more than one dot. --mangle-dos-filenames causes GnuPG to replace (rather than add to) the extension of an output filename to avoid this problem. This option is off by default and has no effect on non-Windows platforms. --ask-cert-level --no-ask-cert-level When making a key signature, prompt for a certification level. If this option is not specified, the certification level used is set via --default-cert-level. See --default-cert-level for information on the specific levels and how they are used. --no-ask-cert-level disables this option. This option defaults to no. --default-cert-level n The default to use for the check level when signing a key. 0 means you make no particular claim as to how carefully you verified the key. 1 means you believe the key is owned by the person who claims to own it but you could not, or did not verify the key at all. This is useful for a \u0026quot;persona\u0026quot; verification, where you sign the key of a pseudonymous user. 2 means you did casual verification of the key. For example, this could mean that you verified the key fingerprint and checked the user ID on the key against a photo ID. 3 means you did extensive verification of the key. For example, this could mean that you verified the key fingerprint with the owner of the key in person, and that you checked, by means of a hard to forge document with a photo ID (such as a passport) that the name of the key owner matches the name in the user ID on the key, and finally that you verified (by exchange of email) that the email address on the key belongs to the key owner. Note that the examples given above for levels 2 and 3 are just that: examples. In the end, it is up to you to decide just what \u0026quot;casual\u0026quot; and \u0026quot;extensive\u0026quot; mean to you. This option defaults to 0 (no particular claim). --min-cert-level When building the trust database, treat any signatures with a certification level below this as invalid. Defaults to 2, which disregards level 1 signatures. Note that level 0 \u0026quot;no par‐ ticular claim\u0026quot; signatures are always accepted. --trusted-key long key ID or fingerprint Assume that the specified key (which should be given as fingerprint) is as trustworthy as one of your own secret keys. This option is useful if you don't want to keep your secret keys (or one of them) online but still want to be able to check the validity of a given recipient's or signator's key. If the given key is not locally available but an LDAP keyserver is configured the missing key is imported from that server. --trust-model {pgp|classic|tofu|tofu+pgp|direct|always|auto} Set what trust model GnuPG should follow. The models are: pgp This is the Web of Trust combined with trust signatures as used in PGP 5.x and later. This is the default trust model when creating a new trust database. classic This is the standard Web of Trust as introduced by PGP 2. tofu TOFU stands for Trust On First Use. In this trust model, the first time a key is seen, it is memorized. If later another key with a user id with the same email address is seen, both keys are marked as suspect. In that case, the next time either is used, a warning is displayed describing the conflict, why it might have occurred (either the user gener‐ ated a new key and failed to cross sign the old and new keys, the key is forgery, or a man-in-the-middle attack is being attempted), and the user is prompted to manually confirm the validity of the key in question. Because a potential attacker is able to control the email address and thereby circumvent the conflict detection algorithm by using an email address that is similar in appearance to a trusted email address, whenever a message is verified, statistics about the number of messages signed with the key are shown. In this way, a user can easily identify at‐ tacks using fake keys for regular correspondents. When compared with the Web of Trust, TOFU offers significantly weaker security guarantees. In particular, TOFU only helps ensure consistency (that is, that the binding between a key and email address doesn't change). A major advantage of TOFU is that it requires little maintenance to use correctly. To use the web of trust properly, you need to actively sign keys and mark users as trusted introducers. This is a time-consuming process and anecdotal evidence suggests that even security-conscious users rarely take the time to do this thoroughly and instead rely on an ad-hoc TOFU process. In the TOFU model, policies are associated with bindings between keys and email addresses (which are extracted from user ids and normalized). There are five policies, which can be set manually using the --tofu-policy option. The default policy can be set using the --tofu-default-policy option. The TOFU policies are: auto, good, unknown, bad and ask. The auto policy is used by default (unless overridden by --tofu-default-policy) and marks a binding as marginally trusted. The good, unknown and bad policies mark a binding as fully trusted, as having unknown trust or as having trust never, respectively. The unknown policy is useful for just using TOFU to detect conflicts, but to never assign positive trust to a binding. The final policy, ask prompts the user to indicate the binding's trust. If batch mode is enabled (or input is inappropriate in the context), then the user is not prompted and the undefined trust level is returned. tofu+pgp This trust model combines TOFU with the Web of Trust. This is done by computing the trust level for each model and then taking the maximum trust level where the trust levels are ordered as follows: unknown \u0026lt; undefined \u0026lt; marginal \u0026lt; fully \u0026lt; ultimate \u0026lt; expired \u0026lt; never. By setting --tofu-default-policy=unknown, this model can be used to implement the web of trust with TOFU's conflict detection algorithm, but without its assignment of positive trust values, which some security-conscious users don't like. direct Key validity is set directly by the user and not calculated via the Web of Trust. This model is solely based on the key and does not distinguish user IDs. Note that when chang‐ ing to another trust model the trust values assigned to a key are transformed into ownertrust values, which also indicate how you trust the owner of the key to sign other keys. always Skip key validation and assume that used keys are always fully valid. You generally won't use this unless you are using some external validation scheme. This option also sup‐ presses the \u0026quot;[uncertain]\u0026quot; tag printed with signature checks when there is no evidence that the user ID is bound to the key. Note that this trust model still does not allow the use of expired, revoked, or disabled keys. auto Select the trust model depending on whatever the internal trust database says. This is the default model if such a database already exists. Note that a tofu trust model is not considered here and must be enabled explicitly. --auto-key-locate mechanisms --no-auto-key-locate GnuPG can automatically locate and retrieve keys as needed using this option. This happens when encrypting to an email address (in the \u0026quot;user@example.com\u0026quot; form), and there are no \u0026quot;user@example.com\u0026quot; keys on the local keyring. This option takes any number of the mechanisms listed below, in the order they are to be tried. Instead of listing the mechanisms as comma delimited arguments, the option may also be given several times to add more mechanism. The option --no-auto-key-locate or the mechanism \u0026quot;clear\u0026quot; resets the list. The default is \u0026quot;local,wkd\u0026quot;. cert Locate a key using DNS CERT, as specified in RFC-4398. dane Locate a key using DANE, as specified in draft-ietf-dane-openpgpkey-05.txt. wkd Locate a key using the Web Key Directory protocol. ldap Using DNS Service Discovery, check the domain in question for any LDAP keyservers to use. If this fails, attempt to locate the key using the PGP Universal method of checking ‘ldap://keys.(thedomain)’. ntds Locate the key using the Active Directory (Windows only). This method also allows to search by fingerprint using the command --locate-external-key. Note that this mechanism is actually a shortcut for the mechanism ‘keyserver’ but using \u0026quot;ldap:///\u0026quot; as the keyserver. keyserver Locate a key using a keyserver. This method also allows to search by fingerprint using the command --locate-external-key if any of the configured keyservers is an LDAP server. keyserver-URL In addition, a keyserver URL as used in the dirmngr configuration may be used here to query that particular keyserver. This method also allows to search by fingerprint using the command --locate-external-key if the URL specifies an LDAP server. local Locate the key using the local keyrings. This mechanism allows the user to select the order a local key lookup is done. Thus using ‘--auto-key-locate local’ is identical to --no-auto-key-locate. nodefault This flag disables the standard local key lookup, done before any of the mechanisms defined by the --auto-key-locate are tried. The position of this mechanism in the list does not matter. It is not required if local is also used. clear Clear all defined mechanisms. This is useful to override mechanisms given in a config file. Note that a nodefault in mechanisms will also be cleared unless it is given after the clear. --auto-key-import --no-auto-key-import This is an offline mechanism to get a missing key for signature verification and for later encryption to this key. If this option is enabled and a signature includes an embedded key, that key is used to verify the signature and on verification success the key is imported. The default is --no-auto-key-import. On the sender (signing) site the option --include-key-block needs to be used to put the public part of the signing key as “Key Block subpacket” into the signature. --auto-key-retrieve --no-auto-key-retrieve These options enable or disable the automatic retrieving of keys from a keyserver when verifying signatures made by keys that are not on the local keyring. The default is --no-auto- key-retrieve. The order of methods tried to lookup the key is: 1. If the option --auto-key-import is set and the signatures includes an embedded key, that key is used to verify the signature and on verification success that key is imported. 2. If a preferred keyserver is specified in the signature and the option honor-keyserver-url is active (which is not the default), that keyserver is tried. Note that the creator of the signature uses the option --sig-keyserver-url to specify the preferred keyserver for data signatures. 3. If the signature has the Signer's UID set (e.g. using --sender while creating the signature) a Web Key Directory (WKD) lookup is done. This is the default configuration but can be disabled by removing WKD from the auto-key-locate list or by using the option --disable-signer-uid. 4. If any keyserver is configured and the Issuer Fingerprint is part of the signature (since GnuPG 2.1.16), the configured keyservers are tried. Note that this option makes a \u0026quot;web bug\u0026quot; like behavior possible. Keyserver or Web Key Directory operators can see which keys you request, so by sending you a message signed by a brand new key (which you naturally will not have on your local keyring), the operator can tell both your IP address and the time when you verified the signature. --keyid-format {none|short|0xshort|long|0xlong} Select how to display key IDs. \u0026quot;none\u0026quot; does not show the key ID at all but shows the fingerprint in a separate line. \u0026quot;short\u0026quot; is the traditional 8-character key ID. \u0026quot;long\u0026quot; is the more accurate (but less convenient) 16-character key ID. Add an \u0026quot;0x\u0026quot; to either to include an \u0026quot;0x\u0026quot; at the beginning of the key ID, as in 0x99242560. Note that this option is ignored if the option --with-colons is used. --keyserver name This option is deprecated - please use the --keyserver in ‘dirmngr.conf’ instead. Use name as your keyserver. This is the server that --receive-keys, --send-keys, and --search-keys will communicate with to receive keys from, send keys to, and search for keys on. The format of the name is a URI: `scheme:[//]keyservername[:port]' The scheme is the type of keyserver: \u0026quot;hkp\u0026quot;/\u0026quot;hkps\u0026quot; for the HTTP (or compatible) keyservers or \u0026quot;ldap\u0026quot;/\u0026quot;ldaps\u0026quot; for the LDAP keyservers. Note that your particular installation of GnuPG may have other keyserver types available as well. Keyserver schemes are case-insensitive. Most keyservers synchronize with each other, so there is generally no need to send keys to more than one server. The keyserver hkp://keys.gnupg.net uses round robin DNS to give a dif‐ ferent keyserver each time you use it. --keyserver-options {name=value} This is a space or comma delimited string that gives options for the keyserver. Options can be prefixed with a `no-' to give the opposite meaning. Valid import-options or export-options may be used here as well to apply to importing (--recv-key) or exporting (--send-key) a key from a keyserver. While not all options are available for all keyserver types, some common options are: include-revoked When searching for a key with --search-keys, include keys that are marked on the keyserver as revoked. Note that not all keyservers differentiate between revoked and unrevoked keys, and for such keyservers this option is meaningless. Note also that most keyservers do not have cryptographic verification of key revocations, and so turning this option off may result in skipping keys that are incorrectly marked as revoked. include-disabled When searching for a key with --search-keys, include keys that are marked on the keyserver as disabled. Note that this option is not used with HKP keyservers. auto-key-retrieve This is an obsolete alias for the option auto-key-retrieve. Please do not use it; it will be removed in future versions.. honor-keyserver-url When using --refresh-keys, if the key in question has a preferred keyserver URL, then use that preferred keyserver to refresh the key from. In addition, if auto-key-retrieve is set, and the signature being verified has a preferred keyserver URL, then use that preferred keyserver to fetch the key from. Note that this option introduces a \u0026quot;web bug\u0026quot;: The creator of the key can see when the keys is refreshed. Thus this option is not enabled by default. include-subkeys When receiving a key, include subkeys as potential targets. Note that this option is not used with HKP keyservers, as they do not support retrieving keys by subkey id. timeout http-proxy=value verbose debug check-cert ca-cert-file These options have no more function since GnuPG 2.1. Use the dirmngr configuration options instead. The default list of options is: \u0026quot;self-sigs-only, import-clean, repair-keys, repair-pks-subkey-bug, export-attributes\u0026quot;. However, if the actual used source is an LDAP server \u0026quot;no-self-sigs-only\u0026quot; is assumed unless \u0026quot;self-sigs-only\u0026quot; has been explictly configured. --completes-needed n Number of completely trusted users to introduce a new key signer (defaults to 1). --marginals-needed n Number of marginally trusted users to introduce a new key signer (defaults to 3) --tofu-default-policy {auto|good|unknown|bad|ask} The default TOFU policy (defaults to auto). For more information about the meaning of this option, see: [trust-model-tofu]. --max-cert-depth n Maximum depth of a certification chain (default is 5). --no-sig-cache Do not cache the verification status of key signatures. Caching gives a much better performance in key listings. However, if you suspect that your public keyring is not safe against write modifications, you can use this option to disable the caching. It probably does not make sense to disable it because all kind of damage can be done if someone else has write ac‐ cess to your public keyring. --auto-check-trustdb --no-auto-check-trustdb If GnuPG feels that its information about the Web of Trust has to be updated, it automatically runs the --check-trustdb command internally. This may be a time consuming process. --no- auto-check-trustdb disables this option. --use-agent --no-use-agent This is dummy option. gpg always requires the agent. --gpg-agent-info This is dummy option. It has no effect when used with gpg. --agent-program file Specify an agent program to be used for secret key operations. The default value is determined by running gpgconf with the option --list-dirs. Note that the pipe symbol (|) is used for a regression test suite hack and may thus not be used in the file name. --dirmngr-program file Specify a dirmngr program to be used for keyserver access. The default value is ‘/usr/bin/dirmngr’. --disable-dirmngr Entirely disable the use of the Dirmngr. --no-autostart Do not start the gpg-agent or the dirmngr if it has not yet been started and its service is required. This option is mostly useful on machines where the connection to gpg-agent has been redirected to another machines. If dirmngr is required on the remote machine, it may be started manually using gpgconf --launch dirmngr. --lock-once Lock the databases the first time a lock is requested and do not release the lock until the process terminates. --lock-multiple Release the locks every time a lock is no longer needed. Use this to override a previous --lock-once from a config file. --lock-never Disable locking entirely. This option should be used only in very special environments, where it can be assured that only one process is accessing those files. A bootable floppy with a stand-alone encryption system will probably use this. Improper usage of this option may lead to data and key corruption. --exit-on-status-write-error This option will cause write errors on the status FD to immediately terminate the process. That should in fact be the default but it never worked this way and thus we need an option to enable this, so that the change won't break applications which close their end of a status fd connected pipe too early. Using this option along with --enable-progress-filter may be used to cleanly cancel long running gpg operations. --limit-card-insert-tries n With n greater than 0 the number of prompts asking to insert a smartcard gets limited to N-1. Thus with a value of 1 gpg won't at all ask to insert a card if none has been inserted at startup. This option is useful in the configuration file in case an application does not know about the smartcard support and waits ad infinitum for an inserted card. --no-random-seed-file GnuPG uses a file to store its internal random pool over invocations. This makes random generation faster; however sometimes write operations are not desired. This option can be used to achieve that with the cost of slower random generation. --no-greeting Suppress the initial copyright message. --no-secmem-warning Suppress the warning about \u0026quot;using insecure memory\u0026quot;. --no-permission-warning Suppress the warning about unsafe file and home directory (--homedir) permissions. Note that the permission checks that GnuPG performs are not intended to be authoritative, but rather they simply warn about certain common permission problems. Do not assume that the lack of a warning means that your system is secure. Note that the warning for unsafe --homedir permissions cannot be suppressed in the gpg.conf file, as this would allow an attacker to place an unsafe gpg.conf file in place, and use this file to suppress warnings about itself. The --homedir permissions warning may only be suppressed on the command line. --require-secmem --no-require-secmem Refuse to run if GnuPG cannot get secure memory. Defaults to no (i.e. run, but give a warning). --require-cross-certification --no-require-cross-certification When verifying a signature made from a subkey, ensure that the cross certification \u0026quot;back signature\u0026quot; on the subkey is present and valid. This protects against a subtle attack against subkeys that can sign. Defaults to --require-cross-certification for gpg. --expert --no-expert Allow the user to do certain nonsensical or \u0026quot;silly\u0026quot; things like signing an expired or revoked key, or certain potentially incompatible things like generating unusual key types. This also disables certain warning messages about potentially incompatible actions. As the name implies, this option is for experts only. If you don't fully understand the implications of what it allows you to do, leave this off. --no-expert disables this option. Key related options --recipient name -r Encrypt for user id name. If this option or --hidden-recipient is not specified, GnuPG asks for the user-id unless --default-recipient is given. --hidden-recipient name -R Encrypt for user ID name, but hide the key ID of this user's key. This option helps to hide the receiver of the message and is a limited countermeasure against traffic analysis. If this option or --recipient is not specified, GnuPG asks for the user ID unless --default-recipient is given. --recipient-file file -f This option is similar to --recipient except that it encrypts to a key stored in the given file. file must be the name of a file containing exactly one key. gpg assumes that the key in this file is fully valid. --hidden-recipient-file file -F This option is similar to --hidden-recipient except that it encrypts to a key stored in the given file. file must be the name of a file containing exactly one key. gpg assumes that the key in this file is fully valid. --encrypt-to name Same as --recipient but this one is intended for use in the options file and may be used with your own user-id as an \u0026quot;encrypt-to-self\u0026quot;. These keys are only used when there are other re‐ cipients given either by use of --recipient or by the asked user id. No trust checking is performed for these user ids and even disabled keys can be used. --hidden-encrypt-to name Same as --hidden-recipient but this one is intended for use in the options file and may be used with your own user-id as a hidden \u0026quot;encrypt-to-self\u0026quot;. These keys are only used when there are other recipients given either by use of --recipient or by the asked user id. No trust checking is performed for these user ids and even disabled keys can be used. --no-encrypt-to Disable the use of all --encrypt-to and --hidden-encrypt-to keys. --group {name=value} Sets up a named group, which is similar to aliases in email programs. Any time the group name is a recipient (-r or --recipient), it will be expanded to the values specified. Multiple groups with the same name are automatically merged into a single group. The values are key IDs or fingerprints, but any key description is accepted. Note that a value with spaces in it will be treated as two different values. Note also there is only one level of expansion --- you cannot make an group that points to another group. When used from the command line, it may be necessary to quote the argument to this option to prevent the shell from treating it as multiple arguments. --ungroup name Remove a given entry from the --group list. --no-groups Remove all entries from the --group list. --local-user name -u Use name as the key to sign with. Note that this option overrides --default-key. --sender mbox This option has two purposes. mbox must either be a complete user ID containing a proper mail address or just a plain mail address. The option can be given multiple times. When creating a signature this option tells gpg the signing key's user id used to make the signature and embeds that user ID into the created signature (using OpenPGP's ``Signer's User ID'' subpacket). If the option is given multiple times a suitable user ID is picked. However, if the signing key was specified directly by using a mail address (i.e. not by using a fingerprint or key ID) this option is used and the mail address is embedded in the created signature. When verifying a signature mbox is used to restrict the information printed by the TOFU code to matching user IDs. If the option is used and the signature contains a ``Signer's User ID'' subpacket that information is is also used to restrict the printed information. Note that GnuPG considers only the mail address part of a User ID. If this option or the said subpacket is available the TRUST lines as printed by option status-fd correspond to the corresponding User ID; if no User ID is known the TRUST lines are com‐ puted directly on the key and do not give any information about the User ID. In the latter case it his highly recommended to scripts and other frontends to evaluate the VALIDSIG line, retrieve the key and print all User IDs along with their validity (trust) information. --try-secret-key name For hidden recipients GPG needs to know the keys to use for trial decryption. The key set with --default-key is always tried first, but this is often not sufficient. This option al‐ lows setting more keys to be used for trial decryption. Although any valid user-id specification may be used for name it makes sense to use at least the long keyid to avoid ambigui‐ ties. Note that gpg-agent might pop up a pinentry for a lot keys to do the trial decryption. If you want to stop all further trial decryption you may use close-window button instead of the cancel button. --try-all-secrets Don't look at the key ID as stored in the message but try all secret keys in turn to find the right decryption key. This option forces the behaviour as used by anonymous recipients (created by using --throw-keyids or --hidden-recipient) and might come handy in case where an encrypted message contains a bogus key ID. --skip-hidden-recipients --no-skip-hidden-recipients During decryption skip all anonymous recipients. This option helps in the case that people use the hidden recipients feature to hide their own encrypt-to key from others. If one has many secret keys this may lead to a major annoyance because all keys are tried in turn to decrypt something which was not really intended for it. The drawback of this option is that it is currently not possible to decrypt a message which includes real anonymous recipients. Input and Output --armor -a Create ASCII armored output. The default is to create the binary OpenPGP format. --no-armor Assume the input data is not in ASCII armored format. --output file -o file Write output to file. To write to stdout use - as the filename. --max-output n This option sets a limit on the number of bytes that will be generated when processing a file. Since OpenPGP supports various levels of compression, it is possible that the plaintext of a given message may be significantly larger than the original OpenPGP message. While GnuPG works properly with such messages, there is often a desire to set a maximum file size that will be generated before processing is forced to stop by the OS limits. Defaults to 0, which means \u0026quot;no limit\u0026quot;. --chunk-size n The AEAD encryption mode encrypts the data in chunks so that a receiving side can check for transmission errors or tampering at the end of each chunk and does not need to delay this un‐ til all data has been received. The used chunk size is 2^n byte. The lowest allowed value for n is 6 (64 byte) and the largest is the default of 22 which creates chunks not larger than 4 MiB. --input-size-hint n This option can be used to tell GPG the size of the input data in bytes. n must be a positive base-10 number. This option is only useful if the input is not taken from a file. GPG may use this hint to optimize its buffer allocation strategy. It is also used by the --status-fd line ``PROGRESS'' to provide a value for ``total'' if that is not available by other means. --key-origin string[,url] gpg can track the origin of a key. Certain origins are implicitly known (e.g. keyserver, web key directory) and set. For a standard import the origin of the keys imported can be set with this option. To list the possible values use \u0026quot;help\u0026quot; for string. Some origins can store an optional url argument. That URL can appended to string after a comma. --import-options parameters This is a space or comma delimited string that gives options for importing keys. Options can be prepended with a `no-' to give the opposite meaning. The options are: import-local-sigs Allow importing key signatures marked as \u0026quot;local\u0026quot;. This is not generally useful unless a shared keyring scheme is being used. Defaults to no. keep-ownertrust Normally possible still existing ownertrust values of a key are cleared if a key is imported. This is in general desirable so that a formerly deleted key does not automatically gain an ownertrust values merely due to import. On the other hand it is sometimes necessary to re-import a trusted set of keys again but keeping already assigned ownertrust val‐ ues. This can be achieved by using this option. repair-pks-subkey-bug During import, attempt to repair the damage caused by the PKS keyserver bug (pre version 0.9.6) that mangles keys with multiple subkeys. Note that this cannot completely repair the damaged key as some crucial data is removed by the keyserver, but it does at least give you back one subkey. Defaults to no for regular --import and to yes for keyserver --receive-keys. import-show show-only Show a listing of the key as imported right before it is stored. This can be combined with the option --dry-run to only look at keys; the option show-only is a shortcut for this combination. The command --show-keys is another shortcut for this. Note that suffixes like '#' for \u0026quot;sec\u0026quot; and \u0026quot;sbb\u0026quot; lines may or may not be printed. import-export Run the entire import code but instead of storing the key to the local keyring write it to the output. The export option export-dane affect the output. This option can for ex‐ ample be used to remove all invalid parts from a key without the need to store it. merge-only During import, allow key updates to existing keys, but do not allow any new keys to be imported. Defaults to no. import-clean After import, compact (remove all signatures except the self-signature) any user IDs from the new key that are not usable. Then, remove any signatures from the new key that are not usable. This includes signatures that were issued by keys that are not present on the keyring. This option is the same as running the --edit-key command \u0026quot;clean\u0026quot; after im‐ port. Defaults to no. self-sigs-only Accept only self-signatures while importing a key. All other key signatures are skipped at an early import stage. This option can be used with keyserver-options to mitigate at‐ tempts to flood a key with bogus signatures from a keyserver. The drawback is that all other valid key signatures, as required by the Web of Trust are also not imported. Note that when using this option along with import-clean it suppresses the final clean step after merging the imported key into the existing key. repair-keys After import, fix various problems with the keys. For example, this reorders signatures, and strips duplicate signatures. Defaults to yes. bulk-import When used the keyboxd (option use-keyboxd in ‘common.conf’) does the import within a single transaction. import-minimal Import the smallest key possible. This removes all signatures except the most recent self-signature on each user ID. This option is the same as running the --edit-key command \u0026quot;minimize\u0026quot; after import. Defaults to no. restore import-restore Import in key restore mode. This imports all data which is usually skipped during import; including all GnuPG specific data. All other contradicting options are overridden. --import-filter {name=expr} --export-filter {name=expr} These options define an import/export filter which are applied to the imported/exported keyblock right before it will be stored/written. name defines the type of filter to use, expr the expression to evaluate. The option can be used several times which then appends more expression to the same name. The available filter types are: keep-uid This filter will keep a user id packet and its dependent packets in the keyblock if the expression evaluates to true. drop-subkey This filter drops the selected subkeys. Currently only implemented for --export-filter. drop-sig This filter drops the selected key signatures on user ids. Self-signatures are not considered. Currently only implemented for --import-filter. For the syntax of the expression see the chapter \u0026quot;FILTER EXPRESSIONS\u0026quot;. The property names for the expressions depend on the actual filter type and are indicated in the following table. The available properties are: uid A string with the user id. (keep-uid) mbox The addr-spec part of a user id with mailbox or the empty string. (keep-uid) key_algo A number with the public key algorithm of a key or subkey packet. (drop-subkey) key_created key_created_d The first is the timestamp a public key or subkey packet was created. The second is the same but given as an ISO string, e.g. \u0026quot;2016-08-17\u0026quot;. (drop-subkey) fpr The hexified fingerprint of the current subkey or primary key. (drop-subkey) primary Boolean indicating whether the user id is the primary one. (keep-uid) expired Boolean indicating whether a user id (keep-uid), a key (drop-subkey), or a signature (drop-sig) expired. revoked Boolean indicating whether a user id (keep-uid) or a key (drop-subkey) has been revoked. disabled Boolean indicating whether a primary key is disabled. (not used) secret Boolean indicating whether a key or subkey is a secret one. (drop-subkey) usage A string indicating the usage flags for the subkey, from the sequence ``ecsa?''. For example, a subkey capable of just signing and authentication would be an exact match for ``sa''. (drop-subkey) sig_created sig_created_d The first is the timestamp a signature packet was created. The second is the same but given as an ISO date string, e.g. \u0026quot;2016-08-17\u0026quot;. (drop-sig) sig_algo A number with the public key algorithm of a signature packet. (drop-sig) sig_digest_algo A number with the digest algorithm of a signature packet. (drop-sig) --export-options parameters This is a space or comma delimited string that gives options for exporting keys. Options can be prepended with a `no-' to give the opposite meaning. The options are: export-local-sigs Allow exporting key signatures marked as \u0026quot;local\u0026quot;. This is not generally useful unless a shared keyring scheme is being used. Defaults to no. export-attributes Include attribute user IDs (photo IDs) while exporting. Not including attribute user IDs is useful to export keys that are going to be used by an OpenPGP program that does not accept attribute user IDs. Defaults to yes. export-sensitive-revkeys Include designated revoker information that was marked as \u0026quot;sensitive\u0026quot;. Defaults to no. backup export-backup Export for use as a backup. The exported data includes all data which is needed to restore the key or keys later with GnuPG. The format is basically the OpenPGP format but en‐ hanced with GnuPG specific data. All other contradicting options are overridden. export-clean Compact (remove all signatures from) user IDs on the key being exported if the user IDs are not usable. Also, do not export any signatures that are not usable. This includes sig‐ natures that were issued by keys that are not present on the keyring. This option is the same as running the --edit-key command \u0026quot;clean\u0026quot; before export except that the local copy of the key is not modified. Defaults to no. export-minimal Export the smallest key possible. This removes all signatures except the most recent self-signature on each user ID. This option is the same as running the --edit-key command \u0026quot;minimize\u0026quot; before export except that the local copy of the key is not modified. Defaults to no. export-dane Instead of outputting the key material output OpenPGP DANE records suitable to put into DNS zone files. An ORIGIN line is printed before each record to allow diverting the records to the corresponding zone file. --with-colons Print key listings delimited by colons. Note that the output will be encoded in UTF-8 regardless of any --display-charset setting. This format is useful when GnuPG is called from scripts and other programs as it is easily machine parsed. The details of this format are documented in the file ‘doc/DETAILS’, which is included in the GnuPG source distribution. --fixed-list-mode Do not merge primary user ID and primary key in --with-colon listing mode and print all timestamps as seconds since 1970-01-01. Since GnuPG 2.0.10, this mode is always used and thus this option is obsolete; it does not harm to use it though. --legacy-list-mode Revert to the pre-2.1 public key list mode. This only affects the human readable output and not the machine interface (i.e. --with-colons). Note that the legacy format does not convey suitable information for elliptic curves. --with-fingerprint Same as the command --fingerprint but changes only the format of the output and may be used together with another command. --with-subkey-fingerprint If a fingerprint is printed for the primary key, this option forces printing of the fingerprint for all subkeys. This could also be achieved by using the --with-fingerprint twice but by using this option along with keyid-format \u0026quot;none\u0026quot; a compact fingerprint is printed. --with-icao-spelling Print the ICAO spelling of the fingerprint in addition to the hex digits. --with-keygrip Include the keygrip in the key listings. In --with-colons mode this is implicitly enable for secret keys. --with-key-origin Include the locally held information on the origin and last update of a key in a key listing. In --with-colons mode this is always printed. This data is currently experimental and shall not be considered part of the stable API. --with-wkd-hash Print a Web Key Directory identifier along with each user ID in key listings. This is an experimental feature and semantics may change. --with-secret Include info about the presence of a secret key in public key listings done with --with-colons. OpenPGP protocol specific options -t, --textmode --no-textmode Treat input files as text and store them in the OpenPGP canonical text form with standard \u0026quot;CRLF\u0026quot; line endings. This also sets the necessary flags to inform the recipient that the en‐ crypted or signed data is text and may need its line endings converted back to whatever the local system uses. This option is useful when communicating between two platforms that have different line ending conventions (UNIX-like to Mac, Mac to Windows, etc). --no-textmode disables this option, and is the default. --force-v3-sigs --no-force-v3-sigs --force-v4-certs --no-force-v4-certs These options are obsolete and have no effect since GnuPG 2.1. --force-aead Force the use of AEAD encryption over MDC encryption. AEAD is a modern and faster way to do authenticated encryption than the old MDC method. See also options --aead-algo and --chunk- size. --force-mdc --disable-mdc These options are obsolete and have no effect since GnuPG 2.2.8. The MDC is always used unless the keys indicate that an AEAD algorithm can be used in which case AEAD is used. But note: If the creation of a legacy non-MDC message is exceptionally required, the option --rfc2440 allows for this. --disable-signer-uid By default the user ID of the signing key is embedded in the data signature. As of now this is only done if the signing key has been specified with local-user using a mail address, or with sender. This information can be helpful for verifier to locate the key; see option --auto-key-retrieve. --include-key-block --no-include-key-block This option is used to embed the actual signing key into a data signature. The embedded key is stripped down to a single user id and includes only the signing subkey used to create the signature as well as as valid encryption subkeys. All other info is removed from the key to keep it and thus the signature small. This option is the OpenPGP counterpart to the gpgsm option --include-certs and allows the recipient of a signed message to reply encrypted to the sender without using any online directories to lookup the key. The default is --no-in‐ clude-key-block. See also the option --auto-key-import. --personal-cipher-preferences string Set the list of personal cipher preferences to string. Use gpg --version to get a list of available algorithms, and use none to set no preference at all. This allows the user to safely override the algorithm chosen by the recipient key preferences, as GPG will only select an algorithm that is usable by all recipients. The most highly ranked cipher in this list is also used for the --symmetric encryption command. --personal-aead-preferences string Set the list of personal AEAD preferences to string. Use gpg --version to get a list of available algorithms, and use none to set no preference at all. This allows the user to safely override the algorithm chosen by the recipient key preferences, as GPG will only select an algorithm that is usable by all recipients. The most highly ranked cipher in this list is also used for the --symmetric encryption command. --personal-digest-preferences string Set the list of personal digest preferences to string. Use gpg --version to get a list of available algorithms, and use none to set no preference at all. This allows the user to safely override the algorithm chosen by the recipient key preferences, as GPG will only select an algorithm that is usable by all recipients. The most highly ranked digest algorithm in this list is also used when signing without encryption (e.g. --clear-sign or --sign). --personal-compress-preferences string Set the list of personal compression preferences to string. Use gpg --version to get a list of available algorithms, and use none to set no preference at all. This allows the user to safely override the algorithm chosen by the recipient key preferences, as GPG will only select an algorithm that is usable by all recipients. The most highly ranked compression algo‐ rithm in this list is also used when there are no recipient keys to consider (e.g. --symmetric). --s2k-cipher-algo name Use name as the cipher algorithm for symmetric encryption with a passphrase if --personal-cipher-preferences and --cipher-algo are not given. The default is AES-128. --s2k-digest-algo name Use name as the digest algorithm used to mangle the passphrases for symmetric encryption. The default is SHA-1. --s2k-mode n Selects how passphrases for symmetric encryption are mangled. If n is 0 a plain passphrase (which is in general not recommended) will be used, a 1 adds a salt (which should not be used) to the passphrase and a 3 (the default) iterates the whole process a number of times (see --s2k-count). --s2k-count n Specify how many times the passphrases mangling for symmetric encryption is repeated. This value may range between 1024 and 65011712 inclusive. The default is inquired from gpg-agent. Note that not all values in the 1024-65011712 range are legal and if an illegal value is selected, GnuPG will round up to the nearest legal value. This option is only meaningful if --s2k-mode is set to the default of 3. Compliance options These options control what GnuPG is compliant to. Only one of these options may be active at a time. Note that the default setting of this is nearly always the correct one. See the INTEROPER‐ ABILITY WITH OTHER OPENPGP PROGRAMS section below before using one of these options. --gnupg Use standard GnuPG behavior. This is essentially OpenPGP behavior (see --openpgp), but with extension from the proposed update to OpenPGP and with some additional workarounds for common compatibility problems in different versions of PGP. This is the default option, so it is not generally needed, but it may be useful to override a different compliance option in the gpg.conf file. --openpgp Reset all packet, cipher and digest options to strict OpenPGP behavior. This option implies --allow-old-cipher-algos. Use this option to reset all previous options like --s2k-*, --ci‐ pher-algo, --digest-algo and --compress-algo to OpenPGP compliant values. All PGP workarounds are disabled. --rfc4880 Reset all packet, cipher and digest options to strict RFC-4880 behavior. This option implies --allow-old-cipher-algos. Note that this is currently the same thing as --openpgp. --rfc4880bis Reset all packet, cipher and digest options to strict according to the proposed updates of RFC-4880. --rfc2440 Reset all packet, cipher and digest options to strict RFC-2440 behavior. Note that by using this option encryption packets are created in a legacy mode without MDC protection. This is dangerous and should thus only be used for experiments. This option implies --allow-old-cipher-algos. See also option --ignore-mdc-error. --pgp6 This option is obsolete; it is handled as an alias for --pgp7 --pgp7 Set up all options to be as PGP 7 compliant as possible. This allowed the ciphers IDEA, 3DES, CAST5,AES128, AES192, AES256, and TWOFISH., the hashes MD5, SHA1 and RIPEMD160, and the compression algorithms none and ZIP. This option implies --escape-from-lines and disables --throw-keyids, --pgp8 Set up all options to be as PGP 8 compliant as possible. PGP 8 is a lot closer to the OpenPGP standard than previous versions of PGP, so all this does is disable --throw-keyids and set --escape-from-lines. All algorithms are allowed except for the SHA224, SHA384, and SHA512 digests. --compliance string This option can be used instead of one of the options above. Valid values for string are the above option names (without the double dash) and possibly others as shown when using \u0026quot;help\u0026quot; for string. --min-rsa-length n This option adjusts the compliance mode \u0026quot;de-vs\u0026quot; for stricter key size requirements. For example, a value of 3000 turns rsa2048 and dsa2048 keys into non-VS-NfD compliant keys. --require-compliance To check that data has been encrypted according to the rules of the current compliance mode, a gpg user needs to evaluate the status lines. This is allows frontends to handle compli‐ ance check in a more flexible way. However, for scripted use the required evaluation of the status-line requires quite some effort; this option can be used instead to make sure that the gpg process exits with a failure if the compliance rules are not fulfilled. Note that this option has currently an effect only in \u0026quot;de-vs\u0026quot; mode. Doing things one usually doesn't want to do -n --dry-run Don't make any changes (this is not completely implemented). --list-only Changes the behaviour of some commands. This is like --dry-run but different in some cases. The semantic of this option may be extended in the future. Currently it only skips the actual decryption pass and therefore enables a fast listing of the encryption keys. -i --interactive Prompt before overwriting any files. --debug-level level Select the debug level for investigating problems. level may be a numeric value or by a keyword: none No debugging at all. A value of less than 1 may be used instead of the keyword. basic Some basic debug messages. A value between 1 and 2 may be used instead of the keyword. advanced More verbose debug messages. A value between 3 and 5 may be used instead of the keyword. expert Even more detailed messages. A value between 6 and 8 may be used instead of the keyword. guru All of the debug messages you can get. A value greater than 8 may be used instead of the keyword. The creation of hash tracing files is only enabled if the keyword is used. How these messages are mapped to the actual debugging flags is not specified and may change with newer releases of this program. They are however carefully selected to best aid in debugging. --debug flags Set debug flags. All flags are or-ed and flags may be given in C syntax (e.g. 0x0042) or as a comma separated list of flag names. To get a list of all supported flags the single word \u0026quot;help\u0026quot; can be used. This option is only useful for debugging and the behavior may change at any time without notice. --debug-all Set all useful debugging flags. --debug-iolbf Set stdout into line buffered mode. This option is only honored when given on the command line. --debug-set-iobuf-size n Change the buffer size of the IOBUFs to n kilobyte. Using 0 prints the current size. Note well: This is a maintainer only option and may thus be changed or removed at any time without notice. --debug-allow-large-chunks To facilitate software tests and experiments this option allows to specify a limit of up to 4 EiB (--chunk-size 62). --faked-system-time epoch This option is only useful for testing; it sets the system time back or forth to epoch which is the number of seconds elapsed since the year 1970. Alternatively epoch may be given as a full ISO time string (e.g. \u0026quot;20070924T154812\u0026quot;). If you suffix epoch with an exclamation mark (!), the system time will appear to be frozen at the specified time. --full-timestrings Change the format of printed creation and expiration times from just the date to the date and time. This is in general not useful and the same information is anyway available in --with-colons mode. These longer strings are also not well aligned with other printed data. --enable-progress-filter Enable certain PROGRESS status outputs. This option allows frontends to display a progress indicator while gpg is processing larger files. There is a slight performance overhead using it. --status-fd n Write special status strings to the file descriptor n. See the file DETAILS in the documentation for a listing of them. --status-file file Same as --status-fd, except the status data is written to file file. --logger-fd n Write log output to file descriptor n and not to STDERR. --log-file file --logger-file file Same as --logger-fd, except the logger data is written to file file. Use ‘socket://’ to log to s socket. --attribute-fd n Write attribute subpackets to the file descriptor n. This is most useful for use with --status-fd, since the status messages are needed to separate out the various subpackets from the stream delivered to the file descriptor. --attribute-file file Same as --attribute-fd, except the attribute data is written to file file. --comment string --no-comments Use string as a comment string in cleartext signatures and ASCII armored messages or keys (see --armor). The default behavior is not to use a comment string. --comment may be repeated multiple times to get multiple comment strings. --no-comments removes all comments. It is a good idea to keep the length of a single comment below 60 characters to avoid problems with mail programs wrapping such lines. Note that comment lines, like all other header lines, are not protected by the signature. --emit-version --no-emit-version Force inclusion of the version string in ASCII armored output. If given once only the name of the program and the major number is emitted, given twice the minor is also emitted, given thrice the micro is added, and given four times an operating system identification is also emitted. --no-emit-version (default) disables the version line. --sig-notation {name=value} --cert-notation {name=value} -N, --set-notation {name=value} Put the name value pair into the signature as notation data. name must consist only of printable characters or spaces, and must contain a '@' character in the form keyname@domain.exam‐ ple.com (substituting the appropriate keyname and domain name, of course). This is to help prevent pollution of the IETF reserved notation namespace. The --expert flag overrides the '@' check. value may be any printable string; it will be encoded in UTF-8, so you should check that your --display-charset is set correctly. If you prefix name with an exclamation mark (!), the notation data will be flagged as critical (rfc4880:5.2.3.16). --sig-notation sets a notation for data signatures. --cert-notation sets a notation for key signatures (certifica‐ tions). --set-notation sets both. There are special codes that may be used in notation names. \u0026quot;%k\u0026quot; will be expanded into the key ID of the key being signed, \u0026quot;%K\u0026quot; into the long key ID of the key being signed, \u0026quot;%f\u0026quot; into the fingerprint of the key being signed, \u0026quot;%s\u0026quot; into the key ID of the key making the signature, \u0026quot;%S\u0026quot; into the long key ID of the key making the signature, \u0026quot;%g\u0026quot; into the fingerprint of the key making the signature (which might be a subkey), \u0026quot;%p\u0026quot; into the fingerprint of the primary key of the key making the signature, \u0026quot;%c\u0026quot; into the signature count from the OpenPGP smartcard, and \u0026quot;%%\u0026quot; results in a single \u0026quot;%\u0026quot;. %k, %K, and %f are only meaningful when making a key signature (certification), and %c is only meaningful when using the OpenPGP smartcard. --known-notation name Adds name to a list of known critical signature notations. The effect of this is that gpg will not mark a signature with a critical signature notation of that name as bad. Note that gpg already knows by default about a few critical signatures notation names. --sig-policy-url string --cert-policy-url string --set-policy-url string Use string as a Policy URL for signatures (rfc4880:5.2.3.20). If you prefix it with an exclamation mark (!), the policy URL packet will be flagged as critical. --sig-policy-url sets a policy url for data signatures. --cert-policy-url sets a policy url for key signatures (certifications). --set-policy-url sets both. The same %-expandos used for notation data are available here as well. --sig-keyserver-url string Use string as a preferred keyserver URL for data signatures. If you prefix it with an exclamation mark (!), the keyserver URL packet will be flagged as critical. The same %-expandos used for notation data are available here as well. --set-filename string Use string as the filename which is stored inside messages. This overrides the default, which is to use the actual filename of the file being encrypted. Using the empty string for string effectively removes the filename from the output. --for-your-eyes-only --no-for-your-eyes-only Set the `for your eyes only' flag in the message. This causes GnuPG to refuse to save the file unless the --output option is given, and PGP to use a \u0026quot;secure viewer\u0026quot; with a claimed Tem‐ pest-resistant font to display the message. This option overrides --set-filename. --no-for-your-eyes-only disables this option. --use-embedded-filename --no-use-embedded-filename Try to create a file with a name as embedded in the data. This can be a dangerous option as it enables overwriting files. Defaults to no. Note that the option --output overrides this option. --cipher-algo name Use name as cipher algorithm. Running the program with the command --version yields a list of supported algorithms. If this is not used the cipher algorithm is selected from the prefer‐ ences stored with the key. In general, you do not want to use this option as it allows you to violate the OpenPGP standard. The option --personal-cipher-preferences is the safe way to accomplish the same thing. --aead-algo name Specify that the AEAD algorithm name is to be used. This is useful for symmetric encryption where no key preference are available to select the AEAD algorithm. Running gpg with option --version shows the available AEAD algorithms. In general, you do not want to use this option as it allows you to violate the OpenPGP standard. The option --personal-aead-preferences is the safe way to accomplish the same thing. --digest-algo name Use name as the message digest algorithm. Running the program with the command --version yields a list of supported algorithms. In general, you do not want to use this option as it al‐ lows you to violate the OpenPGP standard. The option --personal-digest-preferences is the safe way to accomplish the same thing. --compress-algo name Use compression algorithm name. \u0026quot;zlib\u0026quot; is RFC-1950 ZLIB compression. \u0026quot;zip\u0026quot; is RFC-1951 ZIP compression which is used by PGP. \u0026quot;bzip2\u0026quot; is a more modern compression scheme that can com‐ press some things better than zip or zlib, but at the cost of more memory used during compression and decompression. \u0026quot;uncompressed\u0026quot; or \u0026quot;none\u0026quot; disables compression. If this option is not used, the default behavior is to examine the recipient key preferences to see which algorithms the recipient supports. If all else fails, ZIP is used for maximum compatibility. ZLIB may give better compression results than ZIP, as the compression window size is not limited to 8k. BZIP2 may give even better compression results than that, but will use a signifi‐ cantly larger amount of memory while compressing and decompressing. This may be significant in low memory situations. Note, however, that PGP (all versions) only supports ZIP compres‐ sion. Using any algorithm other than ZIP or \u0026quot;none\u0026quot; will make the message unreadable with PGP. In general, you do not want to use this option as it allows you to violate the OpenPGP standard. The option --personal-compress-preferences is the safe way to accomplish the same thing. --cert-digest-algo name Use name as the message digest algorithm used when signing a key. Running the program with the command --version yields a list of supported algorithms. Be aware that if you choose an algorithm that GnuPG supports but other OpenPGP implementations do not, then some users will not be able to use the key signatures you make, or quite possibly your entire key. Note also that a public key algorithm must be compatible with the specified digest algorithm; thus selecting an arbitrary digest algorithm may result in error messages from lower crypto lay‐ ers or lead to security flaws. --disable-cipher-algo name Never allow the use of name as cipher algorithm. The given name will not be checked so that a later loaded algorithm will still get disabled. --disable-pubkey-algo name Never allow the use of name as public key algorithm. The given name will not be checked so that a later loaded algorithm will still get disabled. --throw-keyids --no-throw-keyids Do not put the recipient key IDs into encrypted messages. This helps to hide the receivers of the message and is a limited countermeasure against traffic analysis. ([Using a little so‐ cial engineering anyone who is able to decrypt the message can check whether one of the other recipients is the one he suspects.]) On the receiving side, it may slow down the decryp‐ tion process because all available secret keys must be tried. --no-throw-keyids disables this option. This option is essentially the same as using --hidden-recipient for all recipi‐ ents. --not-dash-escaped This option changes the behavior of cleartext signatures so that they can be used for patch files. You should not send such an armored file via email because all spaces and line endings are hashed too. You can not use this option for data which has 5 dashes at the beginning of a line, patch files don't have this. A special armor header line tells GnuPG about this cleartext signature option. --escape-from-lines --no-escape-from-lines Because some mailers change lines starting with \u0026quot;From \u0026quot; to \u0026quot;\u0026gt;From \u0026quot; it is good to handle such lines in a special way when creating cleartext signatures to prevent the mail system from breaking the signature. Note that all other PGP versions do it this way too. Enabled by default. --no-escape-from-lines disables this option. --passphrase-repeat n Specify how many times gpg will request a new passphrase be repeated. This is useful for helping memorize a passphrase. Defaults to 1 repetition; can be set to 0 to disable any passphrase repetition. Note that a n greater than 1 will pop up the pinentry window n+1 times even if a modern pinentry with two entry fields is used. --passphrase-fd n Read the passphrase from file descriptor n. Only the first line will be read from file descriptor n. If you use 0 for n, the passphrase will be read from STDIN. This can only be used if only one passphrase is supplied. Note that since Version 2.0 this passphrase is only used if the option --batch has also been given. Since Version 2.1 the --pinentry-mode also needs to be set to loopback. --passphrase-file file Read the passphrase from file file. Only the first line will be read from file file. This can only be used if only one passphrase is supplied. Obviously, a passphrase stored in a file is of questionable security if other users can read this file. Don't use this option if you can avoid it. Note that since Version 2.0 this passphrase is only used if the option --batch has also been given. Since Version 2.1 the --pinentry-mode also needs to be set to loopback. --passphrase string Use string as the passphrase. This can only be used if only one passphrase is supplied. Obviously, this is of very questionable security on a multi-user system. Don't use this option if you can avoid it. Note that since Version 2.0 this passphrase is only used if the option --batch has also been given. Since Version 2.1 the --pinentry-mode also needs to be set to loopback. --pinentry-mode mode Set the pinentry mode to mode. Allowed values for mode are: default Use the default of the agent, which is ask. ask Force the use of the Pinentry. cancel Emulate use of Pinentry's cancel button. error Return a Pinentry error (``No Pinentry''). loopback Redirect Pinentry queries to the caller. Note that in contrast to Pinentry the user is not prompted again if he enters a bad password. --no-symkey-cache Disable the passphrase cache used for symmetrical en- and decryption. This cache is based on the message specific salt value (cf. --s2k-mode). --request-origin origin Tell gpg to assume that the operation ultimately originated at origin. Depending on the origin certain restrictions are applied and the Pinentry may include an extra note on the ori‐ gin. Supported values for origin are: local which is the default, remote to indicate a remote origin or browser for an operation requested by a web browser. --command-fd n This is a replacement for the deprecated shared-memory IPC mode. If this option is enabled, user input on questions is not expected from the TTY but from the given file descriptor. It should be used together with --status-fd. See the file doc/DETAILS in the source distribution for details on how to use it. --command-file file Same as --command-fd, except the commands are read out of file file --allow-non-selfsigned-uid --no-allow-non-selfsigned-uid Allow the import and use of keys with user IDs which are not self-signed. This is not recommended, as a non self-signed user ID is trivial to forge. --no-allow-non-selfsigned-uid dis‐ ables. --allow-freeform-uid Disable all checks on the form of the user ID while generating a new one. This option should only be used in very special environments as it does not ensure the de-facto standard format of user IDs. --ignore-time-conflict GnuPG normally checks that the timestamps associated with keys and signatures have plausible values. However, sometimes a signature seems to be older than the key due to clock problems. This option makes these checks just a warning. See also --ignore-valid-from for timestamp issues on subkeys. --ignore-valid-from GnuPG normally does not select and use subkeys created in the future. This option allows the use of such keys and thus exhibits the pre-1.0.7 behaviour. You should not use this option unless there is some clock problem. See also --ignore-time-conflict for timestamp issues with signatures. --ignore-crc-error The ASCII armor used by OpenPGP is protected by a CRC checksum against transmission errors. Occasionally the CRC gets mangled somewhere on the transmission channel but the actual con‐ tent (which is protected by the OpenPGP protocol anyway) is still okay. This option allows GnuPG to ignore CRC errors. --ignore-mdc-error This option changes a MDC integrity protection failure into a warning. It is required to decrypt old messages which did not use an MDC. It may also be useful if a message is partially garbled, but it is necessary to get as much data as possible out of that garbled message. Be aware that a missing or failed MDC can be an indication of an attack. Use with great cau‐ tion; see also option --rfc2440. --allow-old-cipher-algos Old cipher algorithms like 3DES, IDEA, or CAST5 encrypt data using blocks of 64 bits; modern algorithms use blocks of 128 bit instead. To avoid certain attack on these old algorithms it is suggested not to encrypt more than 150 MiByte using the same key. For this reason gpg does not allow the use of 64 bit block size algorithms for encryption unless this option is specified. --allow-weak-digest-algos Signatures made with known-weak digest algorithms are normally rejected with an ``invalid digest algorithm'' message. This option allows the verification of signatures made with such weak algorithms. MD5 is the only digest algorithm considered weak by default. See also --weak-digest to reject other digest algorithms. --weak-digest name Treat the specified digest algorithm as weak. Signatures made over weak digests algorithms are normally rejected. This option can be supplied multiple times if multiple algorithms should be considered weak. See also --allow-weak-digest-algos to disable rejection of weak digests. MD5 is always considered weak, and does not need to be listed explicitly. --allow-weak-key-signatures To avoid a minor risk of collision attacks on third-party key signatures made using SHA-1, those key signatures are considered invalid. This options allows to override this restric‐ tion. --override-compliance-check The signature verification only allows the use of keys suitable in the current compliance mode. If the compliance mode has been forced by a global option, there might be no way to check certain signature. This option allows to override this and prints an extra warning in such a case. This option is ignored in --batch mode so that no accidental unattended veri‐ fication may happen. --no-default-keyring Do not add the default keyring to the list of keyrings. Note that GnuPG needs for almost all operations a keyring. Thus if you use this option and do not provide alternate keyrings via --keyring, then GnuPG will still use the default keyring. Note that if the option use-keyboxd is enabled in ‘common.conf’, no keyrings are used at all and keys are all maintained by the keyboxd process in its own database. --no-keyring Do not use any keyring at all. This overrides the default and all options which specify keyrings. --skip-verify Skip the signature verification step. This may be used to make the decryption faster if the signature verification is not needed. --with-key-data Print key listings delimited by colons (like --with-colons) and print the public key data. --list-signatures --list-sigs Same as --list-keys, but the signatures are listed too. This command has the same effect as using --list-keys with --with-sig-list. Note that in contrast to --check-signatures the key signatures are not verified. This command can be used to create a list of signing keys missing in the local keyring; for example: gpg --list-sigs --with-colons USERID | \\ awk -F: '$1==\u0026quot;sig\u0026quot; \u0026amp;\u0026amp; $2==\u0026quot;?\u0026quot; {if($13){print $13}else{print $5}}' --fast-list-mode Changes the output of the list commands to work faster; this is achieved by leaving some parts empty. Some applications don't need the user ID and the trust information given in the listings. By using this options they can get a faster listing. The exact behaviour of this option may change in future versions. If you are missing some information, don't use this op‐ tion. --no-literal This is not for normal use. Use the source to see for what it might be useful. --set-filesize This is not for normal use. Use the source to see for what it might be useful. --show-session-key Display the session key used for one message. See --override-session-key for the counterpart of this option. We think that Key Escrow is a Bad Thing; however the user should have the freedom to decide whether to go to prison or to reveal the content of one specific message without compromising all messages ever encrypted for one secret key. You can also use this option if you receive an encrypted message which is abusive or offensive, to prove to the administrators of the messaging system that the ciphertext transmitted corresponds to an inappropriate plaintext so they can take action against the offending user. --override-session-key string --override-session-key-fd fd Don't use the public key but the session key string respective the session key taken from the first line read from file descriptor fd. The format of this string is the same as the one printed by --show-session-key. This option is normally not used but comes handy in case someone forces you to reveal the content of an encrypted message; using this option you can do this without handing out the secret key. Note that using --override-session-key may reveal the session key to all local users via the global process table. Often it is useful to com‐ bine this option with --no-keyring. --ask-sig-expire --no-ask-sig-expire When making a data signature, prompt for an expiration time. If this option is not specified, the expiration time set via --default-sig-expire is used. --no-ask-sig-expire disables this option. --default-sig-expire The default expiration time to use for signature expiration. Valid values are \u0026quot;0\u0026quot; for no expiration, a number followed by the letter d (for days), w (for weeks), m (for months), or y (for years) (for example \u0026quot;2m\u0026quot; for two months, or \u0026quot;5y\u0026quot; for five years), or an absolute date in the form YYYY-MM-DD. Defaults to \u0026quot;0\u0026quot;. --ask-cert-expire --no-ask-cert-expire When making a key signature, prompt for an expiration time. If this option is not specified, the expiration time set via --default-cert-expire is used. --no-ask-cert-expire disables this option. --default-cert-expire The default expiration time to use for key signature expiration. Valid values are \u0026quot;0\u0026quot; for no expiration, a number followed by the letter d (for days), w (for weeks), m (for months), or y (for years) (for example \u0026quot;2m\u0026quot; for two months, or \u0026quot;5y\u0026quot; for five years), or an absolute date in the form YYYY-MM-DD. Defaults to \u0026quot;0\u0026quot;. --default-new-key-algo string This option can be used to change the default algorithms for key generation. The string is similar to the arguments required for the command --quick-add-key but slightly different. For example the current default of \u0026quot;rsa2048/cert,sign+rsa2048/encr\u0026quot; (or \u0026quot;rsa3072\u0026quot;) can be changed to the value of what we currently call future default, which is \u0026quot;ed25519/cert,sign+cv25519/encr\u0026quot;. You need to consult the source code to learn the details. Note that the advanced key generation commands can always be used to specify a key algo‐ rithm directly. --no-auto-trust-new-key When creating a new key the ownertrust of the new key is set to ultimate. This option disables this and the user needs to manually assign an ownertrust value. --force-sign-key This option modifies the behaviour of the commands --quick-sign-key, --quick-lsign-key, and the \u0026quot;sign\u0026quot; sub-commands of --edit-key by forcing the creation of a key signature, even if one already exists. --forbid-gen-key This option is intended for use in the global config file to disallow the use of generate key commands. Those commands will then fail with the error code for Not Enabled. --allow-secret-key-import This is an obsolete option and is not used anywhere. --allow-multiple-messages --no-allow-multiple-messages These are obsolete options; they have no more effect since GnuPG 2.2.8. --enable-special-filenames This option enables a mode in which filenames of the form ‘-\u0026amp;n’, where n is a non-negative decimal number, refer to the file descriptor n and not to a file with that name. --no-expensive-trust-checks Experimental use only. --preserve-permissions Don't change the permissions of a secret keyring back to user read/write only. Use this option only if you really know what you are doing. --default-preference-list string Set the list of default preferences to string. This preference list is used for new keys and becomes the default for \u0026quot;setpref\u0026quot; in the --edit-key menu. --default-keyserver-url name Set the default keyserver URL to name. This keyserver will be used as the keyserver URL when writing a new self-signature on a key, which includes key generation and changing prefer‐ ences. --list-config Display various internal configuration parameters of GnuPG. This option is intended for external programs that call GnuPG to perform tasks, and is thus not generally useful. See the file ‘doc/DETAILS’ in the source distribution for the details of which configuration items may be listed. --list-config is only usable with --with-colons set. --list-gcrypt-config Display various internal configuration parameters of Libgcrypt. --gpgconf-list This command is similar to --list-config but in general only internally used by the gpgconf tool. --gpgconf-test This is more or less dummy action. However it parses the configuration file and returns with failure if the configuration file would prevent gpg from startup. Thus it may be used to run a syntax check on the configuration file. --chuid uid Change the current user to uid which may either be a number or a name. This can be used from the root account to run gpg for another user. If uid is not the current UID a standard PATH is set and the envvar GNUPGHOME is unset. To override the latter the option --homedir can be used. This option has only an effect when used on the command line. This option has currently no effect at all on Windows. Deprecated options --show-photos --no-show-photos Causes --list-keys, --list-signatures, --list-public-keys, --list-secret-keys, and verifying a signature to also display the photo ID attached to the key, if any. See also --photo- viewer. These options are deprecated. Use --list-options [no-]show-photos and/or --verify-options [no-]show-photos instead. --show-keyring Display the keyring name at the head of key listings to show which keyring a given key resides on. This option is deprecated: use --list-options [no-]show-keyring instead. --always-trust Identical to --trust-model always. This option is deprecated. --show-notation --no-show-notation Show signature notations in the --list-signatures or --check-signatures listings as well as when verifying a signature with a notation in it. These options are deprecated. Use --list- options [no-]show-notation and/or --verify-options [no-]show-notation instead. --show-policy-url --no-show-policy-url Show policy URLs in the --list-signatures or --check-signatures listings as well as when verifying a signature with a policy URL in it. These options are deprecated. Use --list-options [no-]show-policy-url and/or --verify-options [no-]show-policy-url instead. EXAMPLES gpg -se -r Bob file sign and encrypt for user Bob gpg --clear-sign file make a cleartext signature gpg -sb file make a detached signature gpg -u 0x12345678 -sb file make a detached signature with the key 0x12345678 gpg --list-keys user_ID show keys gpg --fingerprint user_ID show fingerprint gpg --verify pgpfile gpg --verify sigfile [datafile] Verify the signature of the file but do not output the data unless requested. The second form is used for detached signatures, where sigfile is the detached signature (either ASCII ar‐ mored or binary) and datafile are the signed data; if this is not given, the name of the file holding the signed data is constructed by cutting off the extension (\u0026quot;.asc\u0026quot; or \u0026quot;.sig\u0026quot;) of sigfile or by asking the user for the filename. If the option --output is also used the signed data is written to the file specified by that option; use - to write the signed data to stdout. HOW TO SPECIFY A USER ID There are different ways to specify a user ID to GnuPG. Some of them are only valid for gpg others are only good for gpgsm. Here is the entire list of ways to specify a key: By key Id. This format is deduced from the length of the string and its content or 0x prefix. The key Id of an X.509 certificate are the low 64 bits of its SHA-1 fingerprint. The use of key Ids is just a shortcut, for all automated processing the fingerprint should be used. When using gpg an exclamation mark (!) may be appended to force using the specified primary or secondary key and not to try and calculate which primary or secondary key to use. The last four lines of the example give the key ID in their long form as internally used by the OpenPGP protocol. You can see the long key ID using the option --with-colons. 234567C4 0F34E556E 01347A56A 0xAB123456 234AABBCC34567C4 0F323456784E56EAB 01AB3FED1347A5612 0x234AABBCC34567C4 By fingerprint. This format is deduced from the length of the string and its content or the 0x prefix. Note, that only the 20 byte version fingerprint is available with gpgsm (i.e. the SHA-1 hash of the certificate). When using gpg an exclamation mark (!) may be appended to force using the specified primary or secondary key and not to try and calculate which primary or secondary key to use. The best way to specify a key Id is by using the fingerprint. This avoids any ambiguities in case that there are duplicated key IDs. 1234343434343434C434343434343434 123434343434343C3434343434343734349A3434 0E12343434343434343434EAB3484343434343434 0xE12343434343434343434EAB3484343434343434 gpgsm also accepts colons between each pair of hexadecimal digits because this is the de-facto standard on how to present X.509 fingerprints. gpg also allows the use of the space separated SHA-1 fingerprint as printed by the key listing commands. By exact match on OpenPGP user ID. This is denoted by a leading equal sign. It does not make sense for X.509 certificates. =Heinrich Heine \u0026lt;heinrichh@uni-duesseldorf.de\u0026gt; By exact match on an email address. This is indicated by enclosing the email address in the usual way with left and right angles. \u0026lt;heinrichh@uni-duesseldorf.de\u0026gt; By partial match on an email address. This is indicated by prefixing the search string with an @. This uses a substring search but considers only the mail address (i.e. inside the angle brackets). @heinrichh By exact match on the subject's DN. This is indicated by a leading slash, directly followed by the RFC-2253 encoded DN of the subject. Note that you can't use the string printed by gpgsm --list-keys because that one has been reordered and modified for better readability; use --with-colons to print the raw (but standard escaped) RFC-2253 string. /CN=Heinrich Heine,O=Poets,L=Paris,C=FR By exact match on the issuer's DN. This is indicated by a leading hash mark, directly followed by a slash and then directly followed by the RFC-2253 encoded DN of the issuer. This should return the Root cert of the is‐ suer. See note above. #/CN=Root Cert,O=Poets,L=Paris,C=FR By exact match on serial number and issuer's DN. This is indicated by a hash mark, followed by the hexadecimal representation of the serial number, then followed by a slash and the RFC-2253 encoded DN of the issuer. See note above. #4F03/CN=Root Cert,O=Poets,L=Paris,C=FR By keygrip. This is indicated by an ampersand followed by the 40 hex digits of a keygrip. gpgsm prints the keygrip when using the command --dump-cert. \u0026amp;D75F22C3F86E355877348498CDC92BD21010A480 By substring match. This is the default mode but applications may want to explicitly indicate this by putting the asterisk in front. Match is not case sensitive. Heine *Heine . and + prefixes These prefixes are reserved for looking up mails anchored at the end and for a word search mode. They are not yet implemented and using them is undefined. Please note that we have reused the hash mark identifier which was used in old GnuPG versions to indicate the so called local-id. It is not anymore used and there should be no conflict when used with X.509 stuff. Using the RFC-2253 format of DNs has the drawback that it is not possible to map them back to the original encoding, however we don't have to do this because our key database stores this encoding as meta data. FILTER EXPRESSIONS The options --import-filter and --export-filter use expressions with this syntax (square brackets indicate an optional part and curly braces a repetition, white space between the elements are allowed): [lc] {[{flag}] PROPNAME op VALUE [lc]} The name of a property (PROPNAME) may only consist of letters, digits and underscores. The description for the filter type describes which properties are defined. If an undefined property is used it evaluates to the empty string. Unless otherwise noted, the VALUE must always be given and may not be the empty string. No quoting is defined for the value, thus the value may not contain the strings \u0026amp;\u0026amp; or ||, which are used as logical connection operators. The flag -- can be used to remove this restriction. Numerical values are computed as long int; standard C notation applies. lc is the logical connection operator; either \u0026amp;\u0026amp; for a conjunction or || for a disjunction. A conjunction is assumed at the begin of an expression. Conjunctions have higher precedence than disjunctions. If VALUE starts with one of the characters used in any op a space after the op is required. The supported operators (op) are: =~ Substring must match. !~ Substring must not match. = The full string must match. \u0026lt;\u0026gt; The full string must not match. == The numerical value must match. != The numerical value must not match. \u0026lt;= The numerical value of the field must be LE than the value. \u0026lt; The numerical value of the field must be LT than the value. \u0026gt; The numerical value of the field must be GT than the value. \u0026gt;= The numerical value of the field must be GE than the value. -le The string value of the field must be less or equal than the value. -lt The string value of the field must be less than the value. -gt The string value of the field must be greater than the value. -ge The string value of the field must be greater or equal than the value. -n True if value is not empty (no value allowed). -z True if value is empty (no value allowed). -t Alias for \u0026quot;PROPNAME != 0\u0026quot; (no value allowed). -f Alias for \u0026quot;PROPNAME == 0\u0026quot; (no value allowed). Values for flag must be space separated. The supported flags are: -- VALUE spans to the end of the expression. -c The string match in this part is done case-sensitive. -t Leading and trailing spaces are not removed from VALUE. The optional single space after op is here required. The filter options concatenate several specifications for a filter of the same type. For example the four options in this example: --import-filter keep-uid=\u0026quot;uid =~ Alfa\u0026quot; --import-filter keep-uid=\u0026quot;\u0026amp;\u0026amp; uid !~ Test\u0026quot; --import-filter keep-uid=\u0026quot;|| uid =~ Alpha\u0026quot; --import-filter keep-uid=\u0026quot;uid !~ Test\u0026quot; which is equivalent to --import-filter \\ keep-uid=\u0026quot;uid =~ Alfa\u0026quot; \u0026amp;\u0026amp; uid !~ Test\u0026quot; || uid =~ Alpha\u0026quot; \u0026amp;\u0026amp; \u0026quot;uid !~ Test\u0026quot; imports only the user ids of a key containing the strings \u0026quot;Alfa\u0026quot; or \u0026quot;Alpha\u0026quot; but not the string \u0026quot;test\u0026quot;. TRUST VALUES Trust values are used to indicate ownertrust and validity of keys and user IDs. They are displayed with letters or strings: - unknown No ownertrust assigned / not yet calculated. e expired Trust calculation has failed; probably due to an expired key. q undefined, undef Not enough information for calculation. n never Never trust this key. m marginal Marginally trusted. f full Fully trusted. u ultimate Ultimately trusted. r revoked For validity only: the key or the user ID has been revoked. ? err The program encountered an unknown trust value. FILES There are a few configuration files to control certain aspects of gpg's operation. Unless noted, they are expected in the current home directory (see: [option --homedir]). gpg.conf This is the standard configuration file read by gpg on startup. It may contain any valid long option; the leading two dashes may not be entered and the option may not be abbreviated. This default name may be changed on the command line (see: [gpg-option --options]). You should backup this file. common.conf This is an optional configuration file read by gpg on startup. It may contain options pertaining to all components of GnuPG. Its current main use is for the \u0026quot;use-keyboxd\u0026quot; option. Note that on larger installations, it is useful to put predefined files into the directory ‘/etc/skel/.gnupg’ so that newly created users start up with a working configuration. For existing users a small helper script is provided to create these files (see: [addgnupghome]). For internal purposes gpg creates and maintains a few other files; They all live in the current home directory (see: [option --homedir]). Only the gpg program may modify these files. ~/.gnupg This is the default home directory which is used if neither the environment variable GNUPGHOME nor the option --homedir is given. ~/.gnupg/pubring.gpg The public keyring using a legacy format. You should backup this file. If this file is not available, gpg defaults to the new keybox format and creates a file ‘pubring.kbx’ unless that file already exists in which case that file will also be used for OpenPGP keys. Note that in the case that both files, ‘pubring.gpg’ and ‘pubring.kbx’ exists but the latter has no OpenPGP keys, the legacy file ‘pubring.gpg’ will be used. Take care: GnuPG versions before 2.1 will always use the file ‘pubring.gpg’ because they do not know about the new keybox format. In the case that you have to use GnuPG 1.4 to decrypt archived data you should keep this file. ~/.gnupg/pubring.gpg.lock The lock file for the public keyring. ~/.gnupg/pubring.kbx The public keyring using the new keybox format. This file is shared with gpgsm. You should backup this file. See above for the relation between this file and it predecessor. To convert an existing ‘pubring.gpg’ file to the keybox format, you first backup the ownertrust values, then rename ‘pubring.gpg’ to ‘publickeys.backup’, so it won’t be recognized by any GnuPG version, run import, and finally restore the ownertrust values: $ cd ~/.gnupg $ gpg --export-ownertrust \u0026gt;otrust.lst $ mv pubring.gpg publickeys.backup $ gpg --import-options restore --import publickeys.backups $ gpg --import-ownertrust otrust.lst ~/.gnupg/pubring.kbx.lock The lock file for ‘pubring.kbx’. ~/.gnupg/secring.gpg The legacy secret keyring as used by GnuPG versions before 2.1. It is not used by GnuPG 2.1 and later. You may want to keep it in case you have to use GnuPG 1.4 to decrypt archived data. ~/.gnupg/secring.gpg.lock The lock file for the legacy secret keyring. ~/.gnupg/.gpg-v21-migrated File indicating that a migration to GnuPG 2.1 has been done. ~/.gnupg/trustdb.gpg The trust database. There is no need to backup this file; it is better to backup the ownertrust values (see: [option --export-ownertrust]). ~/.gnupg/trustdb.gpg.lock The lock file for the trust database. ~/.gnupg/random_seed A file used to preserve the state of the internal random pool. ~/.gnupg/openpgp-revocs.d/ This is the directory where gpg stores pre-generated revocation certificates. The file name corresponds to the OpenPGP fingerprint of the respective key. It is suggested to backup those certificates and if the primary private key is not stored on the disk to move them to an external storage device. Anyone who can access these files is able to revoke the corre‐ sponding key. You may want to print them out. You should backup all files in this directory and take care to keep this backup closed away. Operation is further controlled by a few environment variables: HOME Used to locate the default home directory. GNUPGHOME If set directory used instead of \u0026quot;~/.gnupg\u0026quot;. GPG_AGENT_INFO This variable is obsolete; it was used by GnuPG versions before 2.1. PINENTRY_USER_DATA This value is passed via gpg-agent to pinentry. It is useful to convey extra information to a custom pinentry. COLUMNS LINES Used to size some displays to the full size of the screen. LANGUAGE Apart from its use by GNU, it is used in the W32 version to override the language selection done through the Registry. If used and set to a valid and available language name (langid), the file with the translation is loaded from gpgdir/gnupg.nls/langid.mo. Here gpgdir is the directory out of which the gpg binary has been loaded. If it can't be loaded the Registry is tried and as last resort the native Windows locale system is used. GNUPG_BUILD_ROOT This variable is only used by the regression test suite as a helper under operating systems without proper support to figure out the name of a process' text file. When calling the gpg-agent component gpg sends a set of environment variables to gpg-agent. The names of these variables can be listed using the command: gpg-connect-agent 'getinfo std_env_names' /bye | awk '$1==\u0026quot;D\u0026quot; {print $2}' BUGS On older systems this program should be installed as setuid(root). This is necessary to lock memory pages. Locking memory pages prevents the operating system from writing memory pages (which may contain passphrases or other sensitive material) to disk. If you get no warning message about insecure memory your operating system supports locking without being root. The program drops root privileges as soon as locked memory is allocated. Note also that some systems (especially laptops) have the ability to ``suspend to disk'' (also known as ``safe sleep'' or ``hibernate''). This writes all memory to disk before going into a low power or even powered off mode. Unless measures are taken in the operating system to protect the saved memory, passphrases or other sensitive material may be recoverable from it later. Before you report a bug you should first search the mailing list archives for similar problems and second check whether such a bug has already been reported to our bug tracker at https://bugs.gnupg.org. SEE ALSO gpgv(1), gpgsm(1), gpg-agent(1) The full documentation for this tool is maintained as a Texinfo manual. If GnuPG and the info program are properly installed at your site, the command info gnupg should give you access to the complete manual including a menu structure and an index. GnuPG 2.3.7 2022-06-27 GPG(1) ```bash "}),e.add({id:75,href:"/docs/tools/code/radare2/",title:"Radare2",description:`Description # Radare2 is a reverse engineering framework.
Installation # brew install radare2 Usage # r2 /bin/ls Resources # radare2 radare2 Book help # r2 /bin/bash Warning: run r2 with -e bin.cache=true to fix relocations in disassembly -- The only way to learn a new programming language is by writing programs in it. [0x00031d80]\u0026gt; ? [0x00031d80]\u0026gt; ? Usage: [.][times][cmd][~grep][@[@iter]addr!size][|\u0026gt;pipe] ; ... Append '?' to any char command to get detailed help Prefix with number to repeat command N times (f.`,content:"Description # Radare2 is a reverse engineering framework.\nInstallation # brew install radare2 Usage # r2 /bin/ls Resources # radare2 radare2 Book help # r2 /bin/bash Warning: run r2 with -e bin.cache=true to fix relocations in disassembly -- The only way to learn a new programming language is by writing programs in it. [0x00031d80]\u0026gt; ? [0x00031d80]\u0026gt; ? Usage: [.][times][cmd][~grep][@[@iter]addr!size][|\u0026gt;pipe] ; ... Append '?' to any char command to get detailed help Prefix with number to repeat command N times (f.ex: 3x) | %var=value alias for 'env' command | *[?] off[=[0x]value] pointer read/write data/values (see ?v, wx, wv) | (macro arg0 arg1) manage scripting macros | .[?] [-|(m)|f|!sh|cmd] Define macro or load r2, cparse or rlang file | ,[?] [/jhr] create a dummy table import from file and query it to filter/sort | _[?] Print last output | =[?] [cmd] send/listen for remote commands (rap://, raps://, udp://, http://, \u0026lt;fd\u0026gt;) | \u0026lt;[...] push escaped string into the RCons.readChar buffer | /[?] search for bytes, regexps, patterns, .. | ![?] [cmd] run given command as in system(3) | #[?] !lang [..] Hashbang to run an rlang script | a[?] analysis commands | b[?] display or change the block size | c[?] [arg] compare block with given data | C[?] code metadata (comments, format, hints, ..) | d[?] debugger commands | e[?] [a[=b]] list/get/set config evaluable vars | f[?] [name][sz][at] add flag at current address | g[?] [arg] generate shellcodes with r_egg | i[?] [file] get info about opened file from r_bin | k[?] [sdb-query] run sdb-query. see k? for help, 'k *', 'k **' ... | l[?] [filepattern] list files and directories | L[?] [-] [plugin] list, unload load r2 plugins | m[?] mountpoints commands | o[?] [file] ([offset]) open file at optional address | p[?] [len] print current block with format and length | P[?] project management utilities | q[?] [ret] quit program with a return value | r[?] [len] resize file | s[?] [addr] seek to address (also for '0x', '0x1' == 's 0x1') | t[?] types, noreturn, signatures, C parser and more | T[?] [-] [num|msg] Text log utility (used to chat, sync, log, ...) | u[?] uname/undo seek/write | v panels mode | V visual mode (Vv = func/var anal, VV = graph mode, ...) | w[?] [str] multiple write operations | x[?] [len] alias for 'px' (print hexadecimal) | y[?] [len] [[[@]addr Yank/paste bytes from/to memory | z[?] zignatures management | ?[??][expr] Help or evaluate math expression | ?$? show available '$' variables and aliases | ?@? misc help for '@' (seek), '~' (grep) (see ~?\u0026quot;\u0026quot;?) | ?\u0026gt;? output redirection | ?|? help for '|' (pipe) ```bash ```bash RADARE2(1) BSD General Commands Manual RADARE2(1) NAME radare2 — Advanced command-line hexadecimal editor, disassembler and debugger SYNOPSIS radare2 [-a arch] [-b bits] [-B baddr] [-c cmd] [-e k=v] [-i file] [-I prefile] [-k kernel] [-m addr] [-p project] [-P patch] [-r rarun2] [-R rr2rule] [-s addr] [-0AdDwntLquvVxX] -|--|=|file DESCRIPTION radare2 is a command-line hexadecimal editor. \u0026quot;r2\u0026quot; is the alias program name for radare2. This manpage is not updated yet. Feel free to contribute. The options are: -- Open radare2 on an empty file - Equivalent of 'r2 malloc://512' -0 Print \\x00 after initialization and after every command executed -2 Close stderr before starting RCore -a arch force asm.arch (x86, ppc, arm, mips, bf, java, ...) -A run 'aaa' command before prompt or patch to analyze all referenced code. Use -AA to run aaaa -b bits force asm.bits (16, 32, 64) -B baddr Specify the base address to be used when loading a new binary. See 'e?bin.baddr' -c cmd Execute the given command before giving prompt -d Start in debugger mode -D dbg.backend Enable debug mode. Set cfg.debug=true -e k=v Set configuration eval variable key=value. For example -e scr.color=false -f Blocksize = file size -i file Run script file. After the file is loaded -I file Run script file. Before the file is loaded -k kernel Select kernel (asm.os) for syscall resolution -l plugfile Load given plugin file -L List supported IO plugins. -m addr map file at given address -M Disable demangling -n Do not perform any analysis (r_bin). Just load the raw file -nn Only load the rbin structures (elf, mach0, ...) -N Do not load user settings/projects from ~/.radare2rc, ~/.config/radare2/radare2rc and the scripts inside .../radare2rc.d/ directory. -NN Same as -N but also disables the automatic loading of plugins on startup time -q Quiet mode (no prompt) and quit after running the commands specified with -i or -c -qq Quit before showing the prompt. Right after all the -e -c and -i arguments are evaluated. -Q Same as q, but exiting without freeing RCore, this produces leaks at exit time, but saves some precious ms to run the testsuite in fast mode. -p prj Set project file -P file Apply rapatch file and quit (see doc/rapatch.md for more details) -r rarun2 Specify dbg.profile rarun2 profile to use when spawning a program for debugging -R rarun2-directive Specify custom rarun2 directives without having to create a rarun2 profile -s addr Start seeking at this address -S Enable sandboxed mode (same as -e cfg.sandbox=true) -t Get binary information using a thread -T Avoid computing the file hashes -u Set bin.filter=false to load rbin info without filtering names -v Show version information and exit (Use -qv to get just the version number) -V Show radare2 library versions (prints JSON format if -j is used) -w Open in write mode -h Show help message -H Show files and environment help -x Open the file map without executable permissions -X Same as -e bin.usextr=false, do not use extract plugins, useful for dyldcache SHELL Type '?' for help VISUAL To enter visual mode use the 'V' command. Then press '?' for help DEBUGGER In r2 the debugger commands are implemented under the 'd' command. Type 'd?' for help ENVIRONMENT R2_IGNVER load plugins ignoring the specified version. (be careful) R2_DEBUG if defined, show error messages and crash signal R2_DEBUG_ASSERT=1 set a breakpoint when hitting an assert R2_MAGICPATH /Users/pancake/.local/share/radare2/share/radare2/4.5.0-git/magic R2_NOPLUGINS do not load r2 shared plugins R2_RCFILE ~/.radare2rc (user preferences, batch script) R2_RDATAHOME /usr/local FILE path to the current working file. SEE ALSO r2r(1), rahash2(1), rafind2(1), rabin2(1), radiff2(1), rasm2(1), rax2(1), ravc2(1), ragg2(1), rarun2(1), AUTHORS pancake \u0026lt;pancake@nopcode.org\u0026gt; May 20, 2022 ```bash "}),e.add({id:76,href:"/docs/tools/code/rats/",title:"Rats",description:`Description # RATS is a static analysis tool for C/C++ code. It is designed to find security vulnerabilities in C/C++ code.
Installation # brew install rats Usage # rats -w 3 -c -s -h -i -d -e -a -l -o rats.txt *.c Resources # RATS help # RATS(1) General Commands Manual RATS(1) NAME rats - Rough Auditing Tool for Security SYNOPSIS rats [options] [file]... DESCRIPTION rats is a rough auditing tool for security developed by Secure Software, Inc.`,content:"Description # RATS is a static analysis tool for C/C++ code. It is designed to find security vulnerabilities in C/C++ code.\nInstallation # brew install rats Usage # rats -w 3 -c -s -h -i -d -e -a -l -o rats.txt *.c Resources # RATS help # RATS(1) General Commands Manual RATS(1) NAME rats - Rough Auditing Tool for Security SYNOPSIS rats [options] [file]... DESCRIPTION rats is a rough auditing tool for security developed by Secure Software, Inc. It is a tool for scanning C, Perl, PHP, and Python source code and flagging common security related programming errors such as buffer overflows and TOCTOU (Time Of Check, Time Of Use) race conditions. As its name implies, the tool performs only a rough analysis of source code. It will not find every error and will also find things that are not errors. Manual inspection of your code is still necessary, but greatly aided with this tool. When started, RATS will scan each file or each file in the directory specified on the command line and produce a report when scanning is complete. What vulnerabilities are reported in the fi‐ nal report depend on the data contained in the vulnerability database or databases that are used and the warning level in use. For each vulnerability, the list of files and line numbers where it occured is given, followed by a brief description of the vulnerability and suggested action. OPTIONS -h, --help Displays a brief usage summary and exit. -a \u0026lt;fun\u0026gt; Report any occurence of function 'fun' in the source file(s) -d \u0026lt;filename\u0026gt;, --database \u0026lt;filename\u0026gt;, --db \u0026lt;filename\u0026gt; Specifies a vulnerability database to be loaded. You may have multiple -d options and each database specified will be loaded. -i, --input Causes a list of function calls that were used which accept external input to be produced at the end of the vulnerability report. -l \u0026lt;lang\u0026gt;, --language \u0026lt;language\u0026gt; Force the specified language to be used regardless of filename extension. Currently valid language names are \u0026quot;c\u0026quot;, \u0026quot;perl\u0026quot;, \u0026quot;php\u0026quot; and \u0026quot;python\u0026quot;. -r, --references Causes references to vulnerable function calls that are not being used as calls themselves to be reported. -w \u0026lt;level\u0026gt;, --warning \u0026lt;level\u0026gt; Sets the warning level. Valid levels are 1, 2 or 3. 1 includes only default and high severity. 2 includes medium severity (default). 3 includes low severity vulnerabilities. -x Causes the default vulnerability databases (which are in the installation data directory, /usr/share/rats by default) to not be loaded. -R, --no-recurssion Do not recurse subdirectories when encountered. --xml Output in XML --html Output in HTML --follow-symlinks Follow symlinks and treat them like whatever they are pointing to. If the symlink points to a directory it will be descended into unless -R is specified, if a pointing to a file, it will be treated as a file. AUTHOR This manual page was orginally written by Adam Lazur \u0026lt;adam@lazur.org\u0026gt;, for the Debian GNU/Linux system (but may be used by others). Modified by Secure Software, Inc. September 17, 2001 RATS(1) ```bash "}),e.add({id:77,href:"/docs/tools/defend/suricata/",title:"Suricata",description:"Description # Suricata is a network IDS, IPS and NSM engine. It can perform real-time intrusion detection (IDS), inline intrusion prevention (IPS), network security monitoring (NSM) and offline pcap processing.\nInstall # brew install suricata ```bash ## Sample Usage ```bash suricata -c /usr/local/etc/suricata/suricata.yaml -i en0 ```bash ## website [https://suricata.io](https://suricata.io) ",content:"Description # Suricata is a network IDS, IPS and NSM engine. It can perform real-time intrusion detection (IDS), inline intrusion prevention (IPS), network security monitoring (NSM) and offline pcap processing.\nInstall # brew install suricata ```bash ## Sample Usage ```bash suricata -c /usr/local/etc/suricata/suricata.yaml -i en0 ```bash ## website [https://suricata.io](https://suricata.io) "}),e.add({id:78,href:"/docs/tools/code/zzuf/",title:"Zzuf",description:`multi-purpose fuzzer
zzuf is a transparent application input fuzzer. Its purpose is to find bugs in applications by corrupting their user-contributed data (which more than often comes from untrusted sources on the Internet). It works by intercepting file and network operations and changing random bits in the program’s input. zzuf’s behaviour is deterministic, making it easier to reproduce bugs. Its main areas of use are:
quality assurance: use zzuf to test existing software, or integrate it into your own software’s testsuite security: very often, segmentation faults or memory corruption issues mean a potential security hole, zzuf helps exposing some of them code coverage analysis: use zzuf to maximise code coverage zzuf’s primary target is media players, image viewers and web browsers, because the data they process is inherently insecure, but it was also successfully used to find bugs in system utilities such as objdump.`,content:"multi-purpose fuzzer\nzzuf is a transparent application input fuzzer. Its purpose is to find bugs in applications by corrupting their user-contributed data (which more than often comes from untrusted sources on the Internet). It works by intercepting file and network operations and changing random bits in the program’s input. zzuf’s behaviour is deterministic, making it easier to reproduce bugs. Its main areas of use are:\nquality assurance: use zzuf to test existing software, or integrate it into your own software’s testsuite security: very often, segmentation faults or memory corruption issues mean a potential security hole, zzuf helps exposing some of them code coverage analysis: use zzuf to maximise code coverage zzuf’s primary target is media players, image viewers and web browsers, because the data they process is inherently insecure, but it was also successfully used to find bugs in system utilities such as objdump.\nzzuf is not rocket science: the idea of fuzzing input data is barely new, but zzuf’s main purpose is to make things easier and automated. You can see an old, impressive list of FIXME: go there -\u0026gt; bugs found with zzuf \u0026lt;- from webpage.\nInstallation # brew install zzuf Usage # Resources # zzuf Basic fuzzing with zzuf YouTube Basic usage help # zzuf(1) General Commands Manual zzuf(1) NAME zzuf - multiple purpose fuzzer SYNOPSIS zzuf [-AcdimnqSvxX] [-s seed|-s start:stop] [-r ratio|-r min:max] [-f fuzzing] [-D delay] [-j jobs] [-C crashes] [-B bytes] [-t seconds] [-T seconds] [-U seconds] [-M mebibytes] [-b ranges] [-p ports] [-P protect] [-R refuse] [-a list] [-l list] [-I include] [-E exclude] [-O opmode] [PROGRAM [ARGS]...] zzuf -h | --help zzuf -V | --version DESCRIPTION zzuf is a transparent application input fuzzer. It works by intercepting file and network operations and changing random bits in the program's input. zzuf's behaviour is deterministic, making it easy to reproduce bugs. USAGE zzuf will run an application specified on its command line, one or several times, with optional arguments, and will report the application's relevant behaviour on the standard error channel, eg: zzuf cat /dev/zero Flags found after the application name are considered arguments for the application, not for zzuf. For instance, -v below is an argument for cat: zzuf -B 1000 cat -v /dev/zero When no program is specified, zzuf simply fuzzes the standard input, as if the cat utility had been called: zzuf \u0026lt; /dev/zero OPTIONS Generic program information -h, --help Display a short help message and exit. -V, --version Output version information and exit. Operating mode -f, --fuzzing=mode Select how the input is fuzzed. Valid values for mode are: xor randomly set and unset bits set only set bits unset only unset bits The default value for mode is xor. -O, --opmode=mode Use operating mode mode. Valid values for mode are: preload override functions by preloading libzzuf into the executable using the system's dynamic linker copy temporarily copy files that need to be fuzzed The default value for mode is preload. copy is useful on platforms that do not support dynamic linker injection, for instance when fuzzing a Cocoa application on Mac OS X. -s, --seed=seed -s, --seed=start: -s, --seed=start:stop Specify the random seed to use for fuzzing, or a range of random seeds. Running zzuf twice with the same random seed will fuzz the files exactly the same way, even with a different target application. The purpose of this is to use simple utilities such as cat or cp to generate a file that causes the target application to crash. If a range is specified, zzuf will run the application several times, each time with a different seed, and report the behaviour of each run. If no ‘stop’ is specified after ‘:’, zzuf will increment the seed value indefinitely. -r, --ratio=ratio -r, --ratio=min:max Specify the proportion of bits that will be randomly fuzzed. A value of 0 will not fuzz anything. A value of 0.05 will fuzz 5% of the open files' bits. A value of 1.0 or more will fuzz all the bytes, theoretically making the input files undiscernible from random data. The default fuzzing ratio is 0.004 (fuzz 0.4% of the files' bits). A range can also be specified. When doing so, zzuf will pick ratio values from the interval. The choice is deterministic and only depends on the interval bounds and the current seed. -A, --autoinc Increment random seed each time a new file is opened. This is only required if one instance of the application is expected to open the same file several times and you want to test a different seed each time. Output -d, --debug Activate the display of debug messages. Can be specified multiple times for increased verbosity. -q, --quiet Hide the output of the fuzzed application. This is useful if the application is very verbose but only its exit code or signaled status is really useful to you. -v, --verbose Print information during the run, such as the current seed, what processes get run, their exit status, etc. -m, --md5 Instead of displaying the program's standard output, just print its MD5 digest to zzuf's standard output. The standard error channel is left untouched. See also the -X flag. -X, --hex Convert the fuzzed program's standard output to hexadecimal. The standard error channel is left untouched. See also the -m flag. Process control -B, --max-bytes=n Automatically stop after n bytes have been output. This either terminates child processes that output more than n bytes on the standard output and standard error channels, or stop reading from standard input if no program is being fuzzed. This is useful to detect infinite loops. See also the -U and -T flags. -C, --max-crashes=n Stop forking when at least n children have crashed. The default value is 1, meaning zzuf will stop as soon as one child has crashed. A value of 0 tells zzuf to never stop. Note that zzuf will not kill any remaining children once n is reached. To ensure that processes do not last forever, see the -U flag. A process is considered to have crashed if any signal (such as, but not limited to, SIGSEGV) caused it to exit. If the -x flag is used, this will also include processes that exit with a non-zero status. This option is only relevant if the -s flag is used with a range argument. See also the -t flag. -D, --delay=delay Do not launch more than one process every delay seconds. This option should be used together with -j to avoid fork bombs. -j, --jobs=jobs Specify the number of simultaneous children that can be run. By default, zzuf only launches one process at a time. This option is only relevant if the -s flag is used with a range argument. See also the -D flag. -M, --max-memory=mebibytes Specify the maximum amount of memory, in mebibytes (1 MiB = 1,048,576 bytes), that children are allowed to allocate. This is useful to detect infinite loops that eat up a lot of memory. The value should be set reasonably high so as not to interfer with normal program operation. By default, it is set to 1024 MiB in order to avoid accidental excessive swapping. To dis‐ able the limitation, set the maximum memory usage to -1 instead. zzuf uses the setrlimit() call to set memory usage limitations and relies on the operating system's ability to enforce such limitations. -S, --signal Prevent children from installing signal handlers for signals that usually cause coredumps. These signals are SIGABRT, SIGFPE, SIGILL, SIGQUIT, SIGSEGV, SIGTRAP and, if available on the running platform, SIGSYS, SIGEMT, SIGBUS, SIGXCPU and SIGXFSZ. Instead of calling the signal handler, the application will simply crash. If you do not want core dumps, you should set appropriate limits with the limit coredumpsize command. See your shell's documentation on how to set such limits. -t, --max-time=n Stop forking after n seconds. By default, zzuf runs until the end of the seed range is reached. Note that zzuf will not kill any remaining children once n is reached. To ensure that processes do not last forever, see the -U flag. This option is only relevant if the -s flag is used with a range argument. See also the -C flag. -T, --max-cputime=n Automatically terminate child processes that use more than n seconds of CPU time. zzuf uses the setrlimit() call to set CPU usage limitations and relies on the operating system's ability to enforce such limitations. If the system sends SIGXCPU signals and the appli‐ cation catches that signal, it will receive a SIGKILL signal after 5 seconds. This is more accurate than -U because the behaviour should be independent from the system load, but it does not detect processes stuck into infinite select() calls because they use very little CPU time. See also the -B and -U flags. -U, --max-usertime=n Automatically terminate child processes that run for more than n seconds. This is useful to detect infinite loops or processes stuck in other situations. See also the -B and -T flags. -x, --check-exit Report processes that exit with a non-zero status. By default only processes that crash due to a signal are reported. Filtering -a, --allow=list Only fuzz network input for IPs in list, a comma-separated list of IP addresses. If the list starts with !, the flag meaning is reversed and all addresses are fuzzed except the ones in the list. As of now, this flag only understands INET (IPv4) addresses. This option requires network fuzzing to be activated using -n. -b, --bytes=ranges Restrict fuzzing to bytes whose offsets in the file are within ranges. Range values start at zero and are inclusive. Use dashes between range values and commas between ranges. If the right-hand part of a range is ommited, it means end of file. For in‐ stance, to restrict fuzzing to bytes 0, 3, 4, 5 and all bytes after offset 31, use ‘-b0,3-5,31-’. This option is useful to preserve file headers or corrupt only a specific portion of a file. -c, --cmdline Only fuzz files whose name is specified in the target application's command line. This is mostly a shortcut to avoid specifying the argument twice: zzuf -c cat file.txt has the same effect as zzuf -I '^file\\.txt$' cat file.txt See the -I flag for more information on restricting fuzzing to specific files. -E, --exclude=regex Do not fuzz files whose name matches the regex regular expression. This option supersedes anything that is specified by the -I flag. Use this for instance if you are unsure of what files your application is going to read and do not want it to fuzz files in the /etc directory. Multiple -E flags can be specified, in which case files matching any one of the regular expressions will be ignored. -i, --stdin Fuzz the application's standard input. By default zzuf only fuzzes files. -I, --include=regex Only fuzz files whose name matches the regex regular expression. Use this for instance if your application reads configuration files at startup and you only want specific files to be fuzzed. Multiple -I flags can be specified, in which case files matching any one of the regular expressions will be fuzzed. See also the -c flag. -l, --list=list Cherry-pick the list of file descriptors that get fuzzed. The Nth descriptor will really be fuzzed only if N is in list. Values start at 1 and ranges are inclusive. Use dashes between values and commas between ranges. If the right-hand part of a range is ommited, it means all subsequent file descriptors. For instance, to restrict fuzzing to the first opened descriptor and all descriptors starting from the 10th, use ‘-l1,10-’. Note that this option only affects file descriptors that would otherwise be fuzzed. Even if 10 write-only descriptors are opened at the beginning of the program, only the next descrip‐ tor with a read flag will be the first one considered by the -l flag. -P, --protect=list Protect a list of characters so that if they appear in input data that would normally be fuzzed, they are left unmodified instead. Characters in list can be expressed verbatim or through escape sequences. The sequences interpreted by zzuf are: \\n new line \\r return \\t tabulation \\NNN the byte whose octal value is NNN \\xNN the byte whose hexadecimal value is NN \\\\ backslash (‘\\’) You can use ‘-’ to specify ranges. For instance, to protect all bytes from ‘\\001’ to ‘/’, use ‘-P '\\001-/'’. The statistical outcome of this option should not be overlooked: if characters are protected, the effect of the ‘-r’ flag will vary depending on the data being fuzzed. For instance, asking to fuzz 1% of input bits (-r0.01) and to protect lowercase characters (-P a-z) will result in an actual average fuzzing ratio of 0.9% with truly random data, 0.3% with random ASCII data and 0.2% with standard English text. See also the -R flag. -R, --refuse=list Refuse a list of characters by not fuzzing bytes that would otherwise be changed to a character that is in list. This does not prevent characters from appearing in the output if the original byte was already in list. See the -P option for a description of list. Network -n, --network Fuzz the application's network input. By default zzuf only fuzzes files. Only INET (IPv4) and INET6 (IPv6) connections are fuzzed. Other protocol families are not yet supported. -p, --ports=ranges Only fuzz network ports that are in ranges. By default zzuf fuzzes all ports. The port considered is the listening port if the socket is listening and the destination port if the socket is connecting, because most of the time the source port cannot be predicted. Range values start at zero and are inclusive. Use dashes between range values and commas between ranges. If the right-hand part of a range is ommited, it means end of file. For in‐ stance, to restrict fuzzing to the HTTP and HTTPS ports and to all unprivileged ports, use ‘-p80,443,1024-’. This option requires network fuzzing to be activated using -n. DIAGNOSTICS Exit status is zero if no child process crashed. If one or several children crashed, zzuf exits with status 1. EXAMPLES Fuzz the input of the cat program using default settings: zzuf cat /etc/motd Fuzz 1% of the input bits of the cat program using seed 94324: zzuf -s94324 -r0.01 cat /etc/motd Fuzz the input of the cat program but do not fuzz newline characters and prevent non-ASCII characters from appearing in the output: zzuf -P '\\n' -R '\\x00-\\x1f\\x7f-\\xff' cat /etc/motd Fuzz the input of the convert program, using file foo.jpeg as the original input and excluding .xml files from fuzzing (because convert will also open its own XML configuration files and we do not want zzuf to fuzz them): zzuf -E '\\.xml$' convert foo.jpeg -format tga /dev/null Fuzz the input of VLC, using file movie.avi as the original input and restricting fuzzing to filenames that appear on the command line (-c), then generate fuzzy-movie.avi which is a file that can be read by VLC to reproduce the same behaviour without using zzuf: zzuf -c -s87423 -r0.01 vlc movie.avi zzuf -c -s87423 -r0.01 \u0026lt;movie.avi \u0026gt;fuzzy-movie.avi vlc fuzzy-movie.avi Fuzz between 0.1% and 2% of MPlayer's input bits (-r0.001:0.02) with seeds 0 to 9999 (-s0:10000), preserving the AVI 4-byte header by restricting fuzzing to offsets after 4 (-b4-), disabling its standard output messages (-q), launching up to five simultaneous child processes (-j5) but waiting at least half a second between launches (-D0.5), killing MPlayer if it takes more than one minute to read the file (-T60) and disabling its SIGSEGV signal handler (-S): zzuf -c -r0.001:0.02 -s0:10000 -b4- -q -j5 -D0.5 -T60 -S \\ mplayer -benchmark -vo null -fps 1000 movie.avi A more advanced VLC fuzzing example, stopping only at the first crash: zzuf -j4 -vqc -r0.000001:0.01 -s0: vlc -v -I dummy movie.avi \\ --sout '#transcode{acodec=s16l,vcodec=I420}:dummy' vlc:quit Create an HTML-like file that loads 200 times the same hello.jpg image and open it in Firefox™ in auto-increment mode (-A): seq -f '\u0026lt;img src=\u0026quot;hello.jpg#%g\u0026quot;\u0026gt;' 1 200 \u0026gt; hello.html (or: jot -w '\u0026lt;img src=\u0026quot;hello.jpg#%d\u0026quot;\u0026gt;' 200 1 \u0026gt; hello.html) zzuf -A -I 'hello[.]jpg' -r0.001 firefox hello.html Run a simple HTTP redirector on the local host using socat and corrupt each network connection (-n) in a different way (-A) after one megabyte of data was received on it (-b1000000-): zzuf -n -A -b1000000- \\ socat TCP4-LISTEN:8080,reuseaddr,fork TCP4:192.168.1.42:80 Browse the intarweb (-n) using Firefox™ without fuzzing local files (-E.) or non-HTTP connections (-p80,8010,8080), preserving the beginning of the data sent with each HTTP response (-b4000-) and using another seed on each connection (-A): zzuf -r 0.0001 -n -E. -p80,8010,8080 -b4000- -A firefox RESTRICTIONS Due to zzuf using shared object preloading (LD_PRELOAD, _RLD_LIST, DYLD_INSERT_LIBRARIES, etc.) to run its child processes, it will fail in the presence of any mechanism that disables preload‐ ing. For instance setuid root binaries will not be fuzzed when run as an unprivileged user. For the same reasons, zzuf will also not work with statically linked binaries. Bear this in mind when using zzuf on the OpenBSD platform, where cat, cp and dd are static binaries. Though best efforts are made, identical behaviour for different versions of zzuf is not guaranteed. The reproducibility for subsequent calls on different operating systems and with different target programs is only guaranteed when the same version of zzuf is being used. BUGS zzuf probably does not behave correctly with 64-bit offsets. It is not yet possible to insert or drop bytes from the input, to fuzz according to the file format, to swap bytes, etc. More advanced fuzzing methods are planned. As of now, zzuf does not really support multithreaded applications. The behaviour with multithreaded applications where more than one thread does file descriptor operations is undefined. HISTORY zzuf started its life in 2002 as the streamfucker tool, a small multimedia stream corrupter used to find bugs in the VLC media player. SEE ALSO libzzuf(3), zzat(1) AUTHOR Copyright © 2002-2015 Sam Hocevar \u0026lt;sam@hocevar.net\u0026gt;. zzuf and this manual page are free software. They come without any warranty, to the extent permitted by applicable law. You can redistribute them and/or modify them under the terms of the Do What the Fuck You Want to Public License, Version 2, as published by the WTFPL Task Force. See http://www.wtfpl.net/ for more details. zzuf's webpage can be found at http://caca.zoy.org/wiki/zzuf. An overview of the architecture and inner works is at http://caca.zoy.org/wiki/zzuf/internals. zzuf 0.15 2015-01-06 zzuf(1) ```bash "}),e.add({id:79,href:"/docs/tools/code/cppcheck/",title:"Cppcheck",description:`Description # Cppcheck is a static analysis tool for C/C++ code.
Installation # brew install cppcheck Usage # cppcheck hello.cpp Resources # Cppcheck Cppcheck User Guide Cppcheck API help # Cppcheck - A tool for static C/C++ code analysis Syntax: cppcheck [OPTIONS] [files or paths] If a directory is given instead of a filename, *.cpp, *.cxx, *.cc, *.c++, *.c, *.ipp, *.ixx, *.tpp, and *.txx files are checked recursively from the given directory.`,content:"Description # Cppcheck is a static analysis tool for C/C++ code.\nInstallation # brew install cppcheck Usage # cppcheck hello.cpp Resources # Cppcheck Cppcheck User Guide Cppcheck API help # Cppcheck - A tool for static C/C++ code analysis Syntax: cppcheck [OPTIONS] [files or paths] If a directory is given instead of a filename, *.cpp, *.cxx, *.cc, *.c++, *.c, *.ipp, *.ixx, *.tpp, and *.txx files are checked recursively from the given directory. Options: --addon=\u0026lt;addon\u0026gt; Execute addon. i.e. --addon=misra. If options must be provided a json configuration is needed. --addon-python=\u0026lt;python interpreter\u0026gt; You can specify the python interpreter either in the addon json files or through this command line option. If not present, Cppcheck will try \u0026quot;python3\u0026quot; first and then \u0026quot;python\u0026quot;. --cppcheck-build-dir=\u0026lt;dir\u0026gt; Cppcheck work folder. Advantages: * whole program analysis * faster analysis; Cppcheck will reuse the results if the hash for a file is unchanged. * some useful debug information, i.e. commands used to execute clang/clang-tidy/addons. --check-config Check cppcheck configuration. The normal code analysis is disabled by this flag. --check-library Show information messages when library files have incomplete info. --clang=\u0026lt;path\u0026gt; Experimental: Use Clang parser instead of the builtin Cppcheck parser. Takes the executable as optional parameter and defaults to `clang`. Cppcheck will run the given Clang executable, import the Clang AST and convert it into Cppcheck data. After that the normal Cppcheck analysis is used. You must have the executable in PATH if no path is given. --config-exclude=\u0026lt;dir\u0026gt; Path (prefix) to be excluded from configuration checking. Preprocessor configurations defined in headers (but not sources) matching the prefix will not be considered for evaluation. --config-excludes-file=\u0026lt;file\u0026gt; A file that contains a list of config-excludes --dump Dump xml data for each translation unit. The dump files have the extension .dump and contain ast, tokenlist, symboldatabase, valueflow. -D\u0026lt;ID\u0026gt; Define preprocessor symbol. Unless --max-configs or --force is used, Cppcheck will only check the given configuration when -D is used. Example: '-DDEBUG=1 -D__cplusplus'. -E Print preprocessor output on stdout and don't do any further processing. --enable=\u0026lt;id\u0026gt; Enable additional checks. The available ids are: * all Enable all checks. It is recommended to only use --enable=all when the whole program is scanned, because this enables unusedFunction. * warning Enable warning messages * style Enable all coding style checks. All messages with the severities 'style', 'warning', 'performance' and 'portability' are enabled. * performance Enable performance messages * portability Enable portability messages * information Enable information messages * unusedFunction Check for unused functions. It is recommended to only enable this when the whole program is scanned. * missingInclude Warn if there are missing includes. For detailed information, use '--check-config'. Several ids can be given if you separate them with commas. See also --std --error-exitcode=\u0026lt;n\u0026gt; If errors are found, integer [n] is returned instead of the default '0'. '1' is returned if arguments are not valid or if no input files are provided. Note that your operating system can modify this value, e.g. '256' can become '0'. --errorlist Print a list of all the error messages in XML format. --exitcode-suppressions=\u0026lt;file\u0026gt; Used when certain messages should be displayed but should not cause a non-zero exitcode. --file-filter=\u0026lt;str\u0026gt; Analyze only those files matching the given filter str Can be used multiple times Example: --file-filter=*bar.cpp analyzes only files that end with bar.cpp. --file-list=\u0026lt;file\u0026gt; Specify the files to check in a text file. Add one filename per line. When file is '-,' the file list will be read from standard input. -f, --force Force checking of all configurations in files. If used together with '--max-configs=', the last option is the one that is effective. -h, --help Print this help. -I \u0026lt;dir\u0026gt; Give path to search for include files. Give several -I parameters to give several paths. First given path is searched for contained header files first. If paths are relative to source files, this is not needed. --includes-file=\u0026lt;file\u0026gt; Specify directory paths to search for included header files in a text file. Add one include path per line. First given path is searched for contained header files first. If paths are relative to source files, this is not needed. --include=\u0026lt;file\u0026gt; Force inclusion of a file before the checked file. -i \u0026lt;dir or file\u0026gt; Give a source file or source file directory to exclude from the check. This applies only to source files so header files included by source files are not matched. Directory name is matched to all parts of the path. --inconclusive Allow that Cppcheck reports even though the analysis is inconclusive. There are false positives with this option. Each result must be carefully investigated before you know if it is good or bad. --inline-suppr Enable inline suppressions. Use them by placing one or more comments, like: '// cppcheck-suppress warningId' on the lines before the warning to suppress. -j \u0026lt;jobs\u0026gt; Start \u0026lt;jobs\u0026gt; threads to do the checking simultaneously. -l \u0026lt;load\u0026gt; Specifies that no new threads should be started if there are other threads running and the load average is at least \u0026lt;load\u0026gt;. --language=\u0026lt;language\u0026gt;, -x \u0026lt;language\u0026gt; Forces cppcheck to check all files as the given language. Valid values are: c, c++ --library=\u0026lt;cfg\u0026gt; Load file \u0026lt;cfg\u0026gt; that contains information about types and functions. With such information Cppcheck understands your code better and therefore you get better results. The std.cfg file that is distributed with Cppcheck is loaded automatically. For more information about library files, read the manual. --max-configs=\u0026lt;limit\u0026gt; Maximum number of configurations to check in a file before skipping it. Default is '12'. If used together with '--force', the last option is the one that is effective. --max-ctu-depth=N Max depth in whole program analysis. The default value is 2. A larger value will mean more errors can be found but also means the analysis will be slower. --output-file=\u0026lt;file\u0026gt; Write results to file, rather than standard error. --platform=\u0026lt;type\u0026gt;, --platform=\u0026lt;file\u0026gt; Specifies platform specific types and sizes. The available builtin platforms are: * unix32 32 bit unix variant * unix64 64 bit unix variant * win32A 32 bit Windows ASCII character encoding * win32W 32 bit Windows UNICODE character encoding * win64 64 bit Windows * avr8 8 bit AVR microcontrollers * elbrus-e1cp Elbrus e1c+ architecture * pic8 8 bit PIC microcontrollers Baseline and mid-range architectures * pic8-enhanced 8 bit PIC microcontrollers Enhanced mid-range and high end (PIC18) architectures * pic16 16 bit PIC microcontrollers * mips32 32 bit MIPS microcontrollers * native Type sizes of host system are assumed, but no further assumptions. * unspecified Unknown type sizes --plist-output=\u0026lt;path\u0026gt; Generate Clang-plist output files in folder. --project=\u0026lt;file\u0026gt; Run Cppcheck on project. The \u0026lt;file\u0026gt; can be a Visual Studio Solution (*.sln), Visual Studio Project (*.vcxproj), compile database (compile_commands.json), or Borland C++ Builder 6 (*.bpr). The files to analyse, include paths, defines, platform and undefines in the specified file will be used. --project-configuration=\u0026lt;config\u0026gt; If used together with a Visual Studio Solution (*.sln) or Visual Studio Project (*.vcxproj) you can limit the configuration cppcheck should check. For example: '--project-configuration=Release|Win32' -q, --quiet Do not show progress reports. -rp=\u0026lt;paths\u0026gt;, --relative-paths=\u0026lt;paths\u0026gt; Use relative paths in output. When given, \u0026lt;paths\u0026gt; are used as base. You can separate multiple paths by ';'. Otherwise path where source files are searched is used. We use string comparison to create relative paths, so using e.g. ~ for home folder does not work. It is currently only possible to apply the base paths to files that are on a lower level in the directory tree. --report-progress Report progress messages while checking a file. --rule=\u0026lt;rule\u0026gt; Match regular expression. --rule-file=\u0026lt;file\u0026gt; Use given rule file. For more information, see: http://sourceforge.net/projects/cppcheck/files/Articles/ --std=\u0026lt;id\u0026gt; Set standard. The available options are: * c89 C code is C89 compatible * c99 C code is C99 compatible * c11 C code is C11 compatible (default) * c++03 C++ code is C++03 compatible * c++11 C++ code is C++11 compatible * c++14 C++ code is C++14 compatible * c++17 C++ code is C++17 compatible * c++20 C++ code is C++20 compatible (default) --suppress=\u0026lt;spec\u0026gt; Suppress warnings that match \u0026lt;spec\u0026gt;. The format of \u0026lt;spec\u0026gt; is: [error id]:[filename]:[line] The [filename] and [line] are optional. If [error id] is a wildcard '*', all error ids match. --suppressions-list=\u0026lt;file\u0026gt; Suppress warnings listed in the file. Each suppression is in the same format as \u0026lt;spec\u0026gt; above. --suppress-xml=\u0026lt;file\u0026gt; Suppress warnings listed in a xml file. XML file should follow the manual.pdf format specified in section. `6.4 XML suppressions` . --template='\u0026lt;text\u0026gt;' Format the error messages. Available fields: {file} file name {line} line number {column} column number {callstack} show a callstack. Example: [file.c:1] -\u0026gt; [file.c:100] {inconclusive:text} if warning is inconclusive, text is written {severity} severity {message} warning message {id} warning id {cwe} CWE id (Common Weakness Enumeration) {code} show the real code \\t insert tab \\n insert newline \\r insert carriage return Example formats: '{file}:{line},{severity},{id},{message}' or '{file}({line}):({severity}) {message}' or '{callstack} {message}' Pre-defined templates: gcc (default), cppcheck1 (old default), vs, edit. --template-location='\u0026lt;text\u0026gt;' Format error message location. If this is not provided then no extra location info is shown. Available fields: {file} file name {line} line number {column} column number {info} location info {code} show the real code \\t insert tab \\n insert newline \\r insert carriage return Example format (gcc-like): '{file}:{line}:{column}: note: {info}\\n{code}' -U\u0026lt;ID\u0026gt; Undefine preprocessor symbol. Use -U to explicitly hide certain #ifdef \u0026lt;ID\u0026gt; code paths from checking. Example: '-UDEBUG' -v, --verbose Output more detailed error information. --version Print out version number. --xml Write results in xml format to error stream (stderr). Example usage: # Recursively check the current folder. Print the progress on the screen and # write errors to a file: cppcheck . 2\u0026gt; err.txt # Recursively check ../myproject/ and don't print progress: cppcheck --quiet ../myproject/ # Check test.cpp, enable all checks: cppcheck --enable=all --inconclusive --library=posix test.cpp # Check f.cpp and search include files from inc1/ and inc2/: cppcheck -I inc1/ -I inc2/ f.cpp For more information: https://cppcheck.sourceforge.io/manual.pdf Many thanks to the 3rd party libraries we use: * tinyxml2 -- loading project/library/ctu files. * picojson -- loading compile database. * pcre -- rules. * qt -- used in GUI ```bash ```bash CPPCHECK(1) cppcheck User Manual CPPCHECK(1) NAME cppcheck - Tool for static C/C++ code analysis SYNOPSIS cppcheck [--check-config] [--check-library] [-D\u0026lt;id\u0026gt;] [-U\u0026lt;id\u0026gt;] [--enable=\u0026lt;id\u0026gt;] [--error-exitcode=\u0026lt;n\u0026gt;] [--errorlist] [--exitcode-suppressions=\u0026lt;file\u0026gt;] [--file-list=\u0026lt;file\u0026gt;] [--force] [--help] [-I\u0026lt;dir\u0026gt;] [--includes-file=\u0026lt;file\u0026gt;] [--config-exclude=\u0026lt;dir\u0026gt;] [--config-excludes-file=\u0026lt;file\u0026gt;] [--include=\u0026lt;file\u0026gt;] [-i\u0026lt;dir\u0026gt;] [--inconclusive] [--inline-suppr] [-j\u0026lt;jobs\u0026gt;] [-l\u0026lt;load\u0026gt;] [--language=\u0026lt;language\u0026gt;] [--library=\u0026lt;cfg\u0026gt;] [--max-configs=\u0026lt;limit\u0026gt;] [--max-ctu-depth=\u0026lt;limit\u0026gt;] [--platform=\u0026lt;type\u0026gt;] [--quiet] [--relative-paths=\u0026lt;paths\u0026gt;] [--report-progress] [--rule=\u0026lt;rule\u0026gt;] [--rule-file=\u0026lt;file\u0026gt;] [--std=\u0026lt;id\u0026gt;] [--suppress=\u0026lt;spec\u0026gt;] [--suppressions-list=\u0026lt;file\u0026gt;] [--suppress-xml=\u0026lt;.xml file\u0026gt;] [--template='\u0026lt;text\u0026gt;'] [--verbose] [--version] [--xml] [--xml-version=\u0026lt;version\u0026gt;]] [file or path] ... DESCRIPTION Cppcheck is a command-line tool that tries to detect bugs that your C/C++ compiler doesn't see. It is versatile, and can check non-standard code including various compiler extensions, inline assembly code, etc. Its internal preprocessor can handle includes, macros, and several preprocessor commands. While Cppcheck is highly configurable, you can start using it just by giving it a path to the source code. OPTIONS Analyze given C/C++ files for common errors. --check-config Check Cppcheck configuration. The normal code analysis is disabled by this flag. --check-library Show information messages when library files have incomplete info. -D\u0026lt;id\u0026gt; By default Cppcheck checks all configurations. Use -D to limit the checking. When -D is used the checking is limited to the given configuration. Example: -DDEBUG=1 -D__cplusplus -U\u0026lt;id\u0026gt; By default Cppcheck checks all configurations. Use '-U' to explicitly hide certain #ifdef \u0026lt;id\u0026gt; code paths from checking. Example: '-UDEBUG' --enable=\u0026lt;id\u0026gt; Enable additional checks. The available ids are: all Enable all checks. It is recommended to only use --enable=all when the whole program is scanned, because this enables unusedFunction. warning Enable warning messages style Enable all coding style checks. All messages with the severities 'style', 'performance' and 'portability' are enabled. performance Enable performance messages portability Enable portability messages information Enable information messages unusedFunction Check for unused functions. It is recommend to only enable this when the whole program is scanned missingInclude Warn if there are missing includes. For detailed information use --check-config By default none of the additional checks are enabled. Several ids can be given if you separate them with commas, e.g. --enable=style,unusedFunction. See also --std --error-exitcode=\u0026lt;n\u0026gt; If errors are found, integer \u0026lt;n\u0026gt; is returned instead of default 0. EXIT_FAILURE is returned if arguments are not valid or if no input files are provided. Note that your operating system can modify this value, e.g. 256 can become 0. --errorlist Print a list of all possible error messages in XML format. --exitcode-suppressions=\u0026lt;file\u0026gt; Used when certain messages should be displayed but should not cause a non-zero exitcode. --file-list=\u0026lt;file\u0026gt; Specify the files to check in a text file. One filename per line. When file is -, the file list will be read from standard input. -f, --force Force checking of files that have a lot of configurations. Error is printed if such a file is found so there is no reason to use this by default. If used together with --max-configs=, the last option is the one that is effective. -h, --help Print help text. -I \u0026lt;dir\u0026gt; Give path to search for include files. Give several -I parameters to give several paths. First given path is searched for contained header files first. If paths are relative to source files, this is not needed. --includes-file=\u0026lt;file\u0026gt; Specify directory paths to search for included header files in a text file. Add one include path per line. First given path is searched for contained header files first. If paths are relative to source files, this is not needed. --config-exclude=\u0026lt;dir\u0026gt; Path (prefix) to be excluded from configuration checking. Preprocessor configurations defined in headers (but not sources) matching the prefix will not be considered for evaluation of configuration alternatives. --config-exclude-file=\u0026lt;file\u0026gt; A file that contains a list of config-excludes. --include=\u0026lt;file\u0026gt; Force inclusion of a file before the checked file. Can be used for example when checking the Linux kernel, where autoconf.h needs to be included for every file compiled. Works the same way as the GCC -include option. -i \u0026lt;dir\u0026gt; Give path to ignore. Give several -i parameters to ignore several paths. Give directory name or filename with path as parameter. Directory name is matched to all parts of the path. --inconclusive Allow that Cppcheck reports even though the analysis is inconclusive. There are false positives with this option. Each result must be carefully investigated before you know if it is good or bad. --inline-suppr Enable inline suppressions. Use them by placing comments in the form: // cppcheck-suppress memleak before the line to suppress. -j \u0026lt;jobs\u0026gt; Start \u0026lt;jobs\u0026gt; threads to do the checking work. -l \u0026lt;load\u0026gt; Specifies that no new threads should be started if there are other threads running and the load average is at least \u0026lt;load\u0026gt; (ignored on non UNIX-like systems) --language=\u0026lt;language\u0026gt; Forces cppcheck to check all files as the given language. Valid values are: c, c++ --library=\u0026lt;cfg\u0026gt; Use library configuration. --max-configs=\u0026lt;limit\u0026gt; Maximum number of configurations to check in a file before skipping it. Default is 12. If used together with --force, the last option is the one that is effective. --max-ctu-depth=\u0026lt;limit\u0026gt; Maximum depth in whole program analysis. Default is 2. --platform=\u0026lt;type\u0026gt; Specifies platform specific types and sizes.The available platforms are: unix32 32 bit unix variant unix64 64 bit unix variant win32A 32 bit Windows ASCII character encoding win32W 32 bit Windows UNICODE character encoding win64 64 bit Windows By default the platform which was used to compile Cppcheck is used. -q, --quiet Only print something when there is an error. -rp, -rp=\u0026lt;paths\u0026gt;, --relative-paths;, --relative-paths=\u0026lt;paths\u0026gt; Use relative paths in output. When given, \u0026lt;paths\u0026gt; are used as base. You can separate multiple paths by ';'. Otherwise path where source files are searched is used. E.g. if given value is test, when checking test/test.cpp, the path in output will be test.cpp instead of test/test.cpp. The feature uses string comparison to create relative paths, so using e.g. ~ for home folder does not work. It is currently only possible to apply the base paths to files that are on a lower level in the directory tree. --report-progress Report progress when checking a file. --rule=\u0026lt;rule\u0026gt; Match regular expression to create your own checks. E.g. rule \u0026quot;/ 0\u0026quot; can be used to check division by zero. This command is only available if cppcheck was compiled with HAVE_RULES=yes. --rule-file=\u0026lt;file\u0026gt; Use given rule XML file. See https://sourceforge.net/projects/cppcheck/files/Articles/ for more info about the syntax. This command is only available if cppcheck was compiled with HAVE_RULES=yes. --std=\u0026lt;id\u0026gt; Set standard. The available options are: c89 C code is C89 compatible c99 C code is C99 compatible c11 C code is C11 compatible (default) c++03 C++ code is C++03 compatible c++11 C++ code is C++11 compatible (default) --suppress=\u0026lt;spec\u0026gt; Suppress a specific warning. The format of \u0026lt;spec\u0026gt; is: [error id]:[filename]:[line]. The [filename] and [line] are optional. [error id] may be * to suppress all warnings (for a specified file or files). [filename] may contain the wildcard characters * or ?. --suppressions-list=\u0026lt;file\u0026gt; Suppress warnings listed in the file. Each suppression is in the format of \u0026lt;spec\u0026gt; above. --suppress-xml=\u0026lt;.xml file\u0026gt; Use suppressions defined in xml as described in the manual --template='\u0026lt;text\u0026gt;' Format the error messages. E.g. '{file}:{line},{severity},{id},{message}' or '{file}({line}):({severity}) {message}'. Pre-defined templates: gcc, vs -v, --verbose More detailed error reports --version Print out version information --xml Write results in XML to error stream --xml-version=\u0026lt;version\u0026gt; Select the XML file version. Also implies --xml. Currently only version 2 is available. The default version is 2. AUTHOR The program was written by Daniel Marjamäki and Cppcheck team. See AUTHORS file for list of team members. SEE ALSO Full list of features: https://sourceforge.net/p/cppcheck/wiki/Home/ AUTHOR Reijo Tomperi \u0026lt;aggro80@users.sourceforge.net\u0026gt; Wrote this manpage for the Debian system. COPYRIGHT Copyright © 2009 - 2016 Reijo Tomperi This manual page was written for the Debian system (but may be used by others). Permission is granted to copy, distribute and/or modify this document under the terms of the GNU General Public License, Version 3 or (at your option) any later version published by the Free Software Foundation. On Debian systems, the complete text of the GNU General Public License can be found in /usr/share/common-licenses/GPL-3. cppcheck 08/28/2022 CPPCHECK(1) ```bash "}),e.add({id:80,href:"/docs/tools/code/fmt/",title:"Fmt",description:`Description # fmt is a small, safe and fast formatting library providing a fast and safe alternative to C printf and C++ iostreams.
Installation # brew install fmt Usage # std::string s = fmt::format(\u0026quot;The answer is {}.\u0026quot;, 42); Resources # fmt fmt User Guide fmt API Similar # stdio iostreams printf `,content:`Description # fmt is a small, safe and fast formatting library providing a fast and safe alternative to C printf and C++ iostreams.
Installation # brew install fmt Usage # std::string s = fmt::format(\u0026quot;The answer is {}.\u0026quot;, 42); Resources # fmt fmt User Guide fmt API Similar # stdio iostreams printf `}),e.add({id:81,href:"/docs/tools/code/gitleaks/",title:"Gitleaks",description:`Description # Gitleaks is a SAST tool for detecting hardcoded secrets like passwords, api keys, and tokens in git repos.
Installation # brew install gitleaks Usage # gitleaks --repo-path /path/to/repo Resources # Gitleaks Gitleaks GitHub help # Gitleaks scans code, past or present, for secrets Usage: gitleaks [command] Available Commands: completion Generate the autocompletion script for the specified shell detect detect secrets in code help Help about any command protect protect secrets in code version display gitleaks version Flags: -b, --baseline-path string path to baseline with issues that can be ignored -c, --config string config file path order of precedence: 1.`,content:"Description # Gitleaks is a SAST tool for detecting hardcoded secrets like passwords, api keys, and tokens in git repos.\nInstallation # brew install gitleaks Usage # gitleaks --repo-path /path/to/repo Resources # Gitleaks Gitleaks GitHub help # Gitleaks scans code, past or present, for secrets Usage: gitleaks [command] Available Commands: completion Generate the autocompletion script for the specified shell detect detect secrets in code help Help about any command protect protect secrets in code version display gitleaks version Flags: -b, --baseline-path string path to baseline with issues that can be ignored -c, --config string config file path order of precedence: 1. --config/-c 2. env var GITLEAKS_CONFIG 3. (--source/-s)/.gitleaks.toml If none of the three options are used, then gitleaks will use the default config --exit-code int exit code when leaks have been encountered (default 1) -h, --help help for gitleaks -l, --log-level string log level (trace, debug, info, warn, error, fatal) (default \u0026quot;info\u0026quot;) --max-target-megabytes int files larger than this will be skipped --no-banner suppress banner --redact redact secrets from logs and stdout -f, --report-format string output format (json, csv, sarif) (default \u0026quot;json\u0026quot;) -r, --report-path string report file -s, --source string path to source (default: $PWD) (default \u0026quot;.\u0026quot;) -v, --verbose show verbose output from scan Use \u0026quot;gitleaks [command] --help\u0026quot; for more information about a command. ```bash "}),e.add({id:82,href:"/docs/tools/code/grpc/",title:"Grpc",description:`Description # gRPC is a modern, open source, high-performance remote procedure call (RPC) framework that can run anywhere.
Installation # brew install grpc Usage # Resources # gRPC gRPC Quick Start gRPC Basics - Go gRPC Basics - Python gRPC Basics - C++ gRPC Basics - Java gRPC Basics - C# gRPC Basics - Node.js gRPC Basics - Ruby gRPC Basics - Objective-C gRPC Basics - PHP gRPC Basics - Dart help # `,content:`Description # gRPC is a modern, open source, high-performance remote procedure call (RPC) framework that can run anywhere.
Installation # brew install grpc Usage # Resources # gRPC gRPC Quick Start gRPC Basics - Go gRPC Basics - Python gRPC Basics - C++ gRPC Basics - Java gRPC Basics - C# gRPC Basics - Node.js gRPC Basics - Ruby gRPC Basics - Objective-C gRPC Basics - PHP gRPC Basics - Dart help # `}),e.add({id:83,href:"/docs/tools/code/hyperscan/",title:"Hyperscan",description:`Description # Hyperscan is a high-performance multiple regex matching library.
Installation # brew install hyperscan Usage # Resources # Hyperscan Hyperscan User Guide Developer Reference Guide help # `,content:`Description # Hyperscan is a high-performance multiple regex matching library.
Installation # brew install hyperscan Usage # Resources # Hyperscan Hyperscan User Guide Developer Reference Guide help # `}),e.add({id:84,href:"/docs/tools/code/jansson/",title:"Jansson",description:`Description # Jansson is a C library for encoding, decoding and manipulating JSON data.
Installation # brew install jansson Usage # Resources # Jansson Jansson User Guide Turorial `,content:`Description # Jansson is a C library for encoding, decoding and manipulating JSON data.
Installation # brew install jansson Usage # Resources # Jansson Jansson User Guide Turorial `}),e.add({id:85,href:"/docs/tools/code/adns/",title:"Adns",description:`Description # adns is a DNS resolver library and command-line tool.
Installation # brew install adns Usage # Resources # adns adns User Guide adns API help # `,content:`Description # adns is a DNS resolver library and command-line tool.
Installation # brew install adns Usage # Resources # adns adns User Guide adns API help # `}),e.add({id:86,href:"/docs/tools/code/bvi/",title:"Bvi",description:`Description # bvi is a binary file editor.
Installation # brew install bvi Usage # bvi /path/to/file Resources # bvi bvi User Guide bvi API Similar # vim vi ed ex nano pico joe micro help # BVI(1) User Commands BVI(1) NAME bvi, bview - visual editor for binary files VERSION bvi-1.4.1 SYNOPSIS bvi [-R] [-c cmd] [-f script] [-s skip] [-e end] [-n length] file... bview [-R] [-c cmd] [-f script] [-s skip] [-e end] [-n length] file.`,content:"Description # bvi is a binary file editor.\nInstallation # brew install bvi Usage # bvi /path/to/file Resources # bvi bvi User Guide bvi API Similar # vim vi ed ex nano pico joe micro help # BVI(1) User Commands BVI(1) NAME bvi, bview - visual editor for binary files VERSION bvi-1.4.1 SYNOPSIS bvi [-R] [-c cmd] [-f script] [-s skip] [-e end] [-n length] file... bview [-R] [-c cmd] [-f script] [-s skip] [-e end] [-n length] file... OPTIONS file... A list of filenames. The first one will be the current file and will be read into the buffer. The cursor will be positioned on the first line of the buffer. You can get to the other files with the \u0026quot;:next\u0026quot; command. -R \u0026quot;Readonly\u0026quot;: The readonly flag is set for all the files, preventing accidental overwriting with a write command. -s skip causes bvi to load a file not from the start but from offset skip. Skip offset bytes from the beginning of the input. By default, offset is interpreted as a decimal number. With a leading 0x or 0X, offset is interpreted as a hexadecimal number, otherwise, with a leading 0, offset is interpreted as an octal number. Appending the character b, k, or m to offset causes it to be interpreted as a multiple of 512, 1024, or 1048576, respectively. -e end causes bvi to load a file not till end but till address end. -n length causes bvi not to load the complete file but only length bytes. -c cmd cmd will be executed after the first file has been read. If the cmd contains spaces it must be enclosed in double quotes (this depends on the shell that is used). -f script This command provides a means for collecting a series of \u0026quot;ex\u0026quot; (colon) commands into a script file, then using this file to edit other files. Since there is no binary stream editor \u0026quot;bsed\u0026quot;, you can use this option to make several global changes in a binary file. DESCRIPTION Bvi stands for \u0026quot;Binary VIsual editor\u0026quot;. Bvi is a screen oriented editor for binary files; its command set is based on that of the vi(1) text editor. As bvi is a binary editor, it does not have the concept of \u0026quot;lines\u0026quot;. All end-of-lines (EOLs) are simply bytes. Therefore bvi's commands are different from vi's commands for all line-oriented commands (see below). COMPARISON The main differences between Vi and Bvi are: The screen is divided in three sections or panes: The byte offset (extreme left), the hex pane (middle), and an ascii pane (right) which shows as printable characters those bytes in the hex pane. On an 80 column terminal there will be sixteen hex values and their ASCII values on each screen line. Note that (as one would expect) the first byte has the offset '0' (zero). You can toggle between the hex and ascii windows with the tab key (TAB). Toggling between these two windows does not change the current position (offset) within the file. No \u0026quot;lines\u0026quot; concept: Files are treated as one long stream of bytes. The characters \u0026quot;newline\u0026quot; and \u0026quot;carriage return\u0026quot; are not special, id est they never mark the end of lines. Therefore the lines on the screen do not represent lines in the usual way. Data is broken across screen lines arbitarily. As a consequence there are no commands in bvi from ex or vi that are based on line numbers, eg \u0026quot;dd\u0026quot;, \u0026quot;yy\u0026quot;, 'C', 'S', 'o', 'O'. This also changes the meaning of \u0026quot;range\u0026quot; before the \u0026quot;:write\u0026quot; command to a byte offset, ie the command \u0026quot;:100,200w foo\u0026quot; writes all *bytes* (not lines) from offset 100 to offset 200 to the file \u0026quot;foo\u0026quot;. No \u0026quot;text objects\u0026quot;: There are also no text-specific arrangements like words, paragraphs, sentences, sections and so on. Extended \u0026quot;ruler\u0026quot;: The bottom line of the screen shows the current address (byte offset) and the current character in these notations: octal, hexadecimal, decimal and ascii. Search patterns: All search commands understand these special characters: . any character [] set of characters * zero or more occurrences of previous char or set But as there is no concept of lines you cannot use the standard symbols (\u0026quot;anchors\u0026quot;) for \u0026quot;begin-of-line\u0026quot; ('^') and \u0026quot;end-of-line\u0026quot; ('$'). Searching for the start/end of lines must be done explicitly by adding these special characters to your search pattern using these meta sequences: \\n newline \\r return \\t tab \\0 binary zero Additional search commands: Similar to the text search commands there are additional hex-search functions '\\' and '#' which allow to search for any byte value. Example: \u0026quot;\\62 76 69\u0026quot; will search for the string \u0026quot;bvi\u0026quot;. Spaces between hex value are optional, so searching for \u0026quot;6775636B6573\u0026quot; will find \u0026quot;guckes\u0026quot;. Changing the length of data (insertion, deletion) moves the data to other addresses; this is bad for many cases (eg. databases, program files) and is thus disabled by default. You can enable this commands by typing :set memmove BVI Modes: Command Mode (Normal Mode): Input is treated as command. Note that command mode is the default mode after startup and after escaping from input mode. Use ESC (escape) to cancel a partial (uncompleted) command. Input Mode: Input is treated as replacement of current characters or (after the end of the file) is appended to the current file. This mode is entered from command mode by typing one of 'i', 'I', 'A', 'r', or 'R'. You can enter the characters from the keyboard (in the ASCII window) or hexadecimal values (in the HEX window). Type TAB to switch between these two windows. Type ESC to finish the current input and return to command mode. Type CTRL-C to cancel current command abnormally. Command line mode (Last Line Mode or : mode): Similar to vi, this mode is entered by typing one of the characters : / ? \\ # ! The command is terminated and executed by typing a carriage return; to cancel a partially typed command, type ESC to cancel the current command and return to command mode. ENVIRONMENT The editor recognizes the environment variable BVIINIT as a command (or list of commands) to run when it starts up. If this variable is undefined, the editor checks for startup commands in the file ~/.bvirc file, which you must own. However, if there is a .bvirc owned by you in the current directory, the editor takes its startup commands from this file - overriding both the file in your home directory and the environment variable. TERMINOLOGY Characters names are abbreviated as follows: Abbr. ASCII name aka CR 010 carriage return ^A 001 control-a ^H 008 control-h ^I 009 control-i aka TAB ^U 021 control-u ^Z 026 control-z ESC 027 escape aka ESC DEL 127 delete LEFT --- left arrow RIGHT --- right arrow DOWN --- down arrow UP --- up arrow COMMAND SUMMARY See the TERMINOLOGY for a summary on key name abbreviations used within the following description of commands. Abstract: Arrow keys move the cursor on the screen within the current window. Sample commands: :version show version info \u0026lt;- v ^ -\u0026gt; arrow keys move the cursor h j k l same as arrow keys u undo previous change ZZ exit bvi, saving changes :q! quit, discarding changes /text search for text ^U ^D scroll up or down Counts before bvi commands: Numbers may be typed as a prefix to some commands. They are interpreted in one of these ways. screen column ⎪ byte of file G scroll amount ^D ^U repeat effect most of the rest Interrupting, canceling ESC end insert or incomplete command DEL (delete or rubout) interrupts File manipulation: ZZ if file modified, write and exit; otherwise, exit :w write changed buffer to file :w! write changed buffer to file, overriding read-only (\u0026quot;forced\u0026quot; write) :q quit when no changes have been made :q! quit and discard all changes :e file edit file :e! re-read current file, discard all changes :e # edit the alternate file :e! # edit the alternate file, discard changes :w file write current buffer to file :w! file write current buffer to file overriding read-only (this \u0026quot;overwrites\u0026quot; the file) :sh run the command as set with option \u0026quot;shell\u0026quot;, then return :!cmd run the command cmd from \u0026quot;shell\u0026quot;, then return :n edit next file in the argument list :f show current filename, modified flag, current byte offset, and percentage of current position within buffer ^G same as :f Additional edit commands You can insert/append/change bytes in ASCII/binary/decimal/ hexadecimal or octal representation. You can enter several (screen) lines of input. A line with only a period (.) in it will terminate the command. You must not type in values greater than a byte value. This causes an abandonment of the command. Pressing the CR key does not insert a newline - character into the file. If you use ASCII mode you can use the special characters \\n, \\r, \\t and \\0. :i aCR insert bytes (ASCII) at cursor position :a bCR append bytes (Binary) at end of file :c hCR change bytes (hexadecimal) at cursor position Bit-level operations :and n bitwise 'and' operation with value n :or n bitwise 'or' operation with value n :xor n bitwise 'xor' operation with value n :neg two's complement :not logical negation :sl i shift each byte i bits to the left :sr i shift each byte i bits to the right :rl i rotate each byte i bits to the left :rr i rotate each byte i bits to the right Command mode addresses :w foo write current buffer to a file named \u0026quot;foo\u0026quot; :5,10w foo copy byte 5 through 100 into as file named foo :.,.+20w foo copy the current byte and the next 20 bytes to foo :^,'aw foo write all bytes from the beginning through marker 'a' :/pat/,$ foo search pattern pat and and copy through end of file Positioning within file: ^B backward screen ^F forward screen ^D scroll down half screen ^U scroll up half screen nG go to the specified character (end default), where n is a decimal address /pat next line matching pat ?pat previous line matching pat \\hex jump to next occurrence of hex string hex #hex jump to previous occurrence of hex string hex n repeat last search command N repeat last search command, but in opposite direction Adjusting the screen: ^L clear and redraw screen zCR redraw screen with current line at top of screen z- redraw screen with current line at bottom of screen z. redraw screen with current line at center of screen /pat/z- search for pattern pat and then move currents line to bottom ^E scroll screen down 1 line ^Y scroll screen up 1 line Marking and returning: mx mark current position with lower-case letter x Note: this command works for all lower-case letters 'x move cursor to mark x in ASCII section `x move cursor to mark x in HEX section '' move cursor to previous context in ASCII section `` move cursor to previous context in HEX section Line positioning: H jump to first line on screen (\u0026quot;top\u0026quot;) L jump to last line on screen (\u0026quot;low\u0026quot;) M jump to middle line on screen (\u0026quot;middle\u0026quot;) - jump onto previous line on screen + jump onto next line on screen CR same as + DOWN or j next line, same column UP or k previous line, same column Character positioning: ^ first byte in HEX window $ end of screen line l or RIGHT jump onto next byte (within current screen line) h or LEFT jump onto previous byte (within current screen line) ^H same as LEFT space same as RIGHT fx find next occurrence of character x Fx find previous occurrence of character x n⎪ jump onto nth byte/character within current line Strings: (works similar to the strings(1) command) Note: \u0026quot;Words\u0026quot; are defined as strings of \u0026quot;nonprinting characters\u0026quot;. e jump to next end of word w jump to next begin of word b jump to previous begin of word W forward to next string delimited with a \\0 or \\n B back to previous string delimited with a nonprinting char Corrections during insert: ^H erase last character (backspace) erase your erase character, same as ^H (backspace) ESC ends insertion, back to command mode Append and replace: A append at end of file rx replace current bte with char 'x' R enter replace mode; for all subsequent input, the current byte is overwritten with the next input character; leave replace mode with ESC. Miscellaneous Operations: TAB toggle between ASCII and HEX section Yank and Put: 3ySPACE yank 3 characters p insert contents of yank buffer o replace text with content of yank buffer P put back at end of file Undo, Redo: u undo last change Note: Only the last change can be undone. Therefore this commands toggles between the last and second-t-last state of the buffer. Setting Options: With the :set command you can set options in bvi Option Default Description autowrite noaw Save current file, if modified, if you give a :n, :r or ! command columns cm=16 on an 80 character wide terminal ignorecase noic Ignores letter case in searching magic nomagic Makes . [ * special in patterns memmove nomm enables insert and delete commands offset of=0 adds an offset to the diplayed addresses readonly noro If set, write fails unless you use ! after command reverse nore display otherwise-printable characters with their high bit set as reverse video scroll sc=1/2 window Number of lines scrolled by ^U and ^D showmode mo Displays statusline on bottom of the screen terse noterse Let you obtain shorter error messages window window=screensize Lines in window, can be reduced at slow terminals wordlength wl=4 Length of an ASCII-string found by w, W, b or B wrapscan ws Searches wrap around past the end of the file unixstyle nous The representation of ascii characters below 32 is displayed in the statusline as shown in ascii(7) if unset rather in DOS-style (^A) AUTHOR bvi was developed by Gerhard Buergmann, Vienna, Austria gerhard@puon.at WWW Bvi Homepage: http://bvi.sourceforge.net/ Vi Pages: http://www.guckes.net/vi/clones.php3 (all about Vi and its clones) FILES $HOME/.bvirc editor startup file ./.bvirc editor startup file BUGS Bvi does not update the screen when the terminal changes its size. SEE ALSO bmore(1), vi(1), strings(1), ascii(5) 3rd Berkeley Distribution BVI Version 1.4.1 BVI(1) ```bash "}),e.add({id:87,href:"/docs/tools/code/capstone/",title:"Capstone",description:`Description # Capstone is a lightweight multi-platform, multi-architecture disassembly framework.
Installation # brew install capstone Usage # extern crate capstone; use capstone::prelude::*; const X86_CODE: \u0026amp;'static [u8] = b\u0026quot;\\x55\\x48\\x8b\\x05\\xb8\\x13\\x00\\x00\\xe9\\x14\\x9e\\x08\\x00\\x45\\x31\\xe4\u0026quot;; /// Print register names fn reg_names(cs: \u0026amp;Capstone, regs: \u0026amp;[RegId]) -\u0026gt; String { let names: Vec\u0026lt;String\u0026gt; = regs.iter().map(|\u0026amp;x| cs.reg_name(x).unwrap()).collect(); names.join(\u0026quot;, \u0026quot;) } /// Print instruction group names fn group_names(cs: \u0026amp;Capstone, regs: \u0026amp;[InsnGroupId]) -\u0026gt; String { let names: Vec\u0026lt;String\u0026gt; = regs.iter().map(|\u0026amp;x| cs.group_name(x).unwrap()).collect(); names.join(\u0026quot;, \u0026quot;) } fn main() { let cs = Capstone::new() .`,content:`Description # Capstone is a lightweight multi-platform, multi-architecture disassembly framework.
Installation # brew install capstone Usage # extern crate capstone; use capstone::prelude::*; const X86_CODE: \u0026amp;'static [u8] = b\u0026quot;\\x55\\x48\\x8b\\x05\\xb8\\x13\\x00\\x00\\xe9\\x14\\x9e\\x08\\x00\\x45\\x31\\xe4\u0026quot;; /// Print register names fn reg_names(cs: \u0026amp;Capstone, regs: \u0026amp;[RegId]) -\u0026gt; String { let names: Vec\u0026lt;String\u0026gt; = regs.iter().map(|\u0026amp;x| cs.reg_name(x).unwrap()).collect(); names.join(\u0026quot;, \u0026quot;) } /// Print instruction group names fn group_names(cs: \u0026amp;Capstone, regs: \u0026amp;[InsnGroupId]) -\u0026gt; String { let names: Vec\u0026lt;String\u0026gt; = regs.iter().map(|\u0026amp;x| cs.group_name(x).unwrap()).collect(); names.join(\u0026quot;, \u0026quot;) } fn main() { let cs = Capstone::new() .x86() .mode(arch::x86::ArchMode::Mode64) .syntax(arch::x86::ArchSyntax::Att) .detail(true) .build() .expect(\u0026quot;Failed to create Capstone object\u0026quot;); let insns = cs.disasm_all(X86_CODE, 0x1000) .expect(\u0026quot;Failed to disassemble\u0026quot;); println!(\u0026quot;Found {} instructions\u0026quot;, insns.len()); for i in insns.as_ref() { println!(); println!(\u0026quot;{}\u0026quot;, i); let detail: InsnDetail = cs.insn_detail(\u0026amp;i).expect(\u0026quot;Failed to get insn detail\u0026quot;); let arch_detail: ArchDetail = detail.arch_detail(); let ops = arch_detail.operands(); let output: \u0026amp;[(\u0026amp;str, String)] = \u0026amp;[ (\u0026quot;insn id:\u0026quot;, format!(\u0026quot;{:?}\u0026quot;, i.id().0)), (\u0026quot;bytes:\u0026quot;, format!(\u0026quot;{:?}\u0026quot;, i.bytes())), (\u0026quot;read regs:\u0026quot;, reg_names(\u0026amp;cs, detail.regs_read())), (\u0026quot;write regs:\u0026quot;, reg_names(\u0026amp;cs, detail.regs_write())), (\u0026quot;insn groups:\u0026quot;, group_names(\u0026amp;cs, detail.groups())), ]; for \u0026amp;(ref name, ref message) in output.iter() { println!(\u0026quot;{:4}{:12} {}\u0026quot;, \u0026quot;\u0026quot;, name, message); } println!(\u0026quot;{:4}operands: {}\u0026quot;, \u0026quot;\u0026quot;, ops.len()); for op in ops { println!(\u0026quot;{:8}{:?}\u0026quot;, \u0026quot;\u0026quot;, op); } } } Output # Found 4 instructions 0x1000: pushq %rbp read regs: rsp write regs: rsp insn groups: mode64 0x1001: movq 0x13b8(%rip), %rax read regs: write regs: insn groups: 0x1008: jmp 0x8ae21 read regs: write regs: insn groups: jump 0x100d: xorl %r12d, %r12d read regs: write regs: rflags insn groups: Resources # Capstone Capstone User Guide Capstone API Rust bindings GitHub crates.io `}),e.add({id:88,href:"/docs/tools/code/cflow/",title:"Cflow",description:`Description # cflow is a program that prints a graph of the control flow of a C program.
Installation # brew install cflow Usage # cflow [options] [file ...] Resources # cflow cflow User Guide cflow API help # CFLOW(1) General Commands Manual CFLOW(1) NAME cflow - generate a C-language flowgraph SYNOPSIS cflow [-ASTrxablnv] [-d NUMBER] [-f NAME] [-i CLASSES] [-o FILE] [-D NAME[=DEFN]] [-I DIR] [-m NAME] [-p NUMBER] [-s SYMBOL:[=]TYPE] [-U NAME] [--all] [--depth=NUMBER] [--format=NAME] [--include=CLASSES] [--output=FILE] [--reverse] [--xref] [--ansi] [--define=NAME[=DEFN]] [--include-dir=DIR] [--main=NAME] [--no-main] [--pushdown=NUMBER] [--preprocess[=COMMAND]] [--cpp[=COMMAND]] [--symbol=SYMBOL:[=]TYPE] [--use-indentation] [--undefine=NAME] [--brief] [--emacs] [--print-level] [--level-indent=ELEMENT] [--number] [--omit-arguments] [--omit-symbol-names] [--tree] [--debug[=NUMBER]] [--verbose] FILE.`,content:"Description # cflow is a program that prints a graph of the control flow of a C program.\nInstallation # brew install cflow Usage # cflow [options] [file ...] Resources # cflow cflow User Guide cflow API help # CFLOW(1) General Commands Manual CFLOW(1) NAME cflow - generate a C-language flowgraph SYNOPSIS cflow [-ASTrxablnv] [-d NUMBER] [-f NAME] [-i CLASSES] [-o FILE] [-D NAME[=DEFN]] [-I DIR] [-m NAME] [-p NUMBER] [-s SYMBOL:[=]TYPE] [-U NAME] [--all] [--depth=NUMBER] [--format=NAME] [--include=CLASSES] [--output=FILE] [--reverse] [--xref] [--ansi] [--define=NAME[=DEFN]] [--include-dir=DIR] [--main=NAME] [--no-main] [--pushdown=NUMBER] [--preprocess[=COMMAND]] [--cpp[=COMMAND]] [--symbol=SYMBOL:[=]TYPE] [--use-indentation] [--undefine=NAME] [--brief] [--emacs] [--print-level] [--level-indent=ELEMENT] [--number] [--omit-arguments] [--omit-symbol-names] [--tree] [--debug[=NUMBER]] [--verbose] FILE... cflow [-?V] [--help] [--usage] [--version] NOTE This manpage is a short description of GNU cflow. For a detailed discussion, including examples and usage recommendations, refer to the GNU Cflow Manual available in texinfo format. If the info reader and the cflow documentation are properly installed on your system, the command info cflow should give you access to the complete manual. You can also view the manual using the info mode in emacs(1), or find it in various formats online at http://www.gnu.org/software/cflow/manual If any discrepancies occur between this manpage and the GNU Cflow Manual, the later shall be considered the authoritative source. DESCRIPTION Cflow analyzes a collection of input files written in C programming language and writes to standard output a graph charting dependencies between various functions. OPTIONS General-purpose options -d, --depth=NUMBER Set the depth at which the flowgraph is cut off. By default the depth is not limited. --debug[=NUMBER] Set debugging level. -f, --format=NAME Use given output format NAME. Valid names are gnu (the default) and posix. -i, --include=CLASSES Include specified classes of symbols. The ^or- symbol excludes the classes that follow it. Valid classes are: _(underscore) Symbols whose names begin with an underscore. s Static symbols t Typedefs (for cross-references only). x All data symbols, both external and static -o, --output=FILE Set output file name (default is -, meaning stdout). -r, --reverse Print reverse call tree. --no-reverse Disable the effect of the previous --reverse option. -x, --xref Produce cross-reference listing only. -v, --verbose Enable verbose error diagnostics. Parser control -a, --ansi Accept only sources in ANSI C. --no-ansi Don't assume input files are written in ANSI C. -D, --define=NAME[=DEFN] Predefine NAME as a macro. -I, --include-dir=DIR Add the directory DIR to the list of directories to be searched for header files. -m, --main=NAME Assume main function is NAME --no-main Assume there's no main function in the program. This option has the same effect as --all, except that, if the program do define the main function, it will be treated as any other func‐ tions, i.e. it will not be placed at the top of output, but in its place as per the lexicographic ordering of function names. See also the description of --all. -p, --pushdown=NUMBER Set initial token stack size to NUMBER. --preprocess[=COMMAND], --cpp[=COMMAND] Run the specified preprocessor command. --no-preprocess, --no-cpp Disable preprocessing. -s, --symbol=SYMBOL:[=]TYPE Register SYMBOL with given TYPE, or define an alias (if := is used). Valid types are: keyword(orkw), modifier, qualifier, identifier, type, and wrapper. Any unambiguous abbreviation of the above is also accepted. -S, --use-indentation Rely on indentation to solve suspicious constructs. --no-use-indentation Don't use indentation in parsing (default). -U, --undefine=NAME Cancel any previous definition of NAME. Output control -A, --all Produce graphs for all global functions in the program. Use this option if your program contains functions which are not directly reachable from main(). The output consist of separate flow graphs for each top-level function defined in the program. These graphs will be placed after the graph for main() (if it exists), and will be or‐ dered lexicographically by the function name. If used twice, graphs for all global functions (whether top-level or not) will be displayed. -b, --brief Brief output. --no-brief Disable brief output. --emacs Format output for use with GNU Emacs. --no-emacs Disable the effect of the previous --emacs option. -l, --print-level Print nesting level along with the call tree. --no-print-level Don't print nesting level. --level-indent=ELEMENT Control graph appearance. -n, --number Print line numbers. --no-number Don't print line numbers. --omit-arguments Do not print argument lists in function declarations. --no-omit-arguments Print argument lists in function declarations (the default). --omit-symbol-names Do not print symbol names in declaration strings. --no-omit-symbol-names Print symbol names in declaration strings (the default). -T, --tree Draw ASCII art tree. --no-tree Disable tree output. Informational options These options instruct the program to output the requested piece of information and exit. -?, --help Print a short help summary. --usage Print a summary of available options. -V, --version Print program version. RETURN VALUE 0 Successful completion. 1 Fatal error occurred. 2 Some input files cannot be read or parsed. 3 Command line usage error. SEE ALSO Online copies of GNU cflow documentation in various formats can be found at: http://www.gnu.org/software/cflow/manual AUTHORS Sergey Poznyakoff BUG REPORTS Report bugs to \u0026lt;bug-cflow@gnu.org\u0026gt;. COPYRIGHT Copyright © 2014-2021 Sergey Poznyakoff License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. CFLOW February 10, 2019 CFLOW(1) ```bash "}),e.add({id:89,href:"/docs/tools/attack/sqlmap/",title:"Sqlmap",description:`Description # sqlmap is an open source penetration testing tool that automates the process of detecting and exploiting SQL injection flaws and taking over of database servers.
Installation # brew install sqlmap Usage # sqlmap -u \u0026quot;http://example.com/vuln.php?id=1\u0026quot; --dbs Resources # User Guide sqlmap cheatsheet sqlmap cheatsheet help # ___ __H__ ___ ___[\u0026quot;]_____ ___ ___ {1.7.2.3#dev} |_ -| . [,] | .'| . | |___|_ [\u0026quot;]_|_|_|__,| _| |_|V... |_| https://sqlmap.org Usage: python3 sqlmap.`,content:"Description # sqlmap is an open source penetration testing tool that automates the process of detecting and exploiting SQL injection flaws and taking over of database servers.\nInstallation # brew install sqlmap Usage # sqlmap -u \u0026quot;http://example.com/vuln.php?id=1\u0026quot; --dbs Resources # User Guide sqlmap cheatsheet sqlmap cheatsheet help # ___ __H__ ___ ___[\u0026quot;]_____ ___ ___ {1.7.2.3#dev} |_ -| . [,] | .'| . | |___|_ [\u0026quot;]_|_|_|__,| _| |_|V... |_| https://sqlmap.org Usage: python3 sqlmap.py [options] Options: -h, --help Show basic help message and exit -hh Show advanced help message and exit --version Show program's version number and exit -v VERBOSE Verbosity level: 0-6 (default 1) Target: At least one of these options has to be provided to define the target(s) -u URL, --url=URL Target URL (e.g. \u0026quot;http://www.site.com/vuln.php?id=1\u0026quot;) -d DIRECT Connection string for direct database connection -l LOGFILE Parse target(s) from Burp or WebScarab proxy log file -m BULKFILE Scan multiple targets given in a textual file -r REQUESTFILE Load HTTP request from a file -g GOOGLEDORK Process Google dork results as target URLs -c CONFIGFILE Load options from a configuration INI file Request: These options can be used to specify how to connect to the target URL -A AGENT, --user.. HTTP User-Agent header value -H HEADER, --hea.. Extra header (e.g. \u0026quot;X-Forwarded-For: 127.0.0.1\u0026quot;) --method=METHOD Force usage of given HTTP method (e.g. PUT) --data=DATA Data string to be sent through POST (e.g. \u0026quot;id=1\u0026quot;) --param-del=PARA.. Character used for splitting parameter values (e.g. \u0026amp;) --cookie=COOKIE HTTP Cookie header value (e.g. \u0026quot;PHPSESSID=a8d127e..\u0026quot;) --cookie-del=COO.. Character used for splitting cookie values (e.g. ;) --live-cookies=L.. Live cookies file used for loading up-to-date values --load-cookies=L.. File containing cookies in Netscape/wget format --drop-set-cookie Ignore Set-Cookie header from response --mobile Imitate smartphone through HTTP User-Agent header --random-agent Use randomly selected HTTP User-Agent header value --host=HOST HTTP Host header value --referer=REFERER HTTP Referer header value --headers=HEADERS Extra headers (e.g. \u0026quot;Accept-Language: fr\\nETag: 123\u0026quot;) --auth-type=AUTH.. HTTP authentication type (Basic, Digest, Bearer, ...) --auth-cred=AUTH.. HTTP authentication credentials (name:password) --auth-file=AUTH.. HTTP authentication PEM cert/private key file --abort-code=ABO.. Abort on (problematic) HTTP error code(s) (e.g. 401) --ignore-code=IG.. Ignore (problematic) HTTP error code(s) (e.g. 401) --ignore-proxy Ignore system default proxy settings --ignore-redirects Ignore redirection attempts --ignore-timeouts Ignore connection timeouts --proxy=PROXY Use a proxy to connect to the target URL --proxy-cred=PRO.. Proxy authentication credentials (name:password) --proxy-file=PRO.. Load proxy list from a file --proxy-freq=PRO.. Requests between change of proxy from a given list --tor Use Tor anonymity network --tor-port=TORPORT Set Tor proxy port other than default --tor-type=TORTYPE Set Tor proxy type (HTTP, SOCKS4 or SOCKS5 (default)) --check-tor Check to see if Tor is used properly --delay=DELAY Delay in seconds between each HTTP request --timeout=TIMEOUT Seconds to wait before timeout connection (default 30) --retries=RETRIES Retries when the connection timeouts (default 3) --retry-on=RETRYON Retry request on regexp matching content (e.g. \u0026quot;drop\u0026quot;) --randomize=RPARAM Randomly change value for given parameter(s) --safe-url=SAFEURL URL address to visit frequently during testing --safe-post=SAFE.. POST data to send to a safe URL --safe-req=SAFER.. Load safe HTTP request from a file --safe-freq=SAFE.. Regular requests between visits to a safe URL --skip-urlencode Skip URL encoding of payload data --csrf-token=CSR.. Parameter used to hold anti-CSRF token --csrf-url=CSRFURL URL address to visit for extraction of anti-CSRF token --csrf-method=CS.. HTTP method to use during anti-CSRF token page visit --csrf-data=CSRF.. POST data to send during anti-CSRF token page visit --csrf-retries=C.. Retries for anti-CSRF token retrieval (default 0) --force-ssl Force usage of SSL/HTTPS --chunked Use HTTP chunked transfer encoded (POST) requests --hpp Use HTTP parameter pollution method --eval=EVALCODE Evaluate provided Python code before the request (e.g. \u0026quot;import hashlib;id2=hashlib.md5(id).hexdigest()\u0026quot;) Optimization: These options can be used to optimize the performance of sqlmap -o Turn on all optimization switches --predict-output Predict common queries output --keep-alive Use persistent HTTP(s) connections --null-connection Retrieve page length without actual HTTP response body --threads=THREADS Max number of concurrent HTTP(s) requests (default 1) Injection: These options can be used to specify which parameters to test for, provide custom injection payloads and optional tampering scripts -p TESTPARAMETER Testable parameter(s) --skip=SKIP Skip testing for given parameter(s) --skip-static Skip testing parameters that not appear to be dynamic --param-exclude=.. Regexp to exclude parameters from testing (e.g. \u0026quot;ses\u0026quot;) --param-filter=P.. Select testable parameter(s) by place (e.g. \u0026quot;POST\u0026quot;) --dbms=DBMS Force back-end DBMS to provided value --dbms-cred=DBMS.. DBMS authentication credentials (user:password) --os=OS Force back-end DBMS operating system to provided value --invalid-bignum Use big numbers for invalidating values --invalid-logical Use logical operations for invalidating values --invalid-string Use random strings for invalidating values --no-cast Turn off payload casting mechanism --no-escape Turn off string escaping mechanism --prefix=PREFIX Injection payload prefix string --suffix=SUFFIX Injection payload suffix string --tamper=TAMPER Use given script(s) for tampering injection data Detection: These options can be used to customize the detection phase --level=LEVEL Level of tests to perform (1-5, default 1) --risk=RISK Risk of tests to perform (1-3, default 1) --string=STRING String to match when query is evaluated to True --not-string=NOT.. String to match when query is evaluated to False --regexp=REGEXP Regexp to match when query is evaluated to True --code=CODE HTTP code to match when query is evaluated to True --smart Perform thorough tests only if positive heuristic(s) --text-only Compare pages based only on the textual content --titles Compare pages based only on their titles Techniques: These options can be used to tweak testing of specific SQL injection techniques --technique=TECH.. SQL injection techniques to use (default \u0026quot;BEUSTQ\u0026quot;) --time-sec=TIMESEC Seconds to delay the DBMS response (default 5) --union-cols=UCOLS Range of columns to test for UNION query SQL injection --union-char=UCHAR Character to use for bruteforcing number of columns --union-from=UFROM Table to use in FROM part of UNION query SQL injection --dns-domain=DNS.. Domain name used for DNS exfiltration attack --second-url=SEC.. Resulting page URL searched for second-order response --second-req=SEC.. Load second-order HTTP request from file Fingerprint: -f, --fingerprint Perform an extensive DBMS version fingerprint Enumeration: These options can be used to enumerate the back-end database management system information, structure and data contained in the tables -a, --all Retrieve everything -b, --banner Retrieve DBMS banner --current-user Retrieve DBMS current user --current-db Retrieve DBMS current database --hostname Retrieve DBMS server hostname --is-dba Detect if the DBMS current user is DBA --users Enumerate DBMS users --passwords Enumerate DBMS users password hashes --privileges Enumerate DBMS users privileges --roles Enumerate DBMS users roles --dbs Enumerate DBMS databases --tables Enumerate DBMS database tables --columns Enumerate DBMS database table columns --schema Enumerate DBMS schema --count Retrieve number of entries for table(s) --dump Dump DBMS database table entries --dump-all Dump all DBMS databases tables entries --search Search column(s), table(s) and/or database name(s) --comments Check for DBMS comments during enumeration --statements Retrieve SQL statements being run on DBMS -D DB DBMS database to enumerate -T TBL DBMS database table(s) to enumerate -C COL DBMS database table column(s) to enumerate -X EXCLUDE DBMS database identifier(s) to not enumerate -U USER DBMS user to enumerate --exclude-sysdbs Exclude DBMS system databases when enumerating tables --pivot-column=P.. Pivot column name --where=DUMPWHERE Use WHERE condition while table dumping --start=LIMITSTART First dump table entry to retrieve --stop=LIMITSTOP Last dump table entry to retrieve --first=FIRSTCHAR First query output word character to retrieve --last=LASTCHAR Last query output word character to retrieve --sql-query=SQLQ.. SQL statement to be executed --sql-shell Prompt for an interactive SQL shell --sql-file=SQLFILE Execute SQL statements from given file(s) Brute force: These options can be used to run brute force checks --common-tables Check existence of common tables --common-columns Check existence of common columns --common-files Check existence of common files User-defined function injection: These options can be used to create custom user-defined functions --udf-inject Inject custom user-defined functions --shared-lib=SHLIB Local path of the shared library File system access: These options can be used to access the back-end database management system underlying file system --file-read=FILE.. Read a file from the back-end DBMS file system --file-write=FIL.. Write a local file on the back-end DBMS file system --file-dest=FILE.. Back-end DBMS absolute filepath to write to Operating system access: These options can be used to access the back-end database management system underlying operating system --os-cmd=OSCMD Execute an operating system command --os-shell Prompt for an interactive operating system shell --os-pwn Prompt for an OOB shell, Meterpreter or VNC --os-smbrelay One click prompt for an OOB shell, Meterpreter or VNC --os-bof Stored procedure buffer overflow exploitation --priv-esc Database process user privilege escalation --msf-path=MSFPATH Local path where Metasploit Framework is installed --tmp-path=TMPPATH Remote absolute path of temporary files directory Windows registry access: These options can be used to access the back-end database management system Windows registry --reg-read Read a Windows registry key value --reg-add Write a Windows registry key value data --reg-del Delete a Windows registry key value --reg-key=REGKEY Windows registry key --reg-value=REGVAL Windows registry key value --reg-data=REGDATA Windows registry key value data --reg-type=REGTYPE Windows registry key value type General: These options can be used to set some general working parameters -s SESSIONFILE Load session from a stored (.sqlite) file -t TRAFFICFILE Log all HTTP traffic into a textual file --abort-on-empty Abort data retrieval on empty results --answers=ANSWERS Set predefined answers (e.g. \u0026quot;quit=N,follow=N\u0026quot;) --base64=BASE64P.. Parameter(s) containing Base64 encoded data --base64-safe Use URL and filename safe Base64 alphabet (RFC 4648) --batch Never ask for user input, use the default behavior --binary-fields=.. Result fields having binary values (e.g. \u0026quot;digest\u0026quot;) --check-internet Check Internet connection before assessing the target --cleanup Clean up the DBMS from sqlmap specific UDF and tables --crawl=CRAWLDEPTH Crawl the website starting from the target URL --crawl-exclude=.. Regexp to exclude pages from crawling (e.g. \u0026quot;logout\u0026quot;) --csv-del=CSVDEL Delimiting character used in CSV output (default \u0026quot;,\u0026quot;) --charset=CHARSET Blind SQL injection charset (e.g. \u0026quot;0123456789abcdef\u0026quot;) --dump-file=DUMP.. Store dumped data to a custom file --dump-format=DU.. Format of dumped data (CSV (default), HTML or SQLITE) --encoding=ENCOD.. Character encoding used for data retrieval (e.g. GBK) --eta Display for each output the estimated time of arrival --flush-session Flush session files for current target --forms Parse and test forms on target URL --fresh-queries Ignore query results stored in session file --gpage=GOOGLEPAGE Use Google dork results from specified page number --har=HARFILE Log all HTTP traffic into a HAR file --hex Use hex conversion during data retrieval --output-dir=OUT.. Custom output directory path --parse-errors Parse and display DBMS error messages from responses --preprocess=PRE.. Use given script(s) for preprocessing (request) --postprocess=PO.. Use given script(s) for postprocessing (response) --repair Redump entries having unknown character marker (?) --save=SAVECONFIG Save options to a configuration INI file --scope=SCOPE Regexp for filtering targets --skip-heuristics Skip heuristic detection of vulnerabilities --skip-waf Skip heuristic detection of WAF/IPS protection --table-prefix=T.. Prefix used for temporary tables (default: \u0026quot;sqlmap\u0026quot;) --test-filter=TE.. Select tests by payloads and/or titles (e.g. ROW) --test-skip=TEST.. Skip tests by payloads and/or titles (e.g. BENCHMARK) --web-root=WEBROOT Web server document root directory (e.g. \u0026quot;/var/www\u0026quot;) Miscellaneous: These options do not fit into any other category -z MNEMONICS Use short mnemonics (e.g. \u0026quot;flu,bat,ban,tec=EU\u0026quot;) --alert=ALERT Run host OS command(s) when SQL injection is found --beep Beep on question and/or when vulnerability is found --dependencies Check for missing (optional) sqlmap dependencies --disable-coloring Disable console output coloring --list-tampers Display list of available tamper scripts --no-logging Disable logging to a file --offline Work in offline mode (only use session data) --purge Safely remove all content from sqlmap data directory --results-file=R.. Location of CSV results file in multiple targets mode --shell Prompt for an interactive sqlmap shell --tmp-dir=TMPDIR Local directory for storing temporary files --unstable Adjust options for unstable connections --update Update sqlmap --wizard Simple wizard interface for beginner users ```bash "}),e.add({id:90,href:"/docs/tools/attack/xh/",title:"Xh",description:`Description # xh is a command-line HTTP client. It is a wrapper around the [reqwest](
Installation # brew install xh Examples # GET # xh https://httpbin.org/get POST # xh POST https://httpbin.org/post \u0026lt; file.json POST with JSON # xh POST https://httpbin.org/post \u0026lt; file.json POST with form data # xh POST https://httpbin.org/post foo=bar baz=quux POST with form data and JSON # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json POST with form data and JSON, and a header # xh POST https://httpbin.`,content:"Description # xh is a command-line HTTP client. It is a wrapper around the [reqwest](\nInstallation # brew install xh Examples # GET # xh https://httpbin.org/get POST # xh POST https://httpbin.org/post \u0026lt; file.json POST with JSON # xh POST https://httpbin.org/post \u0026lt; file.json POST with form data # xh POST https://httpbin.org/post foo=bar baz=quux POST with form data and JSON # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json POST with form data and JSON, and a header # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; POST with form data and JSON, and multiple headers # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; -h \u0026quot;X-Baz: quux\u0026quot; POST with form data and JSON, and multiple headers, and a cookie # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; -h \u0026quot;X-Baz: quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; POST with form data and JSON, and multiple headers, and multiple cookies # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; -h \u0026quot;X-Baz: quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; POST with form data and JSON, and multiple headers, and multiple cookies, and a basic auth # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; -h \u0026quot;X-Baz: quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -a \u0026quot;foo:bar\u0026quot; POST with form data and JSON, and multiple headers, and multiple cookies, and a basic auth, and a timeout # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; -h \u0026quot;X-Baz: quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -a \u0026quot;foo:bar\u0026quot; -t 10 POST with form data and JSON, and multiple headers, and multiple cookies, and a basic auth, and a timeout, and a proxy # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; -h \u0026quot;X-Baz: quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -a \u0026quot;foo:bar\u0026quot; -t 10 -x \u0026quot;http://localhost:8080\u0026quot; POST with form data and JSON, and multiple headers, and multiple cookies, and a basic auth, and a timeout, and a proxy, and a TLS certificate # xh POST https://httpbin.org/post foo=bar baz=quux \u0026lt; file.json -h \u0026quot;X-Foo: bar\u0026quot; -h \u0026quot;X-Baz: quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -c \u0026quot;foo=bar; baz=quux\u0026quot; -a \u0026quot;foo:bar\u0026quot; -t 10 -x \u0026quot;http://localhost:8080\u0026quot; -k \u0026quot;path/to/cert.pem\u0026quot; website # https://github.com/ducaale/xh\nhelp # xh 0.17.0 xh is a friendly and fast tool for sending HTTP requests USAGE: xh [OPTIONS] \u0026lt;[METHOD] URL\u0026gt; [--] [REQUEST_ITEM]... ARGS: \u0026lt;[METHOD] URL\u0026gt; The request URL, preceded by an optional HTTP method \u0026lt;REQUEST_ITEM\u0026gt;... Optional key-value pairs to be included in the request. OPTIONS: -j, --json (default) Serialize data items from the command line as a JSON object -f, --form Serialize data items from the command line as form fields -m, --multipart Like --form, but force a multipart/form-data request even without files --raw \u0026lt;RAW\u0026gt; Pass raw request data without extra processing --pretty \u0026lt;STYLE\u0026gt; Controls output processing [possible values: all, colors, format, none] -s, --style \u0026lt;THEME\u0026gt; Output coloring style [possible values: auto, solarized, monokai, fruity] --response-charset \u0026lt;ENCODING\u0026gt; Override the response encoding for terminal display purposes --response-mime \u0026lt;MIME_TYPE\u0026gt; Override the response mime type for coloring and formatting for the terminal -p, --print \u0026lt;FORMAT\u0026gt; String specifying what the output should contain -h, --headers Print only the response headers. Shortcut for --print=h -b, --body Print only the response body. Shortcut for --print=b -v, --verbose Print the whole request as well as the response --all Show any intermediary requests/responses while following redirects with --follow -P, --history-print \u0026lt;FORMAT\u0026gt; The same as --print but applies only to intermediary requests/responses -4, --ipv4 Resolve hostname to ipv4 addresses only -6, --ipv6 Resolve hostname to ipv6 addresses only -q, --quiet Do not print to stdout or stderr -S, --stream Always stream the response body -o, --output \u0026lt;FILE\u0026gt; Save output to FILE instead of stdout -d, --download Download the body to a file instead of printing it -c, --continue Resume an interrupted download. Requires --download and --output --session \u0026lt;FILE\u0026gt; Create, or reuse and update a session --session-read-only \u0026lt;FILE\u0026gt; Create or read a session without updating it form the request/response exchange -A, --auth-type \u0026lt;AUTH_TYPE\u0026gt; Specify the auth mechanism [possible values: basic, bearer, digest] -a, --auth \u0026lt;USER[:PASS] | TOKEN\u0026gt; Authenticate as USER with PASS (-A basic|digest) or with TOKEN (-A bearer) --ignore-netrc Do not use credentials from .netrc --offline Construct HTTP requests without sending them anywhere --check-status (default) Exit with an error status code if the server replies with an error -F, --follow Do follow redirects --max-redirects \u0026lt;NUM\u0026gt; Number of redirects to follow. Only respected if --follow is used --timeout \u0026lt;SEC\u0026gt; Connection timeout of the request --proxy \u0026lt;PROTOCOL:URL\u0026gt; Use a proxy for a protocol. For example: --proxy https:http://proxy.host:8080 --verify \u0026lt;VERIFY\u0026gt; If \u0026quot;no\u0026quot;, skip SSL verification. If a file path, use it as a CA bundle --cert \u0026lt;FILE\u0026gt; Use a client side certificate for SSL --cert-key \u0026lt;FILE\u0026gt; A private key file to use with --cert --ssl \u0026lt;VERSION\u0026gt; Force a particular TLS version [possible values: auto, tls1, tls1.1, tls1.2, tls1.3] --https Make HTTPS requests if not specified in the URL --http-version \u0026lt;VERSION\u0026gt; HTTP version to use [possible values: 1.0, 1.1, 2] -I, --ignore-stdin Do not attempt to read stdin --curl Print a translation to a curl command --curl-long Use the long versions of curl's flags --help Print help information -V, --version Print version information Each option can be reset with a --no-OPTION argument. Run `xh help` for more complete documentation. xh 0.17.0 xh is a friendly and fast tool for sending HTTP requests. It reimplements as much as possible of HTTPie's excellent design, with a focus on improved performance. USAGE: xh [OPTIONS] \u0026lt;[METHOD] URL\u0026gt; [--] [REQUEST_ITEM]... ARGS: \u0026lt;[METHOD] URL\u0026gt; The request URL, preceded by an optional HTTP method. If the method is omitted, it will default to GET, or to POST if the request contains a body. The URL scheme defaults to \u0026quot;http://\u0026quot; normally, or \u0026quot;https://\u0026quot; if the program is invoked as \u0026quot;xhs\u0026quot;. A leading colon works as shorthand for localhost. \u0026quot;:8000\u0026quot; is equivalent to \u0026quot;localhost:8000\u0026quot;, and \u0026quot;:/path\u0026quot; is equivalent to \u0026quot;localhost/path\u0026quot;. \u0026lt;REQUEST_ITEM\u0026gt;... Optional key-value pairs to be included in the request. The separator is used to determine the type: key==value Add a query string to the URL. key=value Add a JSON property (--json) or form field (--form) to the request body. key=@filename Add a JSON property (--json) or form field (--form) from a file to the request body. key:=value Add a field with a literal JSON value to the request body. Example: \u0026quot;numbers:=[1,2,3] enabled:=true\u0026quot; key:=@filename Add a field with a literal JSON value from a file to the request body. key@filename Upload a file (requires --form or --multipart). To set the filename and mimetype, \u0026quot;;type=\u0026quot; and \u0026quot;;filename=\u0026quot; can be used respectively. Example: \u0026quot;pfp@ra.jpg;type=image/jpeg;filename=profile.jpg\u0026quot; @filename Use a file as the request body. header:value Add a header, e.g. \u0026quot;user-agent:foobar\u0026quot; header: Unset a header, e.g. \u0026quot;connection:\u0026quot; header; Add a header with an empty value. A backslash can be used to escape special characters, e.g. \u0026quot;weird\\:key=value\u0026quot;. To construct a complex JSON object, the REQUEST_ITEM's key can be set to a JSON path instead of a field name. For more information on this syntax, refer to https://httpie.io/docs/cli/nested-json. OPTIONS: -j, --json (default) Serialize data items from the command line as a JSON object. Overrides both --form and --multipart. -f, --form Serialize data items from the command line as form fields. Overrides both --json and --multipart. -m, --multipart Like --form, but force a multipart/form-data request even without files. Overrides both --json and --form. --raw \u0026lt;RAW\u0026gt; Pass raw request data without extra processing --pretty \u0026lt;STYLE\u0026gt; Controls output processing. Possible values are: all (default) Enable both coloring and formatting colors Apply syntax highlighting to output format Pretty-print json and sort headers none Disable both coloring and formatting Defaults to \u0026quot;format\u0026quot; if the NO_COLOR env is set and to \u0026quot;none\u0026quot; if stdout is not tty. -s, --style \u0026lt;THEME\u0026gt; Output coloring style [possible values: auto, solarized, monokai, fruity] --response-charset \u0026lt;ENCODING\u0026gt; Override the response encoding for terminal display purposes. Example: --response-charset=latin1 --response-mime \u0026lt;MIME_TYPE\u0026gt; Override the response mime type for coloring and formatting for the terminal. Example: --response-mime=application/json -p, --print \u0026lt;FORMAT\u0026gt; String specifying what the output should contain. Use \u0026quot;H\u0026quot; and \u0026quot;B\u0026quot; for request header and body respectively, and \u0026quot;h\u0026quot; and \u0026quot;b\u0026quot; for response header and body. Example: --print=Hb -h, --headers Print only the response headers. Shortcut for --print=h -b, --body Print only the response body. Shortcut for --print=b -v, --verbose Print the whole request as well as the response. Additionally, this enables --all for printing intermediary requests/responses while following redirects. Equivalent to --print=HhBb --all. --all Show any intermediary requests/responses while following redirects with --follow -P, --history-print \u0026lt;FORMAT\u0026gt; The same as --print but applies only to intermediary requests/responses -4, --ipv4 Resolve hostname to ipv4 addresses only -6, --ipv6 Resolve hostname to ipv6 addresses only -q, --quiet Do not print to stdout or stderr -S, --stream Always stream the response body -o, --output \u0026lt;FILE\u0026gt; Save output to FILE instead of stdout -d, --download Download the body to a file instead of printing it. The Accept-Encoding header is set to identify and any redirects will be followed. -c, --continue Resume an interrupted download. Requires --download and --output --session \u0026lt;FILE\u0026gt; Create, or reuse and update a session. Within a session, custom headers, auth credentials, as well as any cookies sent by the server persist between requests. --session-read-only \u0026lt;FILE\u0026gt; Create or read a session without updating it form the request/response exchange -A, --auth-type \u0026lt;AUTH_TYPE\u0026gt; Specify the auth mechanism [possible values: basic, bearer, digest] -a, --auth \u0026lt;USER[:PASS] | TOKEN\u0026gt; Authenticate as USER with PASS (-A basic|digest) or with TOKEN (-A bearer). PASS will be prompted if missing. Use a trailing colon (i.e. \u0026quot;USER:\u0026quot;) to authenticate with just a username. TOKEN is expected if --auth-type=bearer. --ignore-netrc Do not use credentials from .netrc --offline Construct HTTP requests without sending them anywhere --check-status (default) Exit with an error status code if the server replies with an error. The exit code will be 4 on 4xx (Client Error), 5 on 5xx (Server Error), or 3 on 3xx (Redirect) if --follow isn't set. If stdout is redirected then a warning is written to stderr. -F, --follow Do follow redirects --max-redirects \u0026lt;NUM\u0026gt; Number of redirects to follow. Only respected if --follow is used --timeout \u0026lt;SEC\u0026gt; Connection timeout of the request. The default value is \u0026quot;0\u0026quot;, i.e., there is no timeout limit. --proxy \u0026lt;PROTOCOL:URL\u0026gt; Use a proxy for a protocol. For example: --proxy https:http://proxy.host:8080. PROTOCOL can be \u0026quot;http\u0026quot;, \u0026quot;https\u0026quot; or \u0026quot;all\u0026quot;. If your proxy requires credentials, put them in the URL, like so: --proxy http:socks5://user:password@proxy.host:8000. You can specify proxies for multiple protocols by repeating this option. The environment variables \u0026quot;http_proxy\u0026quot; and \u0026quot;https_proxy\u0026quot; can also be used, but are completely ignored if --proxy is passed. --verify \u0026lt;VERIFY\u0026gt; If \u0026quot;no\u0026quot;, skip SSL verification. If a file path, use it as a CA bundle. Specifying a CA bundle will disable the system's built-in root certificates. \u0026quot;false\u0026quot; instead of \u0026quot;no\u0026quot; also works. The default is \u0026quot;yes\u0026quot; (\u0026quot;true\u0026quot;). --cert \u0026lt;FILE\u0026gt; Use a client side certificate for SSL --cert-key \u0026lt;FILE\u0026gt; A private key file to use with --cert. Only necessary if the private key is not contained in the cert file. --ssl \u0026lt;VERSION\u0026gt; Force a particular TLS version. \u0026quot;auto\u0026quot; gives the default behavior of negotiating a version with the server. [possible values: auto, tls1, tls1.1, tls1.2, tls1.3] --https Make HTTPS requests if not specified in the URL --http-version \u0026lt;VERSION\u0026gt; HTTP version to use [possible values: 1.0, 1.1, 2] -I, --ignore-stdin Do not attempt to read stdin. This disables the default behaviour of reading the request body from stdin when a redirected input is detected. It is recommended to pass this flag when using xh for scripting purposes. For more information, refer to https://httpie.io/docs/cli/best-practices. --curl Print a translation to a curl command. For translating the other way, try https://curl2httpie.online/. --curl-long Use the long versions of curl's flags --help Print help information -V, --version Print version information Each option can be reset with a --no-OPTION argument. ```bash "}),e.add({id:91,href:"/docs/tools/attack/ettercap/",title:"Ettercap",description:`Description # Ettercap is a comprehensive suite for man in the middle attacks. It features sniffing of live connections, content filtering on the fly and many other interesting tricks. It supports active and passive dissection of many protocols and includes many features for network and host analysis.
Install # brew install ettercap Sample Usage # ettercap -T -i en0 -M arp:remote / website # https://www.ettercap-project.org
help # ettercap 0.8.3.1 copyright 2001-2020 Ettercap Development Team Usage: ettercap [OPTIONS] [TARGET1] [TARGET2] TARGET is in the format MAC/IP/IPv6/PORTs (see the man for further detail) Sniffing and Attack options: -M, --mitm \u0026lt;METHOD:ARGS\u0026gt; perform a mitm attack -o, --only-mitm don't sniff, only perform the mitm attack -b, --broadcast sniff packets destined to broadcast -B, --bridge \u0026lt;IFACE\u0026gt; use bridged sniff (needs 2 ifaces) -p, --nopromisc do not put the iface in promisc mode -S, --nosslmitm do not forge SSL certificates -u, --unoffensive do not forward packets -r, --read \u0026lt;file\u0026gt; read data from pcapfile \u0026lt;file\u0026gt; -f, --pcapfilter \u0026lt;string\u0026gt; set the pcap filter \u0026lt;string\u0026gt; -R, --reversed use reversed TARGET matching -t, --proto \u0026lt;proto\u0026gt; sniff only this proto (default is all) --certificate \u0026lt;file\u0026gt; certificate file to use for SSL MiTM --private-key \u0026lt;file\u0026gt; private key file to use for SSL MiTM User Interface Type: -T, --text use text only GUI -q, --quiet do not display packet contents -s, --script \u0026lt;CMD\u0026gt; issue these commands to the GUI -C, --curses use curses GUI -D, --daemon daemonize ettercap (no GUI) -G, --gtk use GTK+ GUI Logging options: -w, --write \u0026lt;file\u0026gt; write sniffed data to pcapfile \u0026lt;file\u0026gt; -L, --log \u0026lt;logfile\u0026gt; log all the traffic to this \u0026lt;logfile\u0026gt; -l, --log-info \u0026lt;logfile\u0026gt; log only passive infos to this \u0026lt;logfile\u0026gt; -m, --log-msg \u0026lt;logfile\u0026gt; log all the messages to this \u0026lt;logfile\u0026gt; -c, --compress use gzip compression on log files Visualization options: -d, --dns resolves ip addresses into hostnames -V, --visual \u0026lt;format\u0026gt; set the visualization format -e, --regex \u0026lt;regex\u0026gt; visualize only packets matching this regex -E, --ext-headers print extended header for every pck -Q, --superquiet do not display user and password General options: -i, --iface \u0026lt;iface\u0026gt; use this network interface -I, --liface show all the network interfaces -Y, --secondary \u0026lt;ifaces\u0026gt; list of secondary network interfaces -n, --netmask \u0026lt;netmask\u0026gt; force this \u0026lt;netmask\u0026gt; on iface -A, --address \u0026lt;address\u0026gt; force this local \u0026lt;address\u0026gt; on iface -P, --plugin \u0026lt;plugin\u0026gt; launch this \u0026lt;plugin\u0026gt; - multiple occurance allowed --plugin-list \u0026lt;plugin1\u0026gt;,[\u0026lt;plugin2\u0026gt;,.`,content:"Description # Ettercap is a comprehensive suite for man in the middle attacks. It features sniffing of live connections, content filtering on the fly and many other interesting tricks. It supports active and passive dissection of many protocols and includes many features for network and host analysis.\nInstall # brew install ettercap Sample Usage # ettercap -T -i en0 -M arp:remote / website # https://www.ettercap-project.org\nhelp # ettercap 0.8.3.1 copyright 2001-2020 Ettercap Development Team Usage: ettercap [OPTIONS] [TARGET1] [TARGET2] TARGET is in the format MAC/IP/IPv6/PORTs (see the man for further detail) Sniffing and Attack options: -M, --mitm \u0026lt;METHOD:ARGS\u0026gt; perform a mitm attack -o, --only-mitm don't sniff, only perform the mitm attack -b, --broadcast sniff packets destined to broadcast -B, --bridge \u0026lt;IFACE\u0026gt; use bridged sniff (needs 2 ifaces) -p, --nopromisc do not put the iface in promisc mode -S, --nosslmitm do not forge SSL certificates -u, --unoffensive do not forward packets -r, --read \u0026lt;file\u0026gt; read data from pcapfile \u0026lt;file\u0026gt; -f, --pcapfilter \u0026lt;string\u0026gt; set the pcap filter \u0026lt;string\u0026gt; -R, --reversed use reversed TARGET matching -t, --proto \u0026lt;proto\u0026gt; sniff only this proto (default is all) --certificate \u0026lt;file\u0026gt; certificate file to use for SSL MiTM --private-key \u0026lt;file\u0026gt; private key file to use for SSL MiTM User Interface Type: -T, --text use text only GUI -q, --quiet do not display packet contents -s, --script \u0026lt;CMD\u0026gt; issue these commands to the GUI -C, --curses use curses GUI -D, --daemon daemonize ettercap (no GUI) -G, --gtk use GTK+ GUI Logging options: -w, --write \u0026lt;file\u0026gt; write sniffed data to pcapfile \u0026lt;file\u0026gt; -L, --log \u0026lt;logfile\u0026gt; log all the traffic to this \u0026lt;logfile\u0026gt; -l, --log-info \u0026lt;logfile\u0026gt; log only passive infos to this \u0026lt;logfile\u0026gt; -m, --log-msg \u0026lt;logfile\u0026gt; log all the messages to this \u0026lt;logfile\u0026gt; -c, --compress use gzip compression on log files Visualization options: -d, --dns resolves ip addresses into hostnames -V, --visual \u0026lt;format\u0026gt; set the visualization format -e, --regex \u0026lt;regex\u0026gt; visualize only packets matching this regex -E, --ext-headers print extended header for every pck -Q, --superquiet do not display user and password General options: -i, --iface \u0026lt;iface\u0026gt; use this network interface -I, --liface show all the network interfaces -Y, --secondary \u0026lt;ifaces\u0026gt; list of secondary network interfaces -n, --netmask \u0026lt;netmask\u0026gt; force this \u0026lt;netmask\u0026gt; on iface -A, --address \u0026lt;address\u0026gt; force this local \u0026lt;address\u0026gt; on iface -P, --plugin \u0026lt;plugin\u0026gt; launch this \u0026lt;plugin\u0026gt; - multiple occurance allowed --plugin-list \u0026lt;plugin1\u0026gt;,[\u0026lt;plugin2\u0026gt;,...] comma-separated list of plugins -F, --filter \u0026lt;file\u0026gt; load the filter \u0026lt;file\u0026gt; (content filter) -z, --silent do not perform the initial ARP scan -6, --ip6scan send ICMPv6 probes to discover IPv6 nodes on the link -j, --load-hosts \u0026lt;file\u0026gt; load the hosts list from \u0026lt;file\u0026gt; -k, --save-hosts \u0026lt;file\u0026gt; save the hosts list to \u0026lt;file\u0026gt; -W, --wifi-key \u0026lt;wkey\u0026gt; use this key to decrypt wifi packets (wep or wpa) -a, --config \u0026lt;config\u0026gt; use the alternative config file \u0026lt;config\u0026gt; Standard options: -v, --version prints the version and exit -h, --help this help screen ```bash ## help ```bash ETTERCAP(8) System Manager's Manual ETTERCAP(8) NAME ettercap - multipurpose sniffer/content filter for man in the middle attacks ***** IMPORTANT NOTE ****** Since ettercap NG (formerly 0.7.0), all the options have been changed. Even the target specification has been changed. Please read carefully this help. SYNOPSIS ettercap [OPTIONS] [TARGET1] [TARGET2] If IPv6 is enabled: TARGET is in the form MAC/IPs/IPv6/PORTs Otherwise, TARGET is in the form MAC/IPs/PORTs where IPs and PORTs can be ranges (e.g. /192.168.0.1-30,40,50/20,22,25) DESCRIPTION Ettercap was born as a sniffer for switched LAN (and obviously even \u0026quot;hubbed\u0026quot; ones), but during the development process it has gained more and more features that have changed it to a powerful and flexible tool for man-in-the-middle attacks. It supports active and passive dissection of many protocols (even ciphered ones) and includes many features for network and host analysis (such as OS fingerprint). It has two main sniffing options: UNIFIED, this method sniffs all the packets that pass on the cable. You can choose to put or not the interface in promisc mode (-p option). The packet not directed to the host running ettercap will be forwarded automatically using layer 3 routing. So you can use a mitm attack launched from a different tool and let ettercap modify the packets and forward them for you. The kernel ip_forwarding is always disabled by ettercap. This is done to prevent a forward of a packet twice (one by ettercap and one by the kernel). This is an invasive behaviour on gate‐ ways. So we recommend you to use ettercap on the gateways ONLY with the UNOFFENSIVE MODE ENABLED. Since ettercap listens only on one network interface, launching it on the gateway in offensive mode will not allow packets to be rerouted back from the second interface. BRIDGED, it uses two network interfaces and forward the traffic from one to the other while performing sniffing and content filtering. This sniffing method is totally stealthy since there is no way to find that someone is in the middle on the cable. You can look at this method as a mitm attack at layer 1. You will be in the middle of the cable between two entities. Don't use it on gateways or it will transform your gateway into a bridge. HINT: you can use the content filtering engine to drop packets that should not pass. This way ettercap will work as an inline IPS ;) You can also perform man in the middle attacks while using the unified sniffing. You can choose the mitm attack that you prefer. The mitm attack module is independent from the sniffing and filtering process, so you can launch several attacks at the same time or use your own tool for the attack. The crucial point is that the packets have to arrive to ettercap with the correct mac address and a different ip address (only these packets will be forwarded). The most relevant ettercap features are: SSH1 support : you can sniff User and Pass, and even the data of an SSH1 connection. ettercap is the first software capable to sniff an SSH connection in FULL-DUPLEX SSL support : you can sniff SSL secured data... a fake certificate is presented to the client and the session is decrypted. Characters injection in an established connection : you can inject characters to the server (emulating commands) or to the client (emulating replies) maintaining the connection alive !! Packet filtering/dropping: You can set up a filter script that searches for a particular string (even hex) in the TCP or UDP payload and replace it with yours or drop the entire packet. The filtering engine can match any field of the network protocols and modify whatever you want (see etterfilter(8)). Remote traffic sniffing through tunnels and route mangling: You can play with linux cooked interfaces or use the integrated plugin to sniff tunneled or route-mangled remote connections and perform mitm attacks on them. Plug-ins support : You can create your own plugin using the ettercap's API. Password collector for : TELNET, FTP, POP, RLOGIN, SSH1, ICQ, SMB, MySQL, HTTP, NNTP, X11, NAPSTER, IRC, RIP, BGP, SOCKS 5, IMAP 4, VNC, LDAP, NFS, SNMP, HALF LIFE, QUAKE 3, MSN, YMSG (other protocols coming soon...) Passive OS fingerprint: you scan passively the lan (without sending any packet) and gather detailed info about the hosts in the LAN: Operating System, running services, open ports, IP, mac ad‐ dress and network adapter vendor. Kill a connection: from the connections list you can kill all the connections you want TARGET SPECIFICATION There is no concept of SOURCE nor DEST. The two targets are intended to filter traffic coming from one to the other and vice-versa (since the connection is bidirectional). TARGET is in the form MAC/IPs/PORTs. NOTE: If IPv6 is enabled, TARGET is in the form MAC/IPs/IPv6/PORTs. If you want you can omit any of its parts and this will represent an ANY in that part. e.g. \u0026quot;//80\u0026quot; means ANY mac address, ANY ip and ONLY port 80 \u0026quot;/10.0.0.1/\u0026quot; means ANY mac address, ONLY ip 10.0.0.1 and ANY port MAC must be unique and in the form 00:11:22:33:44:55 IPs is a range of IP in dotted notation. You can specify range with the - (hyphen) and single ip with , (comma). You can also use ; (semicolon) to indicate different ip addresses. e.g. \u0026quot;10.0.0.1-5;10.0.1.33\u0026quot; expands into ip 10.0.0.1, 2, 3, 4, 5 and 10.0.1.33 PORTs is a range of PORTS. You can specify range with the - (hyphen) and single port with , (comma). e.g. \u0026quot;20-25,80,110\u0026quot; expands into ports 20, 21, 22, 23, 24, 25, 80 and 110 NOTE: you can reverse the matching of the TARGET by adding the -R option to the command line. So if you want to sniff ALL the traffic BUT the one coming or going to 10.0.0.1 you can specify \u0026quot;./et‐ tercap -R /10.0.0.1/\u0026quot; NOTE: TARGETs are also responsible of the initial scan of the lan. You can use them to restrict the scan to only a subset of the hosts in the netmask. The result of the merging between the two tar‐ gets will be scanned. remember that not specifying a target means \u0026quot;no target\u0026quot;, but specifying \u0026quot;//\u0026quot; means \u0026quot;all the hosts in the subnet\u0026quot;. PRIVILEGES DROPPING ettercap needs root privileges to open the Link Layer sockets. After the initialization phase, the root privs are not needed anymore, so ettercap drops them to UID = 65535 (nobody). Since et‐ tercap has to write (create) log files, it must be executed in a directory with the right permissions (e.g. /tmp/). If you want to drop privs to a different uid, you can export the environment variable EC_UID with the value of the uid you want to drop the privs to (e.g. export EC_UID=500) or set the correct parameter in the etter.conf file. SSL MITM ATTACK SSL mitm attack is dependent on TCP traffic redirection to a custom listener port of ettercap. The redir_command_on and redir_command_off configuration variables take care of this (see \u0026quot;et‐ ter.conf(5)\u0026quot;). However, when ettercap starts, traffic for any source and any destination targeted for the redirectable services will be redirected to ettercap and the SSL stream will be intercepted. This may not be the desired behaviour. Therefore you can adjust the redirect rules after ettercap has been started using the selected user interface. While performing the SSL mitm attack, ettercap substitutes the real ssl certificate with its own. The fake certificate is created on the fly and all the fields are filled according to the real cert presented by the server. Only the issuer is modified and signed with the private key contained in the 'etter.ssl.crt' file. If you want to use a different private key you have to regener‐ ate this file. To regenerate the cert file use the following commands: openssl genrsa -out etter.ssl.crt 1024 openssl req -new -key etter.ssl.crt -out tmp.csr openssl x509 -req -days 1825 -in tmp.csr -signkey etter.ssl.crt -out tmp.new cat tmp.new \u0026gt;\u0026gt; etter.ssl.crt rm -f tmp.new tmp.csr NOTE: SSL mitm is not available (for now) in bridged mode. NOTE: You can use the --certificate/--private-key long options if you want to specify a different file rather than the etter.ssl.crt file. OPTIONS Options that make sense together can generally be combined. ettercap will warn the user about unsupported option combinations. SNIFFING AND ATTACK OPTIONS ettercap NG has a new unified sniffing method. This implies that ip_forwarding in the kernel is always disabled and the forwarding is done by ettercap. Every packet with destination mac ad‐ dress equal to the host's mac address and destination ip address different for the one bound to the iface will be forwarded by ettercap. Before forwarding them, ettercap can content filter, sniff, log or drop them. It does not matter how these packets are hijacked, ettercap will process them. You can even use external programs to hijack packet. You have full control of what ettercap should receive. You can use the internal mitm attacks, set the interface in promisc mode, use plugins or use every method you want. IMPORTANT NOTE: if you run ettercap on a gateway, remember to re-enable the ip_forwarding after you have killed ettercap. Since ettercap drops its privileges, it cannot restore the ip_forward‐ ing for you. -M, --mitm \u0026lt;METHOD:ARGS\u0026gt; MITM attack This option will activate the man in the middle attack. The mitm attack is totally independent from the sniffing. The aim of the attack is to hijack packets and redirect them to etter‐ cap. The sniffing engine will forward them if necessary. You can choose the mitm attack that you prefer and also combine some of them to perform different attacks at the same time. If a mitm method requires some parameters you can specify them after the colon. (e.g. -M dhcp:ip_pool,netmask,etc ) The following mitm attacks are available: arp ([remote],[oneway]) This method implements the ARP poisoning mitm attack. ARP requests/replies are sent to the victims to poison their ARP cache. Once the cache has been poisoned the victims will send all packets to the attacker which, in turn, can modify and forward them to the real destination. In silent mode (-z option) only the first target is selected, if you want to poison multiple target in silent mode use the -j option to load a list from a file. You can select empty targets and they will be expanded as 'ANY' (all the hosts in the LAN). The target list is joined with the hosts list (created by the arp scan) and the result is used to determine the victims of the attack. The parameter \u0026quot;remote\u0026quot; is optional and you have to specify it if you want to sniff remote ip address poisoning a gateway. Indeed if you specify a victim and the gw in the TAR‐ GETS, ettercap will sniff only connection between them, but to enable ettercap to sniff connections that pass thru the gw, you have to use this parameter. The parameter \u0026quot;oneway\u0026quot; will force ettercap to poison only from TARGET1 to TARGET2. Useful if you want to poison only the client and not the router (where an arp watcher can be in place). Example: the targets are: /10.0.0.1-5/ /10.0.0.15-20/ and the host list is: 10.0.0.1 10.0.0.3 10.0.0.16 10.0.0.18 the associations between the victims will be: 1 and 16, 1 and 18, 3 and 16, 3 and 18 if the targets overlap each other, the association with identical ip address will be skipped. NOTE: if you manage to poison a client, you have to set correct routing table in the kernel specifying the GW. If your routing table is incorrect, the poisoned clients will not be able to navigate the Internet. icmp (MAC/IP) This attack implements ICMP redirection. It sends a spoofed icmp redirect message to the hosts in the lan pretending to be a better route for internet. All connections to inter‐ net will be redirected to the attacker which, in turn, will forward them to the real gateway. The resulting attack is a HALF-DUPLEX mitm. Only the client is redirected, since the gateway will not accept redirect messages for a directly connected network. BE SURE TO NOT USE FILTERS THAT MODIFY THE PAYLOAD LENGTH. you can use a filter to modify packets, but the length must be the same since the tcp sequences cannot be updated in both ways. You have to pass as argument the MAC and the IP address of the real gateway for the lan. Obviously you have to be able to sniff all the traffic. If you are on a switch you have to use a different mitm attack such as arp poisoning. NOTE: to restrict the redirection to a given target, specify it as a TARGET Example: -M icmp:00:11:22:33:44:55/10.0.0.1 will redirect all the connections that pass thru that gateway. dhcp (ip_pool/netmask/dns) This attack implements DHCP spoofing. It pretends to be a DHCP server and tries to win the race condition with the real one to force the client to accept the attacker's reply. This way ettercap is able to manipulate the GW parameter and hijack all the outgoing traffic generated by the clients. The resulting attack is a HALF-DUPLEX mitm. So be sure to use appropriate filters (see above in the ICMP section). You have to pass the ip pool to be used, the netmask and the ip of the dns server. Since ettercap tries to win the race with the real server, it DOES NOT CHECK if the ip is al‐ ready assigned. You have to specify an ip pool of FREE addresses to be used. The ip pool has the same form of the target specification. If the client sends a dhcp request (suggesting an ip address) ettercap will ack on that ip and modify only the gw option. If the client makes a dhcp discovery, ettercap will use the first unused ip address of the list you have specified on command line. Every discovery consumes an ip address. When the list is over, ettercap stops offering new ip ad‐ dresses and will reply only to dhcp requests. If you don't want to offer any ip address, but only change the router information of dhcp request/ack, you can specify an empty ip_pool. BIG WARNING: if you specify a list of ip that are in use, you will mess your network! In general, use this attack carefully. It can really mess things up! When you stop the at‐ tack, all the victims will be still convinced that ettercap is the gateway until the lease expires... Example: -M dhcp:192.168.0.30,35,50-60/255.255.255.0/192.168.0.1 reply to DHCP offer and request. -M dhcp:/255.255.255.0/192.168.0.1 reply only to DHCP request. port ([remote],[tree]) This attack implements Port Stealing. This technique is useful to sniff in a switched environment when ARP poisoning is not effective (for example where static mapped ARPs are used). It floods the LAN (based on port_steal_delay option in etter.conf) with ARP packets. If you don't specify the \u0026quot;tree\u0026quot; option, the destination MAC address of each \u0026quot;stealing\u0026quot; packet is the same as the attacker's one (other NICs won't see these packets), the source MAC address will be one of the MACs in the host list. This process \u0026quot;steals\u0026quot; the switch port of each victim host in the host list. Using low delays, packets destined to \u0026quot;stolen\u0026quot; MAC addresses will be received by the attacker, winning the race condition with the real port owner. When the attacker receives packets for \u0026quot;stolen\u0026quot; hosts, it stops the flooding process and performs an ARP request for the real destination of the packet. When it receives the ARP reply it's sure that the victim has \u0026quot;taken back\u0026quot; his port, so ettercap can re-send the packet to the destination as is. Now we can re-start the flooding process waiting for new packets. If you use the \u0026quot;tree\u0026quot; option, the destination MAC address of each stealing packet will be a bogus one, so these packets will be propagated to other switches (not only the di‐ rectly connected one). This way you will be able to steal ports on other switches in the tree (if any), but you will generate a huge amount of traffic (according to port_steal_delay). The \u0026quot;remote\u0026quot; option has the same meaning as in \u0026quot;arp\u0026quot; mitm method. When you stop the attack, ettercap will send an ARP request to each stolen host giving back their switch ports. You can perform either HALF or FULL DUPLEX mitm according to target selection. NOTE: Use this mitm method only on ethernet switches. Use it carefully, it could produce performances loss or general havoc. NOTE: You can NOT use this method in only-mitm mode (-o flag), because it hooks the sniffing engine, and you can't use interactive data injection. NOTE: It could be dangerous to use it in conjunction with other mitm methods. NOTE: This mitm method doesn't work on Solaris and Windows because of the lipcap and libnet design and the lack of certain ioctl(). (We will feature this method on these OSes if someone will request it...) Example: The targets are: /10.0.0.1/ /10.0.0.15/ You will intercept and visualize traffic between 10.0.0.1 and 10.0.0.15, but you will receive all the traffic for 10.0.0.1 and 10.0.0.15 too. The target is: /10.0.0.1/ You will intercept and visualize all the traffic for 10.0.0.1. ndp ([remote],[oneway]) NOTE: This MITM method is only supported if IPv6 support has been enabled. This method implements the NDP poisoning attack which is used for MITM of IPv6 connections. ND requests/replies are sent to the victims to poison their neighbor cache. Once the cache has been poisoned the victims will send all IPv6 packets to the attacker which, in turn, can modify and forward them to the real destination. In silent mode (-z option) only the first target is selected, if you want to poison multiple target in silent mode use the -j option to load a list from a file. You can select empty targets and they will be expanded as 'ANY' (all the hosts in the LAN). The target list is joined with the hosts list (created by the arp scan) and the result is used to determine the victims of the attack. The parameter \u0026quot;remote\u0026quot; is optional and you have to specify it if you want to sniff remote ip address poisoning a gateway. Indeed if you specify a victim and the gw in the TAR‐ GETS, ettercap will sniff only connection between them, but to enable ettercap to sniff connections that pass thru the gw, you have to use this parameter. The parameter \u0026quot;oneway\u0026quot; will force ettercap to poison only from TARGET1 to TARGET2. Useful if you want to poison only the client and not the router (where an arp watcher can be in place). Example: Targets are: //fe80::260d:afff:fe6e:f378/ //2001:db8::2:1/ Ranges of IPv6 addresses are not yet supported. NOTE: if you manage to poison a client, you have to set correct routing table in the kernel specifying the GW. If your routing table is incorrect, the poisoned clients will not be able to navigate the Internet. NOTE: in IPv6 usually the link-local address of the router is being used as the gateway address. Therefore you need to set the link-local address of the router as one target and the global-unicast address of the victim as the other in order to set up a successful IPv6 MITM attack using NDP poisoning. -o, --only-mitm This options disables the sniffing thread and enables only the mitm attack. Useful if you want to use ettercap to perform mitm attacks and another sniffer (such as wireshark) to sniff the traffic. Keep in mind that the packets are not forwarded by ettercap. The kernel will be responsible for the forwarding. Remember to activate the \u0026quot;ip forwarding\u0026quot; feature in your kernel. -f, --pcapfilter \u0026lt;FILTER\u0026gt; Set a capturing filter in the pcap library. The format is the same as tcpdump(1). Remember that this kind of filter will not sniff packets out of the wire, so if you want to perform a mitm attack, ettercap will not be able to forward hijacked packets. These filters are useful to decrease the network load impact into ettercap decoding module. -B, --bridge \u0026lt;IFACE\u0026gt; BRIDGED sniffing You need two network interfaces. ettercap will forward form one to the other all the traffic it sees. It is useful for man in the middle at the physical layer. It is totally stealthy since it is passive and there is no way for an user to see the attacker. You can content filter all the traffic as you were a transparent proxy for the \u0026quot;cable\u0026quot;. OFF LINE SNIFFING -r, --read \u0026lt;FILE\u0026gt; OFF LINE sniffing With this option enabled, ettercap will sniff packets from a pcap compatible file instead of capturing from the wire. This is useful if you have a file dumped from tcpdump or wireshark and you want to make an analysis (search for passwords or passive fingerprint) on it. Obviously you cannot use \u0026quot;active\u0026quot; sniffing (arp poisoning or bridging) while sniffing from a file. -w, --write \u0026lt;FILE\u0026gt; WRITE packet to a pcap file This is useful if you have to use \u0026quot;active\u0026quot; sniffing (arp poison) on a switched LAN but you want to analyze the packets with tcpdump or wireshark. You can use this option to dump the packets to a file and then load it into your favourite application. NOTE: dump file collect ALL the packets disregarding the TARGET. This is done because you may want to log even protocols not supported by ettercap, so you can analyze them with other tools. TIP: you can use the -w option in conjunction with the -r one. This way you will be able to filter the payload of the dumped packets or decrypt WEP-encrypted WiFi traffic and dump them to another file. USER INTERFACES OPTIONS -T, --text The text only interface, only printf ;) It is quite interactive, press 'h' in every moment to get help on what you can do. -q, --quiet Quiet mode. It can be used only in conjunction with the console interface. It does not print packet content. It is useful if you want to convert pcap file to ettercap log files. example: ettercap -Tq -L dumpfile -r pcapfile -s, --script \u0026lt;COMMANDS\u0026gt; With this option you can feed ettercap with command as they were typed on the keyboard by the user. This way you can use ettercap within your favourite scripts. There is a special com‐ mand you can issue thru this command: s(x). this command will sleep for x seconds. example: ettercap -T -s 'lq' will print the list of the hosts and exit ettercap -T -s 's(300)olqq' will collect the infos for 5 minutes, print the list of the local profiles and exit -C, --curses Ncurses based GUI. See ettercap_curses(8) for a full description. -G, --gtk The nice GTK2 interface (thanks Daten...). -D, --daemonize Daemonize ettercap. This option will detach ettercap from the current controlling terminal and set it as a daemon. You can combine this feature with the \u0026quot;log\u0026quot; option to log all the traffic in the background. If the daemon fails for any reason, it will create the file \u0026quot;./ettercap_daemonized.log\u0026quot; in which the error caught by ettercap will be reported. Furthermore, if you want to have a complete debug of the daemon process, you are encouraged to recompile ettercap in debug mode. GENERAL OPTIONS -b, --broadcast Tells Ettercap to process packets coming from Broadcast address. -i, --iface \u0026lt;IFACE\u0026gt; Use this \u0026lt;IFACE\u0026gt; instead of the default one. The interface can be unconfigured (requires libnet \u0026gt;= 1.1.2), but in this case you cannot use MITM attacks and you should set the unoffen‐ sive flag. -I, --iflist This option will print the list of all available network interfaces that can be used within ettercap. The option is particularly useful under windows where the name of the interface is not so obvious as under *nix. -Y, --secondary \u0026lt;interface list\u0026gt; Specify a list of (or single) secondary interfaces to capture packets from. -A, --address \u0026lt;ADDRESS\u0026gt; Use this \u0026lt;ADDRESS\u0026gt; instead of the one autodetected for the current iface. This option is useful if you have an interface with multiple ip addresses. -n, --netmask \u0026lt;NETMASK\u0026gt; Use this \u0026lt;NETMASK\u0026gt; instead of the one associated with the current iface. This option is useful if you have the NIC with an associated netmask of class B and you want to scan (with the arp scan) only a class C. -R, --reversed Reverse the matching in the TARGET selection. It means not(TARGET). All but the selected TARGET. -t, --proto \u0026lt;PROTO\u0026gt; Sniff only PROTO packets (default is TCP + UDP). This is useful if you want to select a port via the TARGET specification but you want to differentiate between tcp or udp. PROTO can be \u0026quot;tcp\u0026quot;, \u0026quot;udp\u0026quot; or \u0026quot;all\u0026quot; for both. -6, --ip6scan Send ICMPv6 probes to discover active IPv6 nodes on the link. This options sends a ping request to the all-nodes address to motivate active IPv6 hosts to respond. You should not use this option if you try to hide yourself. Therefore this option is optional. NOTE: This option is only available if IPv6 support has been enabled. -z, --silent Do not perform the initial ARP scan of the LAN. NOTE: you will not have the hosts list, so you can't use the multipoison feature. you can only select two hosts for an ARP poisoning attack, specifying them through the TARGETs -p, --nopromisc Usually, ettercap will put the interface in promisc mode to sniff all the traffic on the wire. If you want to sniff only your connections, use this flag to NOT enable the promisc mode. -S, --nosslmitm Usually, ettercap forges SSL certificates in order to intercept https traffic. This option disables that behavior. -u, --unoffensive Every time ettercap starts, it disables ip forwarding in the kernel and begins to forward packets itself. This option prevent to do that, so the responsibility of ip forwarding is left to the kernel. This options is useful if you want to run multiple ettercap instances. You will have one instance (the one without the -u option) forwarding the packets, and all the other instances do‐ ing their work without forwarding them. Otherwise you will get packet duplicates. It also disables the internal creation of the sessions for each connection. It increases performances, but you will not be able to modify packets on the fly. If you want to use a mitm attack you have to use a separate instance. You have to use this option if the interface is unconfigured (without an ip address.) This is also useful if you want to run ettercap on the gateway. It will not disable the forwarding and the gateway will correctly route the packets. -j, --load-hosts \u0026lt;FILENAME\u0026gt; It can be used to load a hosts list from a file created by the -k option. (see below) -k, --save-hosts \u0026lt;FILENAME\u0026gt; Saves the hosts list to a file. Useful when you have many hosts and you don't want to do an ARP storm at startup any time you use ettercap. Simply use this options and dump the list to a file, then to load the information from it use the -j \u0026lt;filename\u0026gt; option. -P, --plugin \u0026lt;PLUGIN\u0026gt; Run the selected PLUGIN. Many plugins need target specification, use TARGET as always. Use multiple occurrences of this parameter to select multiple plugins. In console mode (-C option), standalone plugins are executed and then the application exits. Hook plugins are activated and the normal sniffing is performed. To have a list of the available external plugins use \u0026quot;list\u0026quot; (without quotes) as plugin name (e.g. ./ettercap -P list). NOTE: you can also activate plugins directly from the interfaces (always press \u0026quot;h\u0026quot; to get the inline help) More detailed info about plugins and about how to write your own are found in the help ettercap_plugins(8) --plugin-list \u0026lt;PLUGIN1\u0026gt;[,\u0026lt;PLUGIN2\u0026gt;,...] Instead of providing multiple occurances of -P plugin, --plugin-list can be used followed by a comma sepaparated list without any spaces. (e.g. ./ettercap --plugin-list plugin1,plugin2). -F, --filter \u0026lt;FILE\u0026gt; Load the filter from the file \u0026lt;FILE\u0026gt;. The filter must be compiled with etterfilter(8). The utility will compile the filter script and produce an ettercap-compliant binary filter file. Read the etterfilter(8) help for the list of functions you can use inside a filter script. Any number of filters can be loaded by specifying the option multiple times; packets are passed through each filter in the order specified on the command line. You can also load a script without enabling it by appending :0 to the filename. NOTE: these filters are different from those set with --pcapfilter. An ettercap filter is a content filter and can modify the payload of a packet before forwarding it. Pcap filter are used to capture only certain packets. NOTE: you can use filters on pcapfile to modify them and save to another file, but in this case you have to pay attention on what you are doing, since ettercap will not recalculate checksums, nor split packets exceeding the mtu (snaplen) nor anything like that. -W, --wifi-key \u0026lt;KEY\u0026gt; You can specify a key to decrypt WiFi packets (WEP or WPA). Only the packets decrypted successfully will be passed to the decoders stack, the others will be skipped with a message. The parameter has the following syntax: type:bits:t:string. Where 'type' can be: wep, wpa-pws or wpa-psk, 'bits' is the bit length of the key (64, 128 or 256), 't' is the type of the string ('s' for string and 'p' for passphrase). 'string' can be a string or an escaped hex sequences. example: --wifi-key wep:128:p:secret --wifi-key wep:128:s:ettercapwep0 --wifi-key 'wep:64:s:\\x01\\x02\\x03\\x04\\x05' --wifi-key wpa:pwd:ettercapwpa:ssid --wifi-key wpa:psk: 663eb260e87cf389c6bd7331b28d82f5203b0cae4e315f9cbb7602f3236708a6 -a, --config \u0026lt;CONFIG\u0026gt; Loads an alternative config file instead of the default in /etc/etter.conf. This is useful if you have many preconfigured files for different situations. --certificate \u0026lt;FILE\u0026gt; Tells Ettercap to use the specified certificate file for the SSL MiTM attack. --private-key \u0026lt;FILE\u0026gt; Tells Ettercap to use the specified private key file for the SSL MiTM attack. VISUALIZATION OPTIONS -e, --regex \u0026lt;REGEX\u0026gt; Handle only packets that match the regex. This option is useful in conjunction with -L. It logs only packets that match the posix regex REGEX. It impacts even the visualization of the sniffed packets. If it is set only packets matching the regex will be displayed. -V, --visual \u0026lt;FORMAT\u0026gt; Use this option to set the visualization method for the packets to be displayed. FORMAT may be one of the following: hex Print the packets in hex format. example: the string \u0026quot;HTTP/1.1 304 Not Modified\u0026quot; becomes: 0000: 4854 5450 2f31 2e31 2033 3034 204e 6f74 HTTP/1.1 304 Not 0010: 204d 6f64 6966 6965 64 Modified ascii Print only \u0026quot;printable\u0026quot; characters, the others are displayed as dots '.' text Print only the \u0026quot;printable\u0026quot; characters and skip the others. ebcdic Convert an EBCDIC text to ASCII. html Strip all the html tags from the text. A tag is every string between \u0026lt; and \u0026gt;. example: \u0026lt;title\u0026gt;This is the title\u0026lt;/title\u0026gt;, but the following \u0026lt;string\u0026gt; will not be displayed. This is the title, but the following will not be displayed. utf8 Print the packets in UTF-8 format. The encoding used while performing the conversion is declared in the etter.conf(5) file. -d, --dns Resolve ip addresses into hostnames. NOTE: this may seriously slow down ettercap while logging passive information. Every time a new host is found, a query to the dns is performed. Ettercap keeps a cache for already re‐ solved host to increase the speed, but new hosts need a new query and the dns may take up to 2 or 3 seconds to respond for an unknown host. HINT: ettercap collects the dns replies it sniffs in the resolution table, so even if you specify to not resolve the hostnames, some of them will be resolved because the reply was pre‐ viously sniffed. think about it as a passive dns resolution for free... ;) -E, --ext-headers Print extended headers for every displayed packet. (e.g. mac addresses) -Q, --superquiet Super quiet mode. Do not print users and passwords as they are collected. Only store them in the profiles. It can be useful to run ettercap in text only mode but you don't want to be flooded with dissectors messages. Useful when using plugins because the sniffing process is always active, it will print all the collected infos, with this option you can suppress these messages. NOTE: this options automatically sets the -q option. example: ettercap -TzQP finger /192.168.0.1/22 LOGGING OPTIONS -L, --log \u0026lt;LOGFILE\u0026gt; Log all the packets to binary files. These files can be parsed by etterlog(8) to extract human readable data. With this option, all packets sniffed by ettercap will be logged, together with all the passive info (host info + user \u0026amp; pass) it can collect. Given a LOGFILE, ettercap will create LOGFILE.ecp (for packets) and LOGFILE.eci (for the infos). NOTE: if you specify this option on command line you don't have to take care of privileges since the log file is opened in the startup phase (with high privs). But if you enable the log option while ettercap is already started, you have to be in a directory where uid = 65535 or uid = EC_UID can write. NOTE: the logfiles can be compressed with the deflate algorithm using the -c option. -l, --log-info \u0026lt;LOGFILE\u0026gt; Very similar to -L but it logs only passive information + users and passwords for each host. The file will be named LOGFILE.eci -m, --log-msg \u0026lt;LOGFILE\u0026gt; It stores in \u0026lt;LOGFILE\u0026gt; all the user messages printed by ettercap. This can be useful when you are using ettercap in daemon mode or if you want to track down all the messages. Indeed, some dissectors print messages but their information is not stored anywhere, so this is the only way to keep track of them. -c, --compress Compress the logfile with the gzip algorithm while it is dumped. etterlog(8) is capable of handling both compressed and uncompressed log files. -o, --only-local Stores profiles information belonging only to the LAN hosts. NOTE: this option is effective only against the profiles collected in memory. While logging to a file ALL the hosts are logged. If you want to split them, use the related etterlog(8) option. -O, --only-remote Stores profiles information belonging only to remote hosts. STANDARD OPTIONS -v, --version Print the version and exit. -h, --help prints the help screen with a short summary of the available options. EXAMPLES Here are some examples of using ettercap. ettercap -Tp Use the console interface and do not put the interface in promisc mode. You will see only your traffic. ettercap -Tzq Use the console interface, do not ARP scan the net and be quiet. The packet content will not be displayed, but user and passwords, as well as other messages, will be displayed. ettercap -T -j /tmp/victims -M arp /10.0.0.1-7/ /10.0.0.10-20/ Will load the hosts list from /tmp/victims and perform an ARP poisoning attack against the two target. The list will be joined with the target and the resulting list is used for ARP poisoning. ettercap -T -M arp // // Perform the ARP poisoning attack against all the hosts in the LAN. BE CAREFUL !! ettercap -T -M arp:remote /192.168.1.1/ /192.168.1.2-10/ Perform the ARP poisoning against the gateway and the host in the lan between 2 and 10. The 'remote' option is needed to be able to sniff the remote traffic the hosts make through the gateway. ettercap -Tzq //110 Sniff only the pop3 protocol from every hosts. ettercap -Tzq /10.0.0.1/21,22,23 Sniff telnet, ftp and ssh connections to 10.0.0.1. ettercap -P list Prints the list of all available plugins FILES ~/.config/ettercap_gtk Stores persistent information (e.g., window placement) between sessions. ORIGINAL AUTHORS Alberto Ornaghi (ALoR) \u0026lt;alor@users.sf.net\u0026gt; Marco Valleri (NaGA) \u0026lt;naga@antifork.org\u0026gt; PROJECT STEWARDS Emilio Escobar (exfil) \u0026lt;eescobar@gmail.com\u0026gt; Eric Milam (Brav0Hax) \u0026lt;jbrav.hax@gmail.com\u0026gt; OFFICIAL DEVELOPERS Mike Ryan (justfalter) \u0026lt;falter@gmail.com\u0026gt; Gianfranco Costamagna (LocutusOfBorg) \u0026lt;costamagnagianfranco@yahoo.it\u0026gt; Antonio Collarino (sniper) \u0026lt;anto.collarino@gmail.com\u0026gt; Ryan Linn \u0026lt;sussuro@happypacket.net\u0026gt; Jacob Baines \u0026lt;baines.jacob@gmail.com\u0026gt; CONTRIBUTORS Dhiru Kholia (kholia) \u0026lt;dhiru@openwall.com\u0026gt; Alexander Koeppe (koeppea) \u0026lt;format_c@online.de\u0026gt; Martin Bos (PureHate) \u0026lt;purehate@backtrack.com\u0026gt; Enrique Sanchez Gisle Vanem \u0026lt;giva@bgnett.no\u0026gt; Johannes Bauer \u0026lt;JohannesBauer@gmx.de\u0026gt; Daten (Bryan Schneiders) \u0026lt;daten@dnetc.org\u0026gt; SEE ALSO etter.conf(5) ettercap_curses(8) ettercap_plugins(8) etterlog(8) etterfilter(8) ettercap-pkexec(8) AVAILABILITY https://github.com/Ettercap/ettercap/downloads GIT git clone git://github.com/Ettercap/ettercap.git or git clone https://github.com/Ettercap/ettercap.git BUGS Our software never has bugs. It just develops random features. ;) KNOWN-BUGS - ettercap doesn't handle fragmented packets... only the first segment will be displayed by the sniffer. However all the fragments are correctly forwarded. + please send bug-report, patches or suggestions to \u0026lt;ettercap-betatesting@lists.sourceforge.net\u0026gt; or visit https://github.com/Ettercap/ettercap/issues. + to report a bug, follow the instructions in the README.BUGS file PHILOLOGICAL HISTORY \u0026quot;Even if blessed with a feeble intelligence, they are cruel and smart...\u0026quot; this is the description of Ettercap, a monster of the RPG Advanced Dungeons \u0026amp; Dragon. The name \u0026quot;ettercap\u0026quot; was chosen because it has an assonance with \u0026quot;ethercap\u0026quot; which means \u0026quot;ethernet capture\u0026quot; (what ettercap actually does) and also because such monsters have a powerful poison... and you know, arp poisoning... ;) The Lord Of The (Token)Ring (the fellowship of the packet) \u0026quot;One Ring to link them all, One Ring to ping them, one Ring to bring them all and in the darkness sniff them.\u0026quot; Last words \u0026quot;Programming today is a race between software engineers striving to build bigger and better idiot-proof programs, and the Universe trying to produce bigger and better idiots. So far, the Uni‐ verse is winning.\u0026quot; - Rich Cook ettercap 0.8.3.1 ETTERCAP(8) ```bash "}),e.add({id:92,href:"/docs/tools/attack/hashcat/",title:"Hashcat",description:`Description # hashcat is the world\u0026rsquo;s fastest and most advanced password recovery utility, supporting five unique modes of attack for over 200 highly-optimized hashing algorithms. hashcat currently supports CPUs, GPUs, and other hardware accelerators on Linux, Windows, and OSX, and has facilities to help enable distributed password cracking.
Installation # brew install hashcat Usage # hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt Resources # hashcat hashcat on GitHub See Also # John the Ripper Hydra Ncrack help # hashcat (v6.`,content:"Description # hashcat is the world\u0026rsquo;s fastest and most advanced password recovery utility, supporting five unique modes of attack for over 200 highly-optimized hashing algorithms. hashcat currently supports CPUs, GPUs, and other hardware accelerators on Linux, Windows, and OSX, and has facilities to help enable distributed password cracking.\nInstallation # brew install hashcat Usage # hashcat -m 0 -a 0 hash.txt /usr/share/wordlists/rockyou.txt Resources # hashcat hashcat on GitHub See Also # John the Ripper Hydra Ncrack help # hashcat (v6.2.6) starting in help mode Usage: hashcat [options]... hash|hashfile|hccapxfile [dictionary|mask|directory]... - [ Options ] - Options Short / Long | Type | Description | Example ================================+======+======================================================+======================= -m, --hash-type | Num | Hash-type, references below (otherwise autodetect) | -m 1000 -a, --attack-mode | Num | Attack-mode, see references below | -a 3 -V, --version | | Print version | -h, --help | | Print help | --quiet | | Suppress output | --hex-charset | | Assume charset is given in hex | --hex-salt | | Assume salt is given in hex | --hex-wordlist | | Assume words in wordlist are given in hex | --force | | Ignore warnings | --deprecated-check-disable | | Enable deprecated plugins | --status | | Enable automatic update of the status screen | --status-json | | Enable JSON format for status output | --status-timer | Num | Sets seconds between status screen updates to X | --status-timer=1 --stdin-timeout-abort | Num | Abort if there is no input from stdin for X seconds | --stdin-timeout-abort=300 --machine-readable | | Display the status view in a machine-readable format | --keep-guessing | | Keep guessing the hash after it has been cracked | --self-test-disable | | Disable self-test functionality on startup | --loopback | | Add new plains to induct directory | --markov-hcstat2 | File | Specify hcstat2 file to use | --markov-hcstat2=my.hcstat2 --markov-disable | | Disables markov-chains, emulates classic brute-force | --markov-classic | | Enables classic markov-chains, no per-position | --markov-inverse | | Enables inverse markov-chains, no per-position | -t, --markov-threshold | Num | Threshold X when to stop accepting new markov-chains | -t 50 --runtime | Num | Abort session after X seconds of runtime | --runtime=10 --session | Str | Define specific session name | --session=mysession --restore | | Restore session from --session | --restore-disable | | Do not write restore file | --restore-file-path | File | Specific path to restore file | --restore-file-path=x.restore -o, --outfile | File | Define outfile for recovered hash | -o outfile.txt --outfile-format | Str | Outfile format to use, separated with commas | --outfile-format=1,3 --outfile-autohex-disable | | Disable the use of $HEX[] in output plains | --outfile-check-timer | Num | Sets seconds between outfile checks to X | --outfile-check-timer=30 --wordlist-autohex-disable | | Disable the conversion of $HEX[] from the wordlist | -p, --separator | Char | Separator char for hashlists and outfile | -p : --stdout | | Do not crack a hash, instead print candidates only | --show | | Compare hashlist with potfile; show cracked hashes | --left | | Compare hashlist with potfile; show uncracked hashes | --username | | Enable ignoring of usernames in hashfile | --remove | | Enable removal of hashes once they are cracked | --remove-timer | Num | Update input hash file each X seconds | --remove-timer=30 --potfile-disable | | Do not write potfile | --potfile-path | File | Specific path to potfile | --potfile-path=my.pot --encoding-from | Code | Force internal wordlist encoding from X | --encoding-from=iso-8859-15 --encoding-to | Code | Force internal wordlist encoding to X | --encoding-to=utf-32le --debug-mode | Num | Defines the debug mode (hybrid only by using rules) | --debug-mode=4 --debug-file | File | Output file for debugging rules | --debug-file=good.log --induction-dir | Dir | Specify the induction directory to use for loopback | --induction=inducts --outfile-check-dir | Dir | Specify the outfile directory to monitor for plains | --outfile-check-dir=x --logfile-disable | | Disable the logfile | --hccapx-message-pair | Num | Load only message pairs from hccapx matching X | --hccapx-message-pair=2 --nonce-error-corrections | Num | The BF size range to replace AP's nonce last bytes | --nonce-error-corrections=16 --keyboard-layout-mapping | File | Keyboard layout mapping table for special hash-modes | --keyb=german.hckmap --truecrypt-keyfiles | File | Keyfiles to use, separated with commas | --truecrypt-keyf=x.png --veracrypt-keyfiles | File | Keyfiles to use, separated with commas | --veracrypt-keyf=x.txt --veracrypt-pim-start | Num | VeraCrypt personal iterations multiplier start | --veracrypt-pim-start=450 --veracrypt-pim-stop | Num | VeraCrypt personal iterations multiplier stop | --veracrypt-pim-stop=500 -b, --benchmark | | Run benchmark of selected hash-modes | --benchmark-all | | Run benchmark of all hash-modes (requires -b) | --speed-only | | Return expected speed of the attack, then quit | --progress-only | | Return ideal progress step size and time to process | -c, --segment-size | Num | Sets size in MB to cache from the wordfile to X | -c 32 --bitmap-min | Num | Sets minimum bits allowed for bitmaps to X | --bitmap-min=24 --bitmap-max | Num | Sets maximum bits allowed for bitmaps to X | --bitmap-max=24 --cpu-affinity | Str | Locks to CPU devices, separated with commas | --cpu-affinity=1,2,3 --hook-threads | Num | Sets number of threads for a hook (per compute unit) | --hook-threads=8 --hash-info | | Show information for each hash-mode | --example-hashes | | Alias of --hash-info | --backend-ignore-cuda | | Do not try to open CUDA interface on startup | --backend-ignore-hip | | Do not try to open HIP interface on startup | --backend-ignore-metal | | Do not try to open Metal interface on startup | --backend-ignore-opencl | | Do not try to open OpenCL interface on startup | -I, --backend-info | | Show system/evironment/backend API info | -I or -II -d, --backend-devices | Str | Backend devices to use, separated with commas | -d 1 -D, --opencl-device-types | Str | OpenCL device-types to use, separated with commas | -D 1 -O, --optimized-kernel-enable | | Enable optimized kernels (limits password length) | -M, --multiply-accel-disable | | Disable multiply kernel-accel with processor count | -w, --workload-profile | Num | Enable a specific workload profile, see pool below | -w 3 -n, --kernel-accel | Num | Manual workload tuning, set outerloop step size to X | -n 64 -u, --kernel-loops | Num | Manual workload tuning, set innerloop step size to X | -u 256 -T, --kernel-threads | Num | Manual workload tuning, set thread count to X | -T 64 --backend-vector-width | Num | Manually override backend vector-width to X | --backend-vector=4 --spin-damp | Num | Use CPU for device synchronization, in percent | --spin-damp=10 --hwmon-disable | | Disable temperature and fanspeed reads and triggers | --hwmon-temp-abort | Num | Abort if temperature reaches X degrees Celsius | --hwmon-temp-abort=100 --scrypt-tmto | Num | Manually override TMTO value for scrypt to X | --scrypt-tmto=3 -s, --skip | Num | Skip X words from the start | -s 1000000 -l, --limit | Num | Limit X words from the start + skipped words | -l 1000000 --keyspace | | Show keyspace base:mod values and quit | -j, --rule-left | Rule | Single rule applied to each word from left wordlist | -j 'c' -k, --rule-right | Rule | Single rule applied to each word from right wordlist | -k '^-' -r, --rules-file | File | Multiple rules applied to each word from wordlists | -r rules/best64.rule -g, --generate-rules | Num | Generate X random rules | -g 10000 --generate-rules-func-min | Num | Force min X functions per rule | --generate-rules-func-max | Num | Force max X functions per rule | --generate-rules-func-sel | Str | Pool of rule operators valid for random rule engine | --generate-rules-func-sel=ioTlc --generate-rules-seed | Num | Force RNG seed set to X | -1, --custom-charset1 | CS | User-defined charset ?1 | -1 ?l?d?u -2, --custom-charset2 | CS | User-defined charset ?2 | -2 ?l?d?s -3, --custom-charset3 | CS | User-defined charset ?3 | -4, --custom-charset4 | CS | User-defined charset ?4 | --identify | | Shows all supported algorithms for input hashes | --identify my.hash -i, --increment | | Enable mask increment mode | --increment-min | Num | Start mask incrementing at X | --increment-min=4 --increment-max | Num | Stop mask incrementing at X | --increment-max=8 -S, --slow-candidates | | Enable slower (but advanced) candidate generators | --brain-server | | Enable brain server | --brain-server-timer | Num | Update the brain server dump each X seconds (min:60) | --brain-server-timer=300 -z, --brain-client | | Enable brain client, activates -S | --brain-client-features | Num | Define brain client features, see below | --brain-client-features=3 --brain-host | Str | Brain server host (IP or domain) | --brain-host=127.0.0.1 --brain-port | Port | Brain server port | --brain-port=13743 --brain-password | Str | Brain server authentication password | --brain-password=bZfhCvGUSjRq --brain-session | Hex | Overrides automatically calculated brain session | --brain-session=0x2ae611db --brain-session-whitelist | Hex | Allow given sessions only, separated with commas | --brain-session-whitelist=0x2ae611db - [ Hash modes ] - # | Name | Category ======+============================================================+====================================== 900 | MD4 | Raw Hash 0 | MD5 | Raw Hash 100 | SHA1 | Raw Hash 1300 | SHA2-224 | Raw Hash 1400 | SHA2-256 | Raw Hash 10800 | SHA2-384 | Raw Hash 1700 | SHA2-512 | Raw Hash 17300 | SHA3-224 | Raw Hash 17400 | SHA3-256 | Raw Hash 17500 | SHA3-384 | Raw Hash 17600 | SHA3-512 | Raw Hash 6000 | RIPEMD-160 | Raw Hash 600 | BLAKE2b-512 | Raw Hash 11700 | GOST R 34.11-2012 (Streebog) 256-bit, big-endian | Raw Hash 11800 | GOST R 34.11-2012 (Streebog) 512-bit, big-endian | Raw Hash 6900 | GOST R 34.11-94 | Raw Hash 17010 | GPG (AES-128/AES-256 (SHA-1($pass))) | Raw Hash 5100 | Half MD5 | Raw Hash 17700 | Keccak-224 | Raw Hash 17800 | Keccak-256 | Raw Hash 17900 | Keccak-384 | Raw Hash 18000 | Keccak-512 | Raw Hash 6100 | Whirlpool | Raw Hash 10100 | SipHash | Raw Hash 70 | md5(utf16le($pass)) | Raw Hash 170 | sha1(utf16le($pass)) | Raw Hash 1470 | sha256(utf16le($pass)) | Raw Hash 10870 | sha384(utf16le($pass)) | Raw Hash 1770 | sha512(utf16le($pass)) | Raw Hash 610 | BLAKE2b-512($pass.$salt) | Raw Hash salted and/or iterated 620 | BLAKE2b-512($salt.$pass) | Raw Hash salted and/or iterated 10 | md5($pass.$salt) | Raw Hash salted and/or iterated 20 | md5($salt.$pass) | Raw Hash salted and/or iterated 3800 | md5($salt.$pass.$salt) | Raw Hash salted and/or iterated 3710 | md5($salt.md5($pass)) | Raw Hash salted and/or iterated 4110 | md5($salt.md5($pass.$salt)) | Raw Hash salted and/or iterated 4010 | md5($salt.md5($salt.$pass)) | Raw Hash salted and/or iterated 21300 | md5($salt.sha1($salt.$pass)) | Raw Hash salted and/or iterated 40 | md5($salt.utf16le($pass)) | Raw Hash salted and/or iterated 2600 | md5(md5($pass)) | Raw Hash salted and/or iterated 3910 | md5(md5($pass).md5($salt)) | Raw Hash salted and/or iterated 3500 | md5(md5(md5($pass))) | Raw Hash salted and/or iterated 4400 | md5(sha1($pass)) | Raw Hash salted and/or iterated 4410 | md5(sha1($pass).$salt) | Raw Hash salted and/or iterated 20900 | md5(sha1($pass).md5($pass).sha1($pass)) | Raw Hash salted and/or iterated 21200 | md5(sha1($salt).md5($pass)) | Raw Hash salted and/or iterated 4300 | md5(strtoupper(md5($pass))) | Raw Hash salted and/or iterated 30 | md5(utf16le($pass).$salt) | Raw Hash salted and/or iterated 110 | sha1($pass.$salt) | Raw Hash salted and/or iterated 120 | sha1($salt.$pass) | Raw Hash salted and/or iterated 4900 | sha1($salt.$pass.$salt) | Raw Hash salted and/or iterated 4520 | sha1($salt.sha1($pass)) | Raw Hash salted and/or iterated 24300 | sha1($salt.sha1($pass.$salt)) | Raw Hash salted and/or iterated 140 | sha1($salt.utf16le($pass)) | Raw Hash salted and/or iterated 19300 | sha1($salt1.$pass.$salt2) | Raw Hash salted and/or iterated 14400 | sha1(CX) | Raw Hash salted and/or iterated 4700 | sha1(md5($pass)) | Raw Hash salted and/or iterated 4710 | sha1(md5($pass).$salt) | Raw Hash salted and/or iterated 21100 | sha1(md5($pass.$salt)) | Raw Hash salted and/or iterated 18500 | sha1(md5(md5($pass))) | Raw Hash salted and/or iterated 4500 | sha1(sha1($pass)) | Raw Hash salted and/or iterated 4510 | sha1(sha1($pass).$salt) | Raw Hash salted and/or iterated 5000 | sha1(sha1($salt.$pass.$salt)) | Raw Hash salted and/or iterated 130 | sha1(utf16le($pass).$salt) | Raw Hash salted and/or iterated 1410 | sha256($pass.$salt) | Raw Hash salted and/or iterated 1420 | sha256($salt.$pass) | Raw Hash salted and/or iterated 22300 | sha256($salt.$pass.$salt) | Raw Hash salted and/or iterated 20720 | sha256($salt.sha256($pass)) | Raw Hash salted and/or iterated 21420 | sha256($salt.sha256_bin($pass)) | Raw Hash salted and/or iterated 1440 | sha256($salt.utf16le($pass)) | Raw Hash salted and/or iterated 20800 | sha256(md5($pass)) | Raw Hash salted and/or iterated 20710 | sha256(sha256($pass).$salt) | Raw Hash salted and/or iterated 21400 | sha256(sha256_bin($pass)) | Raw Hash salted and/or iterated 1430 | sha256(utf16le($pass).$salt) | Raw Hash salted and/or iterated 10810 | sha384($pass.$salt) | Raw Hash salted and/or iterated 10820 | sha384($salt.$pass) | Raw Hash salted and/or iterated 10840 | sha384($salt.utf16le($pass)) | Raw Hash salted and/or iterated 10830 | sha384(utf16le($pass).$salt) | Raw Hash salted and/or iterated 1710 | sha512($pass.$salt) | Raw Hash salted and/or iterated 1720 | sha512($salt.$pass) | Raw Hash salted and/or iterated 1740 | sha512($salt.utf16le($pass)) | Raw Hash salted and/or iterated 1730 | sha512(utf16le($pass).$salt) | Raw Hash salted and/or iterated 50 | HMAC-MD5 (key = $pass) | Raw Hash authenticated 60 | HMAC-MD5 (key = $salt) | Raw Hash authenticated 150 | HMAC-SHA1 (key = $pass) | Raw Hash authenticated 160 | HMAC-SHA1 (key = $salt) | Raw Hash authenticated 1450 | HMAC-SHA256 (key = $pass) | Raw Hash authenticated 1460 | HMAC-SHA256 (key = $salt) | Raw Hash authenticated 1750 | HMAC-SHA512 (key = $pass) | Raw Hash authenticated 1760 | HMAC-SHA512 (key = $salt) | Raw Hash authenticated 11750 | HMAC-Streebog-256 (key = $pass), big-endian | Raw Hash authenticated 11760 | HMAC-Streebog-256 (key = $salt), big-endian | Raw Hash authenticated 11850 | HMAC-Streebog-512 (key = $pass), big-endian | Raw Hash authenticated 11860 | HMAC-Streebog-512 (key = $salt), big-endian | Raw Hash authenticated 28700 | Amazon AWS4-HMAC-SHA256 | Raw Hash authenticated 11500 | CRC32 | Raw Checksum 27900 | CRC32C | Raw Checksum 28000 | CRC64Jones | Raw Checksum 18700 | Java Object hashCode() | Raw Checksum 25700 | MurmurHash | Raw Checksum 27800 | MurmurHash3 | Raw Checksum 14100 | 3DES (PT = $salt, key = $pass) | Raw Cipher, Known-plaintext attack 14000 | DES (PT = $salt, key = $pass) | Raw Cipher, Known-plaintext attack 26401 | AES-128-ECB NOKDF (PT = $salt, key = $pass) | Raw Cipher, Known-plaintext attack 26402 | AES-192-ECB NOKDF (PT = $salt, key = $pass) | Raw Cipher, Known-plaintext attack 26403 | AES-256-ECB NOKDF (PT = $salt, key = $pass) | Raw Cipher, Known-plaintext attack 15400 | ChaCha20 | Raw Cipher, Known-plaintext attack 14500 | Linux Kernel Crypto API (2.4) | Raw Cipher, Known-plaintext attack 14900 | Skip32 (PT = $salt, key = $pass) | Raw Cipher, Known-plaintext attack 11900 | PBKDF2-HMAC-MD5 | Generic KDF 12000 | PBKDF2-HMAC-SHA1 | Generic KDF 10900 | PBKDF2-HMAC-SHA256 | Generic KDF 12100 | PBKDF2-HMAC-SHA512 | Generic KDF 8900 | scrypt | Generic KDF 400 | phpass | Generic KDF 16100 | TACACS+ | Network Protocol 11400 | SIP digest authentication (MD5) | Network Protocol 5300 | IKE-PSK MD5 | Network Protocol 5400 | IKE-PSK SHA1 | Network Protocol 25100 | SNMPv3 HMAC-MD5-96 | Network Protocol 25000 | SNMPv3 HMAC-MD5-96/HMAC-SHA1-96 | Network Protocol 25200 | SNMPv3 HMAC-SHA1-96 | Network Protocol 26700 | SNMPv3 HMAC-SHA224-128 | Network Protocol 26800 | SNMPv3 HMAC-SHA256-192 | Network Protocol 26900 | SNMPv3 HMAC-SHA384-256 | Network Protocol 27300 | SNMPv3 HMAC-SHA512-384 | Network Protocol 2500 | WPA-EAPOL-PBKDF2 | Network Protocol 2501 | WPA-EAPOL-PMK | Network Protocol 22000 | WPA-PBKDF2-PMKID+EAPOL | Network Protocol 22001 | WPA-PMK-PMKID+EAPOL | Network Protocol 16800 | WPA-PMKID-PBKDF2 | Network Protocol 16801 | WPA-PMKID-PMK | Network Protocol 7300 | IPMI2 RAKP HMAC-SHA1 | Network Protocol 10200 | CRAM-MD5 | Network Protocol 16500 | JWT (JSON Web Token) | Network Protocol 29200 | Radmin3 | Network Protocol 19600 | Kerberos 5, etype 17, TGS-REP | Network Protocol 19800 | Kerberos 5, etype 17, Pre-Auth | Network Protocol 28800 | Kerberos 5, etype 17, DB | Network Protocol 19700 | Kerberos 5, etype 18, TGS-REP | Network Protocol 19900 | Kerberos 5, etype 18, Pre-Auth | Network Protocol 28900 | Kerberos 5, etype 18, DB | Network Protocol 7500 | Kerberos 5, etype 23, AS-REQ Pre-Auth | Network Protocol 13100 | Kerberos 5, etype 23, TGS-REP | Network Protocol 18200 | Kerberos 5, etype 23, AS-REP | Network Protocol 5500 | NetNTLMv1 / NetNTLMv1+ESS | Network Protocol 27000 | NetNTLMv1 / NetNTLMv1+ESS (NT) | Network Protocol 5600 | NetNTLMv2 | Network Protocol 27100 | NetNTLMv2 (NT) | Network Protocol 29100 | Flask Session Cookie ($salt.$salt.$pass) | Network Protocol 4800 | iSCSI CHAP authentication, MD5(CHAP) | Network Protocol 8500 | RACF | Operating System 6300 | AIX {smd5} | Operating System 6700 | AIX {ssha1} | Operating System 6400 | AIX {ssha256} | Operating System 6500 | AIX {ssha512} | Operating System 3000 | LM | Operating System 19000 | QNX /etc/shadow (MD5) | Operating System 19100 | QNX /etc/shadow (SHA256) | Operating System 19200 | QNX /etc/shadow (SHA512) | Operating System 15300 | DPAPI masterkey file v1 (context 1 and 2) | Operating System 15310 | DPAPI masterkey file v1 (context 3) | Operating System 15900 | DPAPI masterkey file v2 (context 1 and 2) | Operating System 15910 | DPAPI masterkey file v2 (context 3) | Operating System 7200 | GRUB 2 | Operating System 12800 | MS-AzureSync PBKDF2-HMAC-SHA256 | Operating System 12400 | BSDi Crypt, Extended DES | Operating System 1000 | NTLM | Operating System 9900 | Radmin2 | Operating System 5800 | Samsung Android Password/PIN | Operating System 28100 | Windows Hello PIN/Password | Operating System 13800 | Windows Phone 8+ PIN/password | Operating System 2410 | Cisco-ASA MD5 | Operating System 9200 | Cisco-IOS $8$ (PBKDF2-SHA256) | Operating System 9300 | Cisco-IOS $9$ (scrypt) | Operating System 5700 | Cisco-IOS type 4 (SHA256) | Operating System 2400 | Cisco-PIX MD5 | Operating System 8100 | Citrix NetScaler (SHA1) | Operating System 22200 | Citrix NetScaler (SHA512) | Operating System 1100 | Domain Cached Credentials (DCC), MS Cache | Operating System 2100 | Domain Cached Credentials 2 (DCC2), MS Cache 2 | Operating System 7000 | FortiGate (FortiOS) | Operating System 26300 | FortiGate256 (FortiOS256) | Operating System 125 | ArubaOS | Operating System 501 | Juniper IVE | Operating System 22 | Juniper NetScreen/SSG (ScreenOS) | Operating System 15100 | Juniper/NetBSD sha1crypt | Operating System 26500 | iPhone passcode (UID key + System Keybag) | Operating System 122 | macOS v10.4, macOS v10.5, macOS v10.6 | Operating System 1722 | macOS v10.7 | Operating System 7100 | macOS v10.8+ (PBKDF2-SHA512) | Operating System 3200 | bcrypt $2*$, Blowfish (Unix) | Operating System 500 | md5crypt, MD5 (Unix), Cisco-IOS $1$ (MD5) | Operating System 1500 | descrypt, DES (Unix), Traditional DES | Operating System 29000 | sha1($salt.sha1(utf16le($username).':'.utf16le($pass))) | Operating System 7400 | sha256crypt $5$, SHA256 (Unix) | Operating System 1800 | sha512crypt $6$, SHA512 (Unix) | Operating System 24600 | SQLCipher | Database Server 131 | MSSQL (2000) | Database Server 132 | MSSQL (2005) | Database Server 1731 | MSSQL (2012, 2014) | Database Server 24100 | MongoDB ServerKey SCRAM-SHA-1 | Database Server 24200 | MongoDB ServerKey SCRAM-SHA-256 | Database Server 12 | PostgreSQL | Database Server 11100 | PostgreSQL CRAM (MD5) | Database Server 28600 | PostgreSQL SCRAM-SHA-256 | Database Server 3100 | Oracle H: Type (Oracle 7+) | Database Server 112 | Oracle S: Type (Oracle 11+) | Database Server 12300 | Oracle T: Type (Oracle 12+) | Database Server 7401 | MySQL $A$ (sha256crypt) | Database Server 11200 | MySQL CRAM (SHA1) | Database Server 200 | MySQL323 | Database Server 300 | MySQL4.1/MySQL5 | Database Server 8000 | Sybase ASE | Database Server 8300 | DNSSEC (NSEC3) | FTP, HTTP, SMTP, LDAP Server 25900 | KNX IP Secure - Device Authentication Code | FTP, HTTP, SMTP, LDAP Server 16400 | CRAM-MD5 Dovecot | FTP, HTTP, SMTP, LDAP Server 1411 | SSHA-256(Base64), LDAP {SSHA256} | FTP, HTTP, SMTP, LDAP Server 1711 | SSHA-512(Base64), LDAP {SSHA512} | FTP, HTTP, SMTP, LDAP Server 24900 | Dahua Authentication MD5 | FTP, HTTP, SMTP, LDAP Server 10901 | RedHat 389-DS LDAP (PBKDF2-HMAC-SHA256) | FTP, HTTP, SMTP, LDAP Server 15000 | FileZilla Server \u0026gt;= 0.9.55 | FTP, HTTP, SMTP, LDAP Server 12600 | ColdFusion 10+ | FTP, HTTP, SMTP, LDAP Server 1600 | Apache $apr1$ MD5, md5apr1, MD5 (APR) | FTP, HTTP, SMTP, LDAP Server 141 | Episerver 6.x \u0026lt; .NET 4 | FTP, HTTP, SMTP, LDAP Server 1441 | Episerver 6.x \u0026gt;= .NET 4 | FTP, HTTP, SMTP, LDAP Server 1421 | hMailServer | FTP, HTTP, SMTP, LDAP Server 101 | nsldap, SHA-1(Base64), Netscape LDAP SHA | FTP, HTTP, SMTP, LDAP Server 111 | nsldaps, SSHA-1(Base64), Netscape LDAP SSHA | FTP, HTTP, SMTP, LDAP Server 7700 | SAP CODVN B (BCODE) | Enterprise Application Software (EAS) 7701 | SAP CODVN B (BCODE) from RFC_READ_TABLE | Enterprise Application Software (EAS) 7800 | SAP CODVN F/G (PASSCODE) | Enterprise Application Software (EAS) 7801 | SAP CODVN F/G (PASSCODE) from RFC_READ_TABLE | Enterprise Application Software (EAS) 10300 | SAP CODVN H (PWDSALTEDHASH) iSSHA-1 | Enterprise Application Software (EAS) 133 | PeopleSoft | Enterprise Application Software (EAS) 13500 | PeopleSoft PS_TOKEN | Enterprise Application Software (EAS) 21500 | SolarWinds Orion | Enterprise Application Software (EAS) 21501 | SolarWinds Orion v2 | Enterprise Application Software (EAS) 24 | SolarWinds Serv-U | Enterprise Application Software (EAS) 8600 | Lotus Notes/Domino 5 | Enterprise Application Software (EAS) 8700 | Lotus Notes/Domino 6 | Enterprise Application Software (EAS) 9100 | Lotus Notes/Domino 8 | Enterprise Application Software (EAS) 26200 | OpenEdge Progress Encode | Enterprise Application Software (EAS) 20600 | Oracle Transportation Management (SHA256) | Enterprise Application Software (EAS) 4711 | Huawei sha1(md5($pass).$salt) | Enterprise Application Software (EAS) 20711 | AuthMe sha256 | Enterprise Application Software (EAS) 22400 | AES Crypt (SHA256) | Full-Disk Encryption (FDE) 27400 | VMware VMX (PBKDF2-HMAC-SHA1 + AES-256-CBC) | Full-Disk Encryption (FDE) 14600 | LUKS v1 (legacy) | Full-Disk Encryption (FDE) 29541 | LUKS v1 RIPEMD-160 + AES | Full-Disk Encryption (FDE) 29542 | LUKS v1 RIPEMD-160 + Serpent | Full-Disk Encryption (FDE) 29543 | LUKS v1 RIPEMD-160 + Twofish | Full-Disk Encryption (FDE) 29511 | LUKS v1 SHA-1 + AES | Full-Disk Encryption (FDE) 29512 | LUKS v1 SHA-1 + Serpent | Full-Disk Encryption (FDE) 29513 | LUKS v1 SHA-1 + Twofish | Full-Disk Encryption (FDE) 29521 | LUKS v1 SHA-256 + AES | Full-Disk Encryption (FDE) 29522 | LUKS v1 SHA-256 + Serpent | Full-Disk Encryption (FDE) 29523 | LUKS v1 SHA-256 + Twofish | Full-Disk Encryption (FDE) 29531 | LUKS v1 SHA-512 + AES | Full-Disk Encryption (FDE) 29532 | LUKS v1 SHA-512 + Serpent | Full-Disk Encryption (FDE) 29533 | LUKS v1 SHA-512 + Twofish | Full-Disk Encryption (FDE) 13711 | VeraCrypt RIPEMD160 + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 13712 | VeraCrypt RIPEMD160 + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 13713 | VeraCrypt RIPEMD160 + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 13741 | VeraCrypt RIPEMD160 + XTS 512 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 13742 | VeraCrypt RIPEMD160 + XTS 1024 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 13743 | VeraCrypt RIPEMD160 + XTS 1536 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 29411 | VeraCrypt RIPEMD160 + XTS 512 bit | Full-Disk Encryption (FDE) 29412 | VeraCrypt RIPEMD160 + XTS 1024 bit | Full-Disk Encryption (FDE) 29413 | VeraCrypt RIPEMD160 + XTS 1536 bit | Full-Disk Encryption (FDE) 29441 | VeraCrypt RIPEMD160 + XTS 512 bit + boot-mode | Full-Disk Encryption (FDE) 29442 | VeraCrypt RIPEMD160 + XTS 1024 bit + boot-mode | Full-Disk Encryption (FDE) 29443 | VeraCrypt RIPEMD160 + XTS 1536 bit + boot-mode | Full-Disk Encryption (FDE) 13751 | VeraCrypt SHA256 + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 13752 | VeraCrypt SHA256 + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 13753 | VeraCrypt SHA256 + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 13761 | VeraCrypt SHA256 + XTS 512 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 13762 | VeraCrypt SHA256 + XTS 1024 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 13763 | VeraCrypt SHA256 + XTS 1536 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 29451 | VeraCrypt SHA256 + XTS 512 bit | Full-Disk Encryption (FDE) 29452 | VeraCrypt SHA256 + XTS 1024 bit | Full-Disk Encryption (FDE) 29453 | VeraCrypt SHA256 + XTS 1536 bit | Full-Disk Encryption (FDE) 29461 | VeraCrypt SHA256 + XTS 512 bit + boot-mode | Full-Disk Encryption (FDE) 29462 | VeraCrypt SHA256 + XTS 1024 bit + boot-mode | Full-Disk Encryption (FDE) 29463 | VeraCrypt SHA256 + XTS 1536 bit + boot-mode | Full-Disk Encryption (FDE) 13721 | VeraCrypt SHA512 + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 13722 | VeraCrypt SHA512 + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 13723 | VeraCrypt SHA512 + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 29421 | VeraCrypt SHA512 + XTS 512 bit | Full-Disk Encryption (FDE) 29422 | VeraCrypt SHA512 + XTS 1024 bit | Full-Disk Encryption (FDE) 29423 | VeraCrypt SHA512 + XTS 1536 bit | Full-Disk Encryption (FDE) 13771 | VeraCrypt Streebog-512 + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 13772 | VeraCrypt Streebog-512 + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 13773 | VeraCrypt Streebog-512 + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 13781 | VeraCrypt Streebog-512 + XTS 512 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 13782 | VeraCrypt Streebog-512 + XTS 1024 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 13783 | VeraCrypt Streebog-512 + XTS 1536 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 29471 | VeraCrypt Streebog-512 + XTS 512 bit | Full-Disk Encryption (FDE) 29472 | VeraCrypt Streebog-512 + XTS 1024 bit | Full-Disk Encryption (FDE) 29473 | VeraCrypt Streebog-512 + XTS 1536 bit | Full-Disk Encryption (FDE) 29481 | VeraCrypt Streebog-512 + XTS 512 bit + boot-mode | Full-Disk Encryption (FDE) 29482 | VeraCrypt Streebog-512 + XTS 1024 bit + boot-mode | Full-Disk Encryption (FDE) 29483 | VeraCrypt Streebog-512 + XTS 1536 bit + boot-mode | Full-Disk Encryption (FDE) 13731 | VeraCrypt Whirlpool + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 13732 | VeraCrypt Whirlpool + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 13733 | VeraCrypt Whirlpool + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 29431 | VeraCrypt Whirlpool + XTS 512 bit | Full-Disk Encryption (FDE) 29432 | VeraCrypt Whirlpool + XTS 1024 bit | Full-Disk Encryption (FDE) 29433 | VeraCrypt Whirlpool + XTS 1536 bit | Full-Disk Encryption (FDE) 23900 | BestCrypt v3 Volume Encryption | Full-Disk Encryption (FDE) 16700 | FileVault 2 | Full-Disk Encryption (FDE) 27500 | VirtualBox (PBKDF2-HMAC-SHA256 \u0026amp; AES-128-XTS) | Full-Disk Encryption (FDE) 27600 | VirtualBox (PBKDF2-HMAC-SHA256 \u0026amp; AES-256-XTS) | Full-Disk Encryption (FDE) 20011 | DiskCryptor SHA512 + XTS 512 bit | Full-Disk Encryption (FDE) 20012 | DiskCryptor SHA512 + XTS 1024 bit | Full-Disk Encryption (FDE) 20013 | DiskCryptor SHA512 + XTS 1536 bit | Full-Disk Encryption (FDE) 22100 | BitLocker | Full-Disk Encryption (FDE) 12900 | Android FDE (Samsung DEK) | Full-Disk Encryption (FDE) 8800 | Android FDE \u0026lt;= 4.3 | Full-Disk Encryption (FDE) 18300 | Apple File System (APFS) | Full-Disk Encryption (FDE) 6211 | TrueCrypt RIPEMD160 + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 6212 | TrueCrypt RIPEMD160 + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 6213 | TrueCrypt RIPEMD160 + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 6241 | TrueCrypt RIPEMD160 + XTS 512 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 6242 | TrueCrypt RIPEMD160 + XTS 1024 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 6243 | TrueCrypt RIPEMD160 + XTS 1536 bit + boot-mode (legacy) | Full-Disk Encryption (FDE) 29311 | TrueCrypt RIPEMD160 + XTS 512 bit | Full-Disk Encryption (FDE) 29312 | TrueCrypt RIPEMD160 + XTS 1024 bit | Full-Disk Encryption (FDE) 29313 | TrueCrypt RIPEMD160 + XTS 1536 bit | Full-Disk Encryption (FDE) 29341 | TrueCrypt RIPEMD160 + XTS 512 bit + boot-mode | Full-Disk Encryption (FDE) 29342 | TrueCrypt RIPEMD160 + XTS 1024 bit + boot-mode | Full-Disk Encryption (FDE) 29343 | TrueCrypt RIPEMD160 + XTS 1536 bit + boot-mode | Full-Disk Encryption (FDE) 6221 | TrueCrypt SHA512 + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 6222 | TrueCrypt SHA512 + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 6223 | TrueCrypt SHA512 + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 29321 | TrueCrypt SHA512 + XTS 512 bit | Full-Disk Encryption (FDE) 29322 | TrueCrypt SHA512 + XTS 1024 bit | Full-Disk Encryption (FDE) 29323 | TrueCrypt SHA512 + XTS 1536 bit | Full-Disk Encryption (FDE) 6231 | TrueCrypt Whirlpool + XTS 512 bit (legacy) | Full-Disk Encryption (FDE) 6232 | TrueCrypt Whirlpool + XTS 1024 bit (legacy) | Full-Disk Encryption (FDE) 6233 | TrueCrypt Whirlpool + XTS 1536 bit (legacy) | Full-Disk Encryption (FDE) 29331 | TrueCrypt Whirlpool + XTS 512 bit | Full-Disk Encryption (FDE) 29332 | TrueCrypt Whirlpool + XTS 1024 bit | Full-Disk Encryption (FDE) 29333 | TrueCrypt Whirlpool + XTS 1536 bit | Full-Disk Encryption (FDE) 12200 | eCryptfs | Full-Disk Encryption (FDE) 10400 | PDF 1.1 - 1.3 (Acrobat 2 - 4) | Document 10410 | PDF 1.1 - 1.3 (Acrobat 2 - 4), collider #1 | Document 10420 | PDF 1.1 - 1.3 (Acrobat 2 - 4), collider #2 | Document 10500 | PDF 1.4 - 1.6 (Acrobat 5 - 8) | Document 25400 | PDF 1.4 - 1.6 (Acrobat 5 - 8) - user and owner pass | Document 10600 | PDF 1.7 Level 3 (Acrobat 9) | Document 10700 | PDF 1.7 Level 8 (Acrobat 10 - 11) | Document 9400 | MS Office 2007 | Document 9500 | MS Office 2010 | Document 9600 | MS Office 2013 | Document 25300 | MS Office 2016 - SheetProtection | Document 9700 | MS Office \u0026lt;= 2003 $0/$1, MD5 + RC4 | Document 9710 | MS Office \u0026lt;= 2003 $0/$1, MD5 + RC4, collider #1 | Document 9720 | MS Office \u0026lt;= 2003 $0/$1, MD5 + RC4, collider #2 | Document 9810 | MS Office \u0026lt;= 2003 $3, SHA1 + RC4, collider #1 | Document 9820 | MS Office \u0026lt;= 2003 $3, SHA1 + RC4, collider #2 | Document 9800 | MS Office \u0026lt;= 2003 $3/$4, SHA1 + RC4 | Document 18400 | Open Document Format (ODF) 1.2 (SHA-256, AES) | Document 18600 | Open Document Format (ODF) 1.1 (SHA-1, Blowfish) | Document 16200 | Apple Secure Notes | Document 23300 | Apple iWork | Document 6600 | 1Password, agilekeychain | Password Manager 8200 | 1Password, cloudkeychain | Password Manager 9000 | Password Safe v2 | Password Manager 5200 | Password Safe v3 | Password Manager 6800 | LastPass + LastPass sniffed | Password Manager 13400 | KeePass 1 (AES/Twofish) and KeePass 2 (AES) | Password Manager 29700 | KeePass 1 (AES/Twofish) and KeePass 2 (AES) - keyfile only mode | Password Manager 23400 | Bitwarden | Password Manager 16900 | Ansible Vault | Password Manager 26000 | Mozilla key3.db | Password Manager 26100 | Mozilla key4.db | Password Manager 23100 | Apple Keychain | Password Manager 11600 | 7-Zip | Archive 12500 | RAR3-hp | Archive 23700 | RAR3-p (Uncompressed) | Archive 13000 | RAR5 | Archive 17220 | PKZIP (Compressed Multi-File) | Archive 17200 | PKZIP (Compressed) | Archive 17225 | PKZIP (Mixed Multi-File) | Archive 17230 | PKZIP (Mixed Multi-File Checksum-Only) | Archive 17210 | PKZIP (Uncompressed) | Archive 20500 | PKZIP Master Key | Archive 20510 | PKZIP Master Key (6 byte optimization) | Archive 23001 | SecureZIP AES-128 | Archive 23002 | SecureZIP AES-192 | Archive 23003 | SecureZIP AES-256 | Archive 13600 | WinZip | Archive 18900 | Android Backup | Archive 24700 | Stuffit5 | Archive 13200 | AxCrypt 1 | Archive 13300 | AxCrypt 1 in-memory SHA1 | Archive 23500 | AxCrypt 2 AES-128 | Archive 23600 | AxCrypt 2 AES-256 | Archive 14700 | iTunes backup \u0026lt; 10.0 | Archive 14800 | iTunes backup \u0026gt;= 10.0 | Archive 8400 | WBB3 (Woltlab Burning Board) | Forums, CMS, E-Commerce 2612 | PHPS | Forums, CMS, E-Commerce 121 | SMF (Simple Machines Forum) \u0026gt; v1.1 | Forums, CMS, E-Commerce 3711 | MediaWiki B type | Forums, CMS, E-Commerce 4521 | Redmine | Forums, CMS, E-Commerce 24800 | Umbraco HMAC-SHA1 | Forums, CMS, E-Commerce 11 | Joomla \u0026lt; 2.5.18 | Forums, CMS, E-Commerce 13900 | OpenCart | Forums, CMS, E-Commerce 11000 | PrestaShop | Forums, CMS, E-Commerce 16000 | Tripcode | Forums, CMS, E-Commerce 7900 | Drupal7 | Forums, CMS, E-Commerce 4522 | PunBB | Forums, CMS, E-Commerce 2811 | MyBB 1.2+, IPB2+ (Invision Power Board) | Forums, CMS, E-Commerce 2611 | vBulletin \u0026lt; v3.8.5 | Forums, CMS, E-Commerce 2711 | vBulletin \u0026gt;= v3.8.5 | Forums, CMS, E-Commerce 25600 | bcrypt(md5($pass)) / bcryptmd5 | Forums, CMS, E-Commerce 25800 | bcrypt(sha1($pass)) / bcryptsha1 | Forums, CMS, E-Commerce 28400 | bcrypt(sha512($pass)) / bcryptsha512 | Forums, CMS, E-Commerce 21 | osCommerce, xt:Commerce | Forums, CMS, E-Commerce 18100 | TOTP (HMAC-SHA1) | One-Time Password 2000 | STDOUT | Plaintext 99999 | Plaintext | Plaintext 21600 | Web2py pbkdf2-sha512 | Framework 10000 | Django (PBKDF2-SHA256) | Framework 124 | Django (SHA-1) | Framework 12001 | Atlassian (PBKDF2-HMAC-SHA1) | Framework 19500 | Ruby on Rails Restful-Authentication | Framework 27200 | Ruby on Rails Restful Auth (one round, no sitekey) | Framework 30000 | Python Werkzeug MD5 (HMAC-MD5 (key = $salt)) | Framework 30120 | Python Werkzeug SHA256 (HMAC-SHA256 (key = $salt)) | Framework 20200 | Python passlib pbkdf2-sha512 | Framework 20300 | Python passlib pbkdf2-sha256 | Framework 20400 | Python passlib pbkdf2-sha1 | Framework 24410 | PKCS#8 Private Keys (PBKDF2-HMAC-SHA1 + 3DES/AES) | Private Key 24420 | PKCS#8 Private Keys (PBKDF2-HMAC-SHA256 + 3DES/AES) | Private Key 15500 | JKS Java Key Store Private Keys (SHA1) | Private Key 22911 | RSA/DSA/EC/OpenSSH Private Keys ($0$) | Private Key 22921 | RSA/DSA/EC/OpenSSH Private Keys ($6$) | Private Key 22931 | RSA/DSA/EC/OpenSSH Private Keys ($1, $3$) | Private Key 22941 | RSA/DSA/EC/OpenSSH Private Keys ($4$) | Private Key 22951 | RSA/DSA/EC/OpenSSH Private Keys ($5$) | Private Key 23200 | XMPP SCRAM PBKDF2-SHA1 | Instant Messaging Service 28300 | Teamspeak 3 (channel hash) | Instant Messaging Service 22600 | Telegram Desktop \u0026lt; v2.1.14 (PBKDF2-HMAC-SHA1) | Instant Messaging Service 24500 | Telegram Desktop \u0026gt;= v2.1.14 (PBKDF2-HMAC-SHA512) | Instant Messaging Service 22301 | Telegram Mobile App Passcode (SHA256) | Instant Messaging Service 23 | Skype | Instant Messaging Service 29600 | Terra Station Wallet (AES256-CBC(PBKDF2($pass))) | Cryptocurrency Wallet 26600 | MetaMask Wallet | Cryptocurrency Wallet 21000 | BitShares v0.x - sha512(sha512_bin(pass)) | Cryptocurrency Wallet 28501 | Bitcoin WIF private key (P2PKH), compressed | Cryptocurrency Wallet 28502 | Bitcoin WIF private key (P2PKH), uncompressed | Cryptocurrency Wallet 28503 | Bitcoin WIF private key (P2WPKH, Bech32), compressed | Cryptocurrency Wallet 28504 | Bitcoin WIF private key (P2WPKH, Bech32), uncompressed | Cryptocurrency Wallet 28505 | Bitcoin WIF private key (P2SH(P2WPKH)), compressed | Cryptocurrency Wallet 28506 | Bitcoin WIF private key (P2SH(P2WPKH)), uncompressed | Cryptocurrency Wallet 11300 | Bitcoin/Litecoin wallet.dat | Cryptocurrency Wallet 16600 | Electrum Wallet (Salt-Type 1-3) | Cryptocurrency Wallet 21700 | Electrum Wallet (Salt-Type 4) | Cryptocurrency Wallet 21800 | Electrum Wallet (Salt-Type 5) | Cryptocurrency Wallet 12700 | Blockchain, My Wallet | Cryptocurrency Wallet 15200 | Blockchain, My Wallet, V2 | Cryptocurrency Wallet 18800 | Blockchain, My Wallet, Second Password (SHA256) | Cryptocurrency Wallet 25500 | Stargazer Stellar Wallet XLM | Cryptocurrency Wallet 16300 | Ethereum Pre-Sale Wallet, PBKDF2-HMAC-SHA256 | Cryptocurrency Wallet 15600 | Ethereum Wallet, PBKDF2-HMAC-SHA256 | Cryptocurrency Wallet 15700 | Ethereum Wallet, SCRYPT | Cryptocurrency Wallet 22500 | MultiBit Classic .key (MD5) | Cryptocurrency Wallet 27700 | MultiBit Classic .wallet (scrypt) | Cryptocurrency Wallet 22700 | MultiBit HD (scrypt) | Cryptocurrency Wallet 28200 | Exodus Desktop Wallet (scrypt) | Cryptocurrency Wallet - [ Brain Client Features ] - # | Features ===+======== 1 | Send hashed passwords 2 | Send attack positions 3 | Send hashed passwords and attack positions - [ Outfile Formats ] - # | Format ===+======== 1 | hash[:salt] 2 | plain 3 | hex_plain 4 | crack_pos 5 | timestamp absolute 6 | timestamp relative - [ Rule Debugging Modes ] - # | Format ===+======== 1 | Finding-Rule 2 | Original-Word 3 | Original-Word:Finding-Rule 4 | Original-Word:Finding-Rule:Processed-Word 5 | Original-Word:Finding-Rule:Processed-Word:Wordlist - [ Attack Modes ] - # | Mode ===+====== 0 | Straight 1 | Combination 3 | Brute-force 6 | Hybrid Wordlist + Mask 7 | Hybrid Mask + Wordlist 9 | Association - [ Built-in Charsets ] - ? | Charset ===+========= l | abcdefghijklmnopqrstuvwxyz [a-z] u | ABCDEFGHIJKLMNOPQRSTUVWXYZ [A-Z] d | 0123456789 [0-9] h | 0123456789abcdef [0-9a-f] H | 0123456789ABCDEF [0-9A-F] s | !\u0026quot;#$%\u0026amp;'()*+,-./:;\u0026lt;=\u0026gt;?@[\\]^_`{|}~ a | ?l?u?d?s b | 0x00 - 0xff - [ OpenCL Device Types ] - # | Device Type ===+============= 1 | CPU 2 | GPU 3 | FPGA, DSP, Co-Processor - [ Workload Profiles ] - # | Performance | Runtime | Power Consumption | Desktop Impact ===+=============+=========+===================+================= 1 | Low | 2 ms | Low | Minimal 2 | Default | 12 ms | Economic | Noticeable 3 | High | 96 ms | High | Unresponsive 4 | Nightmare | 480 ms | Insane | Headless - [ License ] - hashcat is licensed under the MIT license Copyright and license terms are listed in docs/license.txt - [ Basic Examples ] - Attack- | Hash- | Mode | Type | Example command ==================+=======+================================================================== Wordlist | $P$ | hashcat -a 0 -m 400 example400.hash example.dict Wordlist + Rules | MD5 | hashcat -a 0 -m 0 example0.hash example.dict -r rules/best64.rule Brute-Force | MD5 | hashcat -a 3 -m 0 example0.hash ?a?a?a?a?a?a Combinator | MD5 | hashcat -a 1 -m 0 example0.hash example.dict example.dict Association | $1$ | hashcat -a 9 -m 500 example500.hash 1word.dict -r rules/best64.rule If you still have no idea what just happened, try the following pages: * https://hashcat.net/wiki/#howtos_videos_papers_articles_etc_in_the_wild * https://hashcat.net/faq/ If you think you need help by a real human come to the hashcat Discord: * https://hashcat.net/discord ```bash "}),e.add({id:93,href:"/docs/tools/attack/hydra/",title:"Hydra",description:`Description # Hydra is a fast network logon cracker which support many different services.
Install # brew install hydra Sample Usage # hydra -l root -P /usr/share/wordlists/rockyou.txt ssh:// website # https://github.com/vanhauser-thc/thc-hydra
help # HYDRA(1) General Commands Manual HYDRA(1) NAME hydra - a very fast network logon cracker which supports many different services SYNOPSIS hydra [[[-l LOGIN|-L FILE] [-p PASS|-P FILE|-x OPT -y]] | [-C FILE]] [-e nsr] [-u] [-f|-F] [-M FILE] [-o FILE] [-b FORMAT] [-t TASKS] [-T TASKS] [-w TIME] [-W TIME] [-m OPTIONS] [-s PORT] [-c TIME] [-S] [-O] [-4|6] [-I] [-vV] [-d] server service [OPTIONS] DESCRIPTION Hydra is a parallelized login cracker which supports numerous protocols to attack.`,content:"Description # Hydra is a fast network logon cracker which support many different services.\nInstall # brew install hydra Sample Usage # hydra -l root -P /usr/share/wordlists/rockyou.txt ssh:// website # https://github.com/vanhauser-thc/thc-hydra\nhelp # HYDRA(1) General Commands Manual HYDRA(1) NAME hydra - a very fast network logon cracker which supports many different services SYNOPSIS hydra [[[-l LOGIN|-L FILE] [-p PASS|-P FILE|-x OPT -y]] | [-C FILE]] [-e nsr] [-u] [-f|-F] [-M FILE] [-o FILE] [-b FORMAT] [-t TASKS] [-T TASKS] [-w TIME] [-W TIME] [-m OPTIONS] [-s PORT] [-c TIME] [-S] [-O] [-4|6] [-I] [-vV] [-d] server service [OPTIONS] DESCRIPTION Hydra is a parallelized login cracker which supports numerous protocols to attack. New modules are easy to add, beside that, it is flexible and very fast. This tool gives researchers and security consultants the possibility to show how easy it would be to gain unauthorized access from remote to a system. Currently this tool supports: adam6500 afp asterisk cisco cisco-enable cvs firebird ftp ftps http[s]-{head|get|post} http[s]-{get|post}-form http-proxy http-proxy-urlenum icq imap[s] irc ldap2[s] ldap3[-{cram|di‐ gest}md5][s] mssql mysql(v4) mysql5 ncp nntp oracle oracle-listener oracle-sid pcanywhere pcnfs pop3[s] postgres rdp radmin2 redis rexec rlogin rpcap rsh rtsp s7-300 sapr3 sip smb smtp[s] smtp-enum snmp socks5 ssh sshkey svn teamspeak telnet[s] vmauthd vnc xmpp For most protocols SSL is supported (e.g. https-get, ftp-ssl, etc.). If not all necessary libraries are found during compile time, your available services will be less. Type \u0026quot;hydra\u0026quot; to see what is available. Options target a target to attack, can be an IPv4 address, IPv6 address or DNS name. service a service to attack, see the list of protocols available OPTIONAL SERVICE PARAMETER Some modules have optional or mandatory options. type \u0026quot;hydra -U \u0026lt;servicename\u0026gt;\u0026quot; to get help on on the options of a service. -R restore a previously aborted session. Requires a hydra.restore file was written. Options are restored, but can be changed by setting them after -R on the command line -S connect via SSL -O use old SSL v2 and v3 -s PORT if the service is on a different default port, define it here -l LOGIN or -L FILE login with LOGIN name, or load several logins from FILE -p PASS or -P FILE try password PASS, or load several passwords from FILE -x min:max:charset generate passwords from min to max length. charset can contain 1 for numbers, a for lowcase and A for upcase characters. Any other character is added is put to the list. Example: 1:2:a1%. The generated passwords will be of length 1 to 2 and contain lowcase letters, numbers and/or percent signs and dots. -y disable use of symbols in -x bruteforce, see above -e nsr additional checks, \u0026quot;n\u0026quot; for null password, \u0026quot;s\u0026quot; try login as pass, \u0026quot;r\u0026quot; try the reverse login as pass -C FILE colon separated \u0026quot;login:pass\u0026quot; format, instead of -L/-P options -u by default Hydra checks all passwords for one login and then tries the next login. This option loops around the passwords, so the first password is tried on all logins, then the next password. -f exit after the first found login/password pair (per host if -M) -F exit after the first found login/password pair for any host (for usage with -M) -M FILE server list for parallel attacks, one entry per line -o FILE write found login/password pairs to FILE instead of stdout -b FORMAT specify the format for the -o FILE: text(default), json, jsonv1 -t TASKS run TASKS number of connects in parallel (default: 16) -m OPTIONS module specific options. See hydra -U \u0026lt;module\u0026gt; what options are available. -w TIME defines the max wait time in seconds for responses (default: 32) -W TIME defines a wait time between each connection a task performs. This usually only makes sense if a low task number is used, .e.g -t 1 -c TIME the wait time in seconds per login attempt over all threads (-t 1 is recommended) This usually only makes sense if a low task number is used, .e.g -t 1 -4 / -6 prefer IPv4 (default) or IPv6 addresses -v / -V verbose mode / show login+pass combination for each attempt -d debug mode -I ignore an existing restore file (don't wait 10 seconds) -h, --help Show summary of options. SEE ALSO xhydra(1), pw-inspector(1). The programs are documented fully by van Hauser \u0026lt;vh@thc.org\u0026gt; AUTHOR hydra was written by van Hauser / THC \u0026lt;vh@thc.org\u0026gt; Find new versions or report bugs at https://github.com/vanhauser-thc/thc-hydra This manual page was written by Daniel Echeverry \u0026lt;epsilon77@gmail.com\u0026gt;, for the Debian project (and may be used by others). 01/01/2022 HYDRA(1) ```bash "}),e.add({id:94,href:"/docs/tools/attack/john/",title:"John",description:`Description # John the Ripper is a fast password cracker, currently available for many flavors of Unix, Windows, DOS, BeOS, and OpenVMS. Its primary purpose is to detect weak Unix passwords. Besides several crypt(3) password hash types most commonly found on various Unix flavors, supported out of the box are Windows LM hashes, plus lots of other hashes and ciphers in the community-enhanced version.
install # brew install john sample usage # john --wordlist=/usr/share/wordlists/rockyou.`,content:"Description # John the Ripper is a fast password cracker, currently available for many flavors of Unix, Windows, DOS, BeOS, and OpenVMS. Its primary purpose is to detect weak Unix passwords. Besides several crypt(3) password hash types most commonly found on various Unix flavors, supported out of the box are Windows LM hashes, plus lots of other hashes and ciphers in the community-enhanced version.\ninstall # brew install john sample usage # john --wordlist=/usr/share/wordlists/rockyou.txt --format=raw-md5 hash.txt website # https://www.openwall.com/john/\nhelp # https://www.openwall.com/john/doc/\nJohn the Ripper password cracker, version 1.8.0 Copyright (c) 1996-2013 by Solar Designer Homepage: http://www.openwall.com/john/ Usage: john [OPTIONS] [PASSWORD-FILES] --single \u0026quot;single crack\u0026quot; mode --wordlist=FILE --stdin wordlist mode, read words from FILE or stdin --rules enable word mangling rules for wordlist mode --incremental[=MODE] \u0026quot;incremental\u0026quot; mode [using section MODE] --external=MODE external mode or word filter --stdout[=LENGTH] just output candidate passwords [cut at LENGTH] --restore[=NAME] restore an interrupted session [called NAME] --session=NAME give a new session the NAME --status[=NAME] print status of a session [called NAME] --make-charset=FILE make a charset, FILE will be overwritten --show show cracked passwords --test[=TIME] run tests and benchmarks for TIME seconds each --users=[-]LOGIN|UID[,..] [do not] load this (these) user(s) only --groups=[-]GID[,..] load users [not] of this (these) group(s) only --shells=[-]SHELL[,..] load users with[out] this (these) shell(s) only --salts=[-]N load salts with[out] at least N passwords only --save-memory=LEVEL enable memory saving, at LEVEL 1..3 --node=MIN[-MAX]/TOTAL this node's number range out of TOTAL count --fork=N fork N processes --format=NAME force hash type NAME: descrypt/bsdicrypt/md5crypt/ bcrypt/LM/AFS/tripcode/dummy/crypt ```bash "}),e.add({id:95,href:"/docs/tools/attack/metasploit/",title:"Metasploit",description:`Description # Metasploit is a penetration testing framework that allows you to find and exploit vulnerabilities.
Installation # brew install metasploit Usage # msfconsole Resources # Metasploit Metasploit Unleashed help # `,content:`Description # Metasploit is a penetration testing framework that allows you to find and exploit vulnerabilities.
Installation # brew install metasploit Usage # msfconsole Resources # Metasploit Metasploit Unleashed help # `}),e.add({id:96,href:"/docs/tools/attack/mitmproxy/",title:"Mitmproxy",description:`Description # mitmproxy is an interactive TLS-capable intercepting HTTP proxy for penetration testers and software developers.
Installation # brew install mitmproxy Usage # mitmproxy Resources # Features User Guide GitHub help # usage: mitmproxy [options] options: -h, --help show this help message and exit --version show version number and exit --options Show all options and their default values --commands Show all commands and their signatures --set option[=value] Set an option. When the value is omitted, booleans are set to true, strings and integers are set to None (if permitted), and sequences are emptied.`,content:"Description # mitmproxy is an interactive TLS-capable intercepting HTTP proxy for penetration testers and software developers.\nInstallation # brew install mitmproxy Usage # mitmproxy Resources # Features User Guide GitHub help # usage: mitmproxy [options] options: -h, --help show this help message and exit --version show version number and exit --options Show all options and their default values --commands Show all commands and their signatures --set option[=value] Set an option. When the value is omitted, booleans are set to true, strings and integers are set to None (if permitted), and sequences are emptied. Boolean values can be true, false or toggle. Sequences are set using multiple invocations to set for the same option. -q, --quiet Quiet. -v, --verbose Increase log verbosity. --mode MODE, -m MODE The proxy server type(s) to spawn. Can be passed multiple times. Mitmproxy supports \u0026quot;regular\u0026quot; (HTTP), \u0026quot;transparent\u0026quot;, \u0026quot;socks5\u0026quot;, \u0026quot;reverse:SPEC\u0026quot;, and \u0026quot;upstream:SPEC\u0026quot; proxy servers. For reverse and upstream proxy modes, SPEC is host specification in the form of \u0026quot;http[s]://host[:port]\u0026quot;. You may append `@listen_port` or `@listen_host:listen_port` to override `listen_host` or `listen_port` for a specific proxy mode. Features such as client playback will use the first mode to determine which upstream server to use. May be passed multiple times. --no-anticache --anticache Strip out request headers that might cause the server to return 304-not-modified. --no-showhost --showhost Use the Host header to construct URLs for display. --rfile PATH, -r PATH Read flows from file. --scripts SCRIPT, -s SCRIPT Execute a script. May be passed multiple times. --stickycookie FILTER Set sticky cookie filter. Matched against requests. --stickyauth FILTER Set sticky auth filter. Matched against requests. --save-stream-file PATH, -w PATH Stream flows to file as they arrive. Prefix path with + to append. The full path can use python strftime() formating, missing directories are created as needed. A new file is opened every time the formatted string changes. --no-anticomp --anticomp Try to convince servers to send us un- compressed data. --console-layout {horizontal,single,vertical} Console layout. --no-console-layout-headers --console-layout-headers Show layout component headers Proxy Options: --listen-host HOST Address to bind proxy server(s) to (may be overridden for individual modes, see `mode`). --listen-port PORT, -p PORT Port to bind proxy server(s) to (may be overridden for individual modes, see `mode`). By default, the port is mode- specific. The default regular HTTP proxy spawns on port 8080. --no-server, -n --server Start a proxy server. Enabled by default. --ignore-hosts HOST Ignore host and forward all traffic without processing it. In transparent mode, it is recommended to use an IP address (range), not the hostname. In regular mode, only SSL traffic is ignored and the hostname should be used. The supplied value is interpreted as a regular expression and matched on the ip or the hostname. May be passed multiple times. --allow-hosts HOST Opposite of --ignore-hosts. May be passed multiple times. --tcp-hosts HOST Generic TCP SSL proxy mode for all hosts that match the pattern. Similar to --ignore-hosts, but SSL connections are intercepted. The communication contents are printed to the log in verbose mode. May be passed multiple times. --upstream-auth USER:PASS Add HTTP Basic authentication to upstream proxy and reverse proxy requests. Format: username:password. --proxyauth SPEC Require proxy authentication. Format: \u0026quot;username:pass\u0026quot;, \u0026quot;any\u0026quot; to accept any user/pass combination, \u0026quot;@path\u0026quot; to use an Apache htpasswd file, or \u0026quot;ldap[s]:url_serv er_ldap[:port]:dn_auth:password:dn_subtree \u0026quot; for LDAP authentication. --no-rawtcp --rawtcp Enable/disable raw TCP connections. TCP connections are enabled by default. --no-http2 --http2 Enable/disable HTTP/2 support. HTTP/2 support is enabled by default. SSL: --certs SPEC SSL certificates of the form \u0026quot;[domain=]path\u0026quot;. The domain may include a wildcard, and is equal to \u0026quot;*\u0026quot; if not specified. The file at path is a certificate in PEM format. If a private key is included in the PEM, it is used, else the default key in the conf dir is used. The PEM file should contain the full certificate chain, with the leaf certificate as the first entry. May be passed multiple times. --cert-passphrase PASS Passphrase for decrypting the private key provided in the --cert option. Note that passing cert_passphrase on the command line makes your passphrase visible in your system's process list. Specify it in config.yaml to avoid this. --no-ssl-insecure --ssl-insecure, -k Do not verify upstream server SSL/TLS certificates. Client Replay: --client-replay PATH, -C PATH Replay client requests from a saved file. May be passed multiple times. Server Replay: --server-replay PATH, -S PATH Replay server responses from a saved file. May be passed multiple times. --no-server-replay-kill-extra --server-replay-kill-extra Kill extra requests during replay (for which no replayable response was found). --no-server-replay-nopop --server-replay-nopop Don't remove flows from server replay state after use. This makes it possible to replay same response multiple times. --no-server-replay-refresh --server-replay-refresh Refresh server replay responses by adjusting date, expires and last-modified headers, as well as adjusting cookie expiration. Map Remote: --map-remote PATTERN, -M PATTERN Map remote resources to another remote URL using a pattern of the form \u0026quot;[/flow- filter]/url-regex/replacement\u0026quot;, where the separator can be any character. May be passed multiple times. Map Local: --map-local PATTERN Map remote resources to a local file using a pattern of the form \u0026quot;[/flow-filter]/url- regex/file-or-directory-path\u0026quot;, where the separator can be any character. May be passed multiple times. Modify Body: --modify-body PATTERN, -B PATTERN Replacement pattern of the form \u0026quot;[/flow- filter]/regex/[@]replacement\u0026quot;, where the separator can be any character. The @ allows to provide a file path that is used to read the replacement string. May be passed multiple times. Modify Headers: --modify-headers PATTERN, -H PATTERN Header modify pattern of the form \u0026quot;[/flow- filter]/header-name/[@]header-value\u0026quot;, where the separator can be any character. The @ allows to provide a file path that is used to read the header value string. An empty header-value removes existing header-name headers. May be passed multiple times. Filters: See help in mitmproxy for filter expression syntax. --intercept FILTER Intercept filter expression. --view-filter FILTER Limit the view to matching flows. ```bash "}),e.add({id:97,href:"/docs/tools/attack/ncrack/",title:"Ncrack",description:`Description # Ncrack is a high-speed network authentication cracking tool. It can crack more protocols than any other tool of its kind, and is designed to be flexible and highly customizable.
Install # brew install ncrack Sample Usage # ncrack -vv -p 22 -U /usr/share/wordlists/rockyou.txt -P /usr/share/wordlists/rockyou.txt website # https://nmap.org/ncrack/
help # NCRACK(1) Ncrack Reference Guide NCRACK(1) NAME ncrack - Network authentication cracking tool SYNOPSIS ncrack [Options] {target specification} DESCRIPTION Ncrack is an open source tool for network authentication cracking.`,content:"Description # Ncrack is a high-speed network authentication cracking tool. It can crack more protocols than any other tool of its kind, and is designed to be flexible and highly customizable.\nInstall # brew install ncrack Sample Usage # ncrack -vv -p 22 -U /usr/share/wordlists/rockyou.txt -P /usr/share/wordlists/rockyou.txt website # https://nmap.org/ncrack/\nhelp # NCRACK(1) Ncrack Reference Guide NCRACK(1) NAME ncrack - Network authentication cracking tool SYNOPSIS ncrack [Options] {target specification} DESCRIPTION Ncrack is an open source tool for network authentication cracking. It was designed for high-speed parallel cracking using a dynamic engine that can adapt to different network situations. Ncrack can also be extensively fine-tuned for special cases, though the default parameters are generic enough to cover almost every situation. It is built on a modular architecture that allows for easy extension to support additional protocols. Ncrack is designed for companies and security professionals to audit large networks for default or weak passwords in a rapid and reliable way. It can also be used to conduct fairly sophisticated and intensive brute force attacks against individual services. Warning Ncrack is a project started in the Summer of 2009. While it is already useful for some purposes, it is still unfinished, beta quality software. You can help out by testing it and reporting any problems as described in the section called “BUGS”. The output from Ncrack is a list of found credentials, if any, for each of the targets specified. Ncrack can also print an interactive status report of progress so far and possibly additional debugging information that can help track problems, if the user selected that option. A typical Ncrack scan is shown in Example 1. The only Ncrack arguments used in this example are the two target IP addresses along with the the corresponding ports for each of them. The two example ports 21 and 22 are automatically resolved to the default services listening on them: ftp and ssh. Example 1. A representative Ncrack scan $ ncrack 10.0.0.130:21 192.168.1.2:22 Starting Ncrack 0.6 ( http://ncrack.org ) at 2016-01-03 22:10 EEST Discovered credentials for ftp on 10.0.0.130 21/tcp: 10.0.0.130 21/tcp ftp: admin hello1 Discovered credentials for ssh on 192.168.1.2 22/tcp: 192.168.1.2 22/tcp ssh: guest 12345 192.168.1.2 22/tcp ssh: admin money$ Ncrack done: 2 services scanned in 156.03 seconds. Ncrack finished. The latest version of Ncrack can be obtained from http://nmap.org/ncrack. The latest version of this help is available at http://nmap.org/ncrack/man.html . OPTIONS SUMMARY This options summary is printed when Ncrack is run with no arguments. It helps people remember the most common options, but is no substitute for the in-depth documentation in the rest of this manual. Ncrack 0.7 ( http://ncrack.org ) Usage: ncrack [Options] {target and service specification} TARGET SPECIFICATION: Can pass hostnames, IP addresses, networks, etc. Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254 -iX \u0026lt;inputfilename\u0026gt;: Input from Nmap´s -oX XML output format -iN \u0026lt;inputfilename\u0026gt;: Input from Nmap´s -oN Normal output format -iL \u0026lt;inputfilename\u0026gt;: Input from list of hosts/networks --exclude \u0026lt;host1[,host2][,host3],...\u0026gt;: Exclude hosts/networks --excludefile \u0026lt;exclude_file\u0026gt;: Exclude list from file SERVICE SPECIFICATION: Can pass target specific services in \u0026lt;service\u0026gt;://target (standard) notation or using -p which will be applied to all hosts in non-standard notation. Service arguments can be specified to be host-specific, type of service-specific (-m) or global (-g). Ex: ssh://10.0.0.10,at=10,cl=30 -m ssh:at=50 -g cd=3000 Ex2: ncrack -p ssh,ftp:3500,25 10.0.0.10 scanme.nmap.org google.com:80,ssl -p \u0026lt;service-list\u0026gt;: services will be applied to all non-standard notation hosts -m \u0026lt;service\u0026gt;:\u0026lt;options\u0026gt;: options will be applied to all services of this type -g \u0026lt;options\u0026gt;: options will be applied to every service globally Misc options: ssl: enable SSL over this service path \u0026lt;name\u0026gt;: used in modules like HTTP (´=´ needs escaping if used) db \u0026lt;name\u0026gt;: used in modules like MongoDB to specify the database domain \u0026lt;name\u0026gt;: used in modules like WinRM to specify the domain TIMING AND PERFORMANCE: Options which take \u0026lt;time\u0026gt; are in seconds, unless you append ´ms´ (miliseconds), ´m´ (minutes), or ´h´ (hours) to the value (e.g. 30m). Service-specific options: cl (min connection limit): minimum number of concurrent parallel connections CL (max connection limit): maximum number of concurrent parallel connections at (authentication tries): authentication attempts per connection cd (connection delay): delay \u0026lt;time\u0026gt; between each connection initiation cr (connection retries): caps number of service connection attempts to (time-out): maximum cracking \u0026lt;time\u0026gt; for service, regardless of success so far -T\u0026lt;0-5\u0026gt;: Set timing template (higher is faster) --connection-limit \u0026lt;number\u0026gt;: threshold for total concurrent connections --stealthy-linear: try credentials using only one connection against each specified host until you hit the same host again. Overrides all other timing options. AUTHENTICATION: -U \u0026lt;filename\u0026gt;: username file -P \u0026lt;filename\u0026gt;: password file --user \u0026lt;username_list\u0026gt;: comma-separated username list --pass \u0026lt;password_list\u0026gt;: comma-separated password list --passwords-first: Iterate password list for each username. Default is opposite. --pairwise: Choose usernames and passwords in pairs. OUTPUT: -oN/-oX \u0026lt;file\u0026gt;: Output scan in normal and XML format, respectively, to the given filename. -oA \u0026lt;basename\u0026gt;: Output in the two major formats at once -v: Increase verbosity level (use twice or more for greater effect) -d[level]: Set or increase debugging level (Up to 10 is meaningful) --nsock-trace \u0026lt;level\u0026gt;: Set nsock trace level (Valid range: 0 - 10) --log-errors: Log errors/warnings to the normal-format output file --append-output: Append to rather than clobber specified output files MISC: --resume \u0026lt;file\u0026gt;: Continue previously saved session --save \u0026lt;file\u0026gt;: Save restoration file with specific filename -f: quit cracking service after one found credential -6: Enable IPv6 cracking -sL or --list: only list hosts and services --datadir \u0026lt;dirname\u0026gt;: Specify custom Ncrack data file location --proxy \u0026lt;type://proxy:port\u0026gt;: Make connections via socks4, 4a, http. -V: Print version number -h: Print this help summary page. MODULES: SSH, RDP, FTP, Telnet, HTTP(S), Wordpress, POP3(S), IMAP, CVS, SMB, VNC, SIP, Redis, PostgreSQL, MQTT, MySQL, MSSQL, MongoDB, Cassandra, WinRM, OWA, DICOM EXAMPLES: ncrack -v --user root localhost:22 ncrack -v -T5 https://192.168.0.1 ncrack -v -iX ~/nmap.xml -g CL=5,to=1h SEE THE MAN PAGE (http://nmap.org/ncrack/man.html) FOR MORE OPTIONS AND EXAMPLES TARGET SPECIFICATION Everything on the Ncrack command-line that isn´t an option (or an option argument) is treated as a target host specification. The simplest case is to specify a target IP address or a hostname. Note, that you also need to specify a service to crack for the selected targets. Ncrack is very flexible in host/service specification. While hostnames and IP addresses can be defined with the flexibility that you are probably used to from Nmap, services along with service-specific options have a unique specification style that enables a combination of features to be taken advantage of. Sometimes you wish to crack a whole network of adjacent hosts. For this, Ncrack supports CIDR-style addressing. You can append /numbits to an IPv4 address or hostname and Ncrack will try to crack every IP address for which the first numbits are the same as for the reference IP or hostname given. For example, 192.168.10.0/24 would send probes to the 256 hosts between 192.168.10.0 11000000 10101000 00001010 00000000) and 192.168.10.255 (binary: 11000000 10101000 00001010 11111111), inclusive. 192.168.10.40/24 would crack exactly the same targets. Given that the host scanme.nmap.org is at the IP address 64.13.134.52, the specification scanme.nmap.org/16 would send probes to the 65,536 IP addresses between 64.13.0.0 and 64.13.255.255. The smallest allowed value is /0, which targets the whole Internet. The largest value is /32, which targets just the named host or IP address because all address bits are fixed. CIDR notation is short but not always flexible enough. For example, you might want to send probes to 192.168.0.0/16 but skip any IPs ending with .0 or .255 because they may be used as subnet network and broadcast addresses. Ncrack supports this through octet range addressing. Rather than specify a normal IP address, you can specify a comma-separated list of numbers or ranges for each octet. For example, 192.168.0-255.1-254 will skip all addresses in the range that end in .0 or .255, and 192.168.3-5,7.1 will target the four addresses 192.168.3.1, 192.168.4.1, 192.168.5.1, and 192.168.7.1. Either side of a range may be omitted; the default values are 0 on the left and 255 on the right. Using - by itself is the same as 0-255, but remember to use 0- in the first octet so the target specification doesn´t look like a command-line option. Ranges need not be limited to the final octets: the specifier will send probes to all IP addresses on the Internet ending in 13.37 This sort of broad sampling can be useful for Internet surveys and research. Ncrack accepts multiple host specifications on the command line, and they don´t need to be the same type. The command ncrack scanme.nmap.org 192.168.0.0/8 10.0.0,1,3-7.- -p22 does what you would expect. While targets are usually specified on the command lines, the following options are also available to control target selection: -iX inputfilename (Input from Nmap´s -oX XML output format) . Reads target/service specifications from an Nmap XML output file. The Nmap XML file is created by scanning any hosts and specifying the Nmap -oX option. Ncrack will automatically parse the IP addresses and the corresponding ports and services that are open and will use these targets for authentication auditing. This is a really useful option, since it lets you essentially combine these two tools -Nmap and Ncrack- for cracking only those services that are surely open. In addition, if version detection has been enabled in Nmap (-sV option), Ncrack will use those findings to recognize and crack those services that are supported but are listening on non-default ports. For example, if a host is having a server listening on port 41414 and Nmap has identified that it is a SSH service, Ncrack will use that information to crack it using the SSH module. Of course, Ncrack is going to ignore open ports/services that are not supported for authentication cracking by its modules. -iN inputfilename (Input from Nmap´s -oN Normal output format) . Reads target/service specifications from an Nmap Normal output file. The Nmap Normal file is created by scanning any hosts and specifying the Nmap -oN option. This works exactly like Ncrack´s -iX option, the only difference being the format of the input file. -iL inputfilename (Input from list) . Reads target specifications from inputfilename. Passing a huge list of hosts is often awkward on the command line, yet it is a common desire. For example, you might want to crack a list of very specific servers that have been specified for penetration testing. Simply generate the list of hosts to crack and pass that filename to Ncrack as an argument to the -iL option. Entries can be in any of the formats accepted by Ncrack on the command line (IP address, hostname, CIDR, octet ranges or Ncrack´s special host-service syntax. Each entry must be separated by one or more spaces, tabs, or newlines. You can specify a hyphen (-) as the filename if you want Ncrack to read hosts from standard input rather than an actual file. Note, however, that if hosts are specified without any service, you will have to also provide services/ports for the targets using the -p option. --exclude host1[, host2[, ...]] (Exclude hosts/networks) . Specifies a comma-separated list of targets to be excluded from the scan even if they are part of the overall network range you specify. The list you pass in uses normal Ncrack syntax, so it can include hostnames, CIDR netblocks, octet ranges, etc. This can be useful when the network you wish to scan includes untouchable mission-critical servers, systems that are known to react adversely to heavy load, or subnets administered by other people. --excludefile exclude_file (Exclude list from file) . This offers the same functionality as the --exclude option, except that the excluded targets are provided in a newline, space, or tab delimited exclude_file rather than on the command line. SERVICE SPECIFICATION No cracking session can be carried out without targetting a certain service to attack. Service specification is one of the most flexible subsystems of Ncrack and collaborates with target-specification in a way that allows different option combinations to be applied. For Ncrack to start running, you will have to specify at least one target host and one associated service to attack. Ncrack provides ways to specify a service by its default port number, by its name (as extracted from the ncrack-services file) or both. Normally, you need to define both name and port number only in the special case where you know that a particular service is listening on a non-default port. Ncrack offers two distinct ways with which services will be applied to your targets: per-host service specification and global specification. Per-host service specification Services specified in this mode are written next to the host and apply to it only. Keep in mind, however, that target-specification allows wildcards/netmasks, which essentially means that applying a per-host service specification format to that particular target will affect all of the expanded ones as a result. The general format is: [service-name]://target:[port-number] where target is a hostname or IP address in any of the formats described in the target-specification section, [service-name] is one of the common service names as defined in the ncrack-services file (e.g ssh, http) and [port-number] is what it obviously means. Ncrack can determine the default port numbers for each of the services it supports, as well as being able to deduce the service name when a default port number has been specified. Specifying both has meaning only when the user has a priori knowledge of a service listening on a non-default port number. This can easily be determined by using version detection like the one offered by Nmap´s -sV option. Example 2. Per-host service specification example $ ncrack scanme.nmap.org:22 ftp://10.0.0.10 ssh://192.168.1.*:5910 The above command will try to crack hosts: scanme.nmap.org on SSH service (default port 22), 10.0.0.10 on FTP service (default port 21) and 192.168.1.0 - 192.168.1.255 (all of this C subnet) on SSH service on non-default port 5910 which has been explicitly specified. In the last case, Ncrack wouldn´t be able to determine that the subnet hosts are to be scanned against the SSH service on that particular port without the user explicitly asking for it, because there isn´t any mapping of port-number 5910 to service SSH. Global service specification Services specified in this mode are applied to all hosts that haven´t been associated with the per-host service specification format. This is done using the -p option. While this facility may be similar to that of Nmap´s, you should try not to confuse it, since the functionality is of a slightly different nature. Services can be specified using comma separated directives of the general format: -p [service1]:[port-number1],[service2]:[port-number2],... As usual, you need not specify both service name and port number since Ncrack knows the mappings of default-services to default-port numbers. Be careful though not to include any space between each service-name and/or port number, because Ncrack will think that the argument after the space is a host as per the rule \u0026quot;everything that isn´t an option is a target specification\u0026quot;. Example 3. Global service specification example $ ncrack scanme.nmap.org 10.0.0.120-122 192.168.2.0/24 -p 22,ftp:3210,telnet The above command will try to crack all of the specified hosts scanme.nmap.org, 10.0.0.120, 10.0.0.121, 10.0.0.122 and the C class subnet of 192.168.2.0 against the following services: SSH service (mapped from default port 22), FTP service on non-default port 3210, and TELNET service on default port 23. Of course, Ncrack allows you to combine both modes of service specification if you deem that as necessary. Normally, you will only need to specify a couple of services but cracking a lot of hosts against many different services might be a longterm project for large networks that need to be consistently audited for weak passwords. If you are in doubt, about which hosts and services are going to be cracked with the current command, you can use the -sL option (see below for explanation). SERVICE OPTIONS Apart from general service specification, Ncrack allows you to provide a multitude of options that apply to each or a subset of your targets. Options include timing and performance optimizations (which are thoroughly analyzed in a seperate section), SSL enabling/disabling and other module-specific parameters like the relative URL path for the HTTP module. Options can be defined in a variety of ways which include: per-host options, per-module options and global options. Since a combination of these options may be used, there is a strict hierarchy of precedence which will be discussed later. Per-host Options Options in this mode apply only to the host(s) they are referring to and are written next to it according to the following format: [service-name]://target:[port-number],opt1=optval1,opt2=optval,... The format concerning the service specification which comes before the options, has been explained in the previous section. optN is referring to any of the option names that are available (a list will follow below), while optvalN determines the value of that option and depends on the nature of it. For example, most timing-related options expect to receive numbers as values, while the path option obviously needs a string argument. Per-module Options Options in this mode apply to all hosts that are associated with the particular service/module. This is accomplished using the -m which is defined with the format: -m service-name:opt1=optval1,opt2=optval2,... This option can be invoked multiple times, for as many different services as you might need to define service-wide applicable options. Each iteration of this option must refer to only one service. However, to avoid confusion, this option had better not be called more than one time for the same service, although this is allowed and the last iteration will take precedence over the previous ones for all redefined option values. Global Options Options in this mode apply to all hosts regardless of which service they are associated with. This is accomplished using the -g as follows: -g opt1=optval1,opt2=optval2,... This acts as a convenience option, where you can apply options to all services globally. Everything else regarding the available options and option values is the same as the previous modes. List of available Service Options Below follows a list of all the currently available service options. You can apply them with any of the three modes described above. The last six of the options are timing related and will be analyzed in Section \u0026quot;Timing and Performance\u0026quot; of this manual. ssl: enable SSL over this service path: path-name used in modules like HTTP (´=´ needs escaping if used) db: used in modules like MongoDB to specify the database domain: used in modules like WinRM to specify the domain cl (min connection limit): minimum number of concurrent parallel connections CL (max connection limit): maximum number of concurrent parallel connections at (authentication tries): authentication attempts per connection cd (connection delay): delay time between each connection initiation cr (connection retries): caps number of service connection attempts to (time-out): maximum cracking time for service, regardless of success so far ssl (Enable/Disable SSL over service) By enabling SSL, Ncrack will try to open a TCP connection and then negotiate a SSL session with the target. Everything will then be transparently encrypted and decrypted. However, since Ncrack´s job is to provide speed rather than strong crypto, the algorithms and ciphers for SSL are chosen on an efficiency basis. Possible values for this option are ´yes´ but just specifying ssl would be enough. Thus, this is the only option that doesn´t need to be written in the opt=optval format. By default, SSL is disabled for all services except those that are stricly dependent on it like HTTPS. path \u0026lt;name\u0026gt; (Path name for relative URLs) Some services like HTTP or SVN usually require a specific path in the URL. This option takes that pathname string as its value. The path is always relative to the hostname or IP address, so if you want to target something like http://foobar.com/login.php the path must take the value path=login.php . The initial ´/´ is added if you omit it. However, it is usually better if you explicitly specify it at the end of pathnames that are directories. For example, to crack the directory for http://foobar.com/protected-dir/ , it would be better if you wrote it as path=protected-dir/ . This is to avoid the (very) slight probability of a false positive, because there are cases where Web servers might reply with a \u0026quot;301 Moved Permanently\u0026quot; for a non-successful attempt. They normally send that reply, when a successful attempt is made for a requested password-protected path which has omitted the ending ´/´ but the requested source is actually a directory. Consequently, Ncrack regards that reply as having succeeded in the authentication attempt. Also be careful with the symbol ´=´, since it is used by Ncrack for argument parsing and you will have to espace it if it is included in the URL. By default, the path-name is initialized to ´/´, but will be ignored by services that do not require it. db \u0026lt;name\u0026gt; (Database name) Some services like MongoDB require a specific database name to crack. This option allows you to specify the database. By default, the db name for MongoDB is initialized to ´admin´ but will be ignored by services that do not require it. domain \u0026lt;name\u0026gt; (Domain name) Some services like WinRM require a specific domain to crack. This option allows you to specify the domain. By default, the domain name for WinRM is initialized to ´Workstation´ but will be ignored by services that do not require it. Service Option Hierarchy As already noted, Ncrack allows a combination of the three different modes of service option specification. In that case, there is a strict hierarchy that resolves the order in which conflicting values for these options take precedence over each other. The order is as follows, leftmost being the highest priority and rightmost the lowest one: Per-host options \u0026gt; Per-module options \u0026gt; Global options \u0026gt; Timing-Template (for timing options only) The concept of the \u0026quot;Timing-Template\u0026quot; will be explained in the Section \u0026quot;Timing and Performance\u0026quot;, but for now, just have in mind that its values have the least prevalence over everything else and essentially act as defaults for everything timing-related. Global options specified with -g have the directly higher precedence, while -m per-module options are immediately higher. In the top of the hierarcy reside the per-host options which are essentially the most specific ones. Consequently, you can see that the pattern is: the more specific the higher the precedence. Example 4. Service Option Hierarchy example $ ncrack scanme.nmap.org:22,cl=10,at=1 10.0.0.120 10.0.0.20 -p 21 -m ftp:CL=1 -g CL=3 The example demonstrates the hierarchy precedence. The services that are going to be cracked are SSH for scanme.nmap.org and FTP for hosts 10.0.0.120, 10.0.0.20. No particular timing-template has been specified and thus the default will be used (Normal - 3). The per-host options for scanme.nmap.org define that the minimum connection limit (cl) is 10 and that Ncrack should attempt only 1 authentication try (at) per connection. These values would override any other for service SSH of host scanme.nmap.org if there were conflicts with other modes. Since a global option of -g CL=3 was defined and there is no other higher-precedence for service SSH and scanme.nmap.org in particular, this value will also be applied. As for the FTP targets, the per-module -m ftp:CL=1 defined for all FTP services will override the equivalent global one. All these can get quite complex if overused, but they are not expected to be leveraged by the average Ncrack user anyway. Complicated network scanning scenarios might require them, though. To make certain the results are the ones you expect them to be, don´t forget to use the -sL option that prints out details about what Ncrack would crack if invoked normally. You can add the debugging -d option if you want even more verbose output. For the above example, Ncrack would print the following: Example 5. Service Option Hierarchy Output example $ ncrack scanme.nmap.org:22,cl=10,at=1 10.0.0.120 10.0.0.20 -p 21 -m ftp:CL=1 -g CL=3 -sL -d Starting Ncrack 0.6 ( http://ncrack.org ) at 2017-10-12 01:13 CDT ----- [ Timing Template ] ----- cl=7, CL=80, at=0, cd=0, cr=30, to=0 ----- [ ServicesTable ] ----- SERVICE cl CL at cd cr to ssl path db domain ftp:21 N/A 1 N/A N/A N/A N/A no null null null ssh:22 N/A N/A N/A N/A N/A N/A no null null null telnet:23 N/A N/A N/A N/A N/A N/A no null null null http:80 N/A N/A N/A N/A N/A N/A no null null null pop3:110 N/A N/A N/A N/A N/A N/A no null null null imap:143 N/A N/A N/A N/A N/A N/A no null null null netbios-ssn:445 N/A N/A N/A N/A N/A N/A no null null null smb:445 N/A N/A N/A N/A N/A N/A no null null null smb:139 N/A N/A N/A N/A N/A N/A no null null null https:443 N/A N/A N/A N/A N/A N/A yes null null null owa:443 N/A N/A N/A N/A N/A N/A yes null null null sip:5060 N/A N/A N/A N/A N/A N/A no null null null pop3s:995 N/A N/A N/A N/A N/A N/A yes null null null mssql:1433 N/A N/A N/A N/A N/A N/A no null null null mysql:3306 N/A N/A N/A N/A N/A N/A no null null null ms-wbt-server:3389 N/A N/A N/A N/A N/A N/A no null null null rdp:3389 N/A N/A N/A N/A N/A N/A no null null null psql:5432 N/A N/A N/A N/A N/A N/A no null null null vnc:5801 N/A N/A N/A N/A N/A N/A no null null null vnc:5900 N/A N/A N/A N/A N/A N/A no null null null vnc:5901 N/A N/A N/A N/A N/A N/A no null null null vnc:6001 N/A N/A N/A N/A N/A N/A no null null null redis:6379 N/A N/A N/A N/A N/A N/A no null null null winrm:5985 N/A N/A N/A N/A N/A N/A no null null Workstation winrm:5986 N/A N/A N/A N/A N/A N/A no null null Workstation cassandra:9160 N/A N/A N/A N/A N/A N/A no null null null cassandra:9042 N/A N/A N/A N/A N/A N/A no null null null mongodb:27017 N/A N/A N/A N/A N/A N/A no null admin null ----- [ Targets ] ----- Host: 45.33.32.156 ( scanme.nmap.org ) ssh:22 cl=10, CL=10, at=1, cd=0, cr=30, to=0ms, ssl=no, path=/, db=admin, domain=Workstation Host: 10.0.0.120 ftp:21 cl=3, CL=1, at=0, cd=0, cr=30, to=0ms, ssl=no, path=/, db=admin, domain=Workstation Host: 10.0.0.20 ftp:21 cl=3, CL=1, at=0, cd=0, cr=30, to=0ms, ssl=no, path=/, db=admin, domain=Workstation Ncrack done: 3 services would be scanned. Probes sent: 0 | timed-out: 0 | prematurely-closed: 0 Ncrack finished. The ServicesTable just lists the per-module options for all available services. As you can see, the only defined option is in the FTP service for the CL . The Targets table is the most important part of this output and lists all targets and associated options according to the command-line invocation. No network operation takes place in this mode, apart from forward DNS resolution for hostnames (like scanme.nmap.org in this example). TIMING AND PERFORMANCE The timing engine is perhaps the most important part of any serious network authentication cracking tool. Ncrack´s timing engine offers a great many options for optimization and can be bended to serve virtually any user need. As Ncrack is progressing, this subsystem is going to evolve into a dynamic autonomous engine that will be able to automatically adjust its behaviour according to the network feedback it gets, in order to achieve maximum performance and precision without any user intervention. Some options accept a time parameter. This is specified in seconds by default, though you can append ‘ms’, ‘m’, or ‘h’ to the value to specify milliseconds, minutes, or hours (‘s’ for seconds is redundant). So the cd (connection delay) arguments 900000ms, 900s, and 15m all do the same thing. cl num-minconnections; CL num-maxconnections (Adjust number of concurrent parallel connections) Connection Limit These options control the total number of connections that may be outstanding for any service at the same time. Normally, Ncrack tries to dynamically adjust the number of connections for each individual target by counting how many drops or connection failures happen. If a strange network condition occurs, that signifies that something may be going wrong, like the host dropping any new connection attempts, then Ncrack will immediately lower the total number of connections hitting the service. However, the caps number of the minimum or maximum connections that will take place can be overriden using these two options. By properly adjusting them, you can essentially optimize performance, if you can handle the tricky part of knowing or discovering your target´s own limits. The convention here is that cl with lowercase letters is referring to the minimum connection limit, while CL with uppercase letters is referring to the maximum number of connections. The most common usage is to set cl (minimum connection limit) for targets that you are almost certain are going to withstand these many connections at any given time. This is a risky option to play with, as setting it too high might actually do more harm than good by effectively DoS-attacking the target and triggering firewall rules that will ban your IP address. On the other hand, for more stealthy missions, setting the CL (maximum connection limit) to a low value might be what you want. However, setting it too low will surely have a great impact in overall cracking speed. For maximum stealth, this can be combined with the cd (connection delay) described below. at num-attempts (Adjust authentication attempts per connection) Authentication Tries Using this option, you can order Ncrack to limit the authentication attempts it carries out per connection. Ncrack initially sends a reconnaisance probe that lets it calculate the maximum number of such authentication tries and from thereon it always tries to use that number. Most servicse pose an upper limit on the number of authentication per connection and in most cases finding that maximum leads to better performance. Setting this option to lower values can give you some stealth bonus, since services such as SSH tend to log failed attempts after more than a certain number of authentication tries per connection. They use that as a metric rather than counting the total number of authentication attempts or connections per IP address (which is usually done by a firewall). Consequently, a number of 1 or 2 authentication tries might circumvent logging in some cases. Note that setting that option to a high value will not have any effect if Ncrack realizes that the server doesn´t allow that many attempts per connection. In this case, it will just use that maximum number and ignore your setting. cd time (Adjust delay time between each new connection) Connection Delay This option essentially defines the imposed time delay between each new connection. Ncrack will wait the amount of time you specify in this option value, before starting a new connection against the given service. The higher you set it, the slower Ncrack will perform, but the stealthier your attack will become. Ncrack by default tries to initiate new connections as fast as possible given that new probes are actually allowed to be sent and are not restricted by parameters such as Connection Limit which can dynamically increase or decrease. Although this approach achieves blazing speed as long as the host remains responsive, it can lead to a number of disasters such as a firewall being triggered, the targets´ or your bandwidth to be diminished and even the tested service to suffer a Denial of Service attack. By carefully adjusting this option, you can potentially avoid these annoying situations. cr max-conattempts (Adjust the max number of connection retries) Connection Retries This option allows the user to specify the maximum amount of consecutive failed attempts against that particular service. If at any time, during the cracking session, Ncrack fails to connect against that particular service, then it will stop cracking it entirely. to time (Adjust the maximum overall cracking time) Timeout Define how much time Ncrack is going to spend cracking the service, before giving up regardless of whether it has found any credentials so far. However, any authentication token discovered until that time, will be stored and printed normally. Ncrack marks a service as finished when the username/password lists iteration ends or when it can no longer crack it for some serious reason. If Ncrack finishes cracking a service before the time specified in this option, then it will not be taken into account at all. Sometimes, you have a limited time window to scan/crack your hosts. This might occur for various reasons. A common one would be that normal user activity mustn´t be interrupted and since Ncrack can become very aggressive, it might be allowed to scan the hosts only at during certain time period like the night hours. Scanning during certain such hours is also likely to make an attack less detectable. Don´t forget that Ncrack allows you to specify the time unit of measure by appending ‘ms’, ‘m’, or ‘h’ for milliseconds, minutes or hours (seconds is the default time unit). Using them in this particular option, is really convenient as you can specify something like to=8h to give Ncrack a total of 8 hours to crack that service. Setting up cronjobs for scheduled scans in combination with this option, might also be a good idea. -T paranoid|sneaky|polite|normal|aggressive|insane (Set a timing template) . While the fine-grained timing controls discussed in the previous section are powerful and effective, some people find them confusing. Moreover, choosing the appropriate values can sometimes take more time than the scan you are trying to optimize. So Ncrack offers a simpler approach, with six timing templates. You can specify them with the -T option and their number (0–5) or their name. The template names are paranoid (0), sneaky (1), polite (2), normal (3), aggressive (4), and insane (5). The first two are for IDS evasion. Polite mode slows down the scan to use less bandwidth and target machine resources. Normal mode is the default and so -T3 does nothing. Aggressive mode speeds scans up by making the assumption that you are on a reasonably fast and reliable network. Finally insane mode assumes that you are on an extraordinarily fast network or are willing to sacrifice some accuracy for speed. These templates allow the user to specify how aggressive they wish to be, while leaving Ncrack to pick the exact timing values. If you know that the network service is going to withstand a huge number of connections you might try using the aggressive template of -T4 . Even then, this is mostly advised for services residing in the local network. Going over to insane mode -T5 is not recommended, unless you absolutely know what you are doing. While -T0. and -T1. may be useful for avoiding IDS alerts, they will take an extraordinarily long time to crack even a few services. For such a long scan, you may prefer to set the exact timing values you need rather than rely on the canned -T0 and -T1 values. --connection-limit numprobes (Adjust the threshold of total concurrent connections) NOT IMPLEMENTED YET. AUTHENTICATION This section describes ways of specifying your own username and password lists as well as the available modes of iterating over them. Ncrack ships in with a variety of username and password lists which reside under the directory ´lists´ of the source tarball and later installed under Ncrack´s data directory which usually is /usr/local/share/ncrack or /usr/share/ncrack . You can omit specifying any lists and Ncrack is going to use the default ones which contain some of the most common usernames and passwords. The password list is frequency-sorted with the top most common passwords at the beginning of the list so they will be tried out first. The lists have been derived from a combination of sorting publicly leaked password files and other techniques. -U filename (Specify username list) Specify your own username list by giving the path to the filename as argument to this option. Usernames for specific environments can be gathered in numerous ways including harvesting for email-addresses in the company´s website, looking up information in whois databases, using the SMTP VRFY technique at vulnerable mail servers or through social engineering. -P filename (Specify password list) Specify your own password list by giving the path to the filename as argument to this option. Common passwords are usually derived from leaked lists as a result of successful intrusions in public sites such as forums or other social networking places. A great deal of them have already been publicly disclosed and some of these have been used to assemble Ncrack´s own lists. --user username_list (Specify command-line comma-separated username list) Specify your own usernames directly in the command-line as a comma-separated list. --pass password_list (Specify command-line comma-separated password list) Specify your own passwords directly in the command-line as a comma-separated list. --passwords-first (Reverse the way passwords are iterated) Ncrack by default iterates the username list for each password. With this option, you can reverse that. For example, given the username list of -\u0026gt; \u0026quot;root, guest, admin\u0026quot; and the password list of \u0026quot;test, 12345, q1w2e3r4\u0026quot; Ncrack will normally go over them like this -\u0026gt; root:test, guest:test, admin:test, root:12345 etc. By enabling this option it will go over them like this -\u0026gt; root:test, root:12345, root:q1w2e3r4, guest:test etc. Most network authentication cracking tools prefer by default to iterate the password list for each username. This is, however, ineffective compared to the opposite iteration in most cases. This holds true for the simple reason that password lists are usually sorted on a frequency basis, meaning that the more common a password is, the closer to the beginning of the password list it is. Thus, iterating over all usernames for the most common passwords first has usually more chances to get a positive result. With the --passwords-first iteration, very common passwords might not even be tried out for certain usernames if the user chooses to abort the session early. However, this option might prove valuable for cases where the attacker knows and has already verified that the username list contains real usernames, instead of blindly bruteforcing through them. --pairwise (Choose usernames and passwords in pairs) Enabling this option will make Ncrack iterate the username and password list by choosing them in pairs. For example, given the username list of \u0026quot;root, guest, admin\u0026quot; and the password list of \u0026quot;test, 12345, q1w2e3r4\u0026quot; Ncrack will go over them like this: \u0026quot;root:test\u0026quot;, \u0026quot;guest:12345\u0026quot;, \u0026quot;admin:q1w2e3r4\u0026quot;. This is particulary useful when inside knowledge of the infrastructure tested is available and special username and password lists have been made. OUTPUT Any security tool is only as useful as the output it generates. Complex tests and algorithms are of little value if they aren´t presented in an organized and comprehensible fashion. Of course, no single format can please everyone. So Ncrack offers several formats, including the interactive mode for humans to read directly and XML for easy parsing by software. In addition to offering different output formats, Ncrack provides options for controlling the verbosity of output as well as debugging messages. Output types may be sent to standard output or to named files, which Ncrack can append to or clobber. Ncrack makes output available in three different formats. The default is called interactive output, and it is sent to standard output (stdout). There is also normal output, which is similar to interactive except that it displays less runtime information and warnings since it is expected to be analyzed after the scan completes rather than interactively. XML output is one of the most important output types, as it can be converted to HTML, easily parsed by programs such as Ncrack graphical user interfaces, or imported into databases. Currently, XML output hasn´t been implemented. While interactive output is the default and has no associated command-line options, the other two format options use the same syntax. They take one argument, which is the filename that results should be stored in. Multiple formats may be specified, but each format may only be specified once. For example, you may wish to save normal output for your own review while saving XML of the same scan for programmatic analysis. You might do this with the options -oX myscan.xml -oN myscan.ncrack. While this chapter uses the simple names like myscan.xml for brevity, more descriptive names are generally recommended. The names chosen are a matter of personal preference. A scheme could be using long filenames that incorporate the scan date and a word or two describing the scan, placed in a directory named after the company that is being scanned. While these options save results to files, Ncrack still prints interactive output to stdout as usual. For example, the command nmap -oX myscan.xml [target] prints XML to myscan.xml and fills standard output with the same interactive results it would have printed if -oX wasn´t specified at all. You can change this by passing a hyphen character as the argument to one of the format types. This causes Ncrack to deactivate interactive output, and instead print results in the format you specified to the standard output stream. So the command nmap -oX - target will send only XML output to stdout. Serious errors may still be printed to the normal error stream, stderr. Unlike some Ncrack arguments, the space between the logfile option flag (such as -oX) and the filename or hyphen is mandatory. All of these arguments support strftime-like conversions in the filename. %H, %M, %S, %m, %d, %y, and %Y are all exactly the same as in strftime. %T is the same as %H%M%S, %R is the same as %H%M, and %D is the same as %m%d%y. A % followed by any other character just yields that character (%% gives you a percent symbol). So -oX ´scan-%T-%D.xml´ will use an XML file in the form of scan-144840-121307.xml. Ncrack also offers options to control scan verbosity and to append to output files rather than clobbering them. All of these options are described below. Ncrack Output Formats -oN filespec (normal output) . Requests that normal output be directed to the given filename. As discussed above, this differs slightly from interactive output. -oX filespec (XML output) . Requests that XML output be directed to the given filename. -oA basename (Output to all formats) . As a convenience, you may specify -oA basename to store scan results in normal and XML formats at once. They are stored in basename.ncrack, and basename.xml respectively. As with most programs, you can prefix the filenames with a directory path, such as ~/ncracklogs/foocorp/ on Unix or c:\\hacking\\sco on Windows. Verbosity and debugging options -v (Increase verbosity level) . Increases the verbosity level, causing Ncrack to print more information about the scan in progress. Credentials are shown as they are found and more statistical information is printed in the end. Use it twice or more for even greater verbosity. -d [level] (Increase or set debugging level) . When even verbose mode doesn´t provide sufficient data for you, debugging is available to flood you with much more! As with the verbosity option (-v), debugging is enabled with a command-line flag (-d) and the debug level can be increased by specifying it multiple times. Alternatively, you can set a debug level by giving an argument to -d. For example, -d10 sets level ten. That is the highest effective level and will produce thousands of lines, unless your cracking session is going really slow. Debugging output is useful when a bug is suspected in Ncrack, or if you are simply confused as to what Ncrack is doing and why. As this feature is mostly intended for developers, debug lines aren´t always self-explanatory. If you don´t understand a line, your only recourses are to ignore it, look it up in the source code, or request help from the development list (nmap-dev). Some lines are self explanatory, but the messages become more obscure as the debug level is increased. --nsock-trace level (Set nsock trace level) . This option is meant mostly for developers as enabling it will activate the Nsock´s library debugging output. Nsock is the underlying library for parallel socket handling. You will have to specify a certain level for this option. Valid range is 0 up to 10. Usually, a level of 1 or 2 is enough to get a good overview of network operations happening behind the scenes. Nsock prints that information to stdout by default. --log-errors (Log errors/warnings to normal mode output file) . Warnings and errors printed by Ncrack usually go only to the screen (interactive output), leaving any normal-format output files (usually specified with -oN) uncluttered. When you do want to see those messages in the normal output file you specified, add this option. It is useful when you aren´t watching the interactive output or when you want to record errors while debugging a problem. The error and warning messages will still appear in interactive mode too. This won´t work for most errors related to bad command-line arguments because Ncrack may not have initialized its output files yet. An alternative to --log-errors is redirecting interactive output (including the standard error stream) to a file. Most Unix shells make this approach easy, though it can be difficult on Windows. Miscellaneous output options --append-output (Append to rather than clobber output files) . When you specify a filename to an output format flag such as -oX or -oN, that file is overwritten by default. If you prefer to keep the existing content of the file and append the new results, specify the --append-output option. All output filenames specified in that Ncrack execution will then be appended to rather than clobbered. This doesn´t work well for XML (-oX) scan data as the resultant file generally won´t parse properly until you fix it up by hand. MISCELLANEOUS OPTIONS This section describes some important (and not-so-important) options that don´t really fit anywhere else. --resume file (Continue previously saved session) . Whenever the user cancels a running session (usually by pressing Ctrl+C), Ncrack saves the current state into a file which it can later use to continue from where it had stopped. This file is saved in subdirectory .ncrack/ of the user´s home path with a filename format of \u0026quot;restore.YY-MM-DD_hh-mm\u0026quot;. An example would be: \u0026quot;/home/ithilgore/.ncrack/restore.2010-05-18_04-42\u0026quot;. You can then continue your session, by specifying this file as argument to the --resume option. -f (Quit cracking service after one found credential) . This option will force Ncrack to quit cracking a service as soon as it finds a valid username/password combination for it. Assuming many parallel services are being cracked at the same time, this option is applied on each of them separately. This means that Ncrack will stop cracking each individual service after finding a pair of credentials for it, but will not quit entirely. Supplying the option two times, like -f -f will, however, make Ncrack exit immediately as soon as it finds a valid credential for any service. Frequently, attackers will try cracking several services in parallel to maximize the chances of finding a pair of valid credentials. Given that a network is no stronger than its weakest link, this option and especially the -f -f counterpart will often be used to lessen chances of detection and prevent network resources from being wasted aimlessly. -6 (Enable IPv6 scanning) . Warning: This option was just added and it is currently experimental, so please notify us for any problems and bugs related to it. The command syntax is the same as usual except that you also add the -6 option. Of course, you must use IPv6 syntax if you specify an address rather than a hostname. An address might look like 3ffe:7501:4819:2000:210:f3ff:fe03:14d0, so hostnames are recommended. The output looks the same as usual, with the IPv6 address on the “Discovered credentials” line being the only IPv6 give away. While IPv6 hasn´t exactly taken the world by storm, it gets significant use in some (usually Asian) countries and most modern operating systems support it. To use Ncrack with IPv6, both the source and target of your scan must be configured for IPv6. If your ISP (like most of them) does not allocate IPv6 addresses to you, free tunnel brokers are widely available and will probably work fine with Ncrack. A popular IPv6 tunnel broker service is at http://www.tunnelbroker.net. 6to4 tunnels are another popular, free approach. -sL (List Scan) . The list scan simply lists each host and service that would be cracked if this option wasn´t specified. No packets are sent to the target hosts and the only network operation that might happen is DNS-resolution of any hostnames of targets. This option is really helpful in making sure that you have specified everything as you wanted. Service-specific options will also be printed so this acts as a good sanity check of potentially complex command-line arguments such as the advanced modes of Service Option Specification and the equivalent Hierarchy for sessions that require delicate timing handling. If list scan is called along with the -d debug option, then additional output, like the ServicesTable and the current Timing-Template´s parameters, is also going to be printed. --datadir directoryname (Specify custom Ncrack data file location) . Ncrack needs a file called ncrack-services to load a lookup-table of supported services/ports. This file shouldn´t be changed, unless you know what you are doing (e.g extending Ncrack for additional modules). In addition, Ncrack is shipped with various username and password lists, some of which are used by default in case the user doesn´t specify ones of his own. All these files are normally copied during the installation procedure to a directory such as /usr/share/ncrack or /usr/local/share/ncrack . Using the --datadir option, will force Ncrack to start searching for these files in specified directory. If the files aren´t found, then it will continue searching in the directory specified by the NCRACKDIR environmental variable NCRACKDIR (if it is defined). Next comes ~/.ncrack directory for real and effective UIDs (POSIX systems only) or location of the Ncrack executable (Win32 only), and then a compiled-in location such as /usr/local/share/ncrack or /usr/share/ncrack. As a last resort, Ncrack will look in the current directory. --proxy type://proxy:port (Make connections via socks4, 4a, http) . This will make Ncrack perform the authentication cracking session through the proxy host specified. -V; --version (Print version number) . Prints the Ncrack version number and exits. -h; --help (Print help summary page) . Prints a short help screen with the most common command flags. Running Ncrack without any arguments does the same thing. RUNTIME INTERACTION During the execution of Ncrack, all key presses are captured. This allows you to interact with the program without aborting and restarting it. Certain special keys will change options, while any other keys will print out a status message telling you about the scan. The convention is that lowercase letters increase the amount of printing, and uppercase letters decrease the printing. You may also press ‘?’ for help. v / V Increase / decrease the verbosity level d / D Increase / decrease the debugging Level p / P Display found credentials ? Print a runtime interaction help screen Anything else Print out a status message like this: Stats: 0:00:20 elapsed; 0 services completed (1 total) Rate: 6.26; Found: 1; About 13.27% done; ETC: 21:06 (0:02:17 remaining) MODULES Ncrack´s architecture is modular with each module corresponding to one particular service or protocol. Currently, Ncrack supports the protocols SSH, RDP, FTP, Telnet, HTTP(S), POP3(S), IMAP, SMB, VNC, SIP Redis, PostgreSQL, MySQL, MSSQL, MongoDB, Cassandra, WinRM, OWA. If you want to write and contribute your own Ncrack modules, be sure to read the Ncrack Developer´s Guide at http://nmap.org/ncrack/devguide.html Below we describe some key points for each of them. FTP Module FTP authentication is quite fast, since there is very little protocol negotiation overhead. Most FTP daemons allow 3 to 6 authentication attempts but usually impose a certain delay before replying with the results of a failed attempt. Filezilla is one of the most characteristic examples of this case, where the time delay is so great, that it is usually faster to open more connections against it, with each of them doing only 1 authentication per connection. Telnet Module Telnet daemons have been largely substituded by their safer ´counterpart´ of SSH. However, there are many boxes, mainly routers or printers, that still rely on Telnet for remote access. Usually these are also easier to crack, since default passwords for them are publicly known. The drawback is that telnet is a rather slow protocol, so you shouldn´t be expecting really high rates against it. SSH Module SSH is one of the most prevalent protocols in today´s networks. For this reason, a special library, named opensshlib and based on code from OpenSSH, was specifically built and tailored for Ncrack´s needs. Opensshlib ships in with Ncrack, so SSH support comes out of the box. OpenSSL will have to be installed in Unix systems though. Windows OpenSSL dlls are included in Ncrack, so Windows users shouldn´t be worrying about it at all. SSH bruteforcing holds many pitfalls and challenges, and you are well advised to read a paper that was written to explain them. The latest version of the \u0026quot;Hacking the OpenSSH library for Ncrack\u0026quot; document can be found under docs/openssh_library.txt or at http://sock-raw.org/papers/openssh_library HTTP(S) Module The HTTP Module currently supports basic and digest authentication. Ncrack tries to use the \u0026quot;Keepalive\u0026quot; HTTP option, whenever possible, which leads to really high speeds, since that allows dozens of attempts to be carried out per connection. The HTTP module can also be called over SSL. SMB Module The SMB module currently works over raw TCP. NetBIOS isn´t supported yet. This protocol allows for high parallelization, so users could potentially increase the number of concurrent probes against it. SMB is frequently used for file-sharing among other things and is one of the most ubiquitous protocols, being present in both Unix and Windows environments. RDP Module RDP (Remote Desktop Protocol) is a proprietary protocol developed by Microsoft for the purpose of providing remote terminal services by transfering graphics display information from the remote computer to the user and transporting input commands from the user to the remote computer. Fortunately, Microsoft recently decided to open the protocol´s internal workings to the public and has provided official documentation, which can be found at http://msdn.microsoft.com/en-us/library/cc240445%28v=PROT.10%29.aspx RDP is one of the most complex protocols, requiring the exchange of many packets, even for just the authentication phase. For this reason, cracking it takes a lot of time and this is probably the slowest module. The connection phase is briefly described at http://msdn.microsoft.com/en-us/library/cc240452%28v=PROT.10%29.aspx where you can also see a diagram of the various packets involved. Care must be taken against RDP servers in Windows XP versions, since they can´t handle multiple connections at the same time. It is advised to use a very slow timing template or even better limit the maximum parallel connections using timing options such as CL (Connection Limit) or cd (connection delay) against Windows XP (and relevant) RDP servers. Windows Vista and above don´t suffer from the same limitation. VNC Module The VNC protocol has known widespread usage among Unix administrators and users for remote graphical access. VNC is perhaps one of the most vulnerable protocols in terms of brute-forcing, since it often requires a password without a corresponding username for authentication. In addition, some versions of VNC impose an 8-character limit in password length. You should consider adding the --passwords-first option when cracking VNC systems to exploit the fact that the username often has no actual importance in authentication. POP3(S) Module POP3 support is still experimental and hasn´t been thoroughly tested. You can expect it to work against common mail servers, nevertheless. IMAP Module The Internet Message Access Protocol (IMAP) is used by email clients to retrieve email messages from a mail server. The module sends the LOGIN command to authenticate. The LOGIN command is the simplest, fastest and most supported authentication mechanism for IMAP. SIP Module The Session Initiation Protocol is a text-based protocol, very similar to HTTP in its structure. The most common application of SIP is in Internet telephony for voice and video calls. Nearly all enterprises have infrastructure that supports conference calls and part of them are based on SIP, making the authentication part a significant threat vector. Redis Module Redis is one of the most widely used caching servers and the most popular NoSQL database. Despite its reputation, the authentication mechanism is very simple, only allowing for a password to protect remote access to the service. Due to the high performance of Redis and the fact that only 2 packets are needed for the authentication phase, Ncrack can try a lot of passwords in parallel (http://redis.io/commands/AUTH). Specifying a username list or single username will have no effect in this module, since Redis only deals with passwords. PostgreSQL Module PostgreSQL is often used as a backend database. The PostgreSQL module supports md5 authentication, which is the most frequent password authentication method. MySQL Module The MySQL module supports native authentication. MySQL Module The MSSQL module supports mixed authentication. MongoDB Module The MongoDB module supports MongoDB-CR and SCRAM-SHA-1 authentication. The pairwise and passwords-first option will be ignored for the MongoDB module, due to them being inefficient against MongoDB. The optimal way of cracking MongoDB is to take advantage of a user-enumeration vulnerability inherent in its authentication mechanism, which Ncrack exploits. Cassandra Module Apache Cassandra is a popular NoSQL database often left unsecured with weak credentials or no authentication. OWA Module Outlook Web App allows users to access a Microsoft Exchange Server mailbox from a web browser and experience Microsoft Outlook without a mail client. The module supports Basic Authentication. WinRM Module Windows Remote Management (WinRM) is the Microsoft implementation of WS-Management Protocol, a standard Simple Object Access Protocol (SOAP)-based, firewall-friendly protocol that allows hardware and operating systems, from different vendors, to interoperate. It is often used to administer Windows machines. The module supports Basic and Negotiate authentication. DICOM Module Digital Imaging and Communications in Medicine (DICOM) is a protocol used heavily in healthcare environments. Most commonly, it is used as both a file format and network protocol by Picture Archiving and Communication Systems (PACS). The client of a DICOM service is called a service class user (SCU) and the server a service class provider (SCP). DICOM is very unique in how it authenticates clients to servers; there are potentially one to three steps involved: Association, Find Service and Retrieve Images. Association: This is the initial step that almost all PACS servers require. By sending an A-ASSOCIATE request with the correct called Application Entity Title (AET) the client associates with the server and then can go on to perform query / retrieve requests in the next steps. This is the mode that Ncrack currently supports by iterating through the username field. Thus to brute-force the server´s AET, you can specify a list of AETs using the -U option and then specifying a null password. Example: ncrack dicom://127.0.0.1 -U aet.txt --pass DOESNOTMATTER Find Service: This step involves being able to query the PACS server for patient studies that are associated with DICOM images. This takes place after the client has performed the Association phase. A C-FIND request must be sent with the correct calling AET. Knowing the correct allowed client AET (or calling AET) is required by securely configured PACS servers. Many PACS servers by default do not require this. Retrieve Images: This step allows a client to retrieve DICOM images. The most hardened PACS servers will require the client to have a specific allowed IP configured in order to send a C-MOVE / C-STORE request after the above two steps have been performed. MQTT Module The Message Queueing Telemetry Transport (MQTT) protocol is a publish / subscribe machine to machine protocol that allows IoT clients to publish to a broker. Each client device subscribes to a particular topic of interest and receives messages from publishers. Usually MQTT authentication is optional and when enabled can be brute-forced very easily as it only requires a single MQTT CONNECT packet to be sent for each attemped credential pair. Wordpress Module Wodpress is one of the most popular content management systems. This module attacks the web administration endpoint. By default it will try \u0026quot;wp-login.php\u0026quot; but you can change it by specifying the path. For example: ncrack wp://127.0.0.1,path=/non-default/wp-login.php CVS Module The Concurrent Versioning System (CVS) is a revision control system in software development. Although not as popular nowadays, there are many old, oudated CVS servers out there that might have default or weak credentials. BUGS Like its authors, Ncrack isn´t perfect. But you can help make it better by sending bug reports or even writing patches. If Ncrack doesn´t behave the way you expect, first upgrade to the latest version available from http://nmap.org/ncrack. If the problem persists, do some research to determine whether it has already been discovered and addressed. Try searching for the error message on our search page at http://insecure.org/search.html or at Google. Also try browsing the nmap-dev archives at http://seclists.org/ . Read this full manual page as well. If you are developing your own Ncrack module, make sure you have first read the Ncrack Developer´s Guide at http://nmap.org/ncrack/devguide.html . If nothing comes of this, mail a bug report to nmap-dev@insecure.org . Please include everything you have learned about the problem, as well as what version of Ncrack you are running and what operating system version it is running on. Problem reports and Ncrack usage questions sent to nmap-dev@insecure.org are far more likely to be answered than those sent to Fyodor directly. If you subscribe to the nmap-dev list before posting, your message will bypass moderation and get through more quickly. Subscribe at http://cgi.insecure.org/mailman/listinfo/nmap-dev . Code patches to fix bugs are even better than bug reports. Basic instructions for creating patch files with your changes are available at http://nmap.org/data/HACKING . Patches may be sent to nmap-dev (recommended) or to Fyodor directly. AUTHORS ithilgore (Fotios (Fotis) Chantzis) ithilgore@sock-raw.org (http://sock-raw.org) Fyodor fyodor@insecure.org (http://insecure.org) NCRACK COPYRIGHT AND LICENSING While it isn´t distributed with Nmap, Ncrack is part of the Nmap project and falls under the same license and (non) warranty provisions, as described at http://nmap.org/book/man-legal.html. Ncrack 08/23/2019 NCRACK(1) ```bash "}),e.add({id:98,href:"/docs/tools/attack/socat/",title:"Socat",description:`Description # socat is a command line based utility that establishes two bidirectional byte streams and transfers data between them.
install # brew install socat website # http://www.dest-unreach.org/socat/
help # socat(1) socat(1) NAME socat - Multipurpose relay (SOcket CAT) SYNOPSIS socat [options] \u0026lt;address\u0026gt; \u0026lt;address\u0026gt; socat -V socat -h[h[h]] | -?[?[?]] filan procan DESCRIPTION Socat is a command line based utility that establishes two bidirectional byte streams and transfers data between them.`,content:"Description # socat is a command line based utility that establishes two bidirectional byte streams and transfers data between them.\ninstall # brew install socat website # http://www.dest-unreach.org/socat/\nhelp # socat(1) socat(1) NAME socat - Multipurpose relay (SOcket CAT) SYNOPSIS socat [options] \u0026lt;address\u0026gt; \u0026lt;address\u0026gt; socat -V socat -h[h[h]] | -?[?[?]] filan procan DESCRIPTION Socat is a command line based utility that establishes two bidirectional byte streams and transfers data between them. Because the streams can be constructed from a large set of different types of data sinks and sources (see address types), and because lots of address options may be applied to the streams, socat can be used for many different purposes. Filan is a utility that prints information about its active file descriptors to stdout. It has been written for debugging socat, but might be useful for other purposes too. Use the -h option to find more infos. Procan is a utility that prints information about process parameters to stdout. It has been written to better understand some UNIX process properties and for debugging socat, but might be use‐ ful for other purposes too. The life cycle of a socat instance typically consists of four phases. In the init phase, the command line options are parsed and logging is initialized. During the open phase, socat opens the first address and afterwards the second address. These steps are usually blocking; thus, especially for complex address types like socks, connection re‐ quests or authentication dialogs must be completed before the next step is started. In the transfer phase, socat watches both streams’ read and write file descriptors via select() , and, when data is available on one side and can be written to the other side, socat reads it, performs newline character conversions if required, and writes the data to the write file descriptor of the other stream, then continues waiting for more data in both directions. When one of the streams effectively reaches EOF, the closing phase begins. Socat transfers the EOF condition to the other stream, i.e. tries to shutdown only its write stream, giving it a chance to terminate gracefully. For a defined time socat continues to transfer data in the other direction, but then closes all remaining channels and terminates. OPTIONS Socat provides some command line options that modify the behaviour of the program. They have nothing to do with so called address options that are used as parts of address specifications. -V Print version and available feature information to stdout, and exit. -h | -? Print a help text to stdout describing command line options and available address types, and exit. -hh | -?? Like -h, plus a list of the short names of all available address options. Some options are platform dependend, so this output is helpful for checking the particular implementation. -hhh | -??? Like -hh, plus a list of all available address option names. -d Without this option, only fatal and error messages are generated; applying this option also prints warning messages. See DIAGNOSTICS for more information. -d -d Prints fatal, error, warning, and notice messages. -d -d -d Prints fatal, error, warning, notice, and info messages. -d -d -d -d Prints fatal, error, warning, notice, info, and debug messages. -D Logs information about file descriptors before starting the transfer phase. -ly[\u0026lt;facility\u0026gt;] Writes messages to syslog instead of stderr; severity as defined with -d option. With optional \u0026lt;facility\u0026gt;, the syslog type can be selected, default is \u0026quot;daemon\u0026quot;. Third party libraries might not obey this option. -lf \u0026lt;logfile\u0026gt; Writes messages to \u0026lt;logfile\u0026gt; [filename] instead of stderr. Some third party libraries, in particular libwrap, might not obey this option. -ls Writes messages to stderr (this is the default). Some third party libraries might not obey this option, in particular libwrap appears to only log to syslog. -lp\u0026lt;progname\u0026gt; Overrides the program name printed in error messages and used for constructing environment variable names. -lu Extends the timestamp of error messages to microsecond resolution. Does not work when logging to syslog. -lm[\u0026lt;facility\u0026gt;] Mixed log mode. During startup messages are printed to stderr; when socat starts the transfer phase loop or daemon mode (i.e. after opening all streams and before starting data trans‐ fer, or, with listening sockets with fork option, before the first accept call), it switches logging to syslog. With optional \u0026lt;facility\u0026gt;, the syslog type can be selected, default is \u0026quot;daemon\u0026quot;. -lh Adds hostname to log messages. Uses the value from environment variable HOSTNAME or the value retrieved with uname() if HOSTNAME is not set. -v Writes the transferred data not only to their target streams, but also to stderr. The output format is text with some conversions for readability, and prefixed with \u0026quot;\u0026gt; \u0026quot; or \u0026quot;\u0026lt; \u0026quot; indi‐ cating flow directions. -x Writes the transferred data not only to their target streams, but also to stderr. The output format is hexadecimal, prefixed with \u0026quot;\u0026gt; \u0026quot; or \u0026quot;\u0026lt; \u0026quot; indicating flow directions. Can be com‐ bined with -v . -r \u0026lt;file\u0026gt; Dumps the raw (binary) data flowing from left to right address to the given file. -R \u0026lt;file\u0026gt; Dumps the raw (binary) data flowing from right to left address to the given file. -b\u0026lt;size\u0026gt; Sets the data transfer block \u0026lt;size\u0026gt; [size_t]. At most \u0026lt;size\u0026gt; bytes are transferred per step. Default is 8192 bytes. -s By default, socat terminates when an error occurred to prevent the process from running when some option could not be applied. With this option, socat is sloppy with errors and tries to continue. Even with this option, socat will exit on fatals, and will abort connection attempts when security checks failed. -t\u0026lt;timeout\u0026gt; When one channel has reached EOF, the write part of the other channel is shut down. Then, socat waits \u0026lt;timeout\u0026gt; [timeval] seconds before terminating. Default is 0.5 seconds. This time‐ out only applies to addresses where write and read part can be closed independently. When during the timeout interval the read part gives EOF, socat terminates without awaiting the timeout. -T\u0026lt;timeout\u0026gt; Total inactivity timeout: when socat is already in the transfer loop and nothing has happened for \u0026lt;timeout\u0026gt; [timeval] seconds (no data arrived, no interrupt occurred...) then it termi‐ nates. Useful with protocols like UDP that cannot transfer EOF. -u Uses unidirectional mode. The first address is only used for reading, and the second address is only used for writing (example). -U Uses unidirectional mode in reverse direction. The first address is only used for writing, and the second address is only used for reading. -g During address option parsing, don’t check if the option is considered useful in the given address environment. Use it if you want to force, e.g., appliance of a socket option to a se‐ rial device. -L\u0026lt;lockfile\u0026gt; If lockfile exists, exits with error. If lockfile does not exist, creates it and continues, unlinks lockfile on exit. -W\u0026lt;lockfile\u0026gt; If lockfile exists, waits until it disappears. When lockfile does not exist, creates it and continues, unlinks lockfile on exit. -4 Use IP version 4 in case that the addresses do not implicitly or explicitly specify a version; this is the default. -6 Use IP version 6 in case that the addresses do not implicitly or explicitly specify a version. ADDRESS SPECIFICATIONS With the address command line arguments, the user gives socat instructions and the necessary information for establishing the byte streams. An address specification usually consists of an address type keyword, zero or more required address parameters separated by ’:’ from the keyword and from each other, and zero or more address options separated by ’,’. The keyword specifies the address type (e.g., TCP4, OPEN, EXEC). For some keywords there exist synonyms (’-’ for STDIO, TCP for TCP4). Keywords are case insensitive. For a few special address types, the keyword may be omitted: Address specifications starting with a number are assumed to be FD (raw file descriptor) addresses; if a ’/’ is found before the first ’:’ or ’,’, GOPEN (generic file open) is assumed. The required number and type of address parameters depend on the address type. E.g., TCP4 requires a server specification (name or address), and a port specification (number or service name). Zero or more address options may be given with each address. They influence the address in some ways. Options consist of an option keyword or an option keyword and a value, separated by ’=’. Option keywords are case insensitive. For filtering the options that are useful with an address type, each option is member of one option group. For each address type there is a set of option groups allowed. Only options belonging to one of these address groups may be used (except with option -g). Address specifications following the above schema are also called single address specifications. Two single addresses can be combined with \u0026quot;!!\u0026quot; to form a dual type address for one channel. Here, the first address is used by socat for reading data, and the second address for writing data. There is no way to specify an option only once for being applied to both single addresses. Usually, addresses are opened in read/write mode. When an address is part of a dual address specification, or when option -u or -U is used, an address might be used only for reading or for writing. Considering this is important with some address types. With socat version 1.5.0 and higher, the lexical analysis tries to handle quotes and parenthesis meaningfully and allows escaping of special characters. If one of the characters ( { [ ’ is found, the corresponding closing character - ) } ] ’ - is looked for; they may also be nested. Within these constructs, socats special characters and strings : , !! are not handled specially. All those characters and strings can be escaped with \\ or within \u0026quot;\u0026quot; ADDRESS TYPES This section describes the available address types with their keywords, parameters, and semantics. CREATE:\u0026lt;filename\u0026gt; Opens \u0026lt;filename\u0026gt; with creat() and uses the file descriptor for writing. This address type requires write-only context, because a file opened with creat cannot be read from. Flags like O_LARGEFILE cannot be applied. If you need them use OPEN with options create,create. \u0026lt;filename\u0026gt; must be a valid existing or not existing path. If \u0026lt;filename\u0026gt; is a named pipe, creat() might block; if \u0026lt;filename\u0026gt; refers to a socket, this is an error. Option groups: FD,REG,NAMED Useful options: mode, user, group, unlink-early, unlink-late, append See also: OPEN, GOPEN EXEC:\u0026lt;command-line\u0026gt; Forks a sub process that establishes communication with its parent process and invokes the specified program with execvp() . \u0026lt;command-line\u0026gt; is a simple command with arguments separated by single spaces. If the program name contains a ’/’, the part after the last ’/’ is taken as ARGV[0]. If the program name is a relative path, the execvp() semantics for finding the program via $PATH apply. After successful program start, socat writes data to stdin of the process and reads from its stdout using a UNIX domain socket generated by socketpair() per de‐ fault. (example) Option groups: FD,SOCKET,EXEC,FORK,TERMIOS Useful options: path, fdin, fdout, chroot, su, su-d, nofork, pty, stderr, ctty, setsid, pipes, login, sigint, sigquit See also: SYSTEM FD:\u0026lt;fdnum\u0026gt; Uses the file descriptor \u0026lt;fdnum\u0026gt;. It must already exist as valid UN*X file descriptor. Option groups: FD (TERMIOS,REG,SOCKET) See also: STDIO, STDIN, STDOUT, STDERR GOPEN:\u0026lt;filename\u0026gt; (Generic open) This address type tries to handle any file system entry except directories usefully. \u0026lt;filename\u0026gt; may be a relative or absolute path. If it already exists, its type is checked. In case of a UNIX domain socket, socat connects; if connecting fails, socat assumes a datagram socket and uses sendto() calls. If the entry is not a socket, socat opens it applying the O_APPEND flag. If it does not exist, it is opened with flag O_CREAT as a regular file (example). Option groups: FD,REG,SOCKET,NAMED,OPEN See also: OPEN, CREATE, UNIX-CONNECT IP-SENDTO:\u0026lt;host\u0026gt;:\u0026lt;protocol\u0026gt; Opens a raw IP socket. Depending on host specification or option pf, IP protocol version 4 or 6 is used. It uses \u0026lt;protocol\u0026gt; to send packets to \u0026lt;host\u0026gt; [IP address] and receives packets from host, ignores packets from other hosts. Protocol 255 uses the raw socket with the IP header being part of the data. Option groups: FD,SOCKET,IP4,IP6 Useful options: pf, ttl See also: IP4-SENDTO, IP6-SENDTO, IP-RECVFROM, IP-RECV, UDP-SENDTO, UNIX-SENDTO INTERFACE:\u0026lt;interface\u0026gt; Communicates with a network connected on an interface using raw packets including link level data. \u0026lt;interface\u0026gt; is the name of the network interface. Currently only available on Linux. Option groups: FD,SOCKET Useful options: pf, type See also: ip-recv IP4-SENDTO:\u0026lt;host\u0026gt;:\u0026lt;protocol\u0026gt; Like IP-SENDTO, but always uses IPv4. Option groups: FD,SOCKET,IP4 IP6-SENDTO:\u0026lt;host\u0026gt;:\u0026lt;protocol\u0026gt; Like IP-SENDTO, but always uses IPv6. Option groups: FD,SOCKET,IP6 IP-DATAGRAM:\u0026lt;address\u0026gt;:\u0026lt;protocol\u0026gt; Sends outgoing data to the specified address which may in particular be a broadcast or multicast address. Packets arriving on the local socket are checked if their source addresses match RANGE or TCPWRAP options. This address type can for example be used for implementing symmetric or asymmetric broadcast or multicast communications. Option groups: FD, SOCKET, IP4, IP6, RANGE Useful options: bind, range, tcpwrap, broadcast, ip-multicast-loop, ip-multicast-ttl, ip-multicast-if, ip-add-membership, ip-add-source-membership, ttl, tos, pf See also: IP4-DATAGRAM, IP6-DATAGRAM, IP-SENDTO, IP-RECVFROM, IP-RECV, UDP-DATAGRAM IP4-DATAGRAM:\u0026lt;host\u0026gt;:\u0026lt;protocol\u0026gt; Like IP-DATAGRAM, but always uses IPv4. (example) Option groups: FD,SOCKET,IP4,RANGE IP6-DATAGRAM:\u0026lt;host\u0026gt;:\u0026lt;protocol\u0026gt; Like IP-DATAGRAM, but always uses IPv6. Please note that IPv6 does not know broadcasts. Option groups: FD,SOCKET,IP6,RANGE IP-RECVFROM:\u0026lt;protocol\u0026gt; Opens a raw IP socket of \u0026lt;protocol\u0026gt;. Depending on option pf, IP protocol version 4 or 6 is used. It receives one packet from an unspecified peer and may send one or more answer packets to that peer. This mode is particularly useful with fork option where each arriving packet - from arbitrary peers - is handled by its own sub process. This allows a behaviour similar to typical UDP based servers like ntpd or named. Please note that the reply packets might be fetched as incoming traffic when sender and receiver IP address are identical because there is no port number to distinguish the sockets. This address works well with IP-SENDTO address peers (see above). Protocol 255 uses the raw socket with the IP header being part of the data. See the note about RECVFROM addresses. Option groups: FD,SOCKET,IP4,IP6,CHILD,RANGE Useful options: pf, fork, range, ttl, broadcast See also: IP4-RECVFROM, IP6-RECVFROM, IP-SENDTO, IP-RECV, UDP-RECVFROM, UNIX-RECVFROM IP4-RECVFROM:\u0026lt;protocol\u0026gt; Like IP-RECVFROM, but always uses IPv4. Option groups: FD,SOCKET,IP4,CHILD,RANGE IP6-RECVFROM:\u0026lt;protocol\u0026gt; Like IP-RECVFROM, but always uses IPv6. Option groups: FD,SOCKET,IP6,CHILD,RANGE IP-RECV:\u0026lt;protocol\u0026gt; Opens a raw IP socket of \u0026lt;protocol\u0026gt;. Depending on option pf, IP protocol version 4 or 6 is used. It receives packets from multiple unspecified peers and merges the data. No replies are possible. It can be, e.g., addressed by socat IP-SENDTO address peers. Protocol 255 uses the raw socket with the IP header being part of the data. Option groups: FD,SOCKET,IP4,IP6,RANGE Useful options: pf, range See also: IP4-RECV, IP6-RECV, IP-SENDTO, IP-RECVFROM, UDP-RECV, UNIX-RECV IP4-RECV:\u0026lt;protocol\u0026gt; Like IP-RECV, but always uses IPv4. Option groups: FD,SOCKET,IP4,RANGE IP6-RECV:\u0026lt;protocol\u0026gt; Like IP-RECV, but always uses IPv6. Option groups: FD,SOCKET,IP6,RANGE OPEN:\u0026lt;filename\u0026gt; Opens \u0026lt;filename\u0026gt; using the open() system call (example). This operation fails on UNIX domain sockets. Note: This address type is rarely useful in bidirectional mode. Option groups: FD,REG,NAMED,OPEN Useful options: creat, excl, noatime, nofollow, append, rdonly, wronly, lock, readbytes, ignoreeof See also: CREATE, GOPEN, UNIX-CONNECT OPENSSL:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Tries to establish a SSL connection to \u0026lt;port\u0026gt; [TCP service] on \u0026lt;host\u0026gt; [IP address] using TCP/IP version 4 or 6 depending on address specification, name resolution, or option pf. NOTE: Up to version 1.7.2.4 the server certificate was only checked for validity against the system certificate store or cafile or capath, but not for match with the server’s name or its IP address. Since version 1.7.3.0 socat checks the peer certificate for match with the \u0026lt;host\u0026gt; parameter or the value of the openssl-commonname option. Socat tries to match it against the certificates subject commonName, and the certificates extension subjectAltName DNS names. Wildcards in the certificate are supported. Option groups: FD,SOCKET,IP4,IP6,TCP,OPENSSL,RETRY Useful options: min-proto-version, cipher, verify, commonname, cafile, capath, certificate, key, compress, bind, pf, connect-timeout, sourceport, retry See also: OPENSSL-LISTEN, TCP OPENSSL-LISTEN:\u0026lt;port\u0026gt; Listens on tcp \u0026lt;port\u0026gt; [TCP service]. The IP version is 4 or the one specified with pf. When a connection is accepted, this address behaves as SSL server. Note: You probably want to use the certificate option with this address. NOTE: The client certificate is only checked for validity against cafile or capath, but not for match with the client’s name or its IP address! Option groups: FD,SOCKET,IP4,IP6,TCP,LISTEN,OPENSSL,CHILD,RANGE,RETRY Useful options: pf, min-proto-version, cipher, verify, commonname, cafile, capath, certificate, key, compress, fork, bind, range, tcpwrap, su, reuseaddr, retry See also: OPENSSL, TCP-LISTEN OPENSSL-DTLS-CLIENT:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Tries to establish a DTLS connection to \u0026lt;port\u0026gt; [UDP service] on \u0026lt;host\u0026gt; [IP address] using UDP/IP version 4 or 6 depending on address specification, name resolution, or option pf. Socat checks the peer certificates subjectAltName or commonName against the addresses option openssl-commonname or the host name. Wildcards in the certificate are supported. Use socat option -b to make datagrams small enough to fit with overhead on the network. Use option -T to prevent indefinite hanging when peer went down quietly. Option groups: FD,SOCKET,IP4,IP6,OPENSSL,RETRY Useful options: min-proto-version, cipher, verify, commonname, cafile, capath, certificate, key, compress, bind, pf, sourceport, retry See also: OPENSSL-DTLS-SERVER, OPENSSL-CONNECT, UDP-CONNECT OPENSSL-DTLS-SERVER:\u0026lt;port\u0026gt; Listens on UDP \u0026lt;port\u0026gt; [UDP service]. The IP version is 4 or the one specified with pf. When a connection is accepted, this address behaves as DTLS server. Note: You probably want to use the certificate option with this address. NOTE: The client certificate is only checked for validity against cafile or capath, but not for match with the client’s name or its IP address! Use socat option -b to make datagrams small enough to fit with overhead on the network. Use option -T to prevent indefinite hanging when peer went down quietly. Option groups: FD,SOCKET,IP4,IP6,LISTEN,OPENSSL,CHILD,RANGE,RETRY Useful options: pf, min-proto-version, cipher, verify, commonname, cafile, capath, certificate, key, compress, fork, bind, range, tcpwrap, su, reuseaddr, retry See also: OPENSSL-DTLS-CLIENT, OPENSSL-LISTEN, UDP-LISTEN PIPE:\u0026lt;filename\u0026gt; If \u0026lt;filename\u0026gt; already exists, it is opened. If it does not exist, a named pipe is created and opened. Beginning with socat version 1.4.3, the named pipe is removed when the address is closed (but see option unlink-close Note: When a pipe is used for both reading and writing, it works as echo service. Note: When a pipe is used for both reading and writing, and socat tries to write more bytes than the pipe can buffer (Linux 2.4: 2048 bytes), socat might block. Consider using socat op‐ tion, e.g., -b 2048 Option groups: FD,NAMED,OPEN Useful options: rdonly, nonblock, group, user, mode, unlink-early See also: unnamed pipe PIPE Creates an unnamed pipe and uses it for reading and writing. It works as an echo, because everything written to it appeares immediately as read data. Note: When socat tries to write more bytes than the pipe can queue (Linux 2.4: 2048 bytes), socat might block. Consider, e.g., using option -b 2048 Option groups: FD See also: named pipe PROXY:\u0026lt;proxy\u0026gt;:\u0026lt;hostname\u0026gt;:\u0026lt;port\u0026gt; Connects to an HTTP proxy server on port 8080 using TCP/IP version 4 or 6 depending on address specification, name resolution, or option pf, and sends a CONNECT request for host‐ name:port. If the proxy grants access and succeeds to connect to the target, data transfer between socat and the target can start. Note that the traffic need not be HTTP but can be an arbitrary protocol. Option groups: FD,SOCKET,IP4,IP6,TCP,HTTP,RETRY Useful options: proxyport, ignorecr, proxyauth, resolve, crnl, bind, connect-timeout, mss, sourceport, retry See also: SOCKS, TCP PTY Generates a pseudo terminal (pty) and uses its master side. Another process may open the pty’s slave side using it like a serial line or terminal. (example). If both the ptmx and the openpty mechanisms are available, ptmx is used (POSIX). Option groups: FD,NAMED,PTY,TERMIOS Useful options: link, openpty, wait-slave, mode, user, group See also: UNIX-LISTEN, PIPE, EXEC, SYSTEM READLINE Uses GNU readline and history on stdio to allow editing and reusing input lines (example). This requires the GNU readline and history libraries. Note that stdio should be a (pseudo) terminal device, otherwise readline does not seem to work. Option groups: FD,READLINE,TERMIOS Useful options: history, noecho See also: STDIO SCTP-CONNECT:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Establishes an SCTP stream connection to the specified \u0026lt;host\u0026gt; [IP address] and \u0026lt;port\u0026gt; [TCP service] using IP version 4 or 6 depending on address specification, name resolution, or op‐ tion pf. Option groups: FD,SOCKET,IP4,IP6,SCTP,CHILD,RETRY Useful options: bind, pf, connect-timeout, tos, mtudiscover, sctp-maxseg, sctp-nodelay, nonblock, sourceport, retry, readbytes See also: SCTP4-CONNECT, SCTP6-CONNECT, SCTP-LISTEN, TCP-CONNECT SCTP4-CONNECT:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like SCTP-CONNECT, but only supports IPv4 protocol. Option groups: FD,SOCKET,IP4,SCTP,CHILD,RETRY SCTP6-CONNECT:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like SCTP-CONNECT, but only supports IPv6 protocol. Option groups: FD,SOCKET,IP6,SCTP,CHILD,RETRY SCTP-LISTEN:\u0026lt;port\u0026gt; Listens on \u0026lt;port\u0026gt; [TCP service] and accepts an SCTP connection. The IP version is 4 or the one specified with address option pf, socat option (-4, -6), or environment variable SOCAT_DE‐ FAULT_LISTEN_IP. Note that opening this address usually blocks until a client connects. Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP4,IP6,SCTP,RETRY Useful options: crnl, fork, bind, range, tcpwrap, pf, max-children, backlog, accept-timeout, sctp-maxseg, sctp-nodelay, su, reuseaddr, retry, cool-write See also: SCTP4-LISTEN, SCTP6-LISTEN, TCP-LISTEN, SCTP-CONNECT SCTP4-LISTEN:\u0026lt;port\u0026gt; Like SCTP-LISTEN, but only supports IPv4 protocol. Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP4,SCTP,RETRY SCTP6-LISTEN:\u0026lt;port\u0026gt; Like SCTP-LISTEN, but only supports IPv6 protocol. Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP6,SCTP,RETRY SOCKET-CONNECT:\u0026lt;domain\u0026gt;:\u0026lt;protocol\u0026gt;:\u0026lt;remote-address\u0026gt; Creates a stream socket using the first and second given socket parameters and SOCK_STREAM (see man socket(2)) and connects to the remote-address. The two socket parameters have to be specified by int numbers. Consult your OS documentation and include files to find the appropriate values. The remote-address must be the data representation of a sockaddr structure without sa_family and (BSD) sa_len components. Please note that you can - beyond the options of the specified groups - also use options of higher level protocols when you apply socat option -g. Option groups: FD,SOCKET,CHILD,RETRY Useful options: bind, setsockopt, See also: TCP, UDP-CONNECT, UNIX-CONNECT, SOCKET-LISTEN, SOCKET-SENDTO SOCKET-DATAGRAM:\u0026lt;domain\u0026gt;:\u0026lt;type\u0026gt;:\u0026lt;protocol\u0026gt;:\u0026lt;remote-address\u0026gt; Creates a datagram socket using the first three given socket parameters (see man socket(2)) and sends outgoing data to the remote-address. The three socket parameters have to be speci‐ fied by int numbers. Consult your OS documentation and include files to find the appropriate values. The remote-address must be the data representation of a sockaddr structure without sa_family and (BSD) sa_len components. Please note that you can - beyond the options of the specified groups - also use options of higher level protocols when you apply socat option -g. Option groups: FD,SOCKET,RANGE Useful options: bind, range, setsockopt, See also: UDP-DATAGRAM, IP-DATAGRAM, SOCKET-SENDTO, SOCKET-RECV, SOCKET-RECVFROM SOCKET-LISTEN:\u0026lt;domain\u0026gt;:\u0026lt;protocol\u0026gt;:\u0026lt;local-address\u0026gt; Creates a stream socket using the first and second given socket parameters and SOCK_STREAM (see man socket(2)) and waits for incoming connections on local-address. The two socket param‐ eters have to be specified by int numbers. Consult your OS documentation and include files to find the appropriate values. The local-address must be the data representation of a sock‐ addr structure without sa_family and (BSD) sa_len components. Please note that you can - beyond the options of the specified groups - also use options of higher level protocols when you apply socat option -g. Option groups: FD,SOCKET,LISTEN,RANGE,CHILD,RETRY Useful options: setsockopt, setsockopt-listen, See also: TCP, UDP-CONNECT, UNIX-CONNECT, SOCKET-LISTEN, SOCKET-SENDTO, SOCKET-SENDTO SOCKET-RECV:\u0026lt;domain\u0026gt;:\u0026lt;type\u0026gt;:\u0026lt;protocol\u0026gt;:\u0026lt;local-address\u0026gt; Creates a socket using the three given socket parameters (see man socket(2)) and binds it to \u0026lt;local-address\u0026gt;. Receives arriving data. The three parameters have to be specified by int numbers. Consult your OS documentation and include files to find the appropriate values. The local-address must be the data representation of a sockaddr structure without sa_family and (BSD) sa_len components. Option groups: FD,SOCKET,RANGE Useful options: range, setsockopt, setsockopt-listen See also: UDP-RECV, IP-RECV, UNIX-RECV, SOCKET-DATAGRAM, SOCKET-SENDTO, SOCKET-RECVFROM SOCKET-RECVFROM:\u0026lt;domain\u0026gt;:\u0026lt;type\u0026gt;:\u0026lt;protocol\u0026gt;:\u0026lt;local-address\u0026gt; Creates a socket using the three given socket parameters (see man socket(2)) and binds it to \u0026lt;local-address\u0026gt;. Receives arriving data and sends replies back to the sender. The first three parameters have to be specified as int numbers. Consult your OS documentation and include files to find the appropriate values. The local-address must be the data representation of a sockaddr structure without sa_family and (BSD) sa_len components. See the note about RECVFROM addresses. Option groups: FD,SOCKET,CHILD,RANGE Useful options: fork, range, setsockopt, setsockopt-listen See also: UDP-RECVFROM, IP-RECVFROM, UNIX-RECVFROM, SOCKET-DATAGRAM, SOCKET-SENDTO, SOCKET-RECV SOCKET-SENDTO:\u0026lt;domain\u0026gt;:\u0026lt;type\u0026gt;:\u0026lt;protocol\u0026gt;:\u0026lt;remote-address\u0026gt; Creates a socket using the three given socket parameters (see man socket(2)). Sends outgoing data to the given address and receives replies. The three parameters have to be specified as int numbers. Consult your OS documentation and include files to find the appropriate values. The remote-address must be the data representation of a sockaddr structure without sa_family and (BSD) sa_len components. Option groups: FD,SOCKET Useful options: bind, setsockopt, setsockopt-listen See also: UDP-SENDTO, IP-SENDTO, UNIX-SENDTO, SOCKET-DATAGRAM, SOCKET-RECV SOCKET-RECVFROM SOCKS4:\u0026lt;socks-server\u0026gt;:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Connects via \u0026lt;socks-server\u0026gt; [IP address] to \u0026lt;host\u0026gt; [IPv4 address] on \u0026lt;port\u0026gt; [TCP service], using socks version 4 protocol over IP version 4 or 6 depending on address specification, name resolution, or option pf (example). Option groups: FD,SOCKET,IP4,IP6,TCP,SOCKS4,RETRY Useful options: socksuser, socksport, sourceport, pf, retry See also: SOCKS4A, PROXY, TCP SOCKS4A:\u0026lt;socks-server\u0026gt;:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; like SOCKS4, but uses socks protocol version 4a, thus leaving host name resolution to the socks server. Option groups: FD,SOCKET,IP4,IP6,TCP,SOCKS4,RETRY STDERR Uses file descriptor 2. Option groups: FD (TERMIOS,REG,SOCKET) See also: FD STDIN Uses file descriptor 0. Option groups: FD (TERMIOS,REG,SOCKET) Useful options: readbytes See also: FD STDIO Uses file descriptor 0 for reading, and 1 for writing. Option groups: FD (TERMIOS,REG,SOCKET) Useful options: readbytes See also: FD STDOUT Uses file descriptor 1. Option groups: FD (TERMIOS,REG,SOCKET) See also: FD SYSTEM:\u0026lt;shell-command\u0026gt; Forks a sub process that establishes communication with its parent process and invokes the specified program with system() . Please note that \u0026lt;shell-command\u0026gt; [string] must not contain ’,’ or \u0026quot;!!\u0026quot;, and that shell meta characters may have to be protected. After successful program start, socat writes data to stdin of the process and reads from its stdout. Option groups: FD,SOCKET,EXEC,FORK,TERMIOS Useful options: path, fdin, fdout, chroot, su, su-d, nofork, pty, stderr, ctty, setsid, pipes, sigint, sigquit See also: EXEC TCP:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Connects to \u0026lt;port\u0026gt; [TCP service] on \u0026lt;host\u0026gt; [IP address] using TCP/IP version 4 or 6 depending on address specification, name resolution, or option pf. Option groups: FD,SOCKET,IP4,IP6,TCP,RETRY Useful options: crnl, bind, pf, connect-timeout, tos, mtudiscover, mss, nodelay, nonblock, sourceport, retry, readbytes See also: TCP4, TCP6, TCP-LISTEN, UDP, SCTP-CONNECT, UNIX-CONNECT TCP4:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like TCP, but only supports IPv4 protocol (example). Option groups: FD,SOCKET,IP4,TCP,RETRY TCP6:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like TCP, but only supports IPv6 protocol. Option groups: FD,SOCKET,IP6,TCP,RETRY TCP-LISTEN:\u0026lt;port\u0026gt; Listens on \u0026lt;port\u0026gt; [TCP service] and accepts a TCP/IP connection. The IP version is 4 or the one specified with address option pf, socat option (-4, -6), or environment variable SO‐ CAT_DEFAULT_LISTEN_IP. Note that opening this address usually blocks until a client connects. Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP4,IP6,TCP,RETRY Useful options: crnl, fork, bind, range, tcpwrap, pf, max-children, backlog, accept-timeout, mss, su, reuseaddr, retry, cool-write See also: TCP4-LISTEN, TCP6-LISTEN, UDP-LISTEN, SCTP-LISTEN, UNIX-LISTEN, OPENSSL-LISTEN, TCP-CONNECT TCP4-LISTEN:\u0026lt;port\u0026gt; Like TCP-LISTEN, but only supports IPv4 protocol (example). Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP4,TCP,RETRY TCP6-LISTEN:\u0026lt;port\u0026gt; Like TCP-LISTEN, but only supports IPv6 protocol. Additional useful option: ipv6only Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP6,TCP,RETRY TUN[:\u0026lt;if-addr\u0026gt;/\u0026lt;bits\u0026gt;] Creates a Linux TUN/TAP device and optionally assignes it the address and netmask given by the parameters. The resulting network interface is almost ready for use by other processes; socat serves its \u0026quot;wire side\u0026quot;. This address requires read and write access to the tunnel cloning device, usually /dev/net/tun , as well as permission to set some ioctl()s. Option iff-up is required to immediately activate the interface! Note: If you intend to transfer packets between two Socat \u0026quot;wire sides\u0026quot; you need a protocol that keeps packet boundaries, e.g.UDP; TCP might work with option nodelay. Option groups: FD,NAMED,OPEN,TUN Useful options: iff-up, tun-device, tun-name, tun-type, iff-no-pi See also: ip-recv UDP:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Connects to \u0026lt;port\u0026gt; [UDP service] on \u0026lt;host\u0026gt; [IP address] using UDP/IP version 4 or 6 depending on address specification, name resolution, or option pf. Please note that, due to UDP protocol properties, no real connection is established; data has to be sent for `connecting’ to the server, and no end-of-file condition can be transported. Option groups: FD,SOCKET,IP4,IP6 Useful options: ttl, tos, bind, sourceport, pf See also: UDP4, UDP6, UDP-LISTEN, TCP, IP UDP4:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like UDP, but only supports IPv4 protocol. Option groups: FD,SOCKET,IP4 UDP6:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like UDP, but only supports IPv6 protocol. Option groups: FD,SOCKET,IP6 UDP-DATAGRAM:\u0026lt;address\u0026gt;:\u0026lt;port\u0026gt; Sends outgoing data to the specified address which may in particular be a broadcast or multicast address. Packets arriving on the local socket are checked for the correct remote port only when option sourceport is used (this is a change with Socat version 1.7.4.0) and if their source addresses match RANGE or TCPWRAP options. This address type can for example be used for implementing symmetric or asymmetric broadcast or multicast communications. Option groups: FD,SOCKET,IP4,IP6,RANGE Useful options: bind, range, tcpwrap, broadcast, ip-multicast-loop, ip-multicast-ttl, ip-multicast-if, ip-add-membership, ip-add-source-membership, ttl, tos, sourceport, pf See also: UDP4-DATAGRAM, UDP6-DATAGRAM, UDP-SENDTO, UDP-RECVFROM, UDP-RECV, UDP-CONNECT, UDP-LISTEN, IP-DATAGRAM UDP4-DATAGRAM:\u0026lt;address\u0026gt;:\u0026lt;port\u0026gt; Like UDP-DATAGRAM, but only supports IPv4 protocol (example1, example2). Option groups: FD,SOCKET,IP4, RANGE UDP6-DATAGRAM:\u0026lt;address\u0026gt;:\u0026lt;port\u0026gt; Like UDP-DATAGRAM, but only supports IPv6 protocol. Option groups: FD,SOCKET,IP6,RANGE UDP-LISTEN:\u0026lt;port\u0026gt; Waits for a UDP/IP packet arriving on \u0026lt;port\u0026gt; [UDP service] and `connects’ back to sender. The accepted IP version is 4 or the one specified with option pf. Please note that, due to UDP protocol properties, no real connection is established; data has to arrive from the peer first, and no end-of-file condition can be transported. Note that opening this address usu‐ ally blocks until a client connects. Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP4,IP6 Useful options: fork, bind, range, pf See also: UDP, UDP4-LISTEN, UDP6-LISTEN, TCP-LISTEN UDP4-LISTEN:\u0026lt;port\u0026gt; Like UDP-LISTEN, but only support IPv4 protocol. Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP4 UDP6-LISTEN:\u0026lt;port\u0026gt; Like UDP-LISTEN, but only support IPv6 protocol. Option groups: FD,SOCKET,LISTEN,CHILD,RANGE,IP6 UDP-SENDTO:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Communicates with the specified peer socket, defined by \u0026lt;port\u0026gt; [UDP service] on \u0026lt;host\u0026gt; [IP address], using UDP/IP version 4 or 6 depending on address specification, name resolution, or option pf. It sends packets to and receives packets from that peer socket only. This address effectively implements a datagram client. It works well with socat UDP-RECVFROM and UDP-RECV address peers. Option groups: FD,SOCKET,IP4,IP6 Useful options: ttl, tos, bind, sourceport, pf See also: UDP4-SENDTO, UDP6-SENDTO, UDP-RECVFROM, UDP-RECV, UDP-CONNECT, UDP-LISTEN, IP-SENDTO UDP4-SENDTO:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like UDP-SENDTO, but only supports IPv4 protocol. Option groups: FD,SOCKET,IP4 UDP6-SENDTO:\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt; Like UDP-SENDTO, but only supports IPv6 protocol. Option groups: FD,SOCKET,IP6 UDP-RECVFROM:\u0026lt;port\u0026gt; Creates a UDP socket on \u0026lt;port\u0026gt; [UDP service] using UDP/IP version 4 or 6 depending on option pf. It receives one packet from an unspecified peer and may send one or more answer packets to that peer. This mode is particularly useful with fork option where each arriving packet - from arbitrary peers - is handled by its own sub process. This allows a behaviour similar to typical UDP based servers like ntpd or named. This address works well with socat UDP-SENDTO address peers. Note: When the second address fails before entering the transfer loop the packet is dropped. Use option retry or forever on the second address to avoid data loss. Option groups: FD,SOCKET,IP4,IP6,CHILD,RANGE Useful options: fork, ttl, tos, bind, sourceport, pf See also: UDP4-RECVFROM, UDP6-RECVFROM, UDP-SENDTO, UDP-RECV, UDP-CONNECT, UDP-LISTEN, IP-RECVFROM, UNIX-RECVFROM UDP4-RECVFROM:\u0026lt;port\u0026gt; Like UDP-RECVFROM, but only supports IPv4 protocol. Option groups: FD,SOCKET,IP4,CHILD,RANGE UDP6-RECVFROM:\u0026lt;port\u0026gt; Like UDP-RECVFROM, but only supports IPv6 protocol. Option groups: FD,SOCKET,IP6,CHILD,RANGE UDP-RECV:\u0026lt;port\u0026gt; Creates a UDP socket on \u0026lt;port\u0026gt; [UDP service] using UDP/IP version 4 or 6 depending on option pf. It receives packets from multiple unspecified peers and merges the data. No replies are possible. It works well with, e.g., socat UDP-SENDTO address peers; it behaves similar to a syslog server. Note: if you need the fork option, use UDP-RECVFROM in unidirectional mode (with option -u) instead. Option groups: FD,SOCKET,IP4,IP6,RANGE Useful options: pf, bind, sourceport, ttl, tos See also: UDP4-RECV, UDP6-RECV, UDP-SENDTO, UDP-RECVFROM, UDP-CONNECT, UDP-LISTEN, IP-RECV, UNIX-RECV UDP4-RECV:\u0026lt;port\u0026gt; Like UDP-RECV, but only supports IPv4 protocol. Option groups: FD,SOCKET,IP4,RANGE UDP6-RECV:\u0026lt;port\u0026gt; Like UDP-RECV, but only supports IPv6 protocol. Option groups: FD,SOCKET,IP6,RANGE UNIX-CONNECT:\u0026lt;filename\u0026gt; Connects to \u0026lt;filename\u0026gt; assuming it is a UNIX domain socket. If \u0026lt;filename\u0026gt; does not exist, this is an error; if \u0026lt;filename\u0026gt; is not a UNIX domain socket, this is an error; if \u0026lt;filename\u0026gt; is a UNIX domain socket, but no process is listening, this is an error. Option groups: FD,SOCKET,NAMED,RETRY,UNIX ) Useful options: bind See also: UNIX-LISTEN, UNIX-SENDTO, TCP UNIX-LISTEN:\u0026lt;filename\u0026gt; Listens on \u0026lt;filename\u0026gt; using a UNIX domain stream socket and accepts a connection. If \u0026lt;filename\u0026gt; exists and is not a socket, this is an error. If \u0026lt;filename\u0026gt; exists and is a UNIX domain socket, binding to the address fails (use option unlink-early!). Note that opening this address usually blocks until a client connects. Beginning with socat version 1.4.3, the file system entry is removed when this address is closed (but see option unlink-close) (example). Option groups: FD,SOCKET,NAMED,LISTEN,CHILD,RETRY,UNIX Useful options: fork, umask, mode, user, group, unlink-early See also: UNIX-CONNECT, UNIX-RECVFROM, UNIX-RECV, TCP-LISTEN UNIX-SENDTO:\u0026lt;filename\u0026gt; Communicates with the specified peer socket, defined by [\u0026lt;filename\u0026gt;] assuming it is a UNIX domain datagram socket. It sends packets to and receives packets from that peer socket only. Please note that it might be necessary to bind the local socket to an address (e.g. /tmp/sock1, which must not exist before). This address type works well with socat UNIX-RECVFROM and UNIX-RECV address peers. Option groups: FD,SOCKET,NAMED,UNIX Useful options: bind See also: UNIX-RECVFROM, UNIX-RECV, UNIX-CONNECT, UDP-SENDTO, IP-SENDTO UNIX-RECVFROM:\u0026lt;filename\u0026gt; Creates a UNIX domain datagram socket [\u0026lt;filename\u0026gt;]. Receives one packet and may send one or more answer packets to that peer. This mode is particularly useful with fork option where each arriving packet - from arbitrary peers - is handled by its own sub process. This address works well with socat UNIX-SENDTO address peers. Option groups: FD,SOCKET,NAMED,CHILD,UNIX See the note about RECVFROM addresses. Useful options: fork See also: UNIX-SENDTO, UNIX-RECV, UNIX-LISTEN, UDP-RECVFROM, IP-RECVFROM UNIX-RECV:\u0026lt;filename\u0026gt; Creates a UNIX domain datagram socket [\u0026lt;filename\u0026gt;]. Receives packets from multiple unspecified peers and merges the data. No replies are possible. It can be, e.g., addressed by socat UNIX-SENDTO address peers. It behaves similar to a syslog server. Option groups: FD,SOCKET,NAMED,UNIX See also: UNIX-SENDTO, UNIX-RECVFROM, UNIX-LISTEN, UDP-RECV, IP-RECV UNIX-CLIENT:\u0026lt;filename\u0026gt; Communicates with the specified peer socket, defined by [\u0026lt;filename\u0026gt;] assuming it is a UNIX domain socket. It first tries to connect and, if that fails, assumes it is a datagram socket, thus supporting both types. Option groups: FD,SOCKET,NAMED,UNIX Useful options: bind See also: UNIX-CONNECT, UNIX-SENDTO, GOPEN VSOCK-CONNECT:\u0026lt;cid\u0026gt;:\u0026lt;port\u0026gt; Establishes a VSOCK stream connection to the specified \u0026lt;cid\u0026gt; [VSOCK cid] and \u0026lt;port\u0026gt; [VSOCK port]. Option groups: FD,SOCKET,CHILD,RETRY Useful options: bind, pf, connect-timeout, retry, readbytes See also: VSOCK-LISTEN, VSOCK-LISTEN:\u0026lt;port\u0026gt; Listens on \u0026lt;port\u0026gt; [VSOCK port] and accepts a VSOCK connection. Note that opening this address usually blocks until a client connects. Option groups: FD,SOCKET,LISTEN,CHILD,RETRY Useful options: fork, bind, pf, max-children, backlog, su, reuseaddr, retry, cool-write See also: VSOCK-CONNECT ABSTRACT-CONNECT:\u0026lt;string\u0026gt; ABSTRACT-LISTEN:\u0026lt;string\u0026gt; ABSTRACT-SENDTO:\u0026lt;string\u0026gt; ABSTRACT-RECVFROM:\u0026lt;string\u0026gt; ABSTRACT-RECV:\u0026lt;string\u0026gt; ABSTRACT-CLIENT:\u0026lt;string\u0026gt; The ABSTRACT addresses are almost identical to the related UNIX addresses except that they do not address file system based sockets but an alternate UNIX domain address space. To achieve this the socket address strings are prefixed with \u0026quot;\\0\u0026quot; internally. This feature is available (only?) on Linux. Option groups are the same as with the related UNIX addresses, except that the ABSTRACT addresses are not member of the NAMED group. ADDRESS OPTIONS Address options can be applied to address specifications to influence the process of opening the addresses and the properties of the resulting data channels. For technical reasons not every option can be applied to every address type; e.g., applying a socket option to a regular file will fail. To catch most useless combinations as early as in the open phase, the concept of option groups was introduced. Each option belongs to one or more option groups. Options can be used only with address types that support at least one of their option groups (but see option -g). Address options have data types that their values must conform to. Every address option consists of just a keyword or a keyword followed by \u0026quot;=value\u0026quot;, where value must conform to the options type. Some address options manipulate parameters of system calls; e.g., option sync sets the O_SYNC flag with the open() call. Other options cause a system or library call; e.g., with option `ttl=value’ the setsockopt(fd, SOL_IP, IP_TTL, value, sizeof(int)) call is applied. Other options set internal socat variables that are used during data transfer; e.g., `crnl’ causes explicit character conversions. A few options have more complex implementations; e.g., su-d (substuser-delayed) inquires some user and group infos, stores them, and applies them later after a possible chroot() call. If multiple options are given to an address, their sequence in the address specification has (almost) no effect on the sequence of their execution/application. Instead, socat has built in an option phase model that tries to bring the options in a useful order. Some options exist in different forms (e.g., unlink, unlink-early, unlink-late) to control the time of their execution. If the same option is specified more than once within one address specification, with equal or different values, the effect depends on the kind of option. Options resulting in function calls like setsockopt() cause multiple invocations. With options that set parameters for a required call like open() or set internal flags, the value of the last option occurrence is effective. The existence or semantics of many options are system dependent. Socat usually does NOT try to emulate missing libc or kernel features, it just provides an interface to the underlying system. So, if an operating system lacks a feature, the related option is simply not available on this platform. The following paragraphs introduce just the more common address options. For a more comprehensive reference and to find information about canonical option names, alias names, option phases, and platforms see file xio.help. FD option group This option group contains options that are applied to a UN*X style file descriptor, no matter how it was generated. Because all current socat address types are file descriptor based, these options may be applied to any address. Note: Some of these options are also member of another option group, that provides another, non-fd based mechanism. For these options, it depends on the actual address type and its option groups which mechanism is used. The second, non-fd based mechanism is prioritized. cloexec=\u0026lt;bool\u0026gt; Sets the FD_CLOEXEC flag with the fcntl() system call to value \u0026lt;bool\u0026gt;. If set, the file descriptor is closed on exec() family function calls. Socat internally handles this flag for the fds it controls, so in most cases there will be no need to apply this option. setlk Tries to set a discretionary write lock to the whole file using the fcntl(fd, F_SETLK, ...) system call. If the file is already locked, this call results in an error. On Linux, when the file permissions for group are \u0026quot;S\u0026quot; (g-x,g+s), and the file system is locally mounted with the \u0026quot;mand\u0026quot; option, the lock is mandatory, i.e. prevents other processes from opening the file. setlkw Tries to set a discretionary waiting write lock to the whole file using the fcntl(fd, F_SETLKW, ...) system call. If the file is already locked, this call blocks. See option setlk for information about making this lock mandatory. setlk-rd Tries to set a discretionary read lock to the whole file using the fcntl(fd, F_SETLK, ...) system call. If the file is already write locked, this call results in an error. See option setlk for information about making this lock mandatory. setlkw-rd Tries to set a discretionary waiting read lock to the whole file using the fcntl(fd, F_SETLKW, ...) system call. If the file is already write locked, this call blocks. See option setlk for information about making this lock mandatory. flock-ex Tries to set a blocking exclusive advisory lock to the file using the flock(fd, LOCK_EX) system call. Socat hangs in this call if the file is locked by another process. flock-ex-nb Tries to set a nonblocking exclusive advisory lock to the file using the flock(fd, LOCK_EX|LOCK_NB) system call. If the file is already locked, this option results in an error. flock-sh Tries to set a blocking shared advisory lock to the file using the flock(fd, LOCK_SH) system call. Socat hangs in this call if the file is locked by another process. flock-sh-nb Tries to set a nonblocking shared advisory lock to the file using the flock(fd, LOCK_SH|LOCK_NB) system call. If the file is already locked, this option results in an error. lock Sets a blocking lock on the file. Uses the setlk or flock mechanism depending on availability on the particular platform. If both are available, the POSIX variant (setlkw) is used. user=\u0026lt;user\u0026gt; Sets the \u0026lt;user\u0026gt; (owner) of the stream. If the address is member of the NAMED option group, socat uses the chown() system call after opening the file or binding to the UNIX domain socket (race condition!). Without filesystem entry, socat sets the user of the stream using the fchown() system call. These calls might require root privilege. user-late=\u0026lt;user\u0026gt; Sets the owner of the fd to \u0026lt;user\u0026gt; with the fchown() system call after opening or connecting the channel. This is useful only on file system entries. group=\u0026lt;group\u0026gt; Sets the \u0026lt;group\u0026gt; of the stream. If the address is member of the NAMED option group, socat uses the chown() system call after opening the file or binding to the UNIX domain socket (race condition!). Without filesystem entry, socat sets the group of the stream with the fchown() system call. These calls might require group membership or root privilege. group-late=\u0026lt;group\u0026gt; Sets the group of the fd to \u0026lt;group\u0026gt; with the fchown() system call after opening or connecting the channel. This is useful only on file system entries. mode=\u0026lt;mode\u0026gt; Sets the \u0026lt;mode\u0026gt; [mode_t] (permissions) of the stream. If the address is member of the NAMED option group and uses the open() or creat() call, the mode is applied with these. If the address is member of the NAMED option group without using these system calls, socat uses the chmod() system call after opening the filesystem entry or binding to the UNIX domain socket (race condition!). Otherwise, socat sets the mode of the stream using fchmod() . These calls might require ownership or root privilege. perm-late=\u0026lt;mode\u0026gt; Sets the permissions of the fd to value \u0026lt;mode\u0026gt; [mode_t] using the fchmod() system call after opening or connecting the channel. This is useful only on file system entries. append=\u0026lt;bool\u0026gt; Always writes data to the actual end of file. If the address is member of the OPEN option group, socat uses the O_APPEND flag with the open() system call (example). Otherwise, socat applies the fcntl(fd, F_SETFL, O_APPEND) call. nonblock=\u0026lt;bool\u0026gt; Tries to open or use file in nonblocking mode. Its only effects are that the connect() call of TCP addresses does not block, and that opening a named pipe for reading does not block. If the address is member of the OPEN option group, socat uses the O_NONBLOCK flag with the open() system call. Otherwise, socat applies the fcntl(fd, F_SETFL, O_NONBLOCK) call. binary Opens the file in binary mode to avoid implicit line terminator conversions (Cygwin). text Opens the file in text mode to force implicit line terminator conversions (Cygwin). noinherit Does not keep this file open in a spawned process (Cygwin). cool-write Takes it easy when write fails with EPIPE or ECONNRESET and logs the message with notice level instead of error. This prevents the log file from being filled with useless error mes‐ sages when socat is used as a high volume server or proxy where clients often abort the connection. This option is experimental. end-close Changes the (address dependent) method of ending a connection to just close the file descriptors. This is useful when the connection is to be reused by or shared with other processes (example). Normally, socket connections will be ended with shutdown(2) which terminates the socket even if it is shared by multiple processes. close(2) \u0026quot;unlinks\u0026quot; the socket from the process but keeps it active as long as there are still links from other processes. Similarly, when an address of type EXEC or SYSTEM is ended, socat usually will explicitly kill the sub process. With this option, it will just close the file descriptors. shut-none Changes the (address dependent) method of shutting down the write part of a connection to not do anything. shut-down Changes the (address dependent) method of shutting down the write part of a connection to shutdown(fd, SHUT_WR). Is only useful with sockets. shut-close Changes the (address dependent) method of shutting down the write part of a connection to close(fd). shut-null When one address indicates EOF, socat will send a zero sized packet to the write channel of the other address to transfer the EOF condition. This is useful with UDP and other datagram protocols. Has been tested against netcat and socat with option null-eof. null-eof Normally socat will ignore empty (zero size payload) packets arriving on datagram sockets, so it survives port scans. With this option socat interprets empty datagram packets as EOF in‐ dicator (see shut-null). ioctl-void=\u0026lt;request\u0026gt; Calls ioctl() with the request value as second argument and NULL as third argument. This option allows utilizing ioctls that are not explicitly implemented in socat. ioctl-int=\u0026lt;request\u0026gt;:\u0026lt;value\u0026gt; Calls ioctl() with the request value as second argument and the integer value as third argument. ioctl-intp=\u0026lt;request\u0026gt;:\u0026lt;value\u0026gt; Calls ioctl() with the request value as second argument and a pointer to the integer value as third argument. ioctl-bin=\u0026lt;request\u0026gt;:\u0026lt;value\u0026gt; Calls ioctl() with the request value as second argument and a pointer to the given data value as third argument. This data must be specified in \u0026lt;dalan\u0026gt; form. ioctl-string=\u0026lt;request\u0026gt;:\u0026lt;value\u0026gt; Calls ioctl() with the request value as second argument and a pointer to the given string as third argument. \u0026lt;dalan\u0026gt; form. NAMED option group These options work on file system entries. Please note that, with UNIX domain client addresses, this means the bind entry, not the target/peer entry. See also options user, group, and mode. user-early=\u0026lt;user\u0026gt; Changes the \u0026lt;user\u0026gt; (owner) of the file system entry before accessing it, using the chown() system call. This call might require root privilege. group-early=\u0026lt;group\u0026gt; Changes the \u0026lt;group\u0026gt; of the file system entry before accessing it, using the chown() system call. This call might require group membership or root privilege. perm-early=\u0026lt;mode\u0026gt; Changes the \u0026lt;mode\u0026gt; [mode_t] of the file system entry before accessing it, using the chmod() system call. This call might require ownership or root privilege. umask=\u0026lt;mode\u0026gt; Sets the umask of the process to \u0026lt;mode\u0026gt; [mode_t] before accessing the file system entry (useful with UNIX domain sockets!). This call might affect all further operations of the socat process! unlink-early Unlinks (removes) the file before opening it and even before applying user-early etc. unlink Unlinks (removes) the file before accessing it, but after user-early etc. unlink-late Unlinks (removes) the file after opening it to make it inaccessible for other processes after a short race condition. unlink-close Removes the addresses file system entry when closing the address. For named pipes, UNIX domain sockets, and the symbolic links of pty addresses, the default is 1; for created files, opened files, and generic opened files the default is 0. OPEN option group The OPEN group options allow setting flags with the open() system call. E.g., option `creat’ sets the O_CREAT flag. See also options append and nonblock. creat=\u0026lt;bool\u0026gt; Creates the file if it does not exist (example). dsync=\u0026lt;bool\u0026gt; Blocks write() calls until metainfo is physically written to media. excl=\u0026lt;bool\u0026gt; With option creat, if file exists this is an error. largefile=\u0026lt;bool\u0026gt; On 32 bit systems, allows a file larger than 2^31 bytes. noatime Sets the O_NOATIME options, so reads do not change the access timestamp. noctty=\u0026lt;bool\u0026gt; Does not make this file the controlling terminal. nofollow=\u0026lt;bool\u0026gt; Does not follow symbolic links. nshare=\u0026lt;bool\u0026gt; Does not allow sharing this file with other processes. rshare=\u0026lt;bool\u0026gt; Does not allow other processes to open this file for writing. rsync=\u0026lt;bool\u0026gt; Blocks write() until metainfo is physically written to media. sync=\u0026lt;bool\u0026gt; Blocks write() until data is physically written to media. rdonly=\u0026lt;bool\u0026gt; Opens the file for reading only. wronly=\u0026lt;bool\u0026gt; Opens the file for writing only. trunc Truncates the file to size 0 during opening it. REG and BLK option group These options are usually applied to a UN*X file descriptor, but their semantics make sense only on a file supporting random access. seek=\u0026lt;offset\u0026gt; Applies the lseek(fd, \u0026lt;offset\u0026gt;, SEEK_SET) (or lseek64 ) system call, thus positioning the file pointer absolutely to \u0026lt;offset\u0026gt; [off_t or off64_t]. Please note that a missing value de‐ faults to 1, not 0. seek-cur=\u0026lt;offset\u0026gt; Applies the lseek(fd, \u0026lt;offset\u0026gt;, SEEK_CUR) (or lseek64 ) system call, thus positioning the file pointer \u0026lt;offset\u0026gt; [off_t or off64_t] bytes relatively to its current position (which is usually 0). Please note that a missing value defaults to 1, not 0. seek-end=\u0026lt;offset\u0026gt; Applies the lseek(fd, \u0026lt;offset\u0026gt;, SEEK_END) (or lseek64 ) system call, thus positioning the file pointer \u0026lt;offset\u0026gt; [off_t or off64_t] bytes relatively to the files current end. Please note that a missing value defaults to 1, not 0. ftruncate=\u0026lt;offset\u0026gt; Applies the ftruncate(fd, \u0026lt;offset\u0026gt;) (or ftruncate64 if available) system call, thus truncating the file at the position \u0026lt;offset\u0026gt; [off_t or off64_t]. Please note that a missing value de‐ faults to 1, not 0. secrm=\u0026lt;bool\u0026gt; unrm=\u0026lt;bool\u0026gt; compr=\u0026lt;bool\u0026gt; fs-sync=\u0026lt;bool\u0026gt; immutable=\u0026lt;bool\u0026gt; fs-append=\u0026lt;bool\u0026gt; nodump=\u0026lt;bool\u0026gt; fs-noatime=\u0026lt;bool\u0026gt; journal-data=\u0026lt;bool\u0026gt; notail=\u0026lt;bool\u0026gt; dirsync=\u0026lt;bool\u0026gt; These options change non standard file attributes on operating systems and file systems that support these features, like Linux with ext2fs and successors, xfs, or reiserfs. See man 1 chattr for information on these options. Please note that there might be a race condition between creating the file and applying these options. PROCESS option group Options of this group change the process properties instead of just affecting one data channel. For EXEC and SYSTEM addresses and for LISTEN and CONNECT type addresses with option FORK, these options apply to the child processes instead of the main socat process. chroot=\u0026lt;directory\u0026gt; Performs a chroot() operation to \u0026lt;directory\u0026gt; after processing the address (example). This call might require root privilege. chroot-early=\u0026lt;directory\u0026gt; Performs a chroot() operation to \u0026lt;directory\u0026gt; before opening the address. This call might require root privilege. setgid=\u0026lt;group\u0026gt; Changes the primary \u0026lt;group\u0026gt; of the process after processing the address. This call might require root privilege. Please note that this option does not drop other group related privi‐ leges. setgid-early=\u0026lt;group\u0026gt; Like setgit but is performed before opening the address. setuid=\u0026lt;user\u0026gt; Changes the \u0026lt;user\u0026gt; (owner) of the process after processing the address. This call might require root privilege. Please note that this option does not drop group related privileges. Check if option su better fits your needs. setuid-early=\u0026lt;user\u0026gt; Like setuid but is performed before opening the address. su=\u0026lt;user\u0026gt; Changes the \u0026lt;user\u0026gt; (owner) and groups of the process after processing the address (example). This call might require root privilege. su-d=\u0026lt;user\u0026gt; Short name for substuser-delayed. Changes the \u0026lt;user\u0026gt; (owner) and groups of the process after processing the address (example). The user and his groups are retrieved before a possible chroot() . This call might require root privilege. setpgid=\u0026lt;pid_t\u0026gt; Makes the process a member of the specified process group \u0026lt;pid_t\u0026gt;. If no value is given, or if the value is 0 or 1, the process becomes leader of a new process group. setsid Makes the process the leader of a new session (example). READLINE option group These options apply to the readline address type. history=\u0026lt;filename\u0026gt; Reads and writes history from/to \u0026lt;filename\u0026gt; (example). noprompt Since version 1.4.0, socat per default tries to determine a prompt - that is then passed to the readline call - by remembering the last incomplete line of the output. With this option, socat does not pass a prompt to readline, so it begins line editing in the first column of the terminal. noecho=\u0026lt;pattern\u0026gt; Specifies a regular pattern for a prompt that prevents the following input line from being displayed on the screen and from being added to the history. The prompt is defined as the text that was output to the readline address after the lastest newline character and before an input character was typed. The pattern is a regular expression, e.g. \u0026quot;^[Pp]assword:.*$\u0026quot; or \u0026quot;([Uu]ser:|[Pp]assword:)\u0026quot;. See regex(7) for details. (example) prompt=\u0026lt;string\u0026gt; Passes the string as prompt to the readline function. readline prints this prompt when stepping through the history. If this string matches a constant prompt issued by an interactive program on the other socat address, consistent look and feel can be achieved. APPLICATION option group This group contains options that work at data level. Note that these options only apply to the \u0026quot;raw\u0026quot; data transferred by socat, but not to protocol data used by addresses like PROXY. cr Converts the default line termination character NL (’\\n’, 0x0a) to/from CR (’\\r’, 0x0d) when writing/reading on this channel. crnl Converts the default line termination character NL (’\\n’, 0x0a) to/from CRNL (\u0026quot;\\r\\n\u0026quot;, 0x0d0a) when writing/reading on this channel (example). Note: socat simply strips all CR charac‐ ters. ignoreeof When EOF occurs on this channel, socat ignores it and tries to read more data (like \u0026quot;tail -f\u0026quot;) (example). readbytes=\u0026lt;bytes\u0026gt; socat reads only so many bytes from this address (the address provides only so many bytes for transfer and pretends to be at EOF afterwards). Must be greater than 0. lockfile=\u0026lt;filename\u0026gt; If lockfile exists, exits with error. If lockfile does not exist, creates it and continues, unlinks lockfile on exit. waitlock=\u0026lt;filename\u0026gt; If lockfile exists, waits until it disappears. When lockfile does not exist, creates it and continues, unlinks lockfile on exit. escape=\u0026lt;int\u0026gt; Specifies the numeric code of a character that triggers EOF on the input stream. It is useful with a terminal in raw mode (example). SOCKET option group These options are intended for all kinds of sockets, e.g. IP or UNIX domain. Most are applied with a setsockopt() call. bind=\u0026lt;sockname\u0026gt; Binds the socket to the given socket address using the bind() system call. The form of \u0026lt;sockname\u0026gt; is socket domain dependent: IP4 and IP6 allow the form [hostname|hostaddress][:(ser‐ vice|port)] (example), UNIX domain sockets require \u0026lt;filename\u0026gt;, VSOCK allow the form [cid][:(port)]. connect-timeout=\u0026lt;seconds\u0026gt; Abort the connection attempt after \u0026lt;seconds\u0026gt; [timeval] with error status. so-bindtodevice=\u0026lt;interface\u0026gt; Binds the socket to the given \u0026lt;interface\u0026gt;. This option might require root privilege. broadcast For datagram sockets, allows sending to broadcast addresses and receiving packets addressed to broadcast addresses. debug Enables socket debugging. dontroute Only communicates with directly connected peers, does not use routers. keepalive Enables sending keepalives on the socket. linger=\u0026lt;seconds\u0026gt; Blocks shutdown() or close() until data transfers have finished or the given timeout [int] expired. oobinline Places out-of-band data in the input data stream. priority=\u0026lt;priority\u0026gt; Sets the protocol defined \u0026lt;priority\u0026gt; [\u0026lt;int\u0026gt;] for outgoing packets. rcvbuf=\u0026lt;bytes\u0026gt; Sets the size of the receive buffer after the socket() call to \u0026lt;bytes\u0026gt; [int]. With TCP sockets, this value corresponds to the socket’s maximal window size. rcvbuf-late=\u0026lt;bytes\u0026gt; Sets the size of the receive buffer when the socket is already connected to \u0026lt;bytes\u0026gt; [int]. With TCP sockets, this value corresponds to the socket’s maximal window size. rcvlowat=\u0026lt;bytes\u0026gt; Specifies the minimum number of received bytes [int] until the socket layer will pass the buffered data to socat. reuseaddr Allows other sockets to bind to an address even if parts of it (e.g. the local port) are already in use by socat (example). sndbuf=\u0026lt;bytes\u0026gt; Sets the size of the send buffer after the socket() call to \u0026lt;bytes\u0026gt; [int]. sndbuf-late=\u0026lt;bytes\u0026gt; Sets the size of the send buffer when the socket is connected to \u0026lt;bytes\u0026gt; [int]. sndlowat=\u0026lt;bytes\u0026gt; Specifies the minimum number of bytes in the send buffer until the socket layer will send the data to \u0026lt;bytes\u0026gt; [int]. pf=\u0026lt;string\u0026gt; Forces the use of the specified IP version or protocol. \u0026lt;string\u0026gt; can be something like \u0026quot;ip4\u0026quot; or \u0026quot;ip6\u0026quot;. The resulting value is used as first argument to the socket() or socketpair() calls. This option affects address resolution and the required syntax of bind and range options. type=\u0026lt;type\u0026gt; Sets the type of the socket, specified as second argument to the socket() or socketpair() calls, to \u0026lt;type\u0026gt; [int]. Address resolution is not affected by this option. Under Linux, 1 means stream oriented socket, 2 means datagram socket, and 3 means raw socket. protocol Sets the protocol of the socket, specified as third argument to the socket() or socketpair() calls, to \u0026lt;protocol\u0026gt; [int]. Address resolution is not affected by this option. 6 means TCP, 17 means UDP. reuseport Set the SO_REUSEPORT socket option. so-timestamp Sets the SO_TIMESTAMP socket option. This enables receiving and logging of timestamp ancillary messages. setsockopt=\u0026lt;level\u0026gt;:\u0026lt;optname\u0026gt;:\u0026lt;optval\u0026gt; Invokes setsockopt() for the socket with the given parameters. level [int] is used as second argument to setsockopt() and specifies the layer, e.g. SOL_TCP for TCP (6 on Linux), or SOL_SOCKET for the socket layer (1 on Linux). optname [int] is the third argument to setsockopt() and tells which socket option is to be set. For the actual numbers you might have to look up the appropriate include files of your system. For the 4th and 5th setsockopt() parameters, value [dalan] specifies an arbitrary sequence of bytes that are passed to the function per pointer, with the automatically derived length parameter. setsockopt-int=\u0026lt;level\u0026gt;:\u0026lt;optname\u0026gt;:\u0026lt;optval\u0026gt; Like setsockopt, but \u0026lt;optval\u0026gt; is a pointer to int [int] setsockopt-listen=\u0026lt;level\u0026gt;:\u0026lt;optname\u0026gt;:\u0026lt;optval\u0026gt; Like setsockopt, but for listen type addresses it is applied to the listening socket instead of the connected socket. setsockopt-string=\u0026lt;level\u0026gt;:\u0026lt;optname\u0026gt;:\u0026lt;optval\u0026gt; Like setsockopt, but \u0026lt;optval\u0026gt; is a string. This string is passed to the function with trailing null character, and the length parameter is automatically derived from the data. UNIX option group These options apply to UNIX domain based addresses. unix-tightsocklen=[0|1] On socket operations, pass a socket address length that does not include the whole struct sockaddr_un record but (besides other components) only the relevant part of the filename or ab‐ stract string. Default is 1. IP4 and IP6 option groups These options can be used with IPv4 and IPv6 based sockets. tos=\u0026lt;tos\u0026gt; Sets the TOS (type of service) field of outgoing packets to \u0026lt;tos\u0026gt; [byte] (see RFC 791). ttl=\u0026lt;ttl\u0026gt; Sets the TTL (time to live) field of outgoing packets to \u0026lt;ttl\u0026gt; [byte]. ip-options=\u0026lt;data\u0026gt; Sets IP options like source routing. Must be given in binary form, recommended format is a leading \u0026quot;x\u0026quot; followed by an even number of hex digits. This option may be used multiple times, data are appended. E.g., to connect to host 10.0.0.1 via some gateway using a loose source route, use the gateway as address parameter and set a loose source route using the option ip-options=x8307040a000001 . IP options are defined in RFC 791. mtudiscover=\u0026lt;0|1|2\u0026gt; Takes 0, 1, 2 to never, want, or always use path MTU discover on this socket. ip-pktinfo Sets the IP_PKTINFO socket option. This enables receiving and logging of ancillary messages containing destination address and interface (Linux) (example). ip-recverr Sets the IP_RECVERR socket option. This enables receiving and logging of ancillary messages containing detailed error information. ip-recvopts Sets the IP_RECVOPTS socket option. This enables receiving and logging of IP options ancillary messages (Linux, *BSD). ip-recvtos Sets the IP_RECVTOS socket option. This enables receiving and logging of TOS (type of service) ancillary messages (Linux). ip-recvttl Sets the IP_RECVTTL socket option. This enables receiving and logging of TTL (time to live) ancillary messages (Linux, *BSD). ip-recvdstaddr Sets the IP_RECVDSTADDR socket option. This enables receiving and logging of ancillary messages containing destination address (*BSD) (example). ip-recvif Sets the IP_RECVIF socket option. This enables receiving and logging of interface ancillary messages (*BSD) (example). ip-add-membership=\u0026lt;multicast-address:interface-address\u0026gt; ip-add-membership=\u0026lt;multicast-address:interface-name\u0026gt; ip-add-membership=\u0026lt;multicast-address:interface-index\u0026gt; ip-add-membership=\u0026lt;multicast-address:interface-address:interface-name\u0026gt; ip-add-membership=\u0026lt;multicast-address:interface-address:interface-index\u0026gt; Makes the socket member of the specified multicast group. This is currently only implemented for IPv4. The option takes the IP address of the multicast group and info about the desired network interface. The most common syntax is the first one, while the others are only available on systems that provide struct mreqn (Linux). The indices of active network interfaces can be shown using the utility procan. ip-add-source-membership=\u0026lt;multicast-address:interface-address:source-address\u0026gt; Makes the socket member of the specified multicast group for the specified source, i.e. only multicast traffic from this address is to be delivered. This is currently only implemented for IPv4. ip-multicast-if=\u0026lt;hostname\u0026gt; Specifies hostname or address of the network interface to be used for multicast traffic. ip-multicast-loop=\u0026lt;bool\u0026gt; Specifies if outgoing multicast traffic should loop back to the interface. ip-multicast-ttl=\u0026lt;byte\u0026gt; Sets the TTL used for outgoing multicast traffic. Default is 1. ip-transparent Sets the IP_TRANSPARENT socket option. This option might require root privilege. res-debug res-aaonly res-usevc res-primary res-igntc res-recurse res-defnames res-stayopen res-dnsrch These options set the corresponding resolver (name resolution) option flags. Append \u0026quot;=0\u0026quot; to clear a default option. See man resolver(5) for more information on these options. Note: these options are valid only for the address they are applied to. IP6 option group These options can only be used on IPv6 based sockets. See IP options for options that can be applied to both IPv4 and IPv6 sockets. ipv6only=\u0026lt;bool\u0026gt; Sets the IPV6_V6ONLY socket option. If 0, the TCP stack will also accept connections using IPv4 protocol on the same port. The default is system dependent. ipv6-recvdstopts Sets the IPV6_RECVDSTOPTS socket option. This enables receiving and logging of ancillary messages containing the destination options. ipv6-recvhoplimit Sets the IPV6_RECVHOPLIMIT socket option. This enables receiving and logging of ancillary messages containing the hoplimit. ipv6-recvhopopts Sets the IPV6_RECVHOPOPTS socket option. This enables receiving and logging of ancillary messages containing the hop options. ipv6-recvpktinfo Sets the IPV6_RECVPKTINFO socket option. This enables receiving and logging of ancillary messages containing destination address and interface. ipv6-unicast-hops=link(TYPE_INT)(\u0026lt;int\u0026gt;) Sets the IPV6_UNICAST_HOPS socket option. This sets the hop count limit (TTL) for outgoing unicast packets. ipv6-recvrthdr Sets the IPV6_RECVRTHDR socket option. This enables receiving and logging of ancillary messages containing routing information. ipv6-tclass Sets the IPV6_TCLASS socket option. This sets the transfer class of outgoing packets. ipv6-recvtclass Sets the IPV6_RECVTCLASS socket option. This enables receiving and logging of ancillary messages containing the transfer class. TCP option group These options may be applied to TCP sockets. They work by invoking setsockopt() with the appropriate parameters. cork Doesn’t send packets smaller than MSS (maximal segment size). defer-accept While listening, accepts connections only when data from the peer arrived. keepcnt=\u0026lt;count\u0026gt; Sets the number of keepalives before shutting down the socket to \u0026lt;count\u0026gt; [int]. keepidle=\u0026lt;seconds\u0026gt; Sets the idle time before sending the first keepalive to \u0026lt;seconds\u0026gt; [int]. keepintvl=\u0026lt;seconds\u0026gt; Sets the interval between two keepalives to \u0026lt;seconds\u0026gt; [int]. linger2=\u0026lt;seconds\u0026gt; Sets the time to keep the socket in FIN-WAIT-2 state to \u0026lt;seconds\u0026gt; [int]. mss=\u0026lt;bytes\u0026gt; Sets the MSS (maximum segment size) after the socket() call to \u0026lt;bytes\u0026gt; [int]. This value is then proposed to the peer with the SYN or SYN/ACK packet (example). mss-late=\u0026lt;bytes\u0026gt; Sets the MSS of the socket after connection has been established to \u0026lt;bytes\u0026gt; [int]. nodelay Turns off the Nagle algorithm for measuring the RTT (round trip time). rfc1323 Enables RFC1323 TCP options: TCP window scale, round-trip time measurement (RTTM), and protect against wrapped sequence numbers (PAWS) (AIX). stdurg Enables RFC1122 compliant urgent pointer handling (AIX). syncnt=\u0026lt;count\u0026gt; Sets the maximal number of SYN retransmits during connect to \u0026lt;count\u0026gt; [int]. md5sig Enables generation of MD5 digests on the packets (FreeBSD). noopt Disables use of TCP options (FreeBSD, MacOSX). nopush sets the TCP_NOPUSH socket option (FreeBSD, MacOSX). sack-disable Disables use the selective acknowledge feature (OpenBSD). signature-enable Enables generation of MD5 digests on the packets (OpenBSD). abort-threshold=\u0026lt;milliseconds\u0026gt; Sets the time to wait for an answer of the peer on an established connection (HP-UX). conn-abort-threshold=\u0026lt;milliseconds\u0026gt; Sets the time to wait for an answer of the server during the initial connect (HP-UX). keepinit Sets the time to wait for an answer of the server during connect() before giving up. Value in half seconds, default is 150 (75s) (Tru64). paws Enables the \u0026quot;protect against wrapped sequence numbers\u0026quot; feature (Tru64). sackena Enables selective acknowledge (Tru64). tsoptena Enables the time stamp option that allows RTT recalculation on existing connections (Tru64). UDP option group This option may be applied to UDP datagram sockets. udp-ignore-peerport\u0026gt; Address UDP-DATAGRAM expects incoming responses to come from the port specified in its second parameter. With this option, it accepts packets coming from any port. SCTP option group These options may be applied to SCTP stream sockets. sctp-nodelay Sets the SCTP_NODELAY socket option that disables the Nagle algorithm. sctp-maxseg=\u0026lt;bytes\u0026gt; Sets the SCTP_MAXSEG socket option to \u0026lt;bytes\u0026gt; [int]. This value is then proposed to the peer with the SYN or SYN/ACK packet. UDP, TCP, and SCTP option group Here we find options that are related to the network port mechanism and thus can be used with UDP, TCP, and SCTP client and server addresses. sourceport=\u0026lt;port\u0026gt; For outgoing (client) TCP and UDP connections, it sets the source \u0026lt;port\u0026gt; using an extra bind() call. With TCP or UDP listen addresses, socat immediately shuts down the connection if the client does not use this sourceport. UDP-RECV, UDP-RECVFROM, UDP-SENDTO, and UDP-DATAGRAM addresses ignore the packet when it does not match. (example). lowport Outgoing (client) TCP and UDP connections with this option use an unused random source port between 640 and 1023 incl. On UNIX class operating systems, this requires root privilege, and thus indicates that the client process is authorized by local root. TCP and UDP listen addresses with this option immediately shut down the connection if the client does not use a sourceport \u0026lt;= 1023. This mechanism can provide limited authorization under some circumstances. SOCKS option group When using SOCKS type addresses, some socks specific options can be set. socksport=\u0026lt;tcp service\u0026gt; Overrides the default \u0026quot;socks\u0026quot; service or port 1080 for the socks server port with \u0026lt;TCP service\u0026gt;. socksuser=\u0026lt;user\u0026gt; Sends the \u0026lt;user\u0026gt; [string] in the username field to the socks server. Default is the actual user name ($LOGNAME or $USER) (example). HTTP option group Options that can be provided with HTTP type addresses. The only HTTP address currently implemented is proxy-connect. proxyport=\u0026lt;TCP service\u0026gt; Overrides the default HTTP proxy port 8080 with \u0026lt;TCP service\u0026gt;. ignorecr The HTTP protocol requires the use of CR+NL as line terminator. When a proxy server violates this standard, socat might not understand its answer. This option directs socat to inter‐ prete NL as line terminator and to ignore CR in the answer. Nevertheless, socat sends CR+NL to the proxy. proxy-authorization=\u0026lt;username\u0026gt;:\u0026lt;password\u0026gt; Provide \u0026quot;basic\u0026quot; authentication to the proxy server. The argument to the option is used with a \u0026quot;Proxy-Authorization: Basic\u0026quot; header in base64 encoded form. Note: username and password are visible for every user on the local machine in the process list; username and password are transferred to the proxy server unencrypted (base64 encoded) and might be sniffed. proxy-authorization-file=\u0026lt;filename\u0026gt; Like option proxy-authorization, but the credentials are read from the file and therefore not visible in the process list. resolve Per default, socat sends to the proxy a CONNECT request containing the target hostname. With this option, socat resolves the hostname locally and sends the IP address. Please note that, according to RFC 2396, only name resolution to IPv4 addresses is implemented. RANGE option group These options check if a connecting client should be granted access. They can be applied to listening and receiving network sockets. tcp-wrappers options fall into this group. range=\u0026lt;address-range\u0026gt; After accepting a connection, tests if the peer is within range. For IPv4 addresses, address-range takes the form address/bits, e.g. 10.0.0.0/8, or address:mask, e.g. 10.0.0.0:255.0.0.0 (example); for IPv6, it is [ip6-address]/bits, e.g. [::1]/128. If the client address does not match, socat refuses the connection attempt, issues a warning, and keeps listening/receiving. tcpwrap[=\u0026lt;name\u0026gt;] Uses Wietse Venema’s libwrap (tcpd) library to determine if the client is allowed to connect. The configuration files are /etc/hosts.allow and /etc/hosts.deny per default, see \u0026quot;man 5 hosts_access\u0026quot; for more information. The optional \u0026lt;name\u0026gt; (type string) is passed to the wrapper functions as daemon process name (example). If omitted, the basename of socats invocation (argv[0]) is passed. If both tcpwrap and range options are applied to an address, both conditions must be fulfilled to allow the connection. allow-table=\u0026lt;filename\u0026gt; Takes the specified file instead of /etc/hosts.allow. deny-table=\u0026lt;filename\u0026gt; Takes the specified file instead of /etc/hosts.deny. tcpwrap-etc=\u0026lt;directoryname\u0026gt; Looks for hosts.allow and hosts.deny in the specified directory. Is overridden by options hosts-allow and hosts-deny. LISTEN option group Options specific to listening sockets. backlog=\u0026lt;count\u0026gt; Sets the backlog value passed with the listen() system call to \u0026lt;count\u0026gt; [int]. Default is 5. accept-timeout=\u0026lt;seconds\u0026gt; End waiting for a connection after \u0026lt;seconds\u0026gt; [timeval] with error status. max-children=\u0026lt;count\u0026gt; Limits the number of concurrent child processes [int]. Default is no limit. CHILD option group Options for addresses with multiple connections via child processes. fork After establishing a connection, handles its channel in a child process and keeps the parent process attempting to produce more connections, either by listening or by connecting in a loop (example). OPENSSL-CONNECT and OPENSSL-LISTEN differ in when they actually fork off the child: OPENSSL-LISTEN forks before the SSL handshake, while OPENSSL-CONNECT forks afterwards. retry and forever options are not inherited by the child process. On some operating systems (e.g. FreeBSD) this option does not work for UDP-LISTEN addresses. EXEC option group Options for addresses that invoke a program. path=\u0026lt;string\u0026gt; Overrides the PATH environment variable for searching the program with \u0026lt;string\u0026gt;. This $PATH value is effective in the child process too. login Prefixes argv[0] for the execvp() call with ’-’, thus making a shell behave as login shell. FORK option group EXEC or SYSTEM addresses invoke a program using a child process and transfer data between socat and the program. The interprocess communication mechanism can be influenced with the following options. Per default, a socketpair() is created and assigned to stdin and stdout of the child process, while stderr is inherited from the socat process, and the child process uses file de‐ scriptors 0 and 1 for communicating with the main socat process. nofork Does not fork a subprocess for executing the program, instead calls execvp() or system() directly from the actual socat instance. This avoids the overhead of another process between the program and its peer, but introduces a lot of restrictions: o this option can only be applied to the second socat address. o it cannot be applied to a part of a dual address. o the first socat address cannot be OPENSSL or READLINE o socat options -b, -t, -D, -l, -v, -x become useless o for both addresses, options ignoreeof, cr, and crnl become useless o for the second address (the one with option nofork), options append, cloexec, flock, user, group, mode, nonblock, perm-late, setlk, and setpgid cannot be applied. Some of these could be used on the first address though. pipes Creates a pair of unnamed pipes for interprocess communication instead of a socket pair. openpty Establishes communication with the sub process using a pseudo terminal created with openpty() instead of the default (socketpair or ptmx). ptmx Establishes communication with the sub process using a pseudo terminal created by opening /dev/ptmx or /dev/ptc instead of the default (socketpair). pty Establishes communication with the sub process using a pseudo terminal instead of a socket pair. Creates the pty with an available mechanism. If openpty and ptmx are both available, it uses ptmx because this is POSIX compliant (example). ctty Makes the pty the controlling tty of the sub process (example). stderr Directs stderr of the sub process to its output channel by making stderr a dup() of stdout (example). fdin=\u0026lt;fdnum\u0026gt; Assigns the sub processes input channel to its file descriptor \u0026lt;fdnum\u0026gt; instead of stdin (0). The program started from the subprocess has to use this fd for reading data from socat (ex‐ ample). fdout=\u0026lt;fdnum\u0026gt; Assigns the sub processes output channel to its file descriptor \u0026lt;fdnum\u0026gt; instead of stdout (1). The program started from the subprocess has to use this fd for writing data to socat (ex‐ ample). sighup, sigint, sigquit Has socat pass signals of this type to the sub process. If no address has this option, socat terminates on these signals. TERMIOS option group For addresses that work on a tty (e.g., stdio, file:/dev/tty, exec:...,pty), the terminal parameters defined in the UN*X termios mechanism are made available as address option parameters. Please note that changes of the parameters of your interactive terminal remain effective after socat’s termination, so you might have to enter \u0026quot;reset\u0026quot; or \u0026quot;stty sane\u0026quot; in your shell afterwards. For EXEC and SYSTEM addresses with option PTY, these options apply to the pty by the child processes. b0 Disconnects the terminal. b19200 Sets the serial line speed to 19200 baud. Some other rates are possible; use something like socat -hh |grep ’ b[1-9]’ to find all speeds supported by your implementation. Note: On some operating systems, these options may not be available. Use ispeed or ospeed instead. echo=\u0026lt;bool\u0026gt; Enables or disables local echo. icanon=\u0026lt;bool\u0026gt; Sets or clears canonical mode, enabling line buffering and some special characters. raw Sets raw mode, thus passing input and output almost unprocessed. This option is obsolete, use option rawer or cfmakeraw instead. rawer Makes terminal rawer than raw option. This option implicitly turns off echo. (example). cfmakeraw Sets raw mode by invoking cfmakeraw() or by simulating this call. This option implicitly turns off echo. ignbrk=\u0026lt;bool\u0026gt; Ignores or interpretes the BREAK character (e.g., ^C) brkint=\u0026lt;bool\u0026gt; bs0 bs1 bsdly=\u0026lt;0|1\u0026gt; clocal=\u0026lt;bool\u0026gt; cr0 cr1 cr2 cr3 Sets the carriage return delay to 0, 1, 2, or 3, respectively. 0 means no delay, the other values are terminal dependent. crdly=\u0026lt;0|1|2|3\u0026gt; cread=\u0026lt;bool\u0026gt; crtscts=\u0026lt;bool\u0026gt; cs5 cs6 cs7 cs8 Sets the character size to 5, 6, 7, or 8 bits, respectively. csize=\u0026lt;0|1|2|3\u0026gt; cstopb=\u0026lt;bool\u0026gt; Sets two stop bits, rather than one. dsusp=\u0026lt;byte\u0026gt; Sets the value for the VDSUSP character that suspends the current foreground process and reactivates the shell (all except Linux). echoctl=\u0026lt;bool\u0026gt; Echos control characters in hat notation (e.g. ^A) echoe=\u0026lt;bool\u0026gt; echok=\u0026lt;bool\u0026gt; echoke=\u0026lt;bool\u0026gt; echonl=\u0026lt;bool\u0026gt; echoprt=\u0026lt;bool\u0026gt; eof=\u0026lt;byte\u0026gt; eol=\u0026lt;byte\u0026gt; eol2=\u0026lt;byte\u0026gt; erase=\u0026lt;byte\u0026gt; discard=\u0026lt;byte\u0026gt; ff0 ff1 ffdly=\u0026lt;bool\u0026gt; flusho=\u0026lt;bool\u0026gt; hupcl=\u0026lt;bool\u0026gt; icrnl=\u0026lt;bool\u0026gt; iexten=\u0026lt;bool\u0026gt; igncr=\u0026lt;bool\u0026gt; ignpar=\u0026lt;bool\u0026gt; imaxbel=\u0026lt;bool\u0026gt; inlcr=\u0026lt;bool\u0026gt; inpck=\u0026lt;bool\u0026gt; intr=\u0026lt;byte\u0026gt; isig=\u0026lt;bool\u0026gt; ispeed=\u0026lt;unsigned-int\u0026gt; Set the baud rate for incoming data on this line. See also: ospeed, b19200 istrip=\u0026lt;bool\u0026gt; iuclc=\u0026lt;bool\u0026gt; ixany=\u0026lt;bool\u0026gt; ixoff=\u0026lt;bool\u0026gt; ixon=\u0026lt;bool\u0026gt; kill=\u0026lt;byte\u0026gt; lnext=\u0026lt;byte\u0026gt; min=\u0026lt;byte\u0026gt; nl0 Sets the newline delay to 0. nl1 nldly=\u0026lt;bool\u0026gt; noflsh=\u0026lt;bool\u0026gt; ocrnl=\u0026lt;bool\u0026gt; ofdel=\u0026lt;bool\u0026gt; ofill=\u0026lt;bool\u0026gt; olcuc=\u0026lt;bool\u0026gt; onlcr=\u0026lt;bool\u0026gt; onlret=\u0026lt;bool\u0026gt; onocr=\u0026lt;bool\u0026gt; opost=\u0026lt;bool\u0026gt; Enables or disables output processing; e.g., converts NL to CR-NL. ospeed=\u0026lt;unsigned-int\u0026gt; Set the baud rate for outgoing data on this line. See also: ispeed, b19200 parenb=\u0026lt;bool\u0026gt; Enable parity generation on output and parity checking for input. parmrk=\u0026lt;bool\u0026gt; parodd=\u0026lt;bool\u0026gt; pendin=\u0026lt;bool\u0026gt; quit=\u0026lt;byte\u0026gt; reprint=\u0026lt;byte\u0026gt; sane Brings the terminal to something like a useful default state. start=\u0026lt;byte\u0026gt; stop=\u0026lt;byte\u0026gt; susp=\u0026lt;byte\u0026gt; swtc=\u0026lt;byte\u0026gt; tab0 tab1 tab2 tab3 tabdly=\u0026lt;unsigned-int\u0026gt; time=\u0026lt;byte\u0026gt; tostop=\u0026lt;bool\u0026gt; vt0 vt1 vtdly=\u0026lt;bool\u0026gt; werase=\u0026lt;byte\u0026gt; xcase=\u0026lt;bool\u0026gt; xtabs i-pop-all With UNIX System V STREAMS, removes all drivers from the stack. i-push=\u0026lt;string\u0026gt; With UNIX System V STREAMS, pushes the driver (module) with the given name (string) onto the stack. For example, to make sure that a character device on Solaris supports termios etc, use the following options: i-pop-all,i-push=ptem,i-push=ldterm,i-push=ttcompat PTY option group These options are intended for use with the pty address type. link=\u0026lt;filename\u0026gt; Generates a symbolic link that points to the actual pseudo terminal (pty). This might help to solve the problem that ptys are generated with more or less unpredictable names, making it difficult to directly access the socat generated pty automatically. With this option, the user can specify a \u0026quot;fix\u0026quot; point in the file hierarchy that helps him to access the actual pty (example). Beginning with socat version 1.4.3, the symbolic link is removed when the address is closed (but see option unlink-close). wait-slave Blocks the open phase until a process opens the slave side of the pty. Usually, socat continues after generating the pty with opening the next address or with entering the transfer loop. With the wait-slave option, socat waits until some process opens the slave side of the pty before continuing. This option only works if the operating system provides the poll() system call. And it depends on an undocumented behaviour of pty’s, so it does not work on all operating systems. It has successfully been tested on Linux, FreeBSD, NetBSD, and on Tru64 with openpty. pty-interval=\u0026lt;seconds\u0026gt; When the wait-slave option is set, socat periodically checks the HUP condition using poll() to find if the pty’s slave side has been opened. The default polling interval is 1s. Use the pty-interval option [timeval] to change this value. OPENSSL option group These options apply to the openssl and openssl-listen address types. cipher=\u0026lt;cipherlist\u0026gt; Specifies the list of ciphers that may be used for the connection. See the help of ciphers , section CIPHER LIST FORMAT, for detailed information about syntax, values, and default of \u0026lt;cipherlist\u0026gt;. Several cipher strings may be given, separated by ’:’. Some simple cipher strings: 3DES Uses a cipher suite with triple DES. MD5 Uses a cipher suite with MD5. aNULL Uses a cipher suite without authentication. NULL Does not use encryption. HIGH Uses a cipher suite with \u0026quot;high\u0026quot; encryption. Note that the peer must support the selected property, or the negotiation will fail. method=\u0026lt;ssl-method\u0026gt; This option is based on deprecated functions and is only available when socat was build with option --with-openssl-method. Use option min-proto-version and maybe max-proto-version in‐ stead. Sets the protocol version to be used. Valid strings (not case sensitive) are: SSL2 Select SSL protocol version 2. SSL3 Select SSL protocol version 3. SSL23 Select the best available SSL or TLS protocol. TLS1 Select TLS protocol version 1. TLS1.1 Select TLS protocol version 1.1. TLS1.2 Select TLS protocol version 1.2. When this option is not provided OpenSSL negotiates the mothod with its peer. min-proto-version This option tells OpenSSL to use this or a later SSL/TLS protocol version and refuses to accept a lower/older protocol. Valid syntax is: SSL2 Select SSL protocol version 2. SSL3 Select SSL protocol version 3. TLS1 TLS1.0 Select TLS protocol version 1. TLS1.1 Select TLS protocol version 1.1. TLS1.2 Select TLS protocol version 1.2. TLS1.3 Select TLS protocol version 1.3. openssl-max-proto-version This option is similar to min-proto-version, however, it disallows use of a higher protocol version. Useful for testing the peer. verify=\u0026lt;bool\u0026gt; Controls check of the peer’s certificate. Default is 1 (true). Disabling verify might open your socket for everyone, making the encryption useless! cert=\u0026lt;filename\u0026gt; Specifies the file with the certificate and private key for authentication. The certificate must be in OpenSSL format (*.pem). With openssl-listen, use of this option is strongly rec‐ ommended. Except with cipher aNULL, \u0026quot;no shared ciphers\u0026quot; error will occur when no certificate is given. key=\u0026lt;filename\u0026gt; Specifies the file with the private key. The private key may be in this file or in the file given with the cert option. The party that has to proof that it is the owner of a certificate needs the private key. dhparams=\u0026lt;filename\u0026gt; Specifies the file with the Diffie Hellman parameters. These parameters may also be in the file given with the cert option in which case the dhparams option is not needed. cafile=\u0026lt;filename\u0026gt; Specifies the file with the trusted (root) authority certificates. The file must be in PEM format and should contain one or more certificates. The party that checks the authentication of its peer trusts only certificates that are in this file. capath=\u0026lt;dirname\u0026gt; Specifies the directory with the trusted (root) certificates. The directory must contain certificates in PEM format and their hashes (see OpenSSL documentation) egd=\u0026lt;filename\u0026gt; On some systems, openssl requires an explicit source of random data. Specify the socket name where an entropy gathering daemon like egd provides random data, e.g. /dev/egd-pool. pseudo On systems where openssl cannot find an entropy source and where no entropy gathering daemon can be utilized, this option activates a mechanism for providing pseudo entropy. This is achieved by taking the current time in microseconds for feeding the libc pseudo random number generator with an initial value. openssl is then feeded with output from random() calls. NOTE:This mechanism is not sufficient for generation of secure keys! compress Enable or disable the use of compression for a connection. Setting this to \u0026quot;none\u0026quot; disables compression, setting it to \u0026quot;auto\u0026quot; lets OpenSSL choose the best available algorithm supported by both parties. The default is to not touch any compression-related settings. NOTE: Requires OpenSSL 0.9.8 or higher and disabling compression with OpenSSL 0.9.8 affects all new con‐ nections in the process. commonname=\u0026lt;string\u0026gt; Specify the commonname that the peer certificate must match. With OPENSSL-CONNECT address this overrides the given hostname or IP target address; with OPENSSL-LISTEN this turns on check of peer certificates commonname. This option has only meaning when option verify is not disabled and the chosen cipher provides a peer certificate. no-sni=\u0026lt;bool\u0026gt; Do not use the client side Server Name Indication (SNI) feature that selects the desired server certificate. Note: SNI is automatically used since socat version 1.7.4.0 and uses commonname or the given host name. snihost=\u0026lt;string\u0026gt; Set the client side Server Name Indication (SNI) host name different from the addressed server name or common name. This might be useful when the server certificate has multiple host names or wildcard names because the SNI host name is passed in cleartext to the server and might be eavesdropped; with this option a mock name of the desired certificate may be trans‐ ferred. fips Enables FIPS mode if compiled in. For info about the FIPS encryption implementation standard see http://oss-institute.org/fips-faq.html. This mode might require that the involved cer‐ tificates are generated with a FIPS enabled version of openssl. Setting or clearing this option on one socat address affects all OpenSSL addresses of this process. RETRY option group Options that control retry of some system calls, especially connection attempts. retry=\u0026lt;num\u0026gt; Number of retries before the connection or listen attempt is aborted. Default is 0, which means just one attempt. interval=\u0026lt;timespec\u0026gt; Time between consecutive attempts (seconds, [timespec]). Default is 1 second. forever Performs an unlimited number of retry attempts. TUN option group Options that control Linux TUN/TAP interface device addresses. tun-device=\u0026lt;device-file\u0026gt; Instructs socat to take another path for the TUN clone device. Default is /dev/net/tun. tun-name=\u0026lt;if-name\u0026gt; Gives the resulting network interface a specific name instead of the system generated (tun0, tun1, etc.) tun-type=[tun|tap] Sets the type of the TUN device; use this option to generate a TAP device. See the Linux docu for the difference between these types. When you try to establish a tunnel between two TUN devices, their types should be the same. iff-no-pi Sets the IFF_NO_PI flag which controls if the device includes additional packet information in the tunnel. When you try to establish a tunnel between two TUN devices, these flags should have the same values. iff-up Sets the TUN network interface status UP. Strongly recommended. iff-broadcast Sets the BROADCAST flag of the TUN network interface. iff-debug Sets the DEBUG flag of the TUN network interface. iff-loopback Sets the LOOPBACK flag of the TUN network interface. iff-pointopoint Sets the POINTOPOINT flag of the TUN device. iff-notrailers Sets the NOTRAILERS flag of the TUN device. iff-running Sets the RUNNING flag of the TUN device. iff-noarp Sets the NOARP flag of the TUN device. iff-promisc Sets the PROMISC flag of the TUN device. iff-allmulti Sets the ALLMULTI flag of the TUN device. iff-master Sets the MASTER flag of the TUN device. iff-slave Sets the SLAVE flag of the TUN device. iff-multicast Sets the MULTICAST flag of the TUN device. iff-portsel Sets the PORTSEL flag of the TUN device. iff-automedia Sets the AUTOMEDIA flag of the TUN device. iff-dynamic Sets the DYNAMIC flag of the TUN device. DATA VALUES This section explains the different data types that address parameters and address options can take. address-range Is currently only implemented for IPv4 and IPv6. See address-option `range’ bool \u0026quot;0\u0026quot; or \u0026quot;1\u0026quot;; if value is omitted, \u0026quot;1\u0026quot; is taken. byte An unsigned int number, read with strtoul() , lower or equal to UCHAR_MAX . command-line A string specifying a program name and its arguments, separated by single spaces. data This is a more general data specification. The given text string contains information about the target data type and value. Generally a leading character specifies the type of the fol‐ lowing data item. In its specific context a default data type may exist. Currently only the following specifications are implemented: i A signed integer number, stored in host byte order. Example: i-1000 (Integer number -1000) I An unsigned integer number, stored in host byte order. l A signed long integer number, stored in host byte order. L An unsigned long integer number, stored in host byte order. s A signed short integer number, stored in host byte order. S An unsigned short integer number, stored in host byte order. b A signed byte (signed char). B An unsigned byte (unsigned char). x Following is an even number of hex digits, stored as sequence of bytes. Example: x7f000001 (IP address 127.0.0.1) \u0026quot; Following is a string that is used with the common conversions \\n \\r \\t \\f \\b \\a \\e \\0; the string must be closed with ’\u0026quot;’. Please note that the quotes and backslashes need to be es‐ caped from shell and socat conversion. Example: \u0026quot;Hello world!\\n\u0026quot; ’ A single char, with the usual conversions. Please note that the quotes and backslashes need to be escaped from shell and socat conversion. Example: ’a’ Data items may be separated with white space without need to repeat the type specifier again. directory A string with usual UN*X directory name semantics. facility The name of a syslog facility in lower case characters. fdnum An unsigned int type, read with strtoul() , specifying a UN*X file descriptor. filename A string with usual UN*X filename semantics. group If the first character is a decimal digit, the value is read with strtoul() as unsigned integer specifying a group id. Otherwise, it must be an existing group name. int A number following the rules of the strtol() function with base \u0026quot;0\u0026quot;, i.e. decimal number, octal number with leading \u0026quot;0\u0026quot;, or hexadecimal number with leading \u0026quot;0x\u0026quot;. The value must fit into a C int. interface A string specifying the device name of a network interface as shown by ifconfig or procan, e.g. \u0026quot;eth0\u0026quot;. IP address An IPv4 address in numbers-and-dots notation, an IPv6 address in hex notation enclosed in brackets, or a hostname that resolves to an IPv4 or an IPv6 address. Examples: 127.0.0.1, [::1], www.dest-unreach.org, dns1 IPv4 address An IPv4 address in numbers-and-dots notation or a hostname that resolves to an IPv4 address. Examples: 127.0.0.1, www.dest-unreach.org, dns2 IPv6 address An IPv6 address in hexnumbers-and-colons notation enclosed in brackets, or a hostname that resolves to an IPv6 address. Examples: [::1], [1234:5678:9abc:def0:1234:5678:9abc:def0], ip6name.domain.org long A number read with strtol() . The value must fit into a C long. long long A number read with strtoll() . The value must fit into a C long long. off_t An implementation dependend signed number, usually 32 bits, read with strtol or strtoll. off64_t An implementation dependend signed number, usually 64 bits, read with strtol or strtoll. mode_t An unsigned integer, read with strtoul() , specifying mode (permission) bits. pid_t A number, read with strtol() , specifying a process id. port A uint16_t (16 bit unsigned number) specifying a TCP or UDP port, read with strtoul() . protocol An unsigned 8 bit number, read with strtoul() . size_t An unsigned number with size_t limitations, read with strtoul . sockname A socket address. See address-option `bind’ string A sequence of characters, not containing ’\\0’ and, depending on the position within the command line, ’:’, ’,’, or \u0026quot;!!\u0026quot;. Note that you might have to escape shell meta characters in the command line. TCP service A service name, not starting with a digit, that is resolved by getservbyname() , or an unsigned int 16 bit number read with strtoul() . timeval A double float specifying seconds; the number is mapped into a struct timeval, consisting of seconds and microseconds. timespec A double float specifying seconds; the number is mapped into a struct timespec, consisting of seconds and nanoseconds. UDP service A service name, not starting with a digit, that is resolved by getservbyname() , or an unsigned int 16 bit number read with strtoul() . unsigned int A number read with strtoul() . The value must fit into a C unsigned int. user If the first character is a decimal digit, the value is read with strtoul() as unsigned integer specifying a user id. Otherwise, it must be an existing user name. VSOCK cid A uint32_t (32 bit unsigned number) specifying a VSOCK Context Identifier (CID), read with strtoul() . There are several special addresses: VMADDR_CID_ANY (-1U) means any address for binding; VMADDR_CID_HOST (2) is the well-known address of the host. VSOCK port A uint32_t (32 bit unsigned number) specifying a VSOCK port, read with strtoul() . EXAMPLES socat - TCP4:www.domain.org:80 transfers data between STDIO (-) and a TCP4 connection to port 80 of host www.domain.org. This example results in an interactive connection similar to telnet or netcat. The stdin termi‐ nal parameters are not changed, so you may close the relay with ^D or abort it with ^C. socat -d -d READLINE,history=$HOME/.http_history \\ TCP4:www.domain.org:www,crnl this is similar to the previous example, but you can edit the current line in a bash like manner (READLINE) and use the history file .http_history; socat prints messages about progress (-d -d). The port is specified by service name (www), and correct network line termination characters (crnl) instead of NL are used. socat TCP4-LISTEN:www TCP4:www.domain.org:www installs a simple TCP port forwarder. With TCP4-LISTEN it listens on local port \u0026quot;www\u0026quot; until a connection comes in, accepts it, then connects to the remote host (TCP4) and starts data transfer. It will not accept a second connection. socat -d -d -lmlocal2 \\ TCP4-LISTEN:80,bind=myaddr1,reuseaddr,fork,su=nobody,range=10.0.0.0/8 \\ TCP4:www.domain.org:80,bind=myaddr2 TCP port forwarder, each side bound to another local IP address (bind). This example handles an almost arbitrary number of parallel or consecutive connections by fork’ing a new process after each accept() . It provides a little security by su’ing to user nobody after forking; it only permits connections from the private 10 network (range); due to reuseaddr, it allows immediate restart after master process’s termination, even if some child sockets are not completely shut down. With -lmlocal2, socat logs to stderr until successfully reaching the ac‐ cept loop. Further logging is directed to syslog with facility local2. socat TCP4-LISTEN:5555,fork,tcpwrap=script \\ EXEC:/bin/myscript,chroot=/home/sandbox,su-d=sandbox,pty,stderr a simple server that accepts connections (TCP4-LISTEN) and fork’s a new child process for each connection; every child acts as single relay. The client must match the rules for daemon process name \u0026quot;script\u0026quot; in /etc/hosts.allow and /etc/hosts.deny, otherwise it is refused access (see \u0026quot;man 5 hosts_access\u0026quot;). For EXEC’uting the program, the child process chroot’s to /home/sandbox, su’s to user sandbox, and then starts the program /home/sandbox/bin/myscript. Socat and myscript communicate via a pseudo tty (pty); myscript’s stderr is redirected to stdout, so its error messages are transferred via socat to the connected client. socat EXEC:\u0026quot;mail.sh target@domain.com\u0026quot;,fdin=3,fdout=4 \\ TCP4:mail.relay.org:25,crnl,bind=alias1.server.org,mss=512 mail.sh is a shell script, distributed with socat, that implements a simple SMTP client. It is programmed to \u0026quot;speak\u0026quot; SMTP on its FDs 3 (in) and 4 (out). The fdin and fdout options tell socat to use these FDs for communication with the program. Because mail.sh inherits stdin and stdout while socat does not use them, the script can read a mail body from stdin. Socat makes alias1 your local source address (bind), cares for correct network line termination (crnl) and sends at most 512 data bytes per packet (mss). socat -,escape=0x0f /dev/ttyS0,rawer,crnl opens an interactive connection via the serial line, e.g. for talking with a modem. rawer sets the console’s and ttyS0’s terminal parameters to practicable values, crnl converts to cor‐ rect newline characters. escape allows terminating the socat process with character control-O. Consider using READLINE instead of the first address. socat UNIX-LISTEN:/tmp/.X11-unix/X1,fork \\ SOCKS4:host.victim.org:127.0.0.1:6000,socksuser=nobody,sourceport=20 with UNIX-LISTEN, socat opens a listening UNIX domain socket /tmp/.X11-unix/X1. This path corresponds to local XWindow display :1 on your machine, so XWindow client connections to DIS‐ PLAY=:1 are accepted. Socat then speaks with the SOCKS4 server host.victim.org that might permit sourceport 20 based connections due to an FTP related weakness in its static IP filters. Socat pretends to be invoked by socksuser nobody, and requests to be connected to loopback port 6000 (only weak sockd configurations will allow this). So we get a connection to the vic‐ tims XWindow server and, if it does not require MIT cookies or Kerberos authentication, we can start work. Please note that there can only be one connection at a time, because TCP can establish only one session with a given set of addresses and ports. socat -u /tmp/readdata,seek-end=0,ignoreeof - this is an example for unidirectional data transfer (-u). Socat transfers data from file /tmp/readdata (implicit address GOPEN), starting at its current end (seek-end=0 lets socat start reading at current end of file; use seek=0 or no seek option to first read the existing data) in a \u0026quot;tail -f\u0026quot; like mode (ignoreeof). The \u0026quot;file\u0026quot; might also be a listening UNIX domain socket (do not use a seek option then). (sleep 5; echo PASSWORD; sleep 5; echo ls; sleep 1) | socat - EXEC:'ssh -l user server',pty,setsid,ctty EXEC’utes an ssh session to server. Uses a pty for communication between socat and ssh, makes it ssh’s controlling tty (ctty), and makes this pty the owner of a new process group (set‐ sid), so ssh accepts the password from socat. socat -u TCP4-LISTEN:3334,reuseaddr,fork \\ OPEN:/tmp/in.log,creat,append implements a simple network based message collector. For each client connecting to port 3334, a new child process is generated (option fork). All data sent by the clients are ap‐ pend’ed to the file /tmp/in.log. If the file does not exist, socat creat’s it. Option reuseaddr allows immediate restart of the server process. socat READLINE,noecho=’[Pp]assword:’ EXEC:’ftp ftp.server.com’,pty,setsid,ctty wraps a command line history (READLINE) around the EXEC’uted ftp client utility. This allows editing and reuse of FTP commands for relatively comfortable browsing through the ftp di‐ rectory hierarchy. The password is echoed! pty is required to have ftp issue a prompt. Nevertheless, there may occur some confusion with the password and FTP prompts. socat PTY,link=$HOME/dev/vmodem0,rawer,wait-slave \\ EXEC:\u0026quot;ssh modemserver.us.org socat - /dev/ttyS0,nonblock,rawer\u0026quot; generates a pseudo terminal device (PTY) on the client that can be reached under the symbolic link $HOME/dev/vmodem0. An application that expects a serial line or modem can be config‐ ured to use $HOME/dev/vmodem0; its traffic will be directed to a modemserver via ssh where another socat instance links it to /dev/ttyS0. socat TCP4-LISTEN:2022,reuseaddr,fork \\ PROXY:proxy:www.domain.org:22,proxyport=3128,proxyauth=user:pass starts a forwarder that accepts connections on port 2022, and directs them through the proxy daemon listening on port 3128 (proxyport) on host proxy, using the CONNECT method, where they are authenticated as \u0026quot;user\u0026quot; with \u0026quot;pass\u0026quot; (proxyauth). The proxy should establish connections to host www.domain.org on port 22 then. socat - SSL:server:4443,cafile=server.crt,cert=client.pem is an OpenSSL client that tries to establish a secure connection to an SSL server. Option cafile specifies a file that contains trust certificates: we trust the server only when it presents one of these certificates and proofs that it owns the related private key. Otherwise the connection is terminated. With cert a file containing the client certificate and the associated private key is specified. This is required in case the server wishes a client authentication; many Internet servers do not. The first address (’-’) can be replaced by almost any other socat address. socat OPENSSL-LISTEN:4443,reuseaddr,pf=ip4,fork,cert=server.pem,cafile=client.crt PIPE is an OpenSSL server that accepts TCP connections, presents the certificate from the file server.pem and forces the client to present a certificate that is verified against cafile.crt. The second address (’PIPE’) can be replaced by almost any other socat address. For instructions on generating and distributing OpenSSL keys and certificates see the additional socat docu socat-openssl.txt. echo |socat -u - file:/tmp/bigfile,create,largefile,seek=100000000000 creates a 100GB sparse file; this requires a file system type that supports this (ext2, ext3, reiserfs, jfs; not minix, vfat). The operation of writing 1 byte might take long (reiserfs: some minutes; ext2: \u0026quot;no\u0026quot; time), and the resulting file can consume some disk space with just its inodes (reiserfs: 2MB; ext2: 16KB). socat tcp-l:7777,reuseaddr,fork system:’filan -i 0 -s \u0026gt;\u0026amp;2’,nofork listens for incoming TCP connections on port 7777. For each accepted connection, invokes a shell. This shell has its stdin and stdout directly connected to the TCP socket (nofork). The shell starts filan and lets it print the socket addresses to stderr (your terminal window). echo -e \u0026quot;\\0\\14\\0\\0\\c\u0026quot; |socat -u - file:/usr/bin/squid.exe,seek=0x00074420 functions as primitive binary editor: it writes the 4 bytes 000 014 000 000 to the executable /usr/bin/squid at offset 0x00074420 (this is a real world patch to make the squid exe‐ cutable from Cygwin run under Windows, actual per May 2004). socat - tcp:www.blackhat.org:31337,readbytes=1000 connects to an unknown service and prevents being flooded. socat -U TCP:target:9999,end-close TCP-L:8888,reuseaddr,fork merges data arriving from different TCP streams on port 8888 to just one stream to target:9999. The end-close option prevents the child processes forked off by the second address from terminating the shared connection to 9999 (close(2) just unlinks the inode which stays active as long as the parent process lives; shutdown(2) would actively terminate the connection). socat - UDP4-DATAGRAM:192.168.1.0:123,sp=123,broadcast,range=192.168.1.0/24 sends a broadcast to the network 192.168.1.0/24 and receives the replies of the timeservers there. Ignores NTP packets from hosts outside this network. socat - SOCKET-DATAGRAM:2:2:17:x007bxc0a80100x0000000000000000,bind=x007bx00000000x0000000000000000,setsockopt-int=1:6:1,range=x0000xc0a80100x0000000000000000:x0000xffffff00x0000000000000000 is semantically equivalent to the previous example, but all parameters are specified in generic form. the value 6 of setsockopt-int is the Linux value for SO_BROADCAST. socat - IP4-DATAGRAM:255.255.255.255:44,broadcast,range=10.0.0.0/8 sends a broadcast to the local network(s) using protocol 44. Accepts replies from the private address range only. socat - UDP4-DATAGRAM:224.255.0.1:6666,bind=:6666,ip-add-membership=224.255.0.1:eth0 transfers data from stdin to the specified multicast address using UDP. Both local and remote ports are 6666. Tells the interface eth0 to also accept multicast packets of the given group. Multiple hosts on the local network can run this command, so all data sent by any of the hosts will be received by all the other ones. Note that there are many possible reasons for failure, including IP-filters, routing issues, wrong interface selection by the operating system, bridges, or a badly configured switch. socat UDP:host2:4443 TUN:192.168.255.1/24,up establishes one side of a virtual (but not private!) network with host2 where a similar process might run, with UDP-L and tun address 192.168.255.2. They can reach each other using the addresses 192.168.255.1 and 192.168.255.2. Note that streaming eg.via TCP or SSL does not guarantee to retain packet boundaries and might thus cause packet loss. socat - VSOCK-CONNECT:2:1234 establishes a VSOCK connection with the host (host is always reachable with the well-know CID=2) on 1234 port. socat - VSOCK-LISTEN:1234 listens for a VSOCK connection on 1234 port. socat - VSOCK-CONNECT:31:4321,bind:5555 establishes a VSOCK connection with the guest that have CID=31 on 1234 port, binding the local socket to the 5555 port. socat VSOCK-LISTEN:3333,reuseaddr,fork VSOCK-CONNECT:42,3333 starts a forwarder that accepts VSOCK connections on port 3333, and directs them to the guest with CID=42 on the same port. socat VSOCK-LISTEN:22,reuseaddr,fork TCP:localhost:22 forwards VSOCK connections from 22 port to the local SSH server. Running this in a VM allows you to connect via SSH from the host using VSOCK, as in the example below. socat TCP4-LISTEN:22222,reuseaddr,fork VSOCK-CONNECT:33:22 forwards TCP connections from 22222 port to the guest with CID=33 listening on VSOCK port 22. Running this in the host, allows you to connect via SSH running \u0026quot;ssh -p 22222 user@local‐ host\u0026quot;, if the guest runs the example above. socat PTY,link=/var/run/ppp,rawer INTERFACE:hdlc0 circumvents the problem that pppd requires a serial device and thus might not be able to work on a synchronous line that is represented by a network device. socat creates a PTY to make pppd happy, binds to the network interface hdlc0, and can transfer data between both devices. Use pppd on device /var/run/ppp then. socat -T 1 -d -d TCP-L:10081,reuseaddr,fork,crlf SYSTEM:\u0026quot;echo -e \\\u0026quot;\\\\\\\u0026quot;HTTP/1.0 200 OK\\\\\\nDocumentType: text/plain\\\\\\n\\\\\\ndate: \\$\\(date\\)\\\\\\nserver:\\$SOCAT_SOCKADDR:\\$SOCAT_SOCK‐ PORT\\\\\\nclient: \\$SOCAT_PEERADDR:\\$SOCAT_PEERPORT\\\\\\n\\\\\\\u0026quot;\\\u0026quot;; cat; echo -e \\\u0026quot;\\\\\\\u0026quot;\\\\\\n\\\\\\\u0026quot;\\\u0026quot;\u0026quot; creates a simple HTTP echo server: each HTTP client that connects gets a valid HTTP reply that contains information about the client address and port as it is seen by the server host, the host address (which might vary on multihomed servers), and the original client request. socat -d -d UDP4-RECVFROM:9999,so-broadcast,so-timestamp,ip-pktinfo,ip-recverr,ip-recvopts,ip-recvtos,ip-recvttl!!- SYSTEM:’export; sleep 1’ |grep SOCAT waits for an incoming UDP packet on port 9999 and prints the environment variables provided by socat. On BSD based systems you have to replace ip-pktinfo with ip-recvdstaddr,ip-recvif. Especially interesting is SOCAT_IP_DSTADDR: it contains the target address of the packet which may be a unicast, multicast, or broadcast address. echo -e \u0026quot;M-SEARCH * HTTP/1.1\\nHOST: 239.255.255.250:1900\\nMAN: \\\u0026quot;ssdp:discover\\\u0026quot;\\nMX: 4\\nST: \\\u0026quot;ssdp:all\\\u0026quot;\\n\u0026quot; |./socat - UDP-DATAGRAM:239.255.255.250:1900,crlf sends an SSDP (Simple Service Discovery Protocol) query to the local network and collects and outputs the answers received. DIAGNOSTICS Socat uses a logging mechanism that allows filtering messages by severity. The severities provided are more or less compatible to the appropriate syslog priority. With one or up to four occur‐ rences of the -d command line option, the lowest priority of messages that are issued can be selected. Each message contains a single uppercase character specifying the messages severity (one of F, E, W, N, I, or D) FATAL: Conditions that require unconditional and immediate program termination. ERROR: Conditions that prevent proper program processing. Usually the program is terminated (see option -s). WARNING: Something did not function correctly or is in a state where correct further processing cannot be guaranteed, but might be possible. NOTICE: Interesting actions of the program, e.g. for supervising socat in some kind of server mode. INFO: Description of what the program does, and maybe why it happens. Allows monitoring the lifecycles of file descriptors. DEBUG: Description of how the program works, all system or library calls and their results. Log messages can be written to stderr, to a file, or to syslog. On exit, socat gives status 0 if it terminated due to EOF or inactivity timeout, with a positive value on error, and with a negative value on fatal error. FILES /usr/bin/socat /usr/bin/filan /usr/bin/procan ENVIRONMENT VARIABLES Input variables carry information from the environment to socat, output variables are set by socat for use in executed scripts and programs. In the output variables beginning with \u0026quot;SOCAT\u0026quot; this prefix is actually replaced by the upper case name of the executable or the value of option -lp. SOCAT_DEFAULT_LISTEN_IP (input) (Values 4 or 6) Sets the IP version to be used for listen, recv, and recvfrom addresses if no pf (protocol-family) option is given. Is overridden by socat options -4 or -6. SOCAT_PREFERRED_RESOLVE_IP (input) (Values 0, 4, or 6) Sets the IP version to be used when resolving target host names when version is not specified by address type, option pf (protocol-family), or address format. If name resolution does not return a matching entry, the first result (with differing IP version) is taken. With value 0, socat always selects the first record and its IP version. SOCAT_FORK_WAIT (input) Specifies the time (seconds) to sleep the parent and child processes after successful fork(). Useful for debugging. SOCAT_VERSION (output) Socat sets this variable to its version string, e.g. \u0026quot;1.7.0.0\u0026quot; for released versions or e.g. \u0026quot;1.6.0.1+envvar\u0026quot; for temporary versions; can be used in scripts invoked by socat. SOCAT_PID (output) Socat sets this variable to its process id. In case of fork address option, SOCAT_PID gets the child processes id. Forking for exec and system does not change SOCAT_PID. SOCAT_PPID (output) Socat sets this variable to its process id. In case of fork, SOCAT_PPID keeps the pid of the master process. SOCAT_PEERADDR (output) With passive socket addresses (all LISTEN and RECVFROM addresses), this variable is set to a string describing the peers socket address. Port information is not included. SOCAT_PEERPORT (output) With appropriate passive socket addresses (TCP, UDP, and SCTP - LISTEN and RECVFROM), this variable is set to a string containing the number of the peer port. SOCAT_SOCKADDR (output) With all LISTEN addresses, this variable is set to a string describing the local socket address. Port information is not included example SOCAT_SOCKPORT (output) With TCP-LISTEN, UDP-LISTEN, and SCTP-LISTEN addresses, this variable is set to the local port. SOCAT_TIMESTAMP (output) With all RECVFROM addresses where address option so-timestamp is applied, socat sets this variable to the resulting timestamp. SOCAT_IP_OPTIONS (output) With all IPv4 based RECVFROM addresses where address option ip-recvopts is applied, socat fills this variable with the IP options of the received packet. SOCAT_IP_DSTADDR (output) With all IPv4 based RECVFROM addresses where address option ip-recvdstaddr (BSD) or ip-pktinfo (other platforms) is applied, socat sets this variable to the destination address of the received packet. This is particularly useful to identify broadcast and multicast addressed packets. SOCAT_IP_IF (output) With all IPv4 based RECVFROM addresses where address option ip-recvif (BSD) or ip-pktinfo (other platforms) is applied, socat sets this variable to the name of the interface where the packet was received. SOCAT_IP_LOCADDR (output) With all IPv4 based RECVFROM addresses where address option ip-pktinfo is applied, socat sets this variable to the address of the interface where the packet was received. SOCAT_IP_TOS (output) With all IPv4 based RECVFROM addresses where address option ip-recvtos is applied, socat sets this variable to the TOS (type of service) of the received packet. SOCAT_IP_TTL (output) With all IPv4 based RECVFROM addresses where address option ip-recvttl is applied, socat sets this variable to the TTL (time to live) of the received packet. SOCAT_IPV6_HOPLIMIT (output) With all IPv6 based RECVFROM addresses where address option ipv6-recvhoplimit is applied, socat sets this variable to the hoplimit value of the received packet. SOCAT_IPV6_DSTADDR (output) With all IPv6 based RECVFROM addresses where address option ipv6-recvpktinfo is applied, socat sets this variable to the destination address of the received packet. SOCAT_IPV6_TCLASS (output) With all IPv6 based RECVFROM addresses where address option ipv6-recvtclass is applied, socat sets this variable to the transfer class of the received packet. SOCAT_OPENSSL_X509_ISSUER (output) Issuer field from peer certificate SOCAT_OPENSSL_X509_SUBJECT (output) Subject field from peer certificate SOCAT_OPENSSL_X509_COMMONNAME (output) commonName entries from peer certificates subject. Multiple values are separated by \u0026quot; // \u0026quot;. SOCAT_OPENSSL_X509_* (output) all other entries from peer certificates subject SOCAT_OPENSSL_X509V3_DNS (output) DNS entries from peer certificates extensions - subjectAltName field. Multiple values are separated by \u0026quot; // \u0026quot;. HOSTNAME (input) Is used to determine the hostname for logging (see -lh). LOGNAME (input) Is used as name for the socks client user name if no socksuser is given. With options su and su-d, LOGNAME is set to the given user name. USER (input) Is used as name for the socks client user name if no socksuser is given and LOGNAME is empty. With options su and su-d, USER is set to the given user name. SHELL (output) With options su and su-d, SHELL is set to the login shell of the given user. PATH (output) Can be set with option path for exec and system addresses. HOME (output) With options su and su-d, HOME is set to the home directory of the given user. CREDITS The work of the following groups and organizations was invaluable for this project: The FSF (GNU, http://www.fsf.org/) project with their free and portable development software and lots of other useful tools and libraries. The Linux developers community (http://www.linux.org/) for providing a free, open source operating system. The Open Group (http://www.unix-systems.org/) for making their standard specifications available on the Internet for free. VERSION This help describes version 1.7.4 of socat. BUGS Addresses cannot be nested, so a single socat process cannot, e.g., drive ssl over socks. Address option ftruncate without value uses default 1 instead of 0. Verbose modes (-x and/or -v) display line termination characters inconsistently when address options cr or crnl are used: They show the data after conversion in either direction. The data transfer blocksize setting (-b) is ignored with address readline. Send bug reports to \u0026lt;socat@dest-unreach.org\u0026gt; SEE ALSO nc(1), rinetd(8), openssl(1), stunnel(8), rlwrap(1), setsid(1) Socat home page http://www.dest-unreach.org/socat/ AUTHOR Gerhard Rieger \u0026lt;rieger@dest-unreach.org\u0026gt; and contributors socat(1) ```bash "}),e.add({id:99,href:"/docs/tools/attack/bettercap/",title:"Bettercap",description:`Description # Bettercap is a complete, modular, portable and easily extensible MITM framework with every kind of diagnostic and offensive feature you could need in order to perform a man in the middle attack.
install # brew install bettercap ==\u0026gt; Caveats bettercap requires root privileges so you will need to run sudo bettercap. You should be certain that you trust any software you grant root privileges.
sample usage # bettercap -h help # Usage of bettercap: -autostart string Comma separated list of modules to auto start.`,content:"Description # Bettercap is a complete, modular, portable and easily extensible MITM framework with every kind of diagnostic and offensive feature you could need in order to perform a man in the middle attack.\ninstall # brew install bettercap ==\u0026gt; Caveats bettercap requires root privileges so you will need to run sudo bettercap. You should be certain that you trust any software you grant root privileges.\nsample usage # bettercap -h help # Usage of bettercap: -autostart string Comma separated list of modules to auto start. (default \u0026quot;events.stream\u0026quot;) -caplet string Read commands from this file and execute them in the interactive session. -caplets-path string Specify an alternative base path for caplets. -cpu-profile file Write cpu profile file. -debug Print debug messages. -env-file string Load environment variables from this file if found, set to empty to disable environment persistence. -eval string Run one or more commands separated by ; in the interactive session, used to set variables via command line. -gateway-override string Use the provided IP address instead of the default gateway. If not specified or invalid, the default gateway will be used. -iface string Network interface to bind to, if empty the default interface will be auto selected. -mem-profile file Write memory profile to file. -no-colors Disable output color effects. -no-history Disable interactive session history file. -pcap-buf-size int PCAP buffer size, leave to 0 for the default value. (default -1) -script string Load a session script. -silent Suppress all logs which are not errors. -version Print the version and exit. ```bash "}),e.add({id:100,href:"/docs/tools/bing-search/",title:"Bing Search",description:"Search queries in terminal using Bing search engine.",content:`and explore 🌍
Using bing-search you can find information that you want. Although limited to displaying only headers, just like on the graphical interface during initial look up, it might help you tackle your problems better.
Combined with w3m - terminal web browser you can practically not miss the needle in a haystack, and equiped with proper knowledge of search queries syntax, you can achieve magic ✨!
Basics # Simple usage can\u0026rsquo;t be simpler:
bing-search \u0026quot;Where is Poland?\u0026quot; Combine with w3m # then you can copy the address of the website and use it with w3m
w3m https://some.text.only.website Refine your search to look for .txt files # To refine your search and look for only .txt files in your search you can use this syntax:
bing-search \u0026quot;how to cook pancakes filetype:txt\u0026quot; More results # Te get more results printed from your search type this:
bing-search \u0026quot;katy perry\u0026quot; 100 Exclude words # If you would like to search for Katy Perry but without Orlando Bloom you will type\u0026hellip; something with -
bing-search \u0026quot;Katy Perry -Orlando-Bloom\u0026quot; Only on one site # To look for searches only on one site you would write it like that
bing-search \u0026quot;site:rollingstone.com Katy Perry\u0026quot; To look for answers in one language\u0026hellip; # \u0026hellip;You would type
bing-search \u0026quot;language:ro Katy Perry\u0026quot; If you want specific dates # Then you want to include this in your search
bing-search \u0026quot;y2k date:1999-01-01..2001-12-31\u0026quot; Location # Search for a specific location: Use location: operator to search for pages related to a specific location, for example:
bing-search \u0026quot;pancakes recipe location:Paris\u0026quot; Word in title of webpage # To search for specific words in the title, use intitle: operator to search for pages that have a specific word in the title, for example:
bing-search \u0026quot;intitle:pancakes recipe\u0026quot; In URL # Search for specific words in the URL, use inurl: operator to search for pages that have a specific word in the URL, for example:
bing-search \u0026quot;inurl:pancakes recipe\u0026quot; Search for a specific link # Use link: operator to search for pages that link to a specific URL, for example:
bing-search \u0026quot;link:https://example.com/pancakes-recipe\u0026quot; Search for synonyms # Use ~ operator to search for pages that contain synonyms of a specific word, for example:
bing-search \u0026quot;~pancakes recipe\u0026quot; Search for a specific phrase: # Use \u0026quot; operator to search for pages that contain a specific phrase, for example:
bing-search \u0026quot;\\\u0026quot;Katy Perry Part of Me lyrics\\\u0026quot;\u0026quot; Here, you have to escape the inner \u0026quot; with \\ backslash like that \\\u0026quot; somthing \\\u0026quot;
Search for a specific word # Use + operator to search for pages that contain a specific word, for example:
bing-search \u0026quot;+pancakes +recipe\u0026quot; Search for images # Use --image switch to search for images, for example:
bing-search --image \u0026quot;pancakes recipe\u0026quot; Currently supported on Linux and macOS. Also works in Nutek Terminal container.
`}),e.add({id:101,href:"/docs/",title:"Docs",description:"Docs Nutek Terminal.",content:""}),search.addEventListener("input",t,!0);function t(){const s=5;var n=this.value,o=e.search(n,{limit:s,enrich:!0});const t=new Map;for(const e of o.flatMap(e=>e.result)){if(t.has(e.doc.href))continue;t.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),t.size===0&&n){const e=document.createElement("div");e.innerHTML=`No results for "<strong>${n}</strong>"`,e.classList.add("suggestion__no-results"),suggestions.appendChild(e);return}for(const[r,a]of t){const n=document.createElement("div");suggestions.appendChild(n);const e=document.createElement("a");e.href=r,n.appendChild(e);const o=document.createElement("span");o.textContent=a.title,o.classList.add("suggestion__title"),e.appendChild(o);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(n),suggestions.childElementCount==s)break}}})()